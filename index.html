<!DOCTYPE html>
<html>
<head>
<title>Paper collected by Wang</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">


/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

span#pid {
  color:red;
  
}
span#filename{
  font-style: oblique;
}

span#title{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: italic;
  font-size: 20px;
  border:1px solid #B50;
}
span#abs{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: oblique;
  font-size: 18px;
}
</style>
</head>
<body>

</p></br></br><div id='section'>Paperid: <span id='pid'>1, <a href='https://arxiv.org/pdf/2509.08707.pdf' target='_blank'>https://arxiv.org/pdf/2509.08707.pdf</a></span>   <span><a href='https://github.com/prescient-design/igloo' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ada Fang, Robert G. Alberstein, Simon Kelow, Frédéric A. Dreyer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08707">Tokenizing Loops of Antibodies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The complementarity-determining regions of antibodies are loop structures that are key to their interactions with antigens, and of high importance to the design of novel biologics. Since the 1980s, categorizing the diversity of CDR structures into canonical clusters has enabled the identification of key structural motifs of antibodies. However, existing approaches have limited coverage and cannot be readily incorporated into protein foundation models. Here we introduce ImmunoGlobulin LOOp Tokenizer, Igloo, a multimodal antibody loop tokenizer that encodes backbone dihedral angles and sequence. Igloo is trained using a contrastive learning objective to map loops with similar backbone dihedral angles closer together in latent space. Igloo can efficiently retrieve the closest matching loop structures from a structural antibody database, outperforming existing methods on identifying similar H3 loops by 5.9\%. Igloo assigns tokens to all loops, addressing the limited coverage issue of canonical clusters, while retaining the ability to recover canonical loop conformations. To demonstrate the versatility of Igloo tokens, we show that they can be incorporated into protein language models with IglooLM and IglooALM. On predicting binding affinity of heavy chain variants, IglooLM outperforms the base protein language model on 8 out of 10 antibody-antigen targets. Additionally, it is on par with existing state-of-the-art sequence-based and multimodal protein language models, performing comparably to models with $7\times$ more parameters. IglooALM samples antibody loops which are diverse in sequence and more consistent in structure than state-of-the-art antibody inverse folding models. Igloo demonstrates the benefit of introducing multimodal tokens for antibody loops for encoding the diverse landscape of antibody loops, improving protein foundation models, and for antibody CDR design.
<div id='section'>Paperid: <span id='pid'>2, <a href='https://arxiv.org/pdf/2509.05757.pdf' target='_blank'>https://arxiv.org/pdf/2509.05757.pdf</a></span>   <span><a href='https://github.com/sarangp2402/Hyperbolic-LLM-Models/tree/main' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarang Patil, Zeyong Zhang, Yiran Huang, Tengfei Ma, Mengjia Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05757">Hyperbolic Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have achieved remarkable success and demonstrated superior performance across various tasks, including natural language processing (NLP), weather forecasting, biological protein folding, text generation, and solving mathematical problems. However, many real-world data exhibit highly non-Euclidean latent hierarchical anatomy, such as protein networks, transportation networks, financial networks, brain networks, and linguistic structures or syntactic trees in natural languages. Effectively learning intrinsic semantic entailment and hierarchical relationships from these raw, unstructured input data using LLMs remains an underexplored area. Due to its effectiveness in modeling tree-like hierarchical structures, hyperbolic geometry -- a non-Euclidean space -- has rapidly gained popularity as an expressive latent representation space for complex data modeling across domains such as graphs, images, languages, and multi-modal data. Here, we provide a comprehensive and contextual exposition of recent advancements in LLMs that leverage hyperbolic geometry as a representation space to enhance semantic representation learning and multi-scale reasoning. Specifically, the paper presents a taxonomy of the principal techniques of Hyperbolic LLMs (HypLLMs) in terms of four main categories: (1) hyperbolic LLMs through exp/log maps; (2) hyperbolic fine-tuned models; (3) fully hyperbolic LLMs, and (4) hyperbolic state-space models. We also explore crucial potential applications and outline future research directions. A repository of key papers, models, datasets, and code implementations is available at https://github.com/sarangp2402/Hyperbolic-LLM-Models/tree/main.
<div id='section'>Paperid: <span id='pid'>3, <a href='https://arxiv.org/pdf/2509.03487.pdf' target='_blank'>https://arxiv.org/pdf/2509.03487.pdf</a></span>   <span><a href='https://github.com/jigang-fan/SafeProtein' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jigang Fan, Zhenghong Zhou, Ruofan Jin, Le Cong, Mengdi Wang, Zaixi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03487">SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins play crucial roles in almost all biological processes. The advancement of deep learning has greatly accelerated the development of protein foundation models, leading to significant successes in protein understanding and design. However, the lack of systematic red-teaming for these models has raised serious concerns about their potential misuse, such as generating proteins with biological safety risks. This paper introduces SafeProtein, the first red-teaming framework designed for protein foundation models to the best of our knowledge. SafeProtein combines multimodal prompt engineering and heuristic beam search to systematically design red-teaming methods and conduct tests on protein foundation models. We also curated SafeProtein-Bench, which includes a manually constructed red-teaming benchmark dataset and a comprehensive evaluation protocol. SafeProtein achieved continuous jailbreaks on state-of-the-art protein foundation models (up to 70% attack success rate for ESM3), revealing potential biological safety risks in current protein foundation models and providing insights for the development of robust security protection technologies for frontier models. The codes will be made publicly available at https://github.com/jigang-fan/SafeProtein.
<div id='section'>Paperid: <span id='pid'>4, <a href='https://arxiv.org/pdf/2508.18211.pdf' target='_blank'>https://arxiv.org/pdf/2508.18211.pdf</a></span>   <span><a href='https://github.com/graeter-group/flips' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Vsevolod Viliuga, Leif Seute, Nicolas Wolf, Simon Wagner, Arne Elofsson, Jan StÃ¼hmer, Frauke GrÃ¤ter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18211">Flexibility-Conditioned Protein Structure Design with Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in geometric deep learning and generative modeling have enabled the design of novel proteins with a wide range of desired properties. However, current state-of-the-art approaches are typically restricted to generating proteins with only static target properties, such as motifs and symmetries. In this work, we take a step towards overcoming this limitation by proposing a framework to condition structure generation on flexibility, which is crucial for key functionalities such as catalysis or molecular recognition. We first introduce BackFlip, an equivariant neural network for predicting per-residue flexibility from an input backbone structure. Relying on BackFlip, we propose FliPS, an SE(3)-equivariant conditional flow matching model that solves the inverse problem, that is, generating backbones that display a target flexibility profile. In our experiments, we show that FliPS is able to generate novel and diverse protein backbones with the desired flexibility, verified by Molecular Dynamics (MD) simulations. FliPS and BackFlip are available at https://github.com/graeter-group/flips .
<div id='section'>Paperid: <span id='pid'>5, <a href='https://arxiv.org/pdf/2508.17389.pdf' target='_blank'>https://arxiv.org/pdf/2508.17389.pdf</a></span>   <span><a href='https://github.com/Bokai-Zhao/NPF' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bokai Zhao, Weiyang Shi, Hanqing Chao, Zijiang Yang, Yiyang Zhang, Ming Song, Tianzi Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17389">Neural Proteomics Fields for Super-resolved Spatial Proteomics Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spatial proteomics maps protein distributions in tissues, providing transformative insights for life sciences. However, current sequencing-based technologies suffer from low spatial resolution, and substantial inter-tissue variability in protein expression further compromises the performance of existing molecular data prediction methods. In this work, we introduce the novel task of spatial super-resolution for sequencing-based spatial proteomics (seq-SP) and, to the best of our knowledge, propose the first deep learning model for this task--Neural Proteomics Fields (NPF). NPF formulates seq-SP as a protein reconstruction problem in continuous space by training a dedicated network for each tissue. The model comprises a Spatial Modeling Module, which learns tissue-specific protein spatial distributions, and a Morphology Modeling Module, which extracts tissue-specific morphological features. Furthermore, to facilitate rigorous evaluation, we establish an open-source benchmark dataset, Pseudo-Visium SP, for this task. Experimental results demonstrate that NPF achieves state-of-the-art performance with fewer learnable parameters, underscoring its potential for advancing spatial proteomics research. Our code and dataset are publicly available at https://github.com/Bokai-Zhao/NPF.
<div id='section'>Paperid: <span id='pid'>6, <a href='https://arxiv.org/pdf/2508.17345.pdf' target='_blank'>https://arxiv.org/pdf/2508.17345.pdf</a></span>   <span><a href='https://github.com/GenSI-THUAIR/SLM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxuan Song, Zhe Zhang, Yu Pei, Jingjing Gong, Qiying Yu, Zheng Zhang, Mingxuan Wang, Hao Zhou, Jingjing Liu, Wei-Ying Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17345">ShortListing Model: A Streamlined SimplexDiffusion for Discrete Variable Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative modeling of discrete variables is challenging yet crucial for applications in natural language processing and biological sequence design. We introduce the Shortlisting Model (SLM), a novel simplex-based diffusion model inspired by progressive candidate pruning. SLM operates on simplex centroids, reducing generation complexity and enhancing scalability. Additionally, SLM incorporates a flexible implementation of classifier-free guidance, enhancing unconditional generation performance. Extensive experiments on DNA promoter and enhancer design, protein design, character-level and large-vocabulary language modeling demonstrate the competitive performance and strong potential of SLM. Our code can be found at https://github.com/GenSI-THUAIR/SLM
<div id='section'>Paperid: <span id='pid'>7, <a href='https://arxiv.org/pdf/2508.06021.pdf' target='_blank'>https://arxiv.org/pdf/2508.06021.pdf</a></span>   <span><a href='https://github.com/utkuozbulak/svp-generative-ai' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Utku Ozbulak, Michaela Cohrs, Hristo L. Svilenov, Joris Vankerschaver, Wesley De Neve
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06021">Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sub-visible particle analysis using flow imaging microscopy combined with deep learning has proven effective in identifying particle types, enabling the distinction of harmless components such as silicone oil from protein particles. However, the scarcity of available data and severe imbalance between particle types within datasets remain substantial hurdles when applying multi-class classifiers to such problems, often forcing researchers to rely on less effective methods. The aforementioned issue is particularly challenging for particle types that appear unintentionally and in lower numbers, such as silicone oil and air bubbles, as opposed to protein particles, where obtaining large numbers of images through controlled settings is comparatively straightforward. In this work, we develop a state-of-the-art diffusion model to address data imbalance by generating high-fidelity images that can augment training datasets, enabling the effective training of multi-class deep neural networks. We validate this approach by demonstrating that the generated samples closely resemble real particle images in terms of visual quality and structure. To assess the effectiveness of using diffusion-generated images in training datasets, we conduct large-scale experiments on a validation dataset comprising 500,000 protein particle images and demonstrate that this approach improves classification performance with no negligible downside. Finally, to promote open research and reproducibility, we publicly release both our diffusion models and the trained multi-class deep neural network classifiers, along with a straightforward interface for easy integration into future studies, at https://github.com/utkuozbulak/svp-generative-ai.
<div id='section'>Paperid: <span id='pid'>8, <a href='https://arxiv.org/pdf/2507.21260.pdf' target='_blank'>https://arxiv.org/pdf/2507.21260.pdf</a></span>   <span><a href='https://github.com/amartya21/Adam-PnP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Amartya Banerjee, Xingyu Xu, Caroline MoosmÃ¼ller, Harlin Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21260">Adaptive Multimodal Protein Plug-and-Play with Diffusion-Based Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In an inverse problem, the goal is to recover an unknown parameter (e.g., an image) that has typically undergone some lossy or noisy transformation during measurement. Recently, deep generative models, particularly diffusion models, have emerged as powerful priors for protein structure generation. However, integrating noisy experimental data from multiple sources to guide these models remains a significant challenge. Existing methods often require precise knowledge of experimental noise levels and manually tuned weights for each data modality. In this work, we introduce Adam-PnP, a Plug-and-Play framework that guides a pre-trained protein diffusion model using gradients from multiple, heterogeneous experimental sources. Our framework features an adaptive noise estimation scheme and a dynamic modality weighting mechanism integrated into the diffusion process, which reduce the need for manual hyperparameter tuning. Experiments on complex reconstruction tasks demonstrate significantly improved accuracy using Adam-PnP.
<div id='section'>Paperid: <span id='pid'>9, <a href='https://arxiv.org/pdf/2507.20925.pdf' target='_blank'>https://arxiv.org/pdf/2507.20925.pdf</a></span>   <span><a href='https://github.com/Hoch-Zhang/PSRP-CPI' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongzhi Zhang, Zhonglie Liu, Kun Meng, Jiameng Chen, Jia Wu, Bo Du, Di Lin, Yan Che, Wenbin Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.20925">Zero-Shot Learning with Subsequence Reordering Pretraining for Compound-Protein Interaction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the vastness of chemical space and the ongoing emergence of previously uncharacterized proteins, zero-shot compound-protein interaction (CPI) prediction better reflects the practical challenges and requirements of real-world drug development. Although existing methods perform adequately during certain CPI tasks, they still face the following challenges: (1) Representation learning from local or complete protein sequences often overlooks the complex interdependencies between subsequences, which are essential for predicting spatial structures and binding properties. (2) Dependence on large-scale or scarce multimodal protein datasets demands significant training data and computational resources, limiting scalability and efficiency. To address these challenges, we propose a novel approach that pretrains protein representations for CPI prediction tasks using subsequence reordering, explicitly capturing the dependencies between protein subsequences. Furthermore, we apply length-variable protein augmentation to ensure excellent pretraining performance on small training datasets. To evaluate the model's effectiveness and zero-shot learning ability, we combine it with various baseline methods. The results demonstrate that our approach can improve the baseline model's performance on the CPI task, especially in the challenging zero-shot scenario. Compared to existing pre-training models, our model demonstrates superior performance, particularly in data-scarce scenarios where training samples are limited. Our implementation is available at https://github.com/Hoch-Zhang/PSRP-CPI.
<div id='section'>Paperid: <span id='pid'>10, <a href='https://arxiv.org/pdf/2507.20243.pdf' target='_blank'>https://arxiv.org/pdf/2507.20243.pdf</a></span>   <span><a href='https://github.com/BruthYU/protein-se3' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lang Yu, Zhangyang Gao, Cheng Tan, Qin Chen, Jie Zhou, Liang He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.20243">Protein-SE(3): Benchmarking SE(3)-based Generative Models for Protein Structure Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>SE(3)-based generative models have shown great promise in protein geometry modeling and effective structure design. However, the field currently lacks a modularized benchmark to enable comprehensive investigation and fair comparison of different methods. In this paper, we propose Protein-SE(3), a new benchmark based on a unified training framework, which comprises protein scaffolding tasks, integrated generative models, high-level mathematical abstraction, and diverse evaluation metrics. Recent advanced generative models designed for protein scaffolding, from multiple perspectives like DDPM (Genie1 and Genie2), Score Matching (FrameDiff and RfDiffusion) and Flow Matching (FoldFlow and FrameFlow) are integrated into our framework. All integrated methods are fairly investigated with the same training dataset and evaluation metrics. Furthermore, we provide a high-level abstraction of the mathematical foundations behind the generative models, enabling fast prototyping of future algorithms without reliance on explicit protein structures. Accordingly, we release the first comprehensive benchmark built upon unified training framework for SE(3)-based protein structure design, which is publicly accessible at https://github.com/BruthYU/protein-se3.
<div id='section'>Paperid: <span id='pid'>11, <a href='https://arxiv.org/pdf/2507.19523.pdf' target='_blank'>https://arxiv.org/pdf/2507.19523.pdf</a></span>   <span><a href='https://github.com/divelab/AIRS/blob/main/OpenBio/ATGC_Gen' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyu Su, Xiner Li, Yuchao Lin, Ziqian Xie, Degui Zhi, Shuiwang Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19523">Language Models for Controllable DNA Sequence Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider controllable DNA sequence design, where sequences are generated by conditioning on specific biological properties. While language models (LMs) such as GPT and BERT have achieved remarkable success in natural language generation, their application to DNA sequence generation remains largely underexplored. In this work, we introduce ATGC-Gen, an Automated Transformer Generator for Controllable Generation, which leverages cross-modal encoding to integrate diverse biological signals. ATGC-Gen is instantiated with both decoder-only and encoder-only transformer architectures, allowing flexible training and generation under either autoregressive or masked recovery objectives. We evaluate ATGC-Gen on representative tasks including promoter and enhancer sequence design, and further introduce a new dataset based on ChIP-Seq experiments for modeling protein binding specificity. Our experiments demonstrate that ATGC-Gen can generate fluent, diverse, and biologically relevant sequences aligned with the desired properties. Compared to prior methods, our model achieves notable improvements in controllability and functional relevance, highlighting the potential of language models in advancing programmable genomic design. The source code is released at (https://github.com/divelab/AIRS/blob/main/OpenBio/ATGC_Gen).
<div id='section'>Paperid: <span id='pid'>12, <a href='https://arxiv.org/pdf/2507.17731.pdf' target='_blank'>https://arxiv.org/pdf/2507.17731.pdf</a></span>   <span><a href='https://github.com/Violet24K/Awesome-Flow-Matching-Meets-Biology' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihao Li, Zhichen Zeng, Xiao Lin, Feihao Fang, Yanru Qu, Zhe Xu, Zhining Liu, Xuying Ning, Tianxin Wei, Ge Liu, Hanghang Tong, Jingrui He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.17731">Flow Matching Meets Biology and Life Science: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over the past decade, advances in generative modeling, such as generative adversarial networks, masked autoencoders, and diffusion models, have significantly transformed biological research and discovery, enabling breakthroughs in molecule design, protein generation, drug discovery, and beyond. At the same time, biological applications have served as valuable testbeds for evaluating the capabilities of generative models. Recently, flow matching has emerged as a powerful and efficient alternative to diffusion-based generative modeling, with growing interest in its application to problems in biology and life sciences. This paper presents the first comprehensive survey of recent developments in flow matching and its applications in biological domains. We begin by systematically reviewing the foundations and variants of flow matching, and then categorize its applications into three major areas: biological sequence modeling, molecule generation and design, and peptide and protein generation. For each, we provide an in-depth review of recent progress. We also summarize commonly used datasets and software tools, and conclude with a discussion of potential future directions. The corresponding curated resources are available at https://github.com/Violet24K/Awesome-Flow-Matching-Meets-Biology.
<div id='section'>Paperid: <span id='pid'>13, <a href='https://arxiv.org/pdf/2507.14156.pdf' target='_blank'>https://arxiv.org/pdf/2507.14156.pdf</a></span>   <span><a href='https://github.com/ykiiiiii/ADFLIP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai Yi, Kiarash Jamali, Sjors H. W. Scheres
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14156">All-atom inverse protein folding through discrete flow matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent breakthrough of AlphaFold3 in modeling complex biomolecular interactions, including those between proteins and ligands, nucleotides, or metal ions, creates new opportunities for protein design. In so-called inverse protein folding, the objective is to find a sequence of amino acids that adopts a target protein structure. Many inverse folding methods struggle to predict sequences for complexes that contain non-protein components, and perform poorly with complexes that adopt multiple structural states. To address these challenges, we present ADFLIP (All-atom Discrete FLow matching Inverse Protein folding), a generative model based on discrete flow-matching for designing protein sequences conditioned on all-atom structural contexts. ADFLIP progressively incorporates predicted amino acid side chains as structural context during sequence generation and enables the design of dynamic protein complexes through ensemble sampling across multiple structural states. Furthermore, ADFLIP implements training-free classifier guidance sampling, which allows the incorporation of arbitrary pre-trained models to optimise the designed sequence for desired protein properties. We evaluated the performance of ADFLIP on protein complexes with small-molecule ligands, nucleotides, or metal ions, including dynamic complexes for which structure ensembles were determined by nuclear magnetic resonance (NMR). Our model achieves state-of-the-art performance in single-structure and multi-structure inverse folding tasks, demonstrating excellent potential for all-atom protein design. The code is available at https://github.com/ykiiiiii/ADFLIP.
<div id='section'>Paperid: <span id='pid'>14, <a href='https://arxiv.org/pdf/2507.10136.pdf' target='_blank'>https://arxiv.org/pdf/2507.10136.pdf</a></span>   <span><a href='https://github.com/Liu-Zhonglin/pbn-melanoma-project' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhonglin Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10136">A PBN-RL-XAI Framework for Discovering a "Hit-and-Run" Therapeutic Strategy in Melanoma</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Innate resistance to anti-PD-1 immunotherapy remains a major clinical challenge in metastatic melanoma, with the underlying molecular networks being poorly understood. To address this, we constructed a dynamic Probabilistic Boolean Network model using transcriptomic data from patient tumor biopsies to elucidate the regulatory logic governing therapy response. We then employed a reinforcement learning agent to systematically discover optimal, multi-step therapeutic interventions and used explainable artificial intelligence to mechanistically interpret the agent's control policy. The analysis revealed that a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2 protein (LOXL2) was the most effective strategy. Our explainable analysis showed that this ''hit-and-run" intervention is sufficient to erase the molecular signature driving resistance, allowing the network to self-correct without requiring sustained intervention. This study presents a novel, time-dependent therapeutic hypothesis for overcoming immunotherapy resistance and provides a powerful computational framework for identifying non-obvious intervention protocols in complex biological systems.
<div id='section'>Paperid: <span id='pid'>15, <a href='https://arxiv.org/pdf/2507.09054.pdf' target='_blank'>https://arxiv.org/pdf/2507.09054.pdf</a></span>   <span><a href='https://github.com/prescient-design/ibex,' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>FrÃ©dÃ©ric A. Dreyer, Jan Ludwiczak, Karolis Martinkus, Brennan Abanades, Robert G. Alberstein, Pan Kessel, Pranav Rao, Jae Hyeon Lee, Richard Bonneau, Andrew M. Watkins, Franziska Seeger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09054">Conformation-Aware Structure Prediction of Antigen-Recognizing Immune Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Ibex, a pan-immunoglobulin structure prediction model that achieves state-of-the-art accuracy in modeling the variable domains of antibodies, nanobodies, and T-cell receptors. Unlike previous approaches, Ibex explicitly distinguishes between bound and unbound protein conformations by training on labeled apo and holo structural pairs, enabling accurate prediction of both states at inference time. Using a comprehensive private dataset of high-resolution antibody structures, we demonstrate superior out-of-distribution performance compared to existing specialized and general protein structure prediction tools. Ibex combines the accuracy of cutting-edge models with significantly reduced computational requirements, providing a robust foundation for accelerating large molecule design and therapeutic development.
<div id='section'>Paperid: <span id='pid'>16, <a href='https://arxiv.org/pdf/2507.08980.pdf' target='_blank'>https://arxiv.org/pdf/2507.08980.pdf</a></span>   <span><a href='https://github.com/ChenyuWang-Monica/REED' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenyu Wang, Cai Zhou, Sharut Gupta, Zongyu Lin, Stefanie Jegelka, Stephen Bates, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08980">Learning Diffusion Models with Flexible Representation Guidance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models can be improved with additional guidance towards more effective representations of input. Indeed, prior empirical work has already shown that aligning internal representations of the diffusion model with those of pre-trained models improves generation quality. In this paper, we present a systematic framework for incorporating representation guidance into diffusion models. We provide alternative decompositions of denoising models along with their associated training criteria, where the decompositions determine when and how the auxiliary representations are incorporated. Guided by our theoretical insights, we introduce two new strategies for enhancing representation alignment in diffusion models. First, we pair examples with target representations either derived from themselves or arisen from different synthetic modalities, and subsequently learn a joint model over the multimodal pairs. Second, we design an optimal training curriculum that balances representation learning and data generation. Our experiments across image, protein sequence, and molecule generation tasks demonstrate superior performance as well as accelerated training. In particular, on the class-conditional ImageNet $256\times 256$ benchmark, our guidance results in $23.3$ times faster training than the original SiT-XL as well as four times speedup over the state-of-the-art method REPA. The code is available at https://github.com/ChenyuWang-Monica/REED.
<div id='section'>Paperid: <span id='pid'>17, <a href='https://arxiv.org/pdf/2507.05503.pdf' target='_blank'>https://arxiv.org/pdf/2507.05503.pdf</a></span>   <span><a href='https://github.com/huang3170/MolForm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jie Huang, Daiheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05503">MolFORM: Multi-modal Flow Matching for Structure-Based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug design (SBDD) seeks to generate molecules that bind effectively to protein targets by leveraging their 3D structural information. While diffusion-based generative models have become the predominant approach for SBDD, alternative non-autoregressive frameworks remain relatively underexplored. In this work, we introduce MolFORM, a novel generative framework that jointly models discrete (atom types) and continuous (3D coordinates) molecular modalities using multi-flow matching. To further enhance generation quality, we incorporate a preference-guided fine-tuning stage based on Direct Preference Optimization (DPO), using Vina score as a reward signal. We propose a multi-modal flow DPO co-modeling strategy that simultaneously aligns discrete and continuous modalities, leading to consistent improvements across multiple evaluation metrics. The code is provided at: https://github.com/huang3170/MolForm.
<div id='section'>Paperid: <span id='pid'>18, <a href='https://arxiv.org/pdf/2507.05502.pdf' target='_blank'>https://arxiv.org/pdf/2507.05502.pdf</a></span>   <span><a href='https://github.com/LDeng0205/StaB-ddG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Arthur Deng, Karsten Householder, Fang Wu, Sebastian Thrun, K. Christopher Garcia, Brian Trippe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05502">Predicting mutational effects on protein binding from folding energy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate estimation of mutational effects on protein-protein binding energies is an open problem with applications in structural biology and therapeutic design. Several deep learning predictors for this task have been proposed, but, presumably due to the scarcity of binding data, these methods underperform computationally expensive estimates based on empirical force fields. In response, we propose a transfer-learning approach that leverages advances in protein sequence modeling and folding stability prediction for this task. The key idea is to parameterize the binding energy as the difference between the folding energy of the protein complex and the sum of the folding energies of its binding partners. We show that using a pre-trained inverse-folding model as a proxy for folding energy provides strong zero-shot performance, and can be fine-tuned with (1) copious folding energy measurements and (2) more limited binding energy measurements. The resulting predictor, StaB-ddG, is the first deep learning predictor to match the accuracy of the state-of-the-art empirical force-field method FoldX, while offering an over 1,000x speed-up.
<div id='section'>Paperid: <span id='pid'>19, <a href='https://arxiv.org/pdf/2507.05101.pdf' target='_blank'>https://arxiv.org/pdf/2507.05101.pdf</a></span>   <span><a href='https://github.com/SophieSarceau/PRING' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinzhe Zheng, Hao Du, Fanding Xu, Jinzhe Li, Zhiyuan Liu, Wenkang Wang, Tao Chen, Wanli Ouyang, Stan Z. Li, Yan Lu, Nanqing Dong, Yang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05101">PRING: Rethinking Protein-Protein Interaction Prediction from Pairs to Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based computational methods have achieved promising results in predicting protein-protein interactions (PPIs). However, existing benchmarks predominantly focus on isolated pairwise evaluations, overlooking a model's capability to reconstruct biologically meaningful PPI networks, which is crucial for biology research. To address this gap, we introduce PRING, the first comprehensive benchmark that evaluates protein-protein interaction prediction from a graph-level perspective. PRING curates a high-quality, multi-species PPI network dataset comprising 21,484 proteins and 186,818 interactions, with well-designed strategies to address both data redundancy and leakage. Building on this golden-standard dataset, we establish two complementary evaluation paradigms: (1) topology-oriented tasks, which assess intra and cross-species PPI network construction, and (2) function-oriented tasks, including protein complex pathway prediction, GO module analysis, and essential protein justification. These evaluations not only reflect the model's capability to understand the network topology but also facilitate protein function annotation, biological module detection, and even disease mechanism analysis. Extensive experiments on four representative model categories, consisting of sequence similarity-based, naive sequence-based, protein language model-based, and structure-based approaches, demonstrate that current PPI models have potential limitations in recovering both structural and functional properties of PPI networks, highlighting the gap in supporting real-world biological applications. We believe PRING provides a reliable platform to guide the development of more effective PPI prediction models for the community. The dataset and source code of PRING are available at https://github.com/SophieSarceau/PRING.
<div id='section'>Paperid: <span id='pid'>20, <a href='https://arxiv.org/pdf/2506.20686.pdf' target='_blank'>https://arxiv.org/pdf/2506.20686.pdf</a></span>   <span><a href='https://github.com/Supercomputing-System-AI-Lab/MegaFold/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hoa La, Ahan Gupta, Alex Morehead, Jianlin Cheng, Minjia Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.20686">MegaFold: System-Level Optimizations for Accelerating Protein Structure Prediction Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structure prediction models such as AlphaFold3 (AF3) push the frontier of biomolecular modeling by incorporating science-informed architectural changes to the transformer architecture. However, these advances come at a steep system cost, introducing: compute- and memory-intensive operators, 2D attention mechanisms, and retrieval-augmented data pipelines, which collectively hinder the scalability of AF3 training. In this work, we present MegaFold, a cross-platform system to accelerate AF3 training. MegaFold tackles key bottlenecks through ahead-of-time caching to eliminate GPU idle time from the retrieval-augmented data pipeline, Triton-based kernels for memory-efficient EvoAttention on heterogeneous devices, and deep fusion for common and critical small operators in AF3. Evaluation on both NVIDIA H200 and AMD MI250 GPUs shows that MegaFold reduces peak memory usage of AF3 training by up to 1.23$\times$ and improves per-iteration training time by up-to 1.73$\times$ and 1.62$\times$ respectively. More importantly, MegaFold enables training on 1.35$\times$ longer sequence lengths compared to PyTorch baselines without running out-of-memory, significantly improving the scalability of modern protein folding models. We open source our code at https://github.com/Supercomputing-System-AI-Lab/MegaFold/.
<div id='section'>Paperid: <span id='pid'>21, <a href='https://arxiv.org/pdf/2506.19482.pdf' target='_blank'>https://arxiv.org/pdf/2506.19482.pdf</a></span>   <span><a href='https://github.com/GLAD-RUC/DistEGNN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuelin Zhang, Jiacheng Cen, Jiaqi Han, Wenbing Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19482">Fast and Distributed Equivariant Graph Neural Networks by Virtual Node Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Equivariant Graph Neural Networks (GNNs) have achieved remarkable success across diverse scientific applications. However, existing approaches face critical efficiency challenges when scaling to large geometric graphs and suffer significant performance degradation when the input graphs are sparsified for computational tractability. To address these limitations, we introduce FastEGNN and DistEGNN, two novel enhancements to equivariant GNNs for large-scale geometric graphs. FastEGNN employs a key innovation: a small ordered set of virtual nodes that effectively approximates the large unordered graph of real nodes. Specifically, we implement distinct message passing and aggregation mechanisms for different virtual nodes to ensure mutual distinctiveness, and minimize Maximum Mean Discrepancy (MMD) between virtual and real coordinates to achieve global distributedness. This design enables FastEGNN to maintain high accuracy while efficiently processing large-scale sparse graphs. For extremely large-scale geometric graphs, we present DistEGNN, a distributed extension where virtual nodes act as global bridges between subgraphs in different devices, maintaining consistency while dramatically reducing memory and computational overhead. We comprehensively evaluate our models across four challenging domains: N-body systems (100 nodes), protein dynamics (800 nodes), Water-3D (8,000 nodes), and our new Fluid113K benchmark (113,000 nodes). Results demonstrate superior efficiency and performance, establishing new capabilities in large-scale equivariant graph learning. Code is available at https://github.com/GLAD-RUC/DistEGNN.
<div id='section'>Paperid: <span id='pid'>22, <a href='https://arxiv.org/pdf/2506.14796.pdf' target='_blank'>https://arxiv.org/pdf/2506.14796.pdf</a></span>   <span><a href='https://github.com/biomap-research/PFMBench' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangyang Gao, Hao Wang, Cheng Tan, Chenrui Xu, Mengdi Liu, Bozhen Hu, Linlin Chao, Xiaoming Zhang, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14796">PFMBench: Protein Foundation Model Benchmark</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the current landscape and future directions of protein foundation model research. While recent advancements have transformed protein science and engineering, the field lacks a comprehensive benchmark for fair evaluation and in-depth understanding. Since ESM-1B, numerous protein foundation models have emerged, each with unique datasets and methodologies. However, evaluations often focus on limited tasks tailored to specific models, hindering insights into broader generalization and limitations. Specifically, researchers struggle to understand the relationships between tasks, assess how well current models perform across them, and determine the criteria in developing new foundation models. To fill this gap, we present PFMBench, a comprehensive benchmark evaluating protein foundation models across 38 tasks spanning 8 key areas of protein science. Through hundreds of experiments on 17 state-of-the-art models across 38 tasks, PFMBench reveals the inherent correlations between tasks, identifies top-performing models, and provides a streamlined evaluation protocol. Code is available at \href{https://github.com/biomap-research/PFMBench}{\textcolor{blue}{GitHub}}.
<div id='section'>Paperid: <span id='pid'>23, <a href='https://arxiv.org/pdf/2506.08316.pdf' target='_blank'>https://arxiv.org/pdf/2506.08316.pdf</a></span>   <span><a href='https://github.com/AlanNawzadAmin/SCUD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alan N. Amin, Nate Gruver, Andrew Gordon Wilson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08316">Why Masking Diffusion Works: Condition on the Jump Schedule for Improved Discrete Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discrete diffusion models, like continuous diffusion models, generate high-quality samples by gradually undoing noise applied to datapoints with a Markov process. Gradual generation in theory comes with many conceptual benefits; for example, inductive biases can be incorporated into the noising Markov process, and access to improved sampling algorithms. In practice, however, the consistently best performing discrete diffusion model is, surprisingly, masking diffusion, which does not denoise gradually. Here we explain the superior performance of masking diffusion by noting that it makes use of a fundamental difference between continuous and discrete Markov processes: discrete Markov processes evolve by discontinuous jumps at a fixed rate and, unlike other discrete diffusion models, masking diffusion builds in the known distribution of jump times and only learns where to jump to. We show that we can similarly bake in the known distribution of jump times into any discrete diffusion model. The resulting models - schedule-conditioned discrete diffusion (SCUD) - generalize classical discrete diffusion and masking diffusion. By applying SCUD to models with noising processes that incorporate inductive biases on images, text, and protein data, we build models that outperform masking.
<div id='section'>Paperid: <span id='pid'>24, <a href='https://arxiv.org/pdf/2506.07833.pdf' target='_blank'>https://arxiv.org/pdf/2506.07833.pdf</a></span>   <span><a href='https://github.com/michaelchen-lab/caft-llm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael K. Chen, Xikun Zhang, Jiaxing Huang, Dacheng Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.07833">Improving Large Language Models with Concept-Aware Fine-Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have become the cornerstone of modern AI. However, the existing paradigm of next-token prediction fundamentally limits their ability to form coherent, high-level concepts, making it a critical barrier to human-like understanding and reasoning. Take the phrase "ribonucleic acid" as an example: an LLM will first decompose it into tokens, i.e., artificial text fragments ("rib", "on", ...), then learn each token sequentially, rather than grasping the phrase as a unified, coherent semantic entity. This fragmented representation hinders deeper conceptual understanding and, ultimately, the development of truly intelligent systems. In response, we introduce Concept-Aware Fine-Tuning (CAFT), a novel multi-token training method that redefines how LLMs are fine-tuned. By enabling the learning of sequences that span multiple tokens, this method fosters stronger concept-aware learning. Our experiments demonstrate significant improvements compared to conventional next-token finetuning methods across diverse tasks, including traditional applications like text summarization and domain-specific ones like de novo protein design. Multi-token prediction was previously only possible in the prohibitively expensive pretraining phase; CAFT, to our knowledge, is the first to bring the multi-token setting to the post-training phase, thus effectively democratizing its benefits for the broader community of practitioners and researchers. Finally, the unexpected effectiveness of our proposed method suggests wider implications for the machine learning research community. All code and data are available at https://github.com/michaelchen-lab/caft-llm
<div id='section'>Paperid: <span id='pid'>25, <a href='https://arxiv.org/pdf/2506.06701.pdf' target='_blank'>https://arxiv.org/pdf/2506.06701.pdf</a></span>   <span><a href='https://github.com/fudong03/BioIntelligence' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Fudong Lin, Wanrou Du, Jinchan Liu, Tarikul Milon, Shelby Meche, Wu Xu, Xiaoqi Qin, Xu Yuan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06701">Do Protein Transformers Have Biological Intelligence?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks, particularly Transformers, have been widely adopted for predicting the functional properties of proteins. In this work, we focus on exploring whether Protein Transformers can capture biological intelligence among protein sequences. To achieve our goal, we first introduce a protein function dataset, namely Protein-FN, providing over 9000 protein data with meaningful labels. Second, we devise a new Transformer architecture, namely Sequence Protein Transformers (SPT), for computationally efficient protein function predictions. Third, we develop a novel Explainable Artificial Intelligence (XAI) technique called Sequence Score, which can efficiently interpret the decision-making processes of protein models, thereby overcoming the difficulty of deciphering biological intelligence bided in Protein Transformers. Remarkably, even our smallest SPT-Tiny model, which contains only 5.4M parameters, demonstrates impressive predictive accuracy, achieving 94.3% on the Antibiotic Resistance (AR) dataset and 99.6% on the Protein-FN dataset, all accomplished by training from scratch. Besides, our Sequence Score technique helps reveal that our SPT models can discover several meaningful patterns underlying the sequence structures of protein data, with these patterns aligning closely with the domain knowledge in the biology community. We have officially released our Protein-FN dataset on Hugging Face Datasets https://huggingface.co/datasets/Protein-FN/Protein-FN. Our code is available at https://github.com/fudong03/BioIntelligence.
<div id='section'>Paperid: <span id='pid'>26, <a href='https://arxiv.org/pdf/2506.05427.pdf' target='_blank'>https://arxiv.org/pdf/2506.05427.pdf</a></span>   <span><a href='https://github.com/ZishanShu/MTPNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zishan Shu, Yufan Deng, Hongyu Zhang, Zhiwei Nie, Jie Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.05427">MTPNet: Multi-Grained Target Perception for Unified Activity Cliff Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Activity cliff prediction is a critical task in drug discovery and material design. Existing computational methods are limited to handling single binding targets, which restricts the applicability of these prediction models. In this paper, we present the Multi-Grained Target Perception network (MTPNet) to incorporate the prior knowledge of interactions between the molecules and their target proteins. Specifically, MTPNet is a unified framework for activity cliff prediction, which consists of two components: Macro-level Target Semantic (MTS) guidance and Micro-level Pocket Semantic (MPS) guidance. By this way, MTPNet dynamically optimizes molecular representations through multi-grained protein semantic conditions. To our knowledge, it is the first time to employ the receptor proteins as guiding information to effectively capture critical interaction details. Extensive experiments on 30 representative activity cliff datasets demonstrate that MTPNet significantly outperforms previous approaches, achieving an average RMSE improvement of 18.95% on top of several mainstream GNN architectures. Overall, MTPNet internalizes interaction patterns through conditional deep learning to achieve unified predictions of activity cliffs, helping to accelerate compound optimization and design. Codes are available at: https://github.com/ZishanShu/MTPNet.
<div id='section'>Paperid: <span id='pid'>27, <a href='https://arxiv.org/pdf/2506.03373.pdf' target='_blank'>https://arxiv.org/pdf/2506.03373.pdf</a></span>   <span><a href='https://github.com/mahmoodlab/KRONOS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Shaban, Yuzhou Chang, Huaying Qiu, Yao Yu Yeo, Andrew H. Song, Guillaume Jaume, Yuchen Wang, Luca L. Weishaupt, Tong Ding, Anurag Vaidya, Abdallah Lamane, Daniel Shao, Mohammed Zidane, Yunhao Bai, Paige McCallum, Shuli Luo, Wenrui Wu, Yang Wang, Precious Cramer, Chi Ngai Chan, Pierre Stephan, Johanna Schaffenrath, Jia Le Lee, Hendrik A. Michel, Caiwei Tian, Cristina Almagro-Perez, Sophia J. Wagner, Sharifa Sahai, Ming Y. Lu, Richard J. Chen, Andrew Zhang, Mark Edward M. Gonzales, Ahmad Makky, Jia-Ying Joey Lee, Hao Cheng, Nourhan El Ahmar, Sayed Matar, Maximilian Haist, Darci Phillips, Yuqi Tan, Garry P. Nolan, W. Richard Burack, Jacob D. Estes, Jonathan T. C. Liu, Toni K Choueiri, Neeraj Agarwal, Marc Barry, Scott J. Rodig, Long Phi Le, Georg Gerber, Christian M. SchÃ¼rch, Fabian J. Theis, Youn H Kim, Joe Yeong, Sabina Signoretti, Brooke E. Howitt, Lit-Hsin Loo, Qin Ma, Sizun Jiang, Faisal Mahmood
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.03373">A Foundation Model for Spatial Proteomics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models have begun to transform image analysis by acting as pretrained generalist backbones that can be adapted to many tasks even when post-training data are limited, yet their impact on spatial proteomics, imaging that maps proteins at single-cell resolution, remains limited. Here, we introduce KRONOS, a foundation model built for spatial proteomics. KRONOS was trained in a self-supervised manner on over 47 million image patches covering 175 protein markers, 16 tissue types, and 8 fluorescence-based imaging platforms. We introduce key architectural adaptations to address the high-dimensional, multi-channel, and heterogeneous nature of multiplex imaging. We demonstrate that KRONOS learns biologically meaningful representations across multiple scales, ranging from cellular and microenvironment to tissue levels, enabling it to address diverse downstream tasks, including cell phenotyping, region classification, and patient stratification. Evaluated across 11 independent cohorts, KRONOS achieves state-of-the-art performance across cell phenotyping, treatment response prediction, and retrieval tasks, and is highly data-efficient. KRONOS also introduces the paradigm of segmentation-free patch-level processing for efficient and scalable spatial proteomics analysis, allowing cross-institutional comparisons, and as an image reverse search engine for spatial patterns. Together, these results position KRONOS as a flexible and scalable tool for spatial proteomics. The model is publicly accessible at https://github.com/mahmoodlab/KRONOS.
<div id='section'>Paperid: <span id='pid'>28, <a href='https://arxiv.org/pdf/2506.03237.pdf' target='_blank'>https://arxiv.org/pdf/2506.03237.pdf</a></span>   <span><a href='https://github.com/quanlin-wu/unisite' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jigang Fan, Quanlin Wu, Shengjie Luo, Liwei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.03237">UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection of ligand binding sites for proteins is a fundamental step in Structure-Based Drug Design. Despite notable advances in recent years, existing methods, datasets, and evaluation metrics are confronted with several key challenges: (1) current datasets and methods are centered on individual protein-ligand complexes and neglect that diverse binding sites may exist across multiple complexes of the same protein, introducing significant statistical bias; (2) ligand binding site detection is typically modeled as a discontinuous workflow, employing binary segmentation and subsequent clustering algorithms; (3) traditional evaluation metrics do not adequately reflect the actual performance of different binding site prediction methods. To address these issues, we first introduce UniSite-DS, the first UniProt (Unique Protein)-centric ligand binding site dataset, which contains 4.81 times more multi-site data and 2.08 times more overall data compared to the previously most widely used datasets. We then propose UniSite, the first end-to-end ligand binding site detection framework supervised by set prediction loss with bijective matching. In addition, we introduce Average Precision based on Intersection over Union (IoU) as a more accurate evaluation metric for ligand binding site prediction. Extensive experiments on UniSite-DS and several representative benchmark datasets demonstrate that IoU-based Average Precision provides a more accurate reflection of prediction quality, and that UniSite outperforms current state-of-the-art methods in ligand binding site detection. The dataset and codes will be made publicly available at https://github.com/quanlin-wu/unisite.
<div id='section'>Paperid: <span id='pid'>29, <a href='https://arxiv.org/pdf/2506.02203.pdf' target='_blank'>https://arxiv.org/pdf/2506.02203.pdf</a></span>   <span><a href='https://github.com/Stranja572/constrainedswe' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Navid NaderiAlizadeh, Darian Salehi, Xinran Liu, Soheil Kolouri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02203">Constrained Sliced Wasserstein Embedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sliced Wasserstein (SW) distances offer an efficient method for comparing high-dimensional probability measures by projecting them onto multiple 1-dimensional probability distributions. However, identifying informative slicing directions has proven challenging, often necessitating a large number of slices to achieve desirable performance and thereby increasing computational complexity. We introduce a constrained learning approach to optimize the slicing directions for SW distances. Specifically, we constrain the 1D transport plans to approximate the optimal plan in the original space, ensuring meaningful slicing directions. By leveraging continuous relaxations of these transport plans, we enable a gradient-based primal-dual approach to train the slicer parameters, alongside the remaining model parameters. We demonstrate how this constrained slicing approach can be applied to pool high-dimensional embeddings into fixed-length permutation-invariant representations. Numerical results on foundation models trained on images, point clouds, and protein sequences showcase the efficacy of the proposed constrained learning approach in learning more informative slicing directions. Our implementation code can be found at https://github.com/Stranja572/constrainedswe.
<div id='section'>Paperid: <span id='pid'>30, <a href='https://arxiv.org/pdf/2506.02052.pdf' target='_blank'>https://arxiv.org/pdf/2506.02052.pdf</a></span>   <span><a href='https://github.com/Trust-App-AI-Lab/protap' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuo Yan, Yuliang Yan, Bin Ma, Chenao Li, Haochun Tang, Jiahua Lu, Minhua Lin, Yuyuan Feng, Hui Xiong, Enyan Dai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02052">Protap: A Benchmark for Protein Modeling on Realistic Downstream Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, extensive deep learning architectures and pretraining strategies have been explored to support downstream protein applications. Additionally, domain-specific models incorporating biological knowledge have been developed to enhance performance in specialized tasks. In this work, we introduce $\textbf{Protap}$, a comprehensive benchmark that systematically compares backbone architectures, pretraining strategies, and domain-specific models across diverse and realistic downstream protein applications. Specifically, Protap covers five applications: three general tasks and two novel specialized tasks, i.e., enzyme-catalyzed protein cleavage site prediction and targeted protein degradation, which are industrially relevant yet missing from existing benchmarks. For each application, Protap compares various domain-specific models and general architectures under multiple pretraining settings. Our empirical studies imply that: (i) Though large-scale pretraining encoders achieve great results, they often underperform supervised encoders trained on small downstream training sets. (ii) Incorporating structural information during downstream fine-tuning can match or even outperform protein language models pretrained on large-scale sequence corpora. (iii) Domain-specific biological priors can enhance performance on specialized downstream tasks. Code and datasets are publicly available at https://github.com/Trust-App-AI-Lab/protap.
<div id='section'>Paperid: <span id='pid'>31, <a href='https://arxiv.org/pdf/2506.01918.pdf' target='_blank'>https://arxiv.org/pdf/2506.01918.pdf</a></span>   <span><a href='https://github.com/UNITES-Lab/Spatial2Sentence' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chi-Jane Chen, Yuhang Chen, Sukwon Yun, Natalie Stanley, Tianlong Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01918">Spatial Coordinates as a Cell Language: A Multi-Sentence Framework for Imaging Mass Cytometry Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image mass cytometry (IMC) enables high-dimensional spatial profiling by combining mass cytometry's analytical power with spatial distributions of cell phenotypes. Recent studies leverage large language models (LLMs) to extract cell states by translating gene or protein expression into biological context. However, existing single-cell LLMs face two major challenges: (1) Integration of spatial information: they struggle to generalize spatial coordinates and effectively encode spatial context as text, and (2) Treating each cell independently: they overlook cell-cell interactions, limiting their ability to capture biological relationships. To address these limitations, we propose Spatial2Sentence, a novel framework that integrates single-cell expression and spatial information into natural language using a multi-sentence approach. Spatial2Sentence constructs expression similarity and distance matrices, pairing spatially adjacent and expressionally similar cells as positive pairs while using distant and dissimilar cells as negatives. These multi-sentence representations enable LLMs to learn cellular interactions in both expression and spatial contexts. Equipped with multi-task learning, Spatial2Sentence outperforms existing single-cell LLMs on preprocessed IMC datasets, improving cell-type classification by 5.98% and clinical status prediction by 4.18% on the diabetes dataset while enhancing interpretability. The source code can be found here: https://github.com/UNITES-Lab/Spatial2Sentence.
<div id='section'>Paperid: <span id='pid'>32, <a href='https://arxiv.org/pdf/2505.23862.pdf' target='_blank'>https://arxiv.org/pdf/2505.23862.pdf</a></span>   <span><a href='https://github.com/HudenJear/RPLoss' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheng Gong, Ziyi Jiang, Weihao Gao, Deng Zhuo, Lan Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23862">A New Deep-learning-Based Approach For mRNA Optimization: High Fidelity, Computation Efficiency, and Multiple Optimization Factors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The mRNA optimization is critical for therapeutic and biotechnological applications, since sequence features directly govern protein expression levels and efficacy. However, current methods face significant challenges in simultaneously achieving three key objectives: (1) fidelity (preventing unintended amino acid changes), (2) computational efficiency (speed and scalability), and (3) the scope of optimization variables considered (multi-objective capability). Furthermore, existing methods often fall short of comprehensively incorporating the factors related to the mRNA lifecycle and translation process, including intrinsic mRNA sequence properties, secondary structure, translation elongation kinetics, and tRNA availability. To address these limitations, we introduce \textbf{RNop}, a novel deep learning-based method for mRNA optimization. We collect a large-scale dataset containing over 3 million sequences and design four specialized loss functions, the GPLoss, CAILoss, tAILoss, and MFELoss, which simultaneously enable explicit control over sequence fidelity while optimizing species-specific codon adaptation, tRNA availability, and desirable mRNA secondary structure features. Then, we demonstrate RNop's effectiveness through extensive in silico and in vivo experiments. RNop ensures high sequence fidelity, achieves significant computational throughput up to 47.32 sequences/s, and yields optimized mRNA sequences resulting in a significant increase in protein expression for functional proteins compared to controls. RNop surpasses current methodologies in both quantitative metrics and experimental validation, enlightening a new dawn for efficient and effective mRNA design. Code and models will be available at https://github.com/HudenJear/RPLoss.
<div id='section'>Paperid: <span id='pid'>33, <a href='https://arxiv.org/pdf/2505.23839.pdf' target='_blank'>https://arxiv.org/pdf/2505.23839.pdf</a></span>   <span><a href='https://github.com/zaixizhang/GeneBreaker' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zaixi Zhang, Zhenghong Zhou, Ruofan Jin, Le Cong, Mengdi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23839">GeneBreaker: Jailbreak Attacks against DNA Language Models with Pathogenicity Guidance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>DNA, encoding genetic instructions for almost all living organisms, fuels groundbreaking advances in genomics and synthetic biology. Recently, DNA Foundation Models have achieved success in designing synthetic functional DNA sequences, even whole genomes, but their susceptibility to jailbreaking remains underexplored, leading to potential concern of generating harmful sequences such as pathogens or toxin-producing genes. In this paper, we introduce GeneBreaker, the first framework to systematically evaluate jailbreak vulnerabilities of DNA foundation models. GeneBreaker employs (1) an LLM agent with customized bioinformatic tools to design high-homology, non-pathogenic jailbreaking prompts, (2) beam search guided by PathoLM and log-probability heuristics to steer generation toward pathogen-like sequences, and (3) a BLAST-based evaluation pipeline against a curated Human Pathogen Database (JailbreakDNABench) to detect successful jailbreaks. Evaluated on our JailbreakDNABench, GeneBreaker successfully jailbreaks the latest Evo series models across 6 viral categories consistently (up to 60\% Attack Success Rate for Evo2-40B). Further case studies on SARS-CoV-2 spike protein and HIV-1 envelope protein demonstrate the sequence and structural fidelity of jailbreak output, while evolutionary modeling of SARS-CoV-2 underscores biosecurity risks. Our findings also reveal that scaling DNA foundation models amplifies dual-use risks, motivating enhanced safety alignment and tracing mechanisms. Our code is at https://github.com/zaixizhang/GeneBreaker.
<div id='section'>Paperid: <span id='pid'>34, <a href='https://arxiv.org/pdf/2505.22869.pdf' target='_blank'>https://arxiv.org/pdf/2505.22869.pdf</a></span>   <span><a href='https://github.com/yinjunbo/cfpgen' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/yinjunbo/cfpgen' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Junbo Yin, Chao Zha, Wenjia He, Chencheng Xu, Xin Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22869">CFP-Gen: Combinatorial Functional Protein Generation via Diffusion Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing PLMs generate protein sequences based on a single-condition constraint from a specific modality, struggling to simultaneously satisfy multiple constraints across different modalities. In this work, we introduce CFP-Gen, a novel diffusion language model for Combinatorial Functional Protein GENeration. CFP-Gen facilitates the de novo protein design by integrating multimodal conditions with functional, sequence, and structural constraints. Specifically, an Annotation-Guided Feature Modulation (AGFM) module is introduced to dynamically adjust the protein feature distribution based on composable functional annotations, e.g., GO terms, IPR domains and EC numbers. Meanwhile, the Residue-Controlled Functional Encoding (RCFE) module captures residue-wise interaction to ensure more precise control. Additionally, off-the-shelf 3D structure encoders can be seamlessly integrated to impose geometric constraints. We demonstrate that CFP-Gen enables high-throughput generation of novel proteins with functionality comparable to natural proteins, while achieving a high success rate in designing multifunctional proteins. Code and data available at https://github.com/yinjunbo/cfpgen.
<div id='section'>Paperid: <span id='pid'>35, <a href='https://arxiv.org/pdf/2505.22674.pdf' target='_blank'>https://arxiv.org/pdf/2505.22674.pdf</a></span>   <span><a href='https://github.com/BioinfoMachineLearning/PSBench' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pawan Neupane, Jian Liu, Jianlin Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22674">PSBench: a large-scale benchmark for estimating the accuracy of protein complex structural models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting protein complex structures is essential for protein function analysis, protein design, and drug discovery. While AI methods like AlphaFold can predict accurate structural models for many protein complexes, reliably estimating the quality of these predicted models (estimation of model accuracy, or EMA) for model ranking and selection remains a major challenge. A key barrier to developing effective machine learning-based EMA methods is the lack of large, diverse, and well-annotated datasets for training and evaluation. To address this gap, we introduce PSBench, a benchmark suite comprising four large-scale, labeled datasets generated during the 15th and 16th community-wide Critical Assessment of Protein Structure Prediction (CASP15 and CASP16). PSBench includes over one million structural models covering a wide range of protein sequence lengths, complex stoichiometries, functional classes, and modeling difficulties. Each model is annotated with multiple complementary quality scores at the global, local, and interface levels. PSBench also provides multiple evaluation metrics and baseline EMA methods to facilitate rigorous comparisons. To demonstrate PSBench's utility, we trained and evaluated GATE, a graph transformer-based EMA method, on the CASP15 data. GATE was blindly tested in CASP16 (2024), where it ranked among the top-performing EMA methods. These results highlight PSBench as a valuable resource for advancing EMA research in protein complex modeling. PSBench is publicly available at: https://github.com/BioinfoMachineLearning/PSBench.
<div id='section'>Paperid: <span id='pid'>36, <a href='https://arxiv.org/pdf/2505.22525.pdf' target='_blank'>https://arxiv.org/pdf/2505.22525.pdf</a></span>   <span><a href='https://github.com/GAIR-NLP/thinking-with-generated-images' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ethan Chern, Zhulin Hu, Steffi Chern, Siqi Kou, Jiadi Su, Yan Ma, Zhijie Deng, Pengfei Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22525">Thinking with Generated Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present Thinking with Generated Images, a novel paradigm that fundamentally transforms how large multimodal models (LMMs) engage with visual reasoning by enabling them to natively think across text and vision modalities through spontaneous generation of intermediate visual thinking steps. Current visual reasoning with LMMs is constrained to either processing fixed user-provided images or reasoning solely through text-based chain-of-thought (CoT). Thinking with Generated Images unlocks a new dimension of cognitive capability where models can actively construct intermediate visual thoughts, critique their own visual hypotheses, and refine them as integral components of their reasoning process. We demonstrate the effectiveness of our approach through two complementary mechanisms: (1) vision generation with intermediate visual subgoals, where models decompose complex visual tasks into manageable components that are generated and integrated progressively, and (2) vision generation with self-critique, where models generate an initial visual hypothesis, analyze its shortcomings through textual reasoning, and produce refined outputs based on their own critiques. Our experiments on vision generation benchmarks show substantial improvements over baseline approaches, with our models achieving up to 50% (from 38% to 57%) relative improvement in handling complex multi-object scenarios. From biochemists exploring novel protein structures, and architects iterating on spatial designs, to forensic analysts reconstructing crime scenes, and basketball players envisioning strategic plays, our approach enables AI models to engage in the kind of visual imagination and iterative refinement that characterizes human creative, analytical, and strategic thinking. We release our open-source suite at https://github.com/GAIR-NLP/thinking-with-generated-images.
<div id='section'>Paperid: <span id='pid'>37, <a href='https://arxiv.org/pdf/2505.20589.pdf' target='_blank'>https://arxiv.org/pdf/2505.20589.pdf</a></span>   <span><a href='https://github.com/mahdip72/prot2token' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahdi Pourmirzaei, Farzaneh Esmaili, Salhuldin Alqarghuli, Mohammadreza Pourmirzaei, Ye Han, Kai Chen, Mohsen Rezaei, Duolin Wang, Dong Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20589">Prot2Token: A Unified Framework for Protein Modeling via Next-Token Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The diverse nature of protein prediction tasks has traditionally necessitated specialized models, hindering the development of broadly applicable and computationally efficient Protein Language Models (PLMs). In this work, we introduce Prot2Token, a unified framework that overcomes these challenges by converting a wide spectrum of protein-related predictions, from sequence-level properties and residue-specific attributes to complex inter-protein interactions, into a standardized next-token prediction format. At its core, Prot2Token employs an autoregressive decoder, conditioned on embeddings from pre-trained protein encoders and guided by learnable task tokens, to perform diverse predictions. This architecture uniquely facilitates multi-task learning, enabling a single model to master numerous tasks with improved efficiency. We present extensive experimental validation across a variety of benchmarks, demonstrating Prot2Tokens strong predictive power in different types of protein-prediction tasks. Key results include significant speedups (e.g., near 1000x over AlphaFold2 with MSA) and performance often matching or exceeding specialized approaches. Beyond that, we introduce an auxiliary self-supervised decoder pre-training approach to improve spatially sensitive task performance. Prot2Token thus offers a significant step towards a versatile, high-throughput paradigm for protein modeling, promising to accelerate biological discovery and the development of novel therapeutics. The code is available at https://github.com/mahdip72/prot2token .
<div id='section'>Paperid: <span id='pid'>38, <a href='https://arxiv.org/pdf/2505.20354.pdf' target='_blank'>https://arxiv.org/pdf/2505.20354.pdf</a></span>   <span><a href='https://github.com/IDEA-XL/RAPM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Juntong Wu, Zijing Liu, He Cao, Hao Li, Bin Feng, Zishan Shu, Ke Yu, Li Yuan, Yu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20354">Rethinking Text-based Protein Understanding: Retrieval or LLM?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, protein-text models have gained significant attention for their potential in protein generation and understanding. Current approaches focus on integrating protein-related knowledge into large language models through continued pretraining and multi-modal alignment, enabling simultaneous comprehension of textual descriptions and protein sequences. Through a thorough analysis of existing model architectures and text-based protein understanding benchmarks, we identify significant data leakage issues present in current benchmarks. Moreover, conventional metrics derived from natural language processing fail to accurately assess the model's performance in this domain. To address these limitations, we reorganize existing datasets and introduce a novel evaluation framework based on biological entities. Motivated by our observation, we propose a retrieval-enhanced method, which significantly outperforms fine-tuned LLMs for protein-to-text generation and shows accuracy and efficiency in training-free scenarios. Our code and data can be seen at https://github.com/IDEA-XL/RAPM.
<div id='section'>Paperid: <span id='pid'>39, <a href='https://arxiv.org/pdf/2505.17866.pdf' target='_blank'>https://arxiv.org/pdf/2505.17866.pdf</a></span>   <span><a href='https://github.com/MetaEvo/DesignX' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongshu Guo, Zeyuan Ma, Yining Ma, Xinglin Zhang, Wei-Neng Chen, Yue-Jiao Gong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17866">DesignX: Human-Competitive Algorithm Designer for Black-Box Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing effective black-box optimizers is hampered by limited problem-specific knowledge and manual control that spans months for almost every detail. In this paper, we present DesignX, the first automated algorithm design framework that generates an effective optimizer specific to a given black-box optimization problem within seconds. Rooted in the first principles, we identify two key sub-tasks: 1) algorithm structure generation and 2) hyperparameter control. To enable systematic construction, a comprehensive modular algorithmic space is first built, embracing hundreds of algorithm components collected from decades of research. We then introduce a dual-agent reinforcement learning system that collaborates on structural and parametric design through a novel cooperative training objective, enabling large-scale meta-training across 10k diverse instances. Remarkably, through days of autonomous learning, the DesignX-generated optimizers continuously surpass human-crafted optimizers by orders of magnitude, either on synthetic testbed or on realistic optimization scenarios such as Protein-docking, AutoML and UAV path planning. Further in-depth analysis reveals DesignX's capability to discover non-trivial algorithm patterns beyond expert intuition, which, conversely, provides valuable design insights for the optimization community. We provide DesignX's inference code at https://github.com/MetaEvo/DesignX.
<div id='section'>Paperid: <span id='pid'>40, <a href='https://arxiv.org/pdf/2505.11812.pdf' target='_blank'>https://arxiv.org/pdf/2505.11812.pdf</a></span>   <span><a href='https://github.com/ai4protein/VenusX' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Tan, Wenrui Gou, Bozitao Zhong, Liang Hong, Huiqun Yu, Bingxin Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11812">VenusX: Unlocking Fine-Grained Functional Understanding of Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models have driven significant progress in predicting protein function and interactions at the protein level. While these advancements have been invaluable for many biological applications such as enzyme engineering and function annotation, a more detailed perspective is essential for understanding protein functional mechanisms and evaluating the biological knowledge captured by models. To address this demand, we introduce VenusX, the first large-scale benchmark for fine-grained functional annotation and function-based protein pairing at the residue, fragment, and domain levels. VenusX comprises three major task categories across six types of annotations, including residue-level binary classification, fragment-level multi-class classification, and pairwise functional similarity scoring for identifying critical active sites, binding sites, conserved sites, motifs, domains, and epitopes. The benchmark features over 878,000 samples curated from major open-source databases such as InterPro, BioLiP, and SAbDab. By providing mixed-family and cross-family splits at three sequence identity thresholds, our benchmark enables a comprehensive assessment of model performance on both in-distribution and out-of-distribution scenarios. For baseline evaluation, we assess a diverse set of popular and open-source models, including pre-trained protein language models, sequence-structure hybrids, structure-based methods, and alignment-based techniques. Their performance is reported across all benchmark datasets and evaluation settings using multiple metrics, offering a thorough comparison and a strong foundation for future research. Code and data are publicly available at https://github.com/ai4protein/VenusX.
<div id='section'>Paperid: <span id='pid'>41, <a href='https://arxiv.org/pdf/2505.11580.pdf' target='_blank'>https://arxiv.org/pdf/2505.11580.pdf</a></span>   <span><a href='https://github.com/flagshippioneering/flash_ipa' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Liu, Axel Elaldi, Nicholas T Franklin, Nathan Russell, Gurinder S Atwal, Yih-En A Ban, Olivia Viessmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11580">Flash Invariant Point Attention</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Invariant Point Attention (IPA) is a key algorithm for geometry-aware modeling in structural biology, central to many protein and RNA models. However, its quadratic complexity limits the input sequence length. We introduce FlashIPA, a factorized reformulation of IPA that leverages hardware-efficient FlashAttention to achieve linear scaling in GPU memory and wall-clock time with sequence length. FlashIPA matches or exceeds standard IPA performance while substantially reducing computational costs. FlashIPA extends training to previously unattainable lengths, and we demonstrate this by re-training generative models without length restrictions and generating structures of thousands of residues. FlashIPA is available at https://github.com/flagshippioneering/flash_ipa.
<div id='section'>Paperid: <span id='pid'>42, <a href='https://arxiv.org/pdf/2505.01700.pdf' target='_blank'>https://arxiv.org/pdf/2505.01700.pdf</a></span>   <span><a href='https://github.com/CataAI/PoseX' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yize Jiang, Xinze Li, Yuanyuan Zhang, Jin Han, Youjun Xu, Ayush Pandit, Zaixi Zhang, Mengdi Wang, Mengyang Wang, Chong Liu, Guang Yang, Yejin Choi, Wu-Jun Li, Tianfan Fu, Fang Wu, Junhong Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.01700">PoseX: AI Defeats Physics Approaches on Protein-Ligand Cross Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing protein-ligand docking studies typically focus on the self-docking scenario, which is less practical in real applications. Moreover, some studies involve heavy frameworks requiring extensive training, posing challenges for convenient and efficient assessment of docking methods. To fill these gaps, we design PoseX, an open-source benchmark to evaluate both self-docking and cross-docking, enabling a practical and comprehensive assessment of algorithmic advances. Specifically, we curated a novel dataset comprising 718 entries for self-docking and 1,312 entries for cross-docking; second, we incorporated 23 docking methods in three methodological categories, including physics-based methods (e.g., SchrÃ¶dinger Glide), AI docking methods (e.g., DiffDock) and AI co-folding methods (e.g., AlphaFold3); third, we developed a relaxation method for post-processing to minimize conformational energy and refine binding poses; fourth, we built a leaderboard to rank submitted models in real-time. We derived some key insights and conclusions from extensive experiments: (1) AI approaches have consistently outperformed physics-based methods in overall docking success rate. (2) Most intra- and intermolecular clashes of AI approaches can be greatly alleviated with relaxation, which means combining AI modeling with physics-based post-processing could achieve excellent performance. (3) AI co-folding methods exhibit ligand chirality issues, except for Boltz-1x, which introduced physics-inspired potentials to fix hallucinations, suggesting modeling on stereochemistry improves the structural plausibility markedly. (4) Specifying binding pockets significantly promotes docking performance, indicating that pocket information can be leveraged adequately, particularly for AI co-folding methods, in future modeling efforts. The code, dataset, and leaderboard are released at https://github.com/CataAI/PoseX.
<div id='section'>Paperid: <span id='pid'>43, <a href='https://arxiv.org/pdf/2504.13075.pdf' target='_blank'>https://arxiv.org/pdf/2504.13075.pdf</a></span>   <span><a href='https://github.com/bytedance/apm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruizhe Chen, Dongyu Xue, Xiangxin Zhou, Zaixiang Zheng, Xiangxiang Zeng, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13075">An All-Atom Generative Model for Designing Protein Complexes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins typically exist in complexes, interacting with other proteins or biomolecules to perform their specific biological roles. Research on single-chain protein modeling has been extensively and deeply explored, with advancements seen in models like the series of ESM and AlphaFold2. Despite these developments, the study and modeling of multi-chain proteins remain largely uncharted, though they are vital for understanding biological functions. Recognizing the importance of these interactions, we introduce APM (All-Atom Protein Generative Model), a model specifically designed for modeling multi-chain proteins. By integrating atom-level information and leveraging data on multi-chain proteins, APM is capable of precisely modeling inter-chain interactions and designing protein complexes with binding capabilities from scratch. It also performs folding and inverse-folding tasks for multi-chain proteins. Moreover, APM demonstrates versatility in downstream applications: it achieves enhanced performance through supervised fine-tuning (SFT) while also supporting zero-shot sampling in certain tasks, achieving state-of-the-art results. We released our code at https://github.com/bytedance/apm.
<div id='section'>Paperid: <span id='pid'>44, <a href='https://arxiv.org/pdf/2504.06925.pdf' target='_blank'>https://arxiv.org/pdf/2504.06925.pdf</a></span>   <span><a href='https://github.com/AI4Food/FoodNExtDB' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sergio Romero-Tapiador, Ruben Tolosana, Blanca Lacruz-Pleguezuelos, Laura Judith Marcos Zambrano, Guadalupe X. BazÃ¡n, Isabel Espinosa-Salinas, Julian Fierrez, Javier Ortega-Garcia, Enrique Carrillo de Santa Pau, Aythami Morales
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.06925">Are Vision-Language Models Ready for Dietary Assessment? Exploring the Next Frontier in AI-Powered Food Image Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic dietary assessment based on food images remains a challenge, requiring precise food detection, segmentation, and classification. Vision-Language Models (VLMs) offer new possibilities by integrating visual and textual reasoning. In this study, we evaluate six state-of-the-art VLMs (ChatGPT, Gemini, Claude, Moondream, DeepSeek, and LLaVA), analyzing their capabilities in food recognition at different levels. For the experimental framework, we introduce the FoodNExTDB, a unique food image database that contains 9,263 expert-labeled images across 10 categories (e.g., "protein source"), 62 subcategories (e.g., "poultry"), and 9 cooking styles (e.g., "grilled"). In total, FoodNExTDB includes 50k nutritional labels generated by seven experts who manually annotated all images in the database. Also, we propose a novel evaluation metric, Expert-Weighted Recall (EWR), that accounts for the inter-annotator variability. Results show that closed-source models outperform open-source ones, achieving over 90% EWR in recognizing food products in images containing a single product. Despite their potential, current VLMs face challenges in fine-grained food recognition, particularly in distinguishing subtle differences in cooking styles and visually similar food items, which limits their reliability for automatic dietary assessment. The FoodNExTDB database is publicly available at https://github.com/AI4Food/FoodNExtDB.
<div id='section'>Paperid: <span id='pid'>45, <a href='https://arxiv.org/pdf/2504.03278.pdf' target='_blank'>https://arxiv.org/pdf/2504.03278.pdf</a></span>   <span><a href='https://github.com/compbiomed-unito/JanusDDG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Guido Barducci, Ivan Rossi, Francesco CodicÃ¨, Cesare Rollo, Valeria Repetto, Corrado Pancotti, Virginia Iannibelli, Tiziana Sanavia, Piero Fariselli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03278">JanusDDG: A Thermodynamics-Compliant Model for Sequence-Based Protein Stability via Two-Fronts Multi-Head Attention</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding how residue variations affect protein stability is crucial for designing functional proteins and deciphering the molecular mechanisms underlying disease-related mutations. Recent advances in protein language models (PLMs) have revolutionized computational protein analysis, enabling, among other things, more accurate predictions of mutational effects. In this work, we introduce JanusDDG, a deep learning framework that leverages PLM-derived embeddings and a bidirectional cross-attention transformer architecture to predict $ÎÎG$ of single and multiple-residue mutations while simultaneously being constrained to respect fundamental thermodynamic properties, such as antisymmetry and transitivity. Unlike conventional self-attention, JanusDDG computes queries (Q) and values (V) as the difference between wild-type and mutant embeddings, while keys (K) alternate between the two. This cross-interleaved attention mechanism enables the model to capture mutation-induced perturbations while preserving essential contextual information. Experimental results show that JanusDDG achieves state-of-the-art performance in predicting $ÎÎG$ from sequence alone, matching or exceeding the accuracy of structure-based methods for both single and multiple mutations. Code Availability:https://github.com/compbiomed-unito/JanusDDG
<div id='section'>Paperid: <span id='pid'>46, <a href='https://arxiv.org/pdf/2504.02148.pdf' target='_blank'>https://arxiv.org/pdf/2504.02148.pdf</a></span>   <span><a href='https://github.com/FuhaiLiAiLab/OmniCellTOSG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Heming Zhang, Tim Xu, Dekang Cao, Shunning Liang, Lars Schimmelpfennig, Levi Kaster, Di Huang, Carlos Cruchaga, Guangfu Li, Michael Province, Yixin Chen, Philip Payne, Fuhai Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02148">OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Joint LLM and GNN Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Complex cell signaling systems -- governed by varying protein abundances and interactions -- generate diverse cell types across organs. These systems evolve under influences such as age, sex, diet, environmental exposures, and diseases, making them challenging to decode given the involvement of tens of thousands of genes and proteins. Recently, hundreds of millions of single-cell omics data have provided a robust foundation for understanding these signaling networks within various cell subpopulations and conditions. Inspired by the success of large foundation models (for example, large language models and large vision models) pre-trained on massive datasets, we introduce OmniCellTOSG, the first dataset of cell text-omic signaling graphs (TOSGs). Each TOSG represents the signaling network of an individual or meta-cell and is labeled with information such as organ, disease, sex, age, and cell subtype. OmniCellTOSG offers two key contributions. First, it introduces a novel graph model that integrates human-readable annotations -- such as biological functions, cellular locations, signaling pathways, related diseases, and drugs -- with quantitative gene and protein abundance data, enabling graph reasoning to decode cell signaling. This approach calls for new joint models combining large language models and graph neural networks. Second, the dataset is built from single-cell RNA sequencing data of approximately 120 million cells from diverse tissues and conditions (healthy and diseased) and is fully compatible with PyTorch. This facilitates the development of innovative cell signaling models that could transform research in life sciences, healthcare, and precision medicine. The OmniCellTOSG dataset is continuously expanding and will be updated regularly. The dataset and code are available at https://github.com/FuhaiLiAiLab/OmniCellTOSG.
<div id='section'>Paperid: <span id='pid'>47, <a href='https://arxiv.org/pdf/2504.00748.pdf' target='_blank'>https://arxiv.org/pdf/2504.00748.pdf</a></span>   <span><a href='https://github.com/knowlab/IHC-LLMiner' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunsoo Kim, Michal W. S. Ong, Daniel W. Rogalsky, Manuel Rodriguez-Justo, Honghan Wu, Adam P. Levine
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.00748">IHC-LLMiner: Automated extraction of tumour immunohistochemical profiles from PubMed abstracts using large language models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Immunohistochemistry (IHC) is essential in diagnostic pathology and biomedical research, offering critical insights into protein expression and tumour biology. This study presents an automated pipeline, IHC-LLMiner, for extracting IHC-tumour profiles from PubMed abstracts, leveraging advanced biomedical text mining. There are two subtasks: abstract classification (include/exclude as relevant) and IHC-tumour profile extraction on relevant included abstracts. The best-performing model, "Gemma-2 finetuned", achieved 91.5% accuracy and an F1 score of 91.4, outperforming GPT4-O by 9.5% accuracy with 5.9 times faster inference time. From an initial dataset of 107,759 abstracts identified for 50 immunohistochemical markers, the classification task identified 30,481 relevant abstracts (Include) using the Gemma-2 finetuned model. For IHC-tumour profile extraction, the Gemma-2 finetuned model achieved the best performance with 63.3% Correct outputs. Extracted IHC-tumour profiles (tumour types and markers) were normalised to Unified Medical Language System (UMLS) concepts to ensure consistency and facilitate IHC-tumour profile landscape analysis. The extracted IHC-tumour profiles demonstrated excellent concordance with available online summary data and provided considerable added value in terms of both missing IHC-tumour profiles and quantitative assessments. Our proposed LLM based pipeline provides a practical solution for large-scale IHC-tumour profile data mining, enhancing the accessibility and utility of such data for research and clinical applications as well as enabling the generation of quantitative and structured data to support cancer-specific knowledge base development. Models and training datasets are available at https://github.com/knowlab/IHC-LLMiner.
<div id='section'>Paperid: <span id='pid'>48, <a href='https://arxiv.org/pdf/2503.23014.pdf' target='_blank'>https://arxiv.org/pdf/2503.23014.pdf</a></span>   <span><a href='https://github.com/blingbell/MSNGO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Beibei Wang, Boyue Cui, Shiqu Chen, Xuan Wang, Yadong Wang, Junyi Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.23014">MSNGO: multi-species protein function annotation based on 3D protein structure and network propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motivation: In recent years, protein function prediction has broken through the bottleneck of sequence features, significantly improving prediction accuracy using high-precision protein structures predicted by AlphaFold2. While single-species protein function prediction methods have achieved remarkable success, multi-species protein function prediction methods are still in the stage of using PPI networks and sequence features. Providing effective cross-species label propagation for species with sparse protein annotations remains a challenging issue. To address this problem, we propose the MSNGO model, which integrates structural features and network propagation methods. Our validation shows that using structural features can significantly improve the accuracy of multi-species protein function prediction. Results: We employ graph representation learning techniques to extract amino acid representations from protein structure contact maps and train a structural model using a graph convolution pooling module to derive protein-level structural features. After incorporating the sequence features from ESM-2, we apply a network propagation algorithm to aggregate information and update node representations within a heterogeneous network. The results demonstrate that MSNGO outperforms previous multi-species protein function prediction methods that rely on sequence features and PPI networks. Availability: https://github.com/blingbell/MSNGO.
<div id='section'>Paperid: <span id='pid'>49, <a href='https://arxiv.org/pdf/2503.21788.pdf' target='_blank'>https://arxiv.org/pdf/2503.21788.pdf</a></span>   <span><a href='https://github.com/PharMolix/OpenBioMed' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizhen Luo, Jiashuo Wang, Siqi Fan, Zaiqing Nie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.21788">PharMolixFM: All-Atom Foundation Models for Molecular Modeling and Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structural biology relies on accurate three-dimensional biomolecular structures to advance our understanding of biological functions, disease mechanisms, and therapeutics. While recent advances in deep learning have enabled the development of all-atom foundation models for molecular modeling and generation, existing approaches face challenges in generalization due to the multi-modal nature of atomic data and the lack of comprehensive analysis of training and sampling strategies. To address these limitations, we propose PharMolixFM, a unified framework for constructing all-atom foundation models based on multi-modal generative techniques. Our framework includes three variants using state-of-the-art multi-modal generative models. By formulating molecular tasks as a generalized denoising process with task-specific priors, PharMolixFM achieves robust performance across various structural biology applications. Experimental results demonstrate that PharMolixFM-Diff achieves competitive prediction accuracy in protein-small-molecule docking (83.9% vs. 90.2% RMSD < 2Ã, given pocket) with significantly improved inference speed. Moreover, we explore the empirical inference scaling law by introducing more sampling repeats or steps. Our code and model are available at https://github.com/PharMolix/OpenBioMed.
<div id='section'>Paperid: <span id='pid'>50, <a href='https://arxiv.org/pdf/2503.21450.pdf' target='_blank'>https://arxiv.org/pdf/2503.21450.pdf</a></span>   <span><a href='https://github.com/HPC-NEAU/PhysChemDiff' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Changjian Zhou, Yuexi Qiu, Tongtong Ling, Jiafeng Li, Shuanghe Liu, Xiangjing Wang, Jia Song, Wensheng Xiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.21450">CMADiff: Cross-Modal Aligned Diffusion for Controllable Protein Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI-assisted protein design has emerged as a critical tool for advancing biotechnology, as deep generative models have demonstrated their reliability in this domain. However, most existing models primarily utilize protein sequence or structural data for training, neglecting the physicochemical properties of proteins.Moreover, they are deficient to control the generation of proteins in intuitive conditions. To address these limitations,we propose CMADiff here, a novel framework that enables controllable protein generation by aligning the physicochemical properties of protein sequences with text-based descriptions through a latent diffusion process. Specifically, CMADiff employs a Conditional Variational Autoencoder (CVAE) to integrate physicochemical features as conditional input, forming a robust latent space that captures biological traits. In this latent space, we apply a conditional diffusion process, which is guided by BioAligner, a contrastive learning-based module that aligns text descriptions with protein features, enabling text-driven control over protein sequence generation. Validated by a series of evaluations including AlphaFold3, the experimental results indicate that CMADiff outperforms protein sequence generation benchmarks and holds strong potential for future applications. The implementation and code are available at https://github.com/HPC-NEAU/PhysChemDiff.
<div id='section'>Paperid: <span id='pid'>51, <a href='https://arxiv.org/pdf/2503.20291.pdf' target='_blank'>https://arxiv.org/pdf/2503.20291.pdf</a></span>   <span><a href='https://github.com/chenwei-zhang/CryoSAMU' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenwei Zhang, Khanh Dao Duc
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.20291">CryoSAMU: Enhancing 3D Cryo-EM Density Maps of Protein Structures at Intermediate Resolution with Structure-Aware Multimodal U-Nets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enhancing cryogenic electron microscopy (cryo-EM) 3D density maps at intermediate resolution (4-8 Ã) is crucial in protein structure determination. Recent advances in deep learning have led to the development of automated approaches for enhancing experimental cryo-EM density maps. Yet, these methods are not optimized for intermediate-resolution maps and rely on map density features alone. To address this, we propose CryoSAMU, a novel method designed to enhance 3D cryo-EM density maps of protein structures using structure-aware multimodal U-Nets and trained on curated intermediate-resolution density maps. We comprehensively evaluate CryoSAMU across various metrics and demonstrate its competitive performance compared to state-of-the-art methods. Notably, CryoSAMU achieves significantly faster processing speed, showing promise for future practical applications. Our code is available at https://github.com/chenwei-zhang/CryoSAMU.
<div id='section'>Paperid: <span id='pid'>52, <a href='https://arxiv.org/pdf/2503.15438.pdf' target='_blank'>https://arxiv.org/pdf/2503.15438.pdf</a></span>   <span><a href='https://github.com/tyang816/VenusFactory' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Tan, Chen Liu, Jingyuan Gao, Banghao Wu, Mingchen Li, Ruilin Wang, Lingrong Zhang, Huiqun Yu, Guisheng Fan, Liang Hong, Bingxin Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15438">VenusFactory: A Unified Platform for Protein Engineering Data Retrieval and Language Model Fine-Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Natural language processing (NLP) has significantly influenced scientific domains beyond human language, including protein engineering, where pre-trained protein language models (PLMs) have demonstrated remarkable success. However, interdisciplinary adoption remains limited due to challenges in data collection, task benchmarking, and application. This work presents VenusFactory, a versatile engine that integrates biological data retrieval, standardized task benchmarking, and modular fine-tuning of PLMs. VenusFactory supports both computer science and biology communities with choices of both a command-line execution and a Gradio-based no-code interface, integrating $40+$ protein-related datasets and $40+$ popular PLMs. All implementations are open-sourced on https://github.com/tyang816/VenusFactory.
<div id='section'>Paperid: <span id='pid'>53, <a href='https://arxiv.org/pdf/2503.13517.pdf' target='_blank'>https://arxiv.org/pdf/2503.13517.pdf</a></span>   <span><a href='https://github.com/google/curie' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Cui, Zahra Shamsi, Gowoon Cheon, Xuejian Ma, Shutong Li, Maria Tikhanovskaya, Peter Norgaard, Nayantara Mudur, Martyna Plomecka, Paul Raccuglia, Yasaman Bahri, Victor V. Albert, Pranesh Srinivasan, Haining Pan, Philippe Faist, Brian Rohr, Ekin Dogus Cubuk, Muratahan Aykol, Amil Merchant, Michael J. Statt, Dan Morris, Drew Purves, Elise Kleeman, Ruth Alcantara, Matthew Abraham, Muqthar Mohammad, Ean Phing VanLee, Chenfei Jiang, Elizabeth Dorfman, Eun-Ah Kim, Michael P Brenner, Viren Jain, Sameera Ponda, Subhashini Venugopalan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13517">CURIE: Evaluating LLMs On Multitask Scientific Long Context Understanding and Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific problem-solving involves synthesizing information while applying expert knowledge. We introduce CURIE, a scientific long-Context Understanding,Reasoning and Information Extraction benchmark to measure the potential of Large Language Models (LLMs) in scientific problem-solving and assisting scientists in realistic workflows. This benchmark introduces ten challenging tasks with a total of 580 problems and solution pairs curated by experts in six disciplines - materials science, condensed matter physics, quantum computing, geospatial analysis, biodiversity, and proteins - covering both experimental and theoretical work-flows in science. We evaluate a range of closed and open LLMs on tasks in CURIE which requires domain expertise, comprehension of long in-context information,and multi-step reasoning. While Gemini Flash 2.0 and Claude-3 show consistent high comprehension across domains, the popular GPT-4o and command-R+ fail dramatically on protein sequencing tasks. With the best performance at 32% there is much room for improvement for all models. We hope that insights gained from CURIE can guide the future development of LLMs in sciences. Evaluation code and data are in https://github.com/google/curie
<div id='section'>Paperid: <span id='pid'>54, <a href='https://arxiv.org/pdf/2503.08764.pdf' target='_blank'>https://arxiv.org/pdf/2503.08764.pdf</a></span>   <span><a href='https://github.com/johnyang101/reticular-sae' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nithin Parsan, David J. Yang, John J. Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08764">Towards Interpretable Protein Structure Prediction with Sparse Autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models have revolutionized structure prediction, but their nonlinear nature obscures how sequence representations inform structure prediction. While sparse autoencoders (SAEs) offer a path to interpretability here by learning linear representations in high-dimensional space, their application has been limited to smaller protein language models unable to perform structure prediction. In this work, we make two key advances: (1) we scale SAEs to ESM2-3B, the base model for ESMFold, enabling mechanistic interpretability of protein structure prediction for the first time, and (2) we adapt Matryoshka SAEs for protein language models, which learn hierarchically organized features by forcing nested groups of latents to reconstruct inputs independently. We demonstrate that our Matryoshka SAEs achieve comparable or better performance than standard architectures. Through comprehensive evaluations, we show that SAEs trained on ESM2-3B significantly outperform those trained on smaller models for both biological concept discovery and contact map prediction. Finally, we present an initial case study demonstrating how our approach enables targeted steering of ESMFold predictions, increasing structure solvent accessibility while fixing the input sequence. To facilitate further investigation by the broader community, we open-source our code, dataset, pretrained models https://github.com/johnyang101/reticular-sae , and visualizer https://sae.reticular.ai .
<div id='section'>Paperid: <span id='pid'>55, <a href='https://arxiv.org/pdf/2503.04650.pdf' target='_blank'>https://arxiv.org/pdf/2503.04650.pdf</a></span>   <span><a href='https://github.com/lijfrank-open/JmcPPI' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiang Li, Xiaoping Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04650">Joint Masked Reconstruction and Contrastive Learning for Mining Interactions Between Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interaction (PPI) prediction is an instrumental means in elucidating the mechanisms underlying cellular operations, holding significant practical implications for the realms of pharmaceutical development and clinical treatment. Presently, the majority of research methods primarily concentrate on the analysis of amino acid sequences, while investigations predicated on protein structures remain in the nascent stages of exploration. Despite the emergence of several structure-based algorithms in recent years, these are still confronted with inherent challenges: (1) the extraction of intrinsic structural information of proteins typically necessitates the expenditure of substantial computational resources; (2) these models are overly reliant on seen protein data, struggling to effectively unearth interaction cues between unknown proteins. To further propel advancements in this domain, this paper introduces a novel PPI prediction method jointing masked reconstruction and contrastive learning, termed JmcPPI. This methodology dissects the PPI prediction task into two distinct phases: during the residue structure encoding phase, JmcPPI devises two feature reconstruction tasks and employs graph attention mechanism to capture structural information between residues; during the protein interaction inference phase, JmcPPI perturbs the original PPI graph and employs a multi-graph contrastive learning strategy to thoroughly mine extrinsic interaction information of novel proteins. Extensive experiments conducted on three widely utilized PPI datasets demonstrate that JmcPPI surpasses existing optimal baseline models across various data partition schemes. The associated code can be accessed via https://github.com/lijfrank-open/JmcPPI.
<div id='section'>Paperid: <span id='pid'>56, <a href='https://arxiv.org/pdf/2503.00089.pdf' target='_blank'>https://arxiv.org/pdf/2503.00089.pdf</a></span>   <span><a href='https://github.com/KatarinaYuan/StructTokenBench' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyu Yuan, Zichen Wang, Marcus Collins, Huzefa Rangwala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00089">Protein Structure Tokenization: Benchmarking and New Recipe</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent years have witnessed a surge in the development of protein structural tokenization methods, which chunk protein 3D structures into discrete or continuous representations. Structure tokenization enables the direct application of powerful techniques like language modeling for protein structures, and large multimodal models to integrate structures with protein sequences and functional texts. Despite the progress, the capabilities and limitations of these methods remain poorly understood due to the lack of a unified evaluation framework. We first introduce StructTokenBench, a framework that comprehensively evaluates the quality and efficiency of structure tokenizers, focusing on fine-grained local substructures rather than global structures, as typical in existing benchmarks. Our evaluations reveal that no single model dominates all benchmarking perspectives. Observations of codebook under-utilization led us to develop AminoAseed, a simple yet effective strategy that enhances codebook gradient updates and optimally balances codebook size and dimension for improved tokenizer utilization and quality. Compared to the leading model ESM3, our method achieves an average of 6.31% performance improvement across 24 supervised tasks, with sensitivity and utilization rates increased by 12.83% and 124.03%, respectively. Source code and model weights are available at https://github.com/KatarinaYuan/StructTokenBench
<div id='section'>Paperid: <span id='pid'>57, <a href='https://arxiv.org/pdf/2502.17504.pdf' target='_blank'>https://arxiv.org/pdf/2502.17504.pdf</a></span>   <span><a href='https://github.com/Yijia-Xiao/Protein-LLM-Survey' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijia Xiao, Wanjia Zhao, Junkai Zhang, Yiqiao Jin, Han Zhang, Zhicheng Ren, Renliang Sun, Haixin Wang, Guancheng Wan, Pan Lu, Xiao Luo, Yu Zhang, James Zou, Yizhou Sun, Wei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.17504">Protein Large Language Models: A Comprehensive Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-specific large language models (Protein LLMs) are revolutionizing protein science by enabling more efficient protein structure prediction, function annotation, and design. While existing surveys focus on specific aspects or applications, this work provides the first comprehensive overview of Protein LLMs, covering their architectures, training datasets, evaluation metrics, and diverse applications. Through a systematic analysis of over 100 articles, we propose a structured taxonomy of state-of-the-art Protein LLMs, analyze how they leverage large-scale protein sequence data for improved accuracy, and explore their potential in advancing protein engineering and biomedical research. Additionally, we discuss key challenges and future directions, positioning Protein LLMs as essential tools for scientific discovery in protein science. Resources are maintained at https://github.com/Yijia-Xiao/Protein-LLM-Survey.
<div id='section'>Paperid: <span id='pid'>58, <a href='https://arxiv.org/pdf/2502.16189.pdf' target='_blank'>https://arxiv.org/pdf/2502.16189.pdf</a></span>   <span><a href='https://github.com/SRastegari/MBGNN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sayedmohammadreza Rastegari, Sina Tabakhi, Xianyuan Liu, Wei Sang, Haiping Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16189">Co-evolution-based Metal-binding Residue Prediction with Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In computational structural biology, predicting metal-binding sites and their corresponding metal types is challenging due to the complexity of protein structures and interactions. Conventional sequence- and structure-based prediction approaches cannot capture the complex evolutionary relationships driving these interactions to facilitate understanding, while recent co-evolution-based approaches do not fully consider the entire structure of the co-evolved residue network. In this paper, we introduce MBGNN (Metal-Binding Graph Neural Network) that utilizes the entire co-evolved residue network and effectively captures the complex dependencies within protein structures via graph neural networks to enhance the prediction of co-evolved metal-binding residues and their associated metal types. Experimental results on a public dataset show that MBGNN outperforms existing co-evolution-based metal-binding prediction methods, and it is also competitive against recent sequence-based methods, showing the potential of integrating co-evolutionary insights with advanced machine learning to deepen our understanding of protein-metal interactions. The MBGNN code is publicly available at https://github.com/SRastegari/MBGNN.
<div id='section'>Paperid: <span id='pid'>59, <a href='https://arxiv.org/pdf/2502.15610.pdf' target='_blank'>https://arxiv.org/pdf/2502.15610.pdf</a></span>   <span><a href='https://github.com/fondress/PDeepPP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jixiu Zhai, Zikun Wang, Tianchi Lu, Haitian Zhong, Ziyang Xu, Yuhuan Liu, Shengrui Xu, Jingwan Wang, Dan Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15610">A general language model for peptide identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate identification of bioactive peptides (BPs) and protein post-translational modifications (PTMs) is essential for understanding protein function and advancing therapeutic discovery. However, most computational methods remain limited in their generalizability across diverse peptide functions. Here, we present PDeepPP, a unified deep learning framework that integrates pretrained protein language models with a hybrid transformer-convolutional architecture, enabling robust identification across diverse peptide classes and PTM sites. We curated comprehensive benchmark datasets and implemented strategies to address data imbalance, allowing PDeepPP to systematically extract both global and local sequence features. Through extensive analyses-including dimensionality reduction and comparison studies-PDeepPP demonstrates strong, interpretable peptide representations and achieves state-of-the-art performance in 25 of the 33 biological identification tasks. Notably, PDeepPP attains high accuracy in antimicrobial (0.9726) and phosphorylation site (0.9984) identification, with 99.5% specificity in glycosylation site prediction and substantial reduction in false negatives in antimalarial tasks. By enabling large-scale, accurate peptide analysis, PDeepPP supports biomedical research and the discovery of novel therapeutic targets for disease treatment. All code, datasets, and pretrained models are publicly available via GitHub:https://github.com/fondress/PDeepPP and Hugging Face:https://huggingface.co/fondress/PDeppPP.
<div id='section'>Paperid: <span id='pid'>60, <a href='https://arxiv.org/pdf/2502.14944.pdf' target='_blank'>https://arxiv.org/pdf/2502.14944.pdf</a></span>   <span><a href='https://github.com/masa-ue/ProDifEvo-Refinement' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Masatoshi Uehara, Xingyu Su, Yulai Zhao, Xiner Li, Aviv Regev, Shuiwang Ji, Sergey Levine, Tommaso Biancalani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14944">Reward-Guided Iterative Refinement in Diffusion Models at Test-Time with Applications to Protein and DNA Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To fully leverage the capabilities of diffusion models, we are often interested in optimizing downstream reward functions during inference. While numerous algorithms for reward-guided generation have been recently proposed due to their significance, current approaches predominantly focus on single-shot generation, transitioning from fully noised to denoised states. We propose a novel framework for inference-time reward optimization with diffusion models inspired by evolutionary algorithms. Our approach employs an iterative refinement process consisting of two steps in each iteration: noising and reward-guided denoising. This sequential refinement allows for the gradual correction of errors introduced during reward optimization. Besides, we provide a theoretical guarantee for our framework. Finally, we demonstrate its superior empirical performance in protein and cell-type-specific regulatory DNA design. The code is available at \href{https://github.com/masa-ue/ProDifEvo-Refinement}{https://github.com/masa-ue/ProDifEvo-Refinement}.
<div id='section'>Paperid: <span id='pid'>61, <a href='https://arxiv.org/pdf/2502.14934.pdf' target='_blank'>https://arxiv.org/pdf/2502.14934.pdf</a></span>   <span><a href='https://github.com/tmlr-group/FABFlex' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zizhuo Zhang, Lijun Wu, Kaiyuan Gao, Jiangchao Yao, Tao Qin, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14934">Fast and Accurate Blind Flexible Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking that predicts the bound structures of small molecules (ligands) to their protein targets, plays a vital role in drug discovery. However, existing docking methods often face limitations: they either overlook crucial structural changes by assuming protein rigidity or suffer from low computational efficiency due to their reliance on generative models for structure sampling. To address these challenges, we propose FABFlex, a fast and accurate regression-based multi-task learning model designed for realistic blind flexible docking scenarios, where proteins exhibit flexibility and binding pocket sites are unknown (blind). Specifically, FABFlex's architecture comprises three specialized modules working in concert: (1) A pocket prediction module that identifies potential binding sites, addressing the challenges inherent in blind docking scenarios. (2) A ligand docking module that predicts the bound (holo) structures of ligands from their unbound (apo) states. (3) A pocket docking module that forecasts the holo structures of protein pockets from their apo conformations. Notably, FABFlex incorporates an iterative update mechanism that serves as a conduit between the ligand and pocket docking modules, enabling continuous structural refinements. This approach effectively integrates the three subtasks of blind flexible docking-pocket identification, ligand conformation prediction, and protein flexibility modeling-into a unified, coherent framework. Extensive experiments on public benchmark datasets demonstrate that FABFlex not only achieves superior effectiveness in predicting accurate binding modes but also exhibits a significant speed advantage (208 $\times$) compared to existing state-of-the-art methods. Our code is released at https://github.com/tmlr-group/FABFlex.
<div id='section'>Paperid: <span id='pid'>62, <a href='https://arxiv.org/pdf/2502.14637.pdf' target='_blank'>https://arxiv.org/pdf/2502.14637.pdf</a></span>   <span><a href='https://github.com/AngxiaoYue/ReQFlow' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Angxiao Yue, Zichong Wang, Hongteng Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14637">ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein backbone generation plays a central role in de novo protein design and is significant for many biological and medical applications. Although diffusion and flow-based generative models provide potential solutions to this challenging task, they often generate proteins with undesired designability and suffer computational inefficiency. In this study, we propose a novel rectified quaternion flow (ReQFlow) matching method for fast and high-quality protein backbone generation. In particular, our method generates a local translation and a 3D rotation from random noise for each residue in a protein chain, which represents each 3D rotation as a unit quaternion and constructs its flow by spherical linear interpolation (SLERP) in an exponential format. We train the model by quaternion flow (QFlow) matching with guaranteed numerical stability and rectify the QFlow model to accelerate its inference and improve the designability of generated protein backbones, leading to the proposed ReQFlow model. Experiments show that ReQFlow achieves on-par performance in protein backbone generation while requiring much fewer sampling steps and significantly less inference time (e.g., being 37x faster than RFDiffusion and 63x faster than Genie2 when generating a backbone of length 300), demonstrating its effectiveness and efficiency. The code is available at https://github.com/AngxiaoYue/ReQFlow.
<div id='section'>Paperid: <span id='pid'>63, <a href='https://arxiv.org/pdf/2502.12049.pdf' target='_blank'>https://arxiv.org/pdf/2502.12049.pdf</a></span>   <span><a href='https://github.com/Shef-AIRE/StoicIML' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiayang Zhang, Xianyuan Liu, Wei Wu, Sina Tabakhi, Wenrui Fan, Shuo Zhou, Kang Lan Tee, Tuck Seng Wong, Haiping Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12049">Classifying the Stoichiometry of Virus-like Particles with Interpretable Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Virus-like particles (VLPs) are valuable for vaccine development due to their immune-triggering properties. Understanding their stoichiometry, the number of protein subunits to form a VLP, is critical for vaccine optimisation. However, current experimental methods to determine stoichiometry are time-consuming and require highly purified proteins. To efficiently classify stoichiometry classes in proteins, we curate a new dataset and propose an interpretable, data-driven pipeline leveraging linear machine learning models. We also explore the impact of feature encoding on model performance and interpretability, as well as methods to identify key protein sequence features influencing classification. The evaluation of our pipeline demonstrates that it can classify stoichiometry while revealing protein features that possibly influence VLP assembly. The data and code used in this work are publicly available at https://github.com/Shef-AIRE/StoicIML.
<div id='section'>Paperid: <span id='pid'>64, <a href='https://arxiv.org/pdf/2502.07384.pdf' target='_blank'>https://arxiv.org/pdf/2502.07384.pdf</a></span>   <span><a href='https://github.com/ZhangJJ26/SAGEPhos' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingjie Zhang, Hanqun Cao, Zijun Gao, Xiaorui Wang, Chunbin Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07384">SAGEPhos: Sage Bio-Coupled and Augmented Fusion for Phosphorylation Site Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Phosphorylation site prediction based on kinase-substrate interaction plays a vital role in understanding cellular signaling pathways and disease mechanisms. Computational methods for this task can be categorized into kinase-family-focused and individual kinase-targeted approaches. Individual kinase-targeted methods have gained prominence for their ability to explore a broader protein space and provide more precise target information for kinase inhibitors. However, most existing individual kinase-based approaches focus solely on sequence inputs, neglecting crucial structural information. To address this limitation, we introduce SAGEPhos (Structure-aware kinAse-substrate bio-coupled and bio-auGmented nEtwork for Phosphorylation site prediction), a novel framework that modifies the semantic space of main protein inputs using auxiliary inputs at two distinct modality levels. At the inter-modality level, SAGEPhos introduces a Bio-Coupled Modal Fusion method, distilling essential kinase sequence information to refine task-oriented local substrate feature space, creating a shared semantic space that captures crucial kinase-substrate interaction patterns. Within the substrate's intra-modality domain, it focuses on Bio-Augmented Fusion, emphasizing 2D local sequence information while selectively incorporating 3D spatial information from predicted structures to complement the sequence space. Moreover, to address the lack of structural information in current datasets, we contribute a new, refined phosphorylation site prediction dataset, which incorporates crucial structural elements and will serve as a new benchmark for the field. Experimental results demonstrate that SAGEPhos significantly outperforms baseline methods. We release the SAGEPhos models and code at https://github.com/ZhangJJ26/SAGEPhos.
<div id='section'>Paperid: <span id='pid'>65, <a href='https://arxiv.org/pdf/2502.07272.pdf' target='_blank'>https://arxiv.org/pdf/2502.07272.pdf</a></span>   <span><a href='https://github.com/GenerTeam/GENERator' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Wu, Qiuyi Li, Mingyang Li, Kun Fu, Fuli Feng, Jieping Ye, Hui Xiong, Zheng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07272">GENERator: A Long-Context Generative Genomic Foundation Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advancements in DNA sequencing technologies have significantly improved our ability to decode genomic sequences. However, the prediction and interpretation of these sequences remain challenging due to the intricate nature of genetic material. Large language models (LLMs) have introduced new opportunities for biological sequence analysis. Recent developments in genomic language models have underscored the potential of LLMs in deciphering DNA sequences. Nonetheless, existing models often face limitations in robustness and application scope, primarily due to constraints in model structure and training data scale. To address these limitations, we present GENERator, a generative genomic foundation model featuring a context length of 98k base pairs (bp) and 1.2B parameters. Trained on an expansive dataset comprising 386B bp of eukaryotic DNA, the GENERator demonstrates state-of-the-art performance across both established and newly proposed benchmarks. The model adheres to the central dogma of molecular biology, accurately generating protein-coding sequences that translate into proteins structurally analogous to known families. It also shows significant promise in sequence optimization, particularly through the prompt-responsive generation of enhancer sequences with specific activity profiles. These capabilities position the GENERator as a pivotal tool for genomic research and biotechnological advancement, enhancing our ability to interpret and predict complex biological systems and enabling precise genomic interventions. Implementation details and supplementary resources are available at https://github.com/GenerTeam/GENERator.
<div id='section'>Paperid: <span id='pid'>66, <a href='https://arxiv.org/pdf/2502.06999.pdf' target='_blank'>https://arxiv.org/pdf/2502.06999.pdf</a></span>   <span><a href='https://github.com/HyperPotatoNeo/Outsourced_Diffusion_Sampling' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddarth Venkatraman, Mohsin Hasan, Minsu Kim, Luca Scimeca, Marcin Sendera, Yoshua Bengio, Glen Berseth, Nikolay Malkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06999">Outsourced diffusion sampling: Efficient posterior inference in latent spaces of generative models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Any well-behaved generative model over a variable $\mathbf{x}$ can be expressed as a deterministic transformation of an exogenous ('outsourced') Gaussian noise variable $\mathbf{z}$: $\mathbf{x}=f_Î¸(\mathbf{z})$. In such a model (\eg, a VAE, GAN, or continuous-time flow-based model), sampling of the target variable $\mathbf{x} \sim p_Î¸(\mathbf{x})$ is straightforward, but sampling from a posterior distribution of the form $p(\mathbf{x}\mid\mathbf{y}) \propto p_Î¸(\mathbf{x})r(\mathbf{x},\mathbf{y})$, where $r$ is a constraint function depending on an auxiliary variable $\mathbf{y}$, is generally intractable. We propose to amortize the cost of sampling from such posterior distributions with diffusion models that sample a distribution in the noise space ($\mathbf{z}$). These diffusion samplers are trained by reinforcement learning algorithms to enforce that the transformed samples $f_Î¸(\mathbf{z})$ are distributed according to the posterior in the data space ($\mathbf{x}$). For many models and constraints, the posterior in noise space is smoother than in data space, making it more suitable for amortized inference. Our method enables conditional sampling under unconditional GAN, (H)VAE, and flow-based priors, comparing favorably with other inference methods. We demonstrate the proposed outsourced diffusion sampling in several experiments with large pretrained prior models: conditional image generation, reinforcement learning with human feedback, and protein structure generation.
<div id='section'>Paperid: <span id='pid'>67, <a href='https://arxiv.org/pdf/2502.06379.pdf' target='_blank'>https://arxiv.org/pdf/2502.06379.pdf</a></span>   <span><a href='https://github.com/filipekstrm/ddsmc' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Filip EkstrÃ¶m Kelvinius, Zheng Zhao, Fredrik Lindsten
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06379">Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A recent line of research has exploited pre-trained generative diffusion models as priors for solving Bayesian inverse problems. We contribute to this research direction by designing a sequential Monte Carlo method for linear-Gaussian inverse problems which builds on "decoupled diffusion", where the generative process is designed such that larger updates to the sample are possible. The method is asymptotically exact and we demonstrate the effectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC) algorithm on both synthetic as well as protein and image data. Further, we demonstrate how the approach can be extended to discrete data.
<div id='section'>Paperid: <span id='pid'>68, <a href='https://arxiv.org/pdf/2502.05107.pdf' target='_blank'>https://arxiv.org/pdf/2502.05107.pdf</a></span>   <span><a href='https://github.com/HXYfighter/3DMolFormer' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiuyuan Hu, Guoqing Liu, Can Chen, Yang Zhao, Hao Zhang, Xue Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.05107">3DMolFormer: A Dual-channel Framework for Structure-based Drug Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug discovery, encompassing the tasks of protein-ligand docking and pocket-aware 3D drug design, represents a core challenge in drug discovery. However, no existing work can deal with both tasks to effectively leverage the duality between them, and current methods for each task are hindered by challenges in modeling 3D information and the limitations of available data. To address these issues, we propose 3DMolFormer, a unified dual-channel transformer-based framework applicable to both docking and 3D drug design tasks, which exploits their duality by utilizing docking functionalities within the drug design process. Specifically, we represent 3D pocket-ligand complexes using parallel sequences of discrete tokens and continuous numbers, and we design a corresponding dual-channel transformer model to handle this format, thereby overcoming the challenges of 3D information modeling. Additionally, we alleviate data limitations through large-scale pre-training on a mixed dataset, followed by supervised and reinforcement learning fine-tuning techniques respectively tailored for the two tasks. Experimental results demonstrate that 3DMolFormer outperforms previous approaches in both protein-ligand docking and pocket-aware 3D drug design, highlighting its promising application in structure-based drug discovery. The code is available at: https://github.com/HXYfighter/3DMolFormer .
<div id='section'>Paperid: <span id='pid'>69, <a href='https://arxiv.org/pdf/2501.18278.pdf' target='_blank'>https://arxiv.org/pdf/2501.18278.pdf</a></span>   <span><a href='https://github.com/amitaysicherman/ReactEmbed' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Amitay Sicherman, Kira Radinsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18278">ReactEmbed: A Cross-Domain Framework for Protein-Molecule Representation Learning via Biochemical Reaction Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The challenge in computational biology and drug discovery lies in creating comprehensive representations of proteins and molecules that capture their intrinsic properties and interactions. Traditional methods often focus on unimodal data, such as protein sequences or molecular structures, limiting their ability to capture complex biochemical relationships. This work enhances these representations by integrating biochemical reactions encompassing interactions between molecules and proteins. By leveraging reaction data alongside pre-trained embeddings from state-of-the-art protein and molecule models, we develop ReactEmbed, a novel method that creates a unified embedding space through contrastive learning. We evaluate ReactEmbed across diverse tasks, including drug-target interaction, protein-protein interaction, protein property prediction, and molecular property prediction, consistently surpassing all current state-of-the-art models. Notably, we showcase ReactEmbed's practical utility through successful implementation in lipid nanoparticle-based drug delivery, enabling zero-shot prediction of blood-brain barrier permeability for protein-nanoparticle complexes. The code and comprehensive database of reaction pairs are available for open use at \href{https://github.com/amitaysicherman/ReactEmbed}{GitHub}.
<div id='section'>Paperid: <span id='pid'>70, <a href='https://arxiv.org/pdf/2501.15631.pdf' target='_blank'>https://arxiv.org/pdf/2501.15631.pdf</a></span>   <span><a href='https://github.com/khodabandeh-ali/BoKDiff.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Khodabandeh Yalabadi, Mehdi Yazdani-Jahromi, Ozlem Ozmen Garibay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15631">BoKDiff: Best-of-K Diffusion Alignment for Target-Specific 3D Molecule Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug design (SBDD) leverages the 3D structure of biomolecular targets to guide the creation of new therapeutic agents. Recent advances in generative models, including diffusion models and geometric deep learning, have demonstrated promise in optimizing ligand generation. However, the scarcity of high-quality protein-ligand complex data and the inherent challenges in aligning generated ligands with target proteins limit the effectiveness of these methods. We propose BoKDiff, a novel framework that enhances ligand generation by combining multi-objective optimization and Best-of-K alignment methodologies. Built upon the DecompDiff model, BoKDiff generates diverse candidates and ranks them using a weighted evaluation of molecular properties such as QED, SA, and docking scores. To address alignment challenges, we introduce a method that relocates the center of mass of generated ligands to their docking poses, enabling accurate sub-component extraction. Additionally, we integrate a Best-of-N (BoN) sampling approach, which selects the optimal ligand from multiple generated candidates without requiring fine-tuning. BoN achieves exceptional results, with QED values exceeding 0.6, SA scores above 0.75, and a success rate surpassing 35%, demonstrating its efficiency and practicality. BoKDiff achieves state-of-the-art results on the CrossDocked2020 dataset, including a -8.58 average Vina docking score and a 26% success rate in molecule generation. This study is the first to apply Best-of-K alignment and Best-of-N sampling to SBDD, highlighting their potential to bridge generative modeling with practical drug discovery requirements. The code is provided at https://github.com/khodabandeh-ali/BoKDiff.git.
<div id='section'>Paperid: <span id='pid'>71, <a href='https://arxiv.org/pdf/2501.12706.pdf' target='_blank'>https://arxiv.org/pdf/2501.12706.pdf</a></span>   <span><a href='https://github.com/renero/causalgraph' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jesus Renero, Idoia Ochoa, Roberto Maestre
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12706">REX: Causal Discovery based on Machine Learning and Explainability techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explainability techniques hold significant potential for enhancing the causal discovery process, which is crucial for understanding complex systems in areas like healthcare, economics, and artificial intelligence. However, no causal discovery methods currently incorporate explainability into their models to derive causal graphs. Thus, in this paper we explore this innovative approach, as it offers substantial potential and represents a promising new direction worth investigating. Specifically, we introduce REX, a causal discovery method that leverages machine learning (ML) models coupled with explainability techniques, specifically Shapley values, to identify and interpret significant causal relationships among variables.
  Comparative evaluations on synthetic datasets comprising continuous tabular data reveal that REX outperforms state-of-the-art causal discovery methods across diverse data generation processes, including non-linear and additive noise models. Moreover, REX was tested on the Sachs single-cell protein-signaling dataset, achieving a precision of 0.952 and recovering key causal relationships with no incorrect edges. Taking together, these results showcase REX's effectiveness in accurately recovering true causal structures while minimizing false positive predictions, its robustness across diverse datasets, and its applicability to real-world problems. By combining ML and explainability techniques with causal discovery, REX bridges the gap between predictive modeling and causal inference, offering an effective tool for understanding complex causal structures. REX is publicly available at https://github.com/renero/causalgraph.
<div id='section'>Paperid: <span id='pid'>72, <a href='https://arxiv.org/pdf/2501.09685.pdf' target='_blank'>https://arxiv.org/pdf/2501.09685.pdf</a></span>   <span><a href='https://github.com/masa-ue/AlignInversePro' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Masatoshi Uehara, Yulai Zhao, Chenyu Wang, Xiner Li, Aviv Regev, Sergey Levine, Tommaso Biancalani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.09685">Inference-Time Alignment in Diffusion Models with Reward-Guided Generation: Tutorial and Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This tutorial provides an in-depth guide on inference-time guidance and alignment methods for optimizing downstream reward functions in diffusion models. While diffusion models are renowned for their generative modeling capabilities, practical applications in fields such as biology often require sample generation that maximizes specific metrics (e.g., stability, affinity in proteins, closeness to target structures). In these scenarios, diffusion models can be adapted not only to generate realistic samples but also to explicitly maximize desired measures at inference time without fine-tuning. This tutorial explores the foundational aspects of such inference-time algorithms. We review these methods from a unified perspective, demonstrating that current techniques -- such as Sequential Monte Carlo (SMC)-based guidance, value-based sampling, and classifier guidance -- aim to approximate soft optimal denoising processes (a.k.a. policies in RL) that combine pre-trained denoising processes with value functions serving as look-ahead functions that predict from intermediate states to terminal rewards. Within this framework, we present several novel algorithms not yet covered in the literature. Furthermore, we discuss (1) fine-tuning methods combined with inference-time techniques, (2) inference-time algorithms based on search algorithms such as Monte Carlo tree search, which have received limited attention in current research, and (3) connections between inference-time algorithms in language models and diffusion models. The code of this tutorial on protein design is available at https://github.com/masa-ue/AlignInversePro
<div id='section'>Paperid: <span id='pid'>73, <a href='https://arxiv.org/pdf/2501.09064.pdf' target='_blank'>https://arxiv.org/pdf/2501.09064.pdf</a></span>   <span><a href='https://github.com/kantamasuki/RGDM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kanta Masuki, Yuto Ashida
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.09064">Generative diffusion model with inverse renormalization group flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models represent a class of generative models that produce data by denoising a sample corrupted by white noise. Despite the success of diffusion models in computer vision, audio synthesis, and point cloud generation, so far they overlook inherent multiscale structures in data and have a slow generation process due to many iteration steps. In physics, the renormalization group offers a fundamental framework for linking different scales and giving an accurate coarse-grained model. Here we introduce a renormalization group-based diffusion model that leverages multiscale nature of data distributions for realizing a high-quality data generation. In the spirit of renormalization group procedures, we define a flow equation that progressively erases data information from fine-scale details to coarse-grained structures. Through reversing the renormalization group flows, our model is able to generate high-quality samples in a coarse-to-fine manner. We validate the versatility of the model through applications to protein structure prediction and image generation. Our model consistently outperforms conventional diffusion models across standard evaluation metrics, enhancing sample quality and/or accelerating sampling speed by an order of magnitude. The proposed method alleviates the need for data-dependent tuning of hyperparameters in the generative diffusion models, showing promise for systematically increasing sample efficiency based on the concept of the renormalization group.
<div id='section'>Paperid: <span id='pid'>74, <a href='https://arxiv.org/pdf/2501.06848.pdf' target='_blank'>https://arxiv.org/pdf/2501.06848.pdf</a></span>   <span><a href='https://github.com/zacharyhorvitz/Fk-Diffusion-Steering' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Raghav Singhal, Zachary Horvitz, Ryan Teehan, Mengye Ren, Zhou Yu, Kathleen McKeown, Rajesh Ranganath
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06848">A General Framework for Inference-time Scaling and Steering of Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models produce impressive results in modalities ranging from images and video to protein design and text. However, generating samples with user-specified properties remains a challenge. Recent research proposes fine-tuning models to maximize rewards that capture desired properties, but these methods require expensive training and are prone to mode collapse. In this work, we present Feynman-Kac (FK) steering, an inference-time framework for steering diffusion models with reward functions. FK steering works by sampling a system of multiple interacting diffusion processes, called particles, and resampling particles at intermediate steps based on scores computed using functions called potentials. Potentials are defined using rewards for intermediate states and are selected such that a high value indicates that the particle will yield a high-reward sample. We explore various choices of potentials, intermediate rewards, and samplers. We evaluate FK steering on text-to-image and text diffusion models. For steering text-to-image models with a human preference reward, we find that FK steering a 0.8B parameter model outperforms a 2.6B parameter fine-tuned model on prompt fidelity, with faster sampling and no training. For steering text diffusion models with rewards for text quality and specific text attributes, we find that FK steering generates lower perplexity, more linguistically acceptable outputs and enables gradient-free control of attributes like toxicity. Our results demonstrate that inference-time scaling and steering of diffusion models - even with off-the-shelf rewards - can provide significant sample quality gains and controllability benefits. Code is available at https://github.com/zacharyhorvitz/Fk-Diffusion-Steering .
<div id='section'>Paperid: <span id='pid'>75, <a href='https://arxiv.org/pdf/2501.05644.pdf' target='_blank'>https://arxiv.org/pdf/2501.05644.pdf</a></span>   <span><a href='https://github.com/yangzhao1230/ProtDETR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhao Yang, Bing Su, Jiahao Chen, Ji-Rong Wen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.05644">Interpretable Enzyme Function Prediction via Residue-Level Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting multiple functions labeled with Enzyme Commission (EC) numbers from the enzyme sequence is of great significance but remains a challenge due to its sparse multi-label classification nature, i.e., each enzyme is typically associated with only a few labels out of more than 6000 possible EC numbers. However, existing machine learning algorithms generally learn a fixed global representation for each enzyme to classify all functions, thereby they lack interpretability and the fine-grained information of some function-specific local residue fragments may be overwhelmed. Here we present an attention-based framework, namely ProtDETR (Protein Detection Transformer), by casting enzyme function prediction as a detection problem. It uses a set of learnable functional queries to adaptatively extract different local representations from the sequence of residue-level features for predicting different EC numbers. ProtDETR not only significantly outperforms existing deep learning-based enzyme function prediction methods, but also provides a new interpretable perspective on automatically detecting different local regions for identifying different functions through cross-attentions between queries and residue-level features. Code is available at https://github.com/yangzhao1230/ProtDETR.
<div id='section'>Paperid: <span id='pid'>76, <a href='https://arxiv.org/pdf/2501.01458.pdf' target='_blank'>https://arxiv.org/pdf/2501.01458.pdf</a></span>   <span><a href='https://github.com/george-yuanji-wang/GAN-TAT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>George Yuanji Wang, Srisharan Murugesan, Aditya Prince Rohatgi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01458">GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying druggable genes is essential for developing effective pharmaceuticals. With the availability of extensive, high-quality data, computational methods have become a significant asset. Protein Interaction Network (PIN) is valuable but challenging to implement due to its high dimensionality and sparsity. Previous methods relied on indirect integration, leading to resolution loss. This study proposes GAN-TAT, a framework utilizing an advanced graph embedding technology, ImGAGN, to directly integrate PIN for druggable gene inference work. Tested on three Pharos datasets, GAN-TAT achieved the highest AUC-ROC score of 0.951 on Tclin. Further evaluation shows that GAN-TAT's predictions are supported by clinical evidence, highlighting its potential practical applications in pharmacogenomics. This research represents a methodological attempt with the direct utilization of PIN, expanding potential new solutions for developing drug targets. The source code of GAN-TAT is available at (https://github.com/george-yuanji-wang/GAN-TAT).
<div id='section'>Paperid: <span id='pid'>77, <a href='https://arxiv.org/pdf/2412.10966.pdf' target='_blank'>https://arxiv.org/pdf/2412.10966.pdf</a></span>   <span><a href='https://github.com/BioinfoMachineLearning/FlowDock' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/BioinfoMachineLearning/FlowDock' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Morehead, Jianlin Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.10966">FlowDock: Geometric Flow Matching for Generative Protein-Ligand Docking and Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Powerful generative AI models of protein-ligand structure have recently been proposed, but few of these methods support both flexible protein-ligand docking and affinity estimation. Of those that do, none can directly model multiple binding ligands concurrently or have been rigorously benchmarked on pharmacologically relevant drug targets, hindering their widespread adoption in drug discovery efforts. In this work, we propose FlowDock, the first deep geometric generative model based on conditional flow matching that learns to directly map unbound (apo) structures to their bound (holo) counterparts for an arbitrary number of binding ligands. Furthermore, FlowDock provides predicted structural confidence scores and binding affinity values with each of its generated protein-ligand complex structures, enabling fast virtual screening of new (multi-ligand) drug targets. For the well-known PoseBusters Benchmark dataset, FlowDock outperforms single-sequence AlphaFold 3 with a 51% blind docking success rate using unbound (apo) protein input structures and without any information derived from multiple sequence alignments, and for the challenging new DockGen-E dataset, FlowDock outperforms single-sequence AlphaFold 3 and matches single-sequence Chai-1 for binding pocket generalization. Additionally, in the ligand category of the 16th community-wide Critical Assessment of Techniques for Structure Prediction (CASP16), FlowDock ranked among the top-5 methods for pharmacological binding affinity estimation across 140 protein-ligand complexes, demonstrating the efficacy of its learned representations in virtual screening. Source code, data, and pre-trained models are available at https://github.com/BioinfoMachineLearning/FlowDock.
<div id='section'>Paperid: <span id='pid'>78, <a href='https://arxiv.org/pdf/2412.08649.pdf' target='_blank'>https://arxiv.org/pdf/2412.08649.pdf</a></span>   <span><a href='https://github.com/kansil/HOPER' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>SerbÃ¼lent Ãnsal, Sinem Ãzdemir, BÃ¼nyamin Kasap, M. ErÅan KalaycÄ±, Kemal Turhan, Tunca DoÄan, Aybar C. Acar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.08649">Multi-modal Representation Learning Enables Accurate Protein Function Prediction in Low-Data Setting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we propose HOPER (HOlistic ProtEin Representation), a novel multimodal learning framework designed to enhance protein function prediction (PFP) in low-data settings. The challenge of predicting protein functions is compounded by the limited availability of labeled data. Traditional machine learning models already struggle in such cases, and while deep learning models excel with abundant data, they also face difficulties when data is scarce. HOPER addresses this issue by integrating three distinct modalities - protein sequences, biomedical text, and protein-protein interaction (PPI) networks - to create a comprehensive protein representation. The model utilizes autoencoders to generate holistic embeddings, which are then employed for PFP tasks using transfer learning. HOPER outperforms existing methods on a benchmark dataset across all Gene Ontology categories, i.e., molecular function, biological process, and cellular component. Additionally, we demonstrate its practical utility by identifying new immune-escape proteins in lung adenocarcinoma, offering insights into potential therapeutic targets. Our results highlight the effectiveness of multimodal representation learning for overcoming data limitations in biological research, potentially enabling more accurate and scalable protein function prediction. HOPER source code and datasets are available at https://github.com/kansil/HOPER
<div id='section'>Paperid: <span id='pid'>79, <a href='https://arxiv.org/pdf/2412.05788.pdf' target='_blank'>https://arxiv.org/pdf/2412.05788.pdf</a></span>   <span><a href='https://github.com/matsagad/mres-project' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>James Matthew Young, O. Deniz Akyildiz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05788">On Diffusion Posterior Sampling via Sequential Monte Carlo for Zero-Shot Scaffolding of Protein Motifs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the advent of diffusion models, new proteins can be generated at an unprecedented rate. The \textit{motif scaffolding problem} requires steering this generative process to yield proteins with a desirable functional substructure -- a motif. While models have been trained to take the motif as conditional input, recent techniques in diffusion posterior sampling can be leveraged as zero-shot alternatives whose approximations can be corrected with sequential Monte Carlo (SMC) algorithms. In this work, we introduce a new set of guidance potentials to describe and solve scaffolding tasks by adapting SMC-aided diffusion posterior samplers with an unconditional model, Genie, acting as a prior. Against established benchmarks, we successfully scaffold several single-motif and multi-motif problems. The latter is possible by pairing reconstruction guidance with $\mathrm{SE}(3)$-invariant potentials. In the single-motif case, we find these potentials perform comparably to the conventional masking approach and that reconstruction guidance outperforms replacement methods when aided with SMC. We additionally consider a guidance potential for point symmetry constraints and produce designable internally symmetric monomers with our setup. Overall, this work highlights the capabilities and areas for improvement of zero-shot posterior samplers in motif scaffolding tasks. Code is available at: https://github.com/matsagad/mres-project
<div id='section'>Paperid: <span id='pid'>80, <a href='https://arxiv.org/pdf/2412.05430.pdf' target='_blank'>https://arxiv.org/pdf/2412.05430.pdf</a></span>   <span><a href='https://github.com/kundajelab/DART-Eval' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Aman Patel, Arpita Singhal, Austin Wang, Anusri Pampari, Maya Kasowski, Anshul Kundaje
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05430">DART-Eval: A Comprehensive DNA Language Model Evaluation Benchmark on Regulatory DNA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in self-supervised models for natural language, vision, and protein sequences have inspired the development of large genomic DNA language models (DNALMs). These models aim to learn generalizable representations of diverse DNA elements, potentially enabling various genomic prediction, interpretation and design tasks. Despite their potential, existing benchmarks do not adequately assess the capabilities of DNALMs on key downstream applications involving an important class of non-coding DNA elements critical for regulating gene activity. In this study, we introduce DART-Eval, a suite of representative benchmarks specifically focused on regulatory DNA to evaluate model performance across zero-shot, probed, and fine-tuned scenarios against contemporary ab initio models as baselines. Our benchmarks target biologically meaningful downstream tasks such as functional sequence feature discovery, predicting cell-type specific regulatory activity, and counterfactual prediction of the impacts of genetic variants. We find that current DNALMs exhibit inconsistent performance and do not offer compelling gains over alternative baseline models for most tasks, while requiring significantly more computational resources. We discuss potentially promising modeling, data curation, and evaluation strategies for the next generation of DNALMs. Our code is available at https://github.com/kundajelab/DART-Eval.
<div id='section'>Paperid: <span id='pid'>81, <a href='https://arxiv.org/pdf/2412.01108.pdf' target='_blank'>https://arxiv.org/pdf/2412.01108.pdf</a></span>   <span><a href='https://github.com/DeepGraphLearning/S3F' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zuobai Zhang, Pascal Notin, Yining Huang, AurÃ©lie Lozano, Vijil Chenthamarakshan, Debora Marks, Payel Das, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01108">Multi-Scale Representation Learning for Protein Fitness Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing novel functional proteins crucially depends on accurately modeling their fitness landscape. Given the limited availability of functional annotations from wet-lab experiments, previous methods have primarily relied on self-supervised models trained on vast, unlabeled protein sequence or structure datasets. While initial protein representation learning studies solely focused on either sequence or structural features, recent hybrid architectures have sought to merge these modalities to harness their respective strengths. However, these sequence-structure models have so far achieved only incremental improvements when compared to the leading sequence-only approaches, highlighting unresolved challenges effectively leveraging these modalities together. Moreover, the function of certain proteins is highly dependent on the granular aspects of their surface topology, which have been overlooked by prior models. To address these limitations, we introduce the Sequence-Structure-Surface Fitness (S3F) model - a novel multimodal representation learning framework that integrates protein features across several scales. Our approach combines sequence representations from a protein language model with Geometric Vector Perceptron networks encoding protein backbone and detailed surface topology. The proposed method achieves state-of-the-art fitness prediction on the ProteinGym benchmark encompassing 217 substitution deep mutational scanning assays, and provides insights into the determinants of protein function. Our code is at https://github.com/DeepGraphLearning/S3F.
<div id='section'>Paperid: <span id='pid'>82, <a href='https://arxiv.org/pdf/2411.18463.pdf' target='_blank'>https://arxiv.org/pdf/2411.18463.pdf</a></span>   <span><a href='https://github.com/Ced3-han/PepHAR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahan Li, Tong Chen, Shitong Luo, Chaoran Cheng, Jiaqi Guan, Ruihan Guo, Sheng Wang, Ge Liu, Jian Peng, Jianzhu Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.18463">Hotspot-Driven Peptide Design via Multi-Fragment Autoregressive Extension</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Peptides, short chains of amino acids, interact with target proteins, making them a unique class of protein-based therapeutics for treating human diseases. Recently, deep generative models have shown great promise in peptide generation. However, several challenges remain in designing effective peptide binders. First, not all residues contribute equally to peptide-target interactions. Second, the generated peptides must adopt valid geometries due to the constraints of peptide bonds. Third, realistic tasks for peptide drug development are still lacking. To address these challenges, we introduce PepHAR, a hot-spot-driven autoregressive generative model for designing peptides targeting specific proteins. Building on the observation that certain hot spot residues have higher interaction potentials, we first use an energy-based density model to fit and sample these key residues. Next, to ensure proper peptide geometry, we autoregressively extend peptide fragments by estimating dihedral angles between residue frames. Finally, we apply an optimization process to iteratively refine fragment assembly, ensuring correct peptide structures. By combining hot spot sampling with fragment-based extension, our approach enables de novo peptide design tailored to a target protein and allows the incorporation of key hot spot residues into peptide scaffolds. Extensive experiments, including peptide design and peptide scaffold generation, demonstrate the strong potential of PepHAR in computational peptide binder design. Source code will be available at https://github.com/Ced3-han/PepHAR.
<div id='section'>Paperid: <span id='pid'>83, <a href='https://arxiv.org/pdf/2411.17196.pdf' target='_blank'>https://arxiv.org/pdf/2411.17196.pdf</a></span>   <span><a href='https://github.com/BLEACH366/P2DFlow' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaowei Jin, Qi Huang, Ziyang Song, Mingyue Zheng, Dan Teng, Qian Shi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17196">P2DFlow: A Protein Ensemble Generative Model with SE(3) Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biological processes, functions, and properties are intricately linked to the ensemble of protein conformations, rather than being solely determined by a single stable conformation. In this study, we have developed P2DFlow, a generative model based on SE(3) flow matching, to predict the structural ensembles of proteins. We specifically designed a valuable prior for the flow process and enhanced the model's ability to distinguish each intermediate state by incorporating an additional dimension to describe the ensemble data, which can reflect the physical laws governing the distribution of ensembles, so that the prior knowledge can effectively guide the generation process. When trained and evaluated on the MD datasets of ATLAS, P2DFlow outperforms other baseline models on extensive experiments, successfully capturing the observable dynamic fluctuations as evidenced in crystal structure and MD simulations. As a potential proxy agent for protein molecular simulation, the high-quality ensembles generated by P2DFlow could significantly aid in understanding protein functions across various scenarios. Code is available at https://github.com/BLEACH366/P2DFlow
<div id='section'>Paperid: <span id='pid'>84, <a href='https://arxiv.org/pdf/2411.16694.pdf' target='_blank'>https://arxiv.org/pdf/2411.16694.pdf</a></span>   <span><a href='https://github.com/WillHua127/GENzyme' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenqing Hua, Jiarui Lu, Yong Liu, Odin Zhang, Jian Tang, Rex Ying, Wengong Jin, Guy Wolf, Doina Precup, Shuangjia Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16694">Reaction-conditioned De Novo Enzyme Design with GENzyme</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The introduction of models like RFDiffusionAA, AlphaFold3, AlphaProteo, and Chai1 has revolutionized protein structure modeling and interaction prediction, primarily from a binding perspective, focusing on creating ideal lock-and-key models. However, these methods can fall short for enzyme-substrate interactions, where perfect binding models are rare, and induced fit states are more common. To address this, we shift to a functional perspective for enzyme design, where the enzyme function is defined by the reaction it catalyzes. Here, we introduce \textsc{GENzyme}, a \textit{de novo} enzyme design model that takes a catalytic reaction as input and generates the catalytic pocket, full enzyme structure, and enzyme-substrate binding complex. \textsc{GENzyme} is an end-to-end, three-staged model that integrates (1) a catalytic pocket generation and sequence co-design module, (2) a pocket inpainting and enzyme inverse folding module, and (3) a binding and screening module to optimize and predict enzyme-substrate complexes. The entire design process is driven by the catalytic reaction being targeted. This reaction-first approach allows for more accurate and biologically relevant enzyme design, potentially surpassing structure-based and binding-focused models in creating enzymes capable of catalyzing specific reactions. We provide \textsc{GENzyme} code at https://github.com/WillHua127/GENzyme.
<div id='section'>Paperid: <span id='pid'>85, <a href='https://arxiv.org/pdf/2411.13280.pdf' target='_blank'>https://arxiv.org/pdf/2411.13280.pdf</a></span>   <span><a href='https://github.com/AlgoMole/MolCRAFT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Keyue Qiu, Yuxuan Song, Jie Yu, Hongbo Ma, Ziyao Cao, Zhilong Zhang, Yushuai Wu, Mingyue Zheng, Hao Zhou, Wei-Ying Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.13280">Empower Structure-Based Molecule Optimization with Gradient Guided Bayesian Flow Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-Based molecule optimization (SBMO) aims to optimize molecules with both continuous coordinates and discrete types against protein targets. A promising direction is to exert gradient guidance on generative models given its remarkable success in images, but it is challenging to guide discrete data and risks inconsistencies between modalities. To this end, we leverage a continuous and differentiable space derived through Bayesian inference, presenting Molecule Joint Optimization (MolJO), the gradient-based SBMO framework that facilitates joint guidance signals across different modalities while preserving SE(3)-equivariance. We introduce a novel backward correction strategy that optimizes within a sliding window of the past histories, allowing for a seamless trade-off between explore-and-exploit during optimization. MolJO achieves state-of-the-art performance on CrossDocked2020 benchmark (Success Rate 51.3%, Vina Dock -9.05 and SA 0.78), more than 4x improvement in Success Rate compared to the gradient-based counterpart, and 2x "Me-Better" Ratio as much as 3D baselines. Furthermore, we extend MolJO to a wide range of optimization settings, including multi-objective optimization and challenging tasks in drug design such as R-group optimization and scaffold hopping, further underscoring its versatility. Code is available at https://github.com/AlgoMole/MolCRAFT.
<div id='section'>Paperid: <span id='pid'>86, <a href='https://arxiv.org/pdf/2411.10618.pdf' target='_blank'>https://arxiv.org/pdf/2411.10618.pdf</a></span>   <span><a href='https://github.com/smiles724/PeptideDesign' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Fang Wu, Tinson Xu, Shuting Jin, Xiangru Tang, Zerui Xu, James Zou, Brian Hie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.10618">D-Flow: Multi-modality Flow Matching for D-peptide Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins play crucial roles in biological processes, with therapeutic peptides emerging as promising pharmaceutical agents. They allow new possibilities to leverage target binding sites that were previously undruggable. While deep learning (DL) has advanced peptide discovery, generating D-proteins composed of D-amino acids remains challenging due to the scarcity of natural examples. This paper proposes D-Flow, a full-atom flow-based framework for {de novo} D-peptide design. D-Flow is conditioned on receptor binding and utilizes a comprehensive representation of peptide structure, incorporating backbone frames, side-chain angles, and discrete amino acid types. A mirror-image algorithm is implemented to address the lack of training data for D-proteins, which converts L-receptors' chirality. Furthermore, we enhance D-Flow's capacity by integrating large protein language models (PLMs) with structural awareness through a lightweight structural adapter. A two-stage training pipeline and a controlling toolkit also enable D-Flow to transition from general protein design to targeted binder design while preserving pretraining knowledge.
  Extensive experimental results on the PepMerge benchmark demonstrate D-Flow's effectiveness, particularly in developing peptides with entire D-residues. This approach represents a significant advancement in computational D-peptide design, offering unique opportunities for bioorthogonal and stable molecular tools and diagnostics. The code is available in~\url{https://github.com/smiles724/PeptideDesign}.
<div id='section'>Paperid: <span id='pid'>87, <a href='https://arxiv.org/pdf/2411.08909.pdf' target='_blank'>https://arxiv.org/pdf/2411.08909.pdf</a></span>   <span><a href='https://github.com/amazon-science/LC-PLM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingheng Wang, Zichen Wang, Gil Sadeh, Luca Zancato, Alessandro Achille, George Karypis, Huzefa Rangwala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08909">Long-context Protein Language Modeling Using Bidirectional Mamba with Shared Projection Layers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised training of language models (LMs) has seen great success for protein sequences in learning meaningful representations and for generative drug design. Most protein LMs are based on the Transformer architecture trained on individual proteins with short context lengths. Such protein LMs cannot extrapolate to longer proteins and protein complexes well. They also fail to account for the underlying biological mechanisms carried out by biomolecular interactions and dynamics i.e., proteins often interact with other proteins, molecules, and pathways in complex biological systems. In this work, we propose LC-PLM based on an alternative protein LM architecture, BiMamba-S, built upon selective structured state-space models, to learn high-quality universal protein representations at the amino acid token level using masked language modeling. We also introduce its graph-contextual variant, LC-PLM, which contextualizes protein-protein interaction (PPI) graphs for a second stage of training. LC-PLM demonstrates favorable neural scaling laws, better length extrapolation capability, and up to 30% and 16% improvements on protein downstream tasks compared to Transformer-based ESM-2 when trained with 100B and 1T tokens, respectively. LC-PLM-G further trained within the context of PPI graphs shows promising results on protein structure and function prediction tasks. Our study demonstrates the benefit of increasing the context size with computationally efficient LM architecture (e.g., structured state space models) in learning universal protein representations and incorporating molecular interaction contexts contained in biological graphs.
<div id='section'>Paperid: <span id='pid'>88, <a href='https://arxiv.org/pdf/2411.05316.pdf' target='_blank'>https://arxiv.org/pdf/2411.05316.pdf</a></span>   <span><a href='https://github.com/Tizzzzy/LLM-GDM-alignment' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dong Shu, Bingbing Duan, Kai Guo, Kaixiong Zhou, Jiliang Tang, Mengnan Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05316">Aligning Large Language Models and Geometric Deep Models for Protein Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Latent representation alignment has become a foundational technique for constructing multimodal large language models (MLLM) by mapping embeddings from different modalities into a shared space, often aligned with the embedding space of large language models (LLMs) to enable effective cross-modal understanding. While preliminary protein-focused MLLMs have emerged, they have predominantly relied on heuristic approaches, lacking a fundamental understanding of optimal alignment practices across representations. In this study, we explore the alignment of multimodal representations between LLMs and Geometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate three state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with four protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines alignment factors from both model and protein perspectives, identifying challenges in current alignment methodologies and proposing strategies to improve the alignment process. Our key findings reveal that GDMs incorporating both graph and 3D structural information align better with LLMs, larger LLMs demonstrate improved alignment capabilities, and protein rarity significantly impacts alignment performance. We also find that increasing GDM embedding dimensions, using two-layer projection heads, and fine-tuning LLMs on protein-specific data substantially enhance alignment quality. These strategies offer potential enhancements to the performance of protein-related multimodal models. Our code and data are available at https://github.com/Tizzzzy/LLM-GDM-alignment.
<div id='section'>Paperid: <span id='pid'>89, <a href='https://arxiv.org/pdf/2411.02142.pdf' target='_blank'>https://arxiv.org/pdf/2411.02142.pdf</a></span>   <span><a href='https://github.com/cxysteven/ScalingProteinLM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyi Cheng, Bo Chen, Pan Li, Jing Gong, Jie Tang, Le Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.02142">Training Compute-Optimal Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We explore optimally training protein language models, an area of significant interest in biological research where guidance on best practices is limited. Most models are trained with extensive compute resources until performance gains plateau, focusing primarily on increasing model sizes rather than optimizing the efficient compute frontier that balances performance and compute budgets. Our investigation is grounded in a massive dataset consisting of 939 million protein sequences. We trained over 300 models ranging from 3.5 million to 10.7 billion parameters on 5 to 200 billion unique tokens, to investigate the relations between model sizes, training token numbers, and objectives. First, we observed the effect of diminishing returns for the Causal Language Model (CLM) and that of overfitting for the Masked Language Model~(MLM) when repeating the commonly used Uniref database. To address this, we included metagenomic protein sequences in the training set to increase the diversity and avoid the plateau or overfitting effects. Second, we obtained the scaling laws of CLM and MLM on Transformer, tailored to the specific characteristics of protein sequence data. Third, we observe a transfer scaling phenomenon from CLM to MLM, further demonstrating the effectiveness of transfer through scaling behaviors based on estimated Effectively Transferred Tokens. Finally, to validate our scaling laws, we compare the large-scale versions of ESM-2 and PROGEN2 on downstream tasks, encompassing evaluations of protein generation as well as structure- and function-related tasks, all within less or equivalent pre-training compute budgets.
<div id='section'>Paperid: <span id='pid'>90, <a href='https://arxiv.org/pdf/2411.02120.pdf' target='_blank'>https://arxiv.org/pdf/2411.02120.pdf</a></span>   <span><a href='https://github.com/violet-sto/Bridge-IF' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiheng Zhu, Jialu Wu, Qiuyi Li, Jiahuan Yan, Mingze Yin, Wei Wu, Mingyang Li, Jieping Ye, Zheng Wang, Jian Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.02120">Bridge-IF: Learning Inverse Protein Folding with Markov Bridges</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse protein folding is a fundamental task in computational protein design, which aims to design protein sequences that fold into the desired backbone structures. While the development of machine learning algorithms for this task has seen significant success, the prevailing approaches, which predominantly employ a discriminative formulation, frequently encounter the error accumulation issue and often fail to capture the extensive variety of plausible sequences. To fill these gaps, we propose Bridge-IF, a generative diffusion bridge model for inverse folding, which is designed to learn the probabilistic dependency between the distributions of backbone structures and protein sequences. Specifically, we harness an expressive structure encoder to propose a discrete, informative prior derived from structures, and establish a Markov bridge to connect this prior with native sequences. During the inference stage, Bridge-IF progressively refines the prior sequence, culminating in a more plausible design. Moreover, we introduce a reparameterization perspective on Markov bridge models, from which we derive a simplified loss function that facilitates more effective training. We also modulate protein language models (PLMs) with structural conditions to precisely approximate the Markov bridge process, thereby significantly enhancing generation performance while maintaining parameter-efficient training. Extensive experiments on well-established benchmarks demonstrate that Bridge-IF predominantly surpasses existing baselines in sequence recovery and excels in the design of plausible proteins with high foldability. The code is available at https://github.com/violet-sto/Bridge-IF.
<div id='section'>Paperid: <span id='pid'>91, <a href='https://arxiv.org/pdf/2411.01856.pdf' target='_blank'>https://arxiv.org/pdf/2411.01856.pdf</a></span>   <span><a href='https://github.com/A4Bio/MeToken' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng Tan, Zhenxiao Cao, Zhangyang Gao, Lirong Wu, Siyuan Li, Yufei Huang, Jun Xia, Bozhen Hu, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.01856">MeToken: Uniform Micro-environment Token Boosts Post-Translational Modification Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Post-translational modifications (PTMs) profoundly expand the complexity and functionality of the proteome, regulating protein attributes and interactions that are crucial for biological processes. Accurately predicting PTM sites and their specific types is therefore essential for elucidating protein function and understanding disease mechanisms. Existing computational approaches predominantly focus on protein sequences to predict PTM sites, driven by the recognition of sequence-dependent motifs. However, these approaches often overlook protein structural contexts. In this work, we first compile a large-scale sequence-structure PTM dataset, which serves as the foundation for fair comparison. We introduce the MeToken model, which tokenizes the micro-environment of each amino acid, integrating both sequence and structural information into unified discrete tokens. This model not only captures the typical sequence motifs associated with PTMs but also leverages the spatial arrangements dictated by protein tertiary structures, thus providing a holistic view of the factors influencing PTM sites. Designed to address the long-tail distribution of PTM types, MeToken employs uniform sub-codebooks that ensure even the rarest PTMs are adequately represented and distinguished. We validate the effectiveness and generalizability of MeToken across multiple datasets, demonstrating its superior performance in accurately identifying PTM types. The results underscore the importance of incorporating structural data and highlight MeToken's potential in facilitating accurate and comprehensive PTM predictions, which could significantly impact proteomics research. The code and datasets are available at https://github.com/A4Bio/MeToken.
<div id='section'>Paperid: <span id='pid'>92, <a href='https://arxiv.org/pdf/2410.22949.pdf' target='_blank'>https://arxiv.org/pdf/2410.22949.pdf</a></span>   <span><a href='https://github.com/PharMolix/MutaPLM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizhen Luo, Zikun Nie, Massimo Hong, Suyuan Zhao, Hao Zhou, Zaiqing Nie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.22949">MutaPLM: Protein Language Modeling for Mutation Explanation and Engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Studying protein mutations within amino acid sequences holds tremendous significance in life sciences. Protein language models (PLMs) have demonstrated strong capabilities in broad biological applications. However, due to architectural design and lack of supervision, PLMs model mutations implicitly with evolutionary plausibility, which is not satisfactory to serve as explainable and engineerable tools in real-world studies. To address these issues, we present MutaPLM, a unified framework for interpreting and navigating protein mutations with protein language models. MutaPLM introduces a protein delta network that captures explicit protein mutation representations within a unified feature space, and a transfer learning pipeline with a chain-of-thought (CoT) strategy to harvest protein mutation knowledge from biomedical texts. We also construct MutaDescribe, the first large-scale protein mutation dataset with rich textual annotations, which provides cross-modal supervision signals. Through comprehensive experiments, we demonstrate that MutaPLM excels at providing human-understandable explanations for mutational effects and prioritizing novel mutations with desirable properties. Our code, model, and data are open-sourced at https://github.com/PharMolix/MutaPLM.
<div id='section'>Paperid: <span id='pid'>93, <a href='https://arxiv.org/pdf/2410.21283.pdf' target='_blank'>https://arxiv.org/pdf/2410.21283.pdf</a></span>   <span><a href='https://github.com/jw-chae/pLDDT_Predictor,' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Joongwon Chae, Zhenyu Wang, Ijaz Gul, Jiansong Ji, Zhenglin Chen, Peiwu Qin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21283">pLDDT-Predictor: High-speed Protein Screening Using Transformer and ESM2</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in protein structure prediction, particularly AlphaFold2, have revolutionized structural biology by achieving near-experimental accuracy ($\text{average RMSD} < 1.5\textÃ$). However, the computational demands of these models (approximately 30 minutes per protein on an RTX 4090) significantly limit their application in high-throughput protein screening. While large language models like ESM (Evolutionary Scale Modeling) have shown promise in extracting structural information directly from protein sequences, rapid assessment of protein structure quality for large-scale analyses remains a major challenge.
  We introduce pLDDT-Predictor, a high-speed protein screening tool that achieves a $250,000\times$ speedup compared to AlphaFold2 by leveraging pre-trained ESM2 protein embeddings and a Transformer architecture. Our model predicts AlphaFold2's pLDDT (predicted Local Distance Difference Test) scores with a Pearson correlation of 0.7891 and processes proteins in just 0.007 seconds on average. Using a comprehensive dataset of 1.5 million diverse protein sequences (ranging from 50 to 2048 amino acids), we demonstrate that pLDDT-Predictor accurately classifies high-confidence structures (pLDDT $>$ 70) with 91.2\% accuracy and achieves an MSE of 84.8142 compared to AlphaFold2's predictions.
  The source code and pre-trained models are freely available at https://github.com/jw-chae/pLDDT_Predictor, enabling the research community to perform rapid, large-scale protein structure quality assessments.
<div id='section'>Paperid: <span id='pid'>94, <a href='https://arxiv.org/pdf/2410.21127.pdf' target='_blank'>https://arxiv.org/pdf/2410.21127.pdf</a></span>   <span><a href='https://github.com/tyang816/ProtREM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Tan, Ruilin Wang, Banghao Wu, Liang Hong, Bingxin Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21127">Retrieval-Enhanced Mutation Mastery: Augmenting Zero-Shot Prediction of Protein Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enzyme engineering enables the modification of wild-type proteins to meet industrial and research demands by enhancing catalytic activity, stability, binding affinities, and other properties. The emergence of deep learning methods for protein modeling has demonstrated superior results at lower costs compared to traditional approaches such as directed evolution and rational design. In mutation effect prediction, the key to pre-training deep learning models lies in accurately interpreting the complex relationships among protein sequence, structure, and function. This study introduces a retrieval-enhanced protein language model for comprehensive analysis of native properties from sequence and local structural interactions, as well as evolutionary properties from retrieved homologous sequences. The state-of-the-art performance of the proposed ProtREM is validated on over 2 million mutants across 217 assays from an open benchmark (ProteinGym). We also conducted post-hoc analyses of the model's ability to improve the stability and binding affinity of a VHH antibody. Additionally, we designed 10 new mutants on a DNA polymerase and conducted wet-lab experiments to evaluate their enhanced activity at higher temperatures. Both in silico and experimental evaluations confirmed that our method provides reliable predictions of mutation effects, offering an auxiliary tool for biologists aiming to evolve existing enzymes. The implementation is publicly available at https://github.com/tyang816/ProtREM.
<div id='section'>Paperid: <span id='pid'>95, <a href='https://arxiv.org/pdf/2410.19222.pdf' target='_blank'>https://arxiv.org/pdf/2410.19222.pdf</a></span>   <span><a href='https://github.com/aayush-shah14/PeptideGPT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Aayush Shah, Chakradhar Guntuboina, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19222">Peptide-GPT: Generative Design of Peptides using Generative Pre-trained Transformers and Bio-informatic Supervision</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, natural language processing (NLP) models have demonstrated remarkable capabilities in various domains beyond traditional text generation. In this work, we introduce PeptideGPT, a protein language model tailored to generate protein sequences with distinct properties: hemolytic activity, solubility, and non-fouling characteristics. To facilitate a rigorous evaluation of these generated sequences, we established a comprehensive evaluation pipeline consisting of ideas from bioinformatics to retain valid proteins with ordered structures. First, we rank the generated sequences based on their perplexity scores, then we filter out those lying outside the permissible convex hull of proteins. Finally, we predict the structure using ESMFold and select the proteins with pLDDT values greater than 70 to ensure ordered structure. The properties of generated sequences are evaluated using task-specific classifiers - PeptideBERT and HAPPENN. We achieved an accuracy of 76.26% in hemolytic, 72.46% in non-hemolytic, 78.84% in non-fouling, and 68.06% in solubility protein generation. Our experimental results demonstrate the effectiveness of PeptideGPT in de novo protein design and underscore the potential of leveraging NLP-based approaches for paving the way for future innovations and breakthroughs in synthetic biology and bioinformatics. Codes, models, and data used in this study are freely available at: https://github.com/aayush-shah14/PeptideGPT.
<div id='section'>Paperid: <span id='pid'>96, <a href='https://arxiv.org/pdf/2410.16474.pdf' target='_blank'>https://arxiv.org/pdf/2410.16474.pdf</a></span>   <span><a href='https://github.com/aqlaboratory/QuickBind' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wojtek Treyde, Seohyun Chris Kim, Nazim Bouatta, Mohammed AlQuraishi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.16474">QuickBind: A Light-Weight And Interpretable Molecular Docking Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting a ligand's bound pose to a target protein is a key component of early-stage computational drug discovery. Recent developments in machine learning methods have focused on improving pose quality at the cost of model runtime. For high-throughput virtual screening applications, this exposes a capability gap that can be filled by moderately accurate but fast pose prediction. To this end, we developed QuickBind, a light-weight pose prediction algorithm. We assess QuickBind on widely used benchmarks and find that it provides an attractive trade-off between model accuracy and runtime. To facilitate virtual screening applications, we augment QuickBind with a binding affinity module and demonstrate its capabilities for multiple clinically-relevant drug targets. Finally, we investigate the mechanistic basis by which QuickBind makes predictions and find that it has learned key physicochemical properties of molecular docking, providing new insights into how machine learning models generate protein-ligand poses. By virtue of its simplicity, QuickBind can serve as both an effective virtual screening tool and a minimal test bed for exploring new model architectures and innovations. Model code and weights are available at https://github.com/aqlaboratory/QuickBind .
<div id='section'>Paperid: <span id='pid'>97, <a href='https://arxiv.org/pdf/2410.15592.pdf' target='_blank'>https://arxiv.org/pdf/2410.15592.pdf</a></span>   <span><a href='https://github.com/GouWenrui/CPE-Pro-main.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenrui Gou, Wenhui Ge, Yang Tan, Mingchen Li, Guisheng Fan, Huiqun Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15592">CPE-Pro: A Structure-Sensitive Deep Learning Method for Protein Representation and Origin Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structures are important for understanding their functions and interactions. Currently, many protein structure prediction methods are enriching the structure database. Discriminating the origin of structures is crucial for distinguishing between experimentally resolved and computationally predicted structures, evaluating the reliability of prediction methods, and guiding downstream biological studies. Building on works in structure prediction, We developed a structure-sensitive supervised deep learning model, Crystal vs Predicted Evaluator for Protein Structure (CPE-Pro), to represent and discriminate the origin of protein structures. CPE-Pro learns the structural information of proteins and captures inter-structural differences to achieve accurate traceability on four data classes, and is expected to be extended to more. Simultaneously, we utilized Foldseek to encode protein structures into "structure-sequences" and trained a protein Structural Sequence Language Model, SSLM. Preliminary experiments demonstrated that, compared to large-scale protein language models pre-trained on vast amounts of amino acid sequences, the "structure-sequence" enables the language model to learn more informative protein features, enhancing and optimizing structural representations. We have provided the code, model weights, and all related materials on https://github.com/GouWenrui/CPE-Pro-main.git.
<div id='section'>Paperid: <span id='pid'>98, <a href='https://arxiv.org/pdf/2410.14621.pdf' target='_blank'>https://arxiv.org/pdf/2410.14621.pdf</a></span>   <span><a href='https://github.com/prescient-design/jamun' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ameya Daigavane, Bodhi P. Vani, Darcy Davidson, Saeed Saremi, Joshua Rackers, Joseph Kleinhenz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14621">JAMUN: Bridging Smoothed Molecular Dynamics and Score-Based Learning for Conformational Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conformational ensembles of protein structures are immensely important both for understanding protein function and drug discovery in novel modalities such as cryptic pockets. Current techniques for sampling ensembles such as molecular dynamics (MD) are computationally inefficient, while many recent machine learning methods do not transfer to systems outside their training data. We propose JAMUN which performs MD in a smoothed, noised space of all-atom 3D conformations of molecules by utilizing the framework of walk-jump sampling. JAMUN enables ensemble generation for small peptides at rates of an order of magnitude faster than traditional molecular dynamics. The physical priors in JAMUN enables transferability to systems outside of its training data, even to peptides that are longer than those originally trained on. Our model, code and weights are available at https://github.com/prescient-design/jamun.
<div id='section'>Paperid: <span id='pid'>99, <a href='https://arxiv.org/pdf/2410.10083.pdf' target='_blank'>https://arxiv.org/pdf/2410.10083.pdf</a></span>   <span><a href='https://github.com/iMoonLab/LLM4Hypergraph' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Feng, Chengwu Yang, Xingliang Hou, Shaoyi Du, Shihui Ying, Zongze Wu, Yue Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10083">Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing benchmarks like NLGraph and GraphQA evaluate LLMs on graphs by focusing mainly on pairwise relationships, overlooking the high-order correlations found in real-world data. Hypergraphs, which can model complex beyond-pairwise relationships, offer a more robust framework but are still underexplored in the context of LLMs. To address this gap, we introduce LLM4Hypergraph, the first comprehensive benchmark comprising 21,500 problems across eight low-order, five high-order, and two isomorphism tasks, utilizing both synthetic and real-world hypergraphs from citation networks and protein structures. We evaluate six prominent LLMs, including GPT-4o, demonstrating our benchmark's effectiveness in identifying model strengths and weaknesses. Our specialized prompting framework incorporates seven hypergraph languages and introduces two novel techniques, Hyper-BAG and Hyper-COT, which enhance high-order reasoning and achieve an average 4% (up to 9%) performance improvement on structure classification tasks. This work establishes a foundational testbed for integrating hypergraph computational capabilities into LLMs, advancing their comprehension. The source codes are at https://github.com/iMoonLab/LLM4Hypergraph.
<div id='section'>Paperid: <span id='pid'>100, <a href='https://arxiv.org/pdf/2410.08355.pdf' target='_blank'>https://arxiv.org/pdf/2410.08355.pdf</a></span>   <span><a href='https://github.com/instadeepai/metalic' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jacob Beck, Shikha Surana, Manus McAuliffe, Oliver Bent, Thomas D. Barrett, Juan Jose Garau Luis, Paul Duckworth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08355">Metalic: Meta-Learning In-Context with Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the biophysical and functional properties of proteins is essential for in silico protein design. Machine learning has emerged as a promising technique for such prediction tasks. However, the relative scarcity of in vitro annotations means that these models often have little, or no, specific data on the desired fitness prediction task. As a result of limited data, protein language models (PLMs) are typically trained on general protein sequence modeling tasks, and then fine-tuned, or applied zero-shot, to protein fitness prediction. When no task data is available, the models make strong assumptions about the correlation between the protein sequence likelihood and fitness scores. In contrast, we propose meta-learning over a distribution of standard fitness prediction tasks, and demonstrate positive transfer to unseen fitness prediction tasks. Our method, called Metalic (Meta-Learning In-Context), uses in-context learning and fine-tuning, when data is available, to adapt to new tasks. Crucially, fine-tuning enables considerable generalization, even though it is not accounted for during meta-training. Our fine-tuned models achieve strong results with 18 times fewer parameters than state-of-the-art models. Moreover, our method sets a new state-of-the-art in low-data settings on ProteinGym, an established fitness-prediction benchmark. Due to data scarcity, we believe meta-learning will play a pivotal role in advancing protein engineering.
<div id='section'>Paperid: <span id='pid'>101, <a href='https://arxiv.org/pdf/2410.05670.pdf' target='_blank'>https://arxiv.org/pdf/2410.05670.pdf</a></span>   <span><a href='https://github.com/xihan-qin/Biologically-Supervised-Graph-Embedding' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xihan Qin, Li Liao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.05670">Improving Disease Comorbidity Prediction Based on Human Interactome with Biologically Supervised Graph Embedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Comorbidity carries significant implications for disease understanding and management. The genetic causes for comorbidity often trace back to mutations occurred either in the same gene associated with two diseases or in different genes associated with different diseases respectively but coming into connection via protein-protein interactions. Therefore, human interactome has been used in more sophisticated study of disease comorbidity. Human interactome, as a large incomplete graph, presents its own challenges to extracting useful features for comorbidity prediction. In this work, we introduce a novel approach named Biologically Supervised Graph Embedding (BSE) to allow for selecting most relevant features to enhance the prediction accuracy of comorbid disease pairs. Our investigation into BSE's impact on both centered and uncentered embedding methods showcases its consistent superiority over the state-of-the-art techniques and its adeptness in selecting dimensions enriched with vital biological insights, thereby improving prediction performance significantly, up to 50% when measured by ROC for some variations. Further analysis indicates that BSE consistently and substantially improves the ratio of disease associations to gene connectivity, affirming its potential in uncovering latent biological factors affecting comorbidity. The statistically significant enhancements across diverse metrics underscore BSE's potential to introduce novel avenues for precise disease comorbidity predictions and other potential applications. The GitHub repository containing the source code can be accessed at the following link: https://github.com/xihan-qin/Biologically-Supervised-Graph-Embedding.
<div id='section'>Paperid: <span id='pid'>102, <a href='https://arxiv.org/pdf/2410.02647.pdf' target='_blank'>https://arxiv.org/pdf/2410.02647.pdf</a></span>   <span><a href='https://github.com/songleee/VenusVaccine' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Song Li, Yang Tan, Song Ke, Liang Hong, Bingxin Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.02647">Immunogenicity Prediction with Dual Attention Enables Vaccine Target Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Immunogenicity prediction is a central topic in reverse vaccinology for finding candidate vaccines that can trigger protective immune responses. Existing approaches typically rely on highly compressed features and simple model architectures, leading to limited prediction accuracy and poor generalizability. To address these challenges, we introduce VenusVaccine, a novel deep learning solution with a dual attention mechanism that integrates pre-trained latent vector representations of protein sequences and structures. We also compile the most comprehensive immunogenicity dataset to date, encompassing over 7000 antigen sequences, structures, and immunogenicity labels from bacteria, virus, and tumor. Extensive experiments demonstrate that VenusVaccine outperforms existing methods across a wide range of evaluation metrics. Furthermore, we establish a post-hoc validation protocol to assess the practical significance of deep learning models in tackling vaccine design challenges. Our work provides an effective tool for vaccine design and sets valuable benchmarks for future research. The implementation is at https://github.com/songleee/VenusVaccine.
<div id='section'>Paperid: <span id='pid'>103, <a href='https://arxiv.org/pdf/2410.02023.pdf' target='_blank'>https://arxiv.org/pdf/2410.02023.pdf</a></span>   <span><a href='https://github.com/jiaqingxie/DeepProtein' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaqing Xie, Tianfan Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.02023">DeepProtein: Deep Learning Library and Benchmark for Protein Sequence Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has deeply influenced protein science, enabling breakthroughs in predicting protein properties, higher-order structures, and molecular interactions. This paper introduces DeepProtein, a comprehensive and user-friendly deep learning library tailored for protein-related tasks. It enables researchers to seamlessly address protein data with cutting-edge deep learning models. To assess model performance, we establish a benchmark evaluating different deep learning architectures across multiple protein-related tasks, including protein function prediction, subcellular localization prediction, protein-protein interaction prediction, and protein structure prediction. Furthermore, we introduce DeepProt-T5, a series of fine-tuned Prot-T5-based models that achieve state-of-the-art performance on four benchmark tasks, while demonstrating competitive results on six of others. Comprehensive documentation and tutorials are available which could ensure accessibility and support reproducibility. Built upon the widely used drug discovery library DeepPurpose, DeepProtein is publicly available at https://github.com/jiaqingxie/DeepProtein.
<div id='section'>Paperid: <span id='pid'>104, <a href='https://arxiv.org/pdf/2410.00327.pdf' target='_blank'>https://arxiv.org/pdf/2410.00327.pdf</a></span>   <span><a href='https://github.com/WillHua127/EnzymeFlow/blob/main/enzymeflow_demo.ipynb' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/WillHua127/EnzymeFlow' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenqing Hua, Yong Liu, Dinghuai Zhang, Odin Zhang, Sitao Luan, Kevin K. Yang, Guy Wolf, Doina Precup, Shuangjia Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00327">EnzymeFlow: Generating Reaction-specific Enzyme Catalytic Pockets through Flow Matching and Co-Evolutionary Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enzyme design is a critical area in biotechnology, with applications ranging from drug development to synthetic biology. Traditional methods for enzyme function prediction or protein binding pocket design often fall short in capturing the dynamic and complex nature of enzyme-substrate interactions, particularly in catalytic processes. To address the challenges, we introduce EnzymeFlow, a generative model that employs flow matching with hierarchical pre-training and enzyme-reaction co-evolution to generate catalytic pockets for specific substrates and catalytic reactions. Additionally, we introduce a large-scale, curated, and validated dataset of enzyme-reaction pairs, specifically designed for the catalytic pocket generation task, comprising a total of $328,192$ pairs. By incorporating evolutionary dynamics and reaction-specific adaptations, EnzymeFlow becomes a powerful model for designing enzyme pockets, which is capable of catalyzing a wide range of biochemical reactions. Experiments on the new dataset demonstrate the model's effectiveness in designing high-quality, functional enzyme catalytic pockets, paving the way for advancements in enzyme engineering and synthetic biology. We provide EnzymeFlow code at https://github.com/WillHua127/EnzymeFlow with notebook demonstration at https://github.com/WillHua127/EnzymeFlow/blob/main/enzymeflow_demo.ipynb.
<div id='section'>Paperid: <span id='pid'>105, <a href='https://arxiv.org/pdf/2409.20227.pdf' target='_blank'>https://arxiv.org/pdf/2409.20227.pdf</a></span>   <span><a href='https://github.com/Exscientia/plif_validity,' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>David Errington, Constantin Schneider, CÃ©dric Bouysset, FrÃ©dÃ©ric A. Dreyer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.20227">Assessing interaction recovery of predicted protein-ligand poses</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The field of protein-ligand pose prediction has seen significant advances in recent years, with machine learning-based methods now being commonly used in lieu of classical docking methods or even to predict all-atom protein-ligand complex structures. Most contemporary studies focus on the accuracy and physical plausibility of ligand placement to determine pose quality, often neglecting a direct assessment of the interactions observed with the protein. In this work, we demonstrate that ignoring protein-ligand interaction fingerprints can lead to overestimation of model performance, most notably in recent protein-ligand cofolding models which often fail to recapitulate key interactions.
<div id='section'>Paperid: <span id='pid'>106, <a href='https://arxiv.org/pdf/2409.17808.pdf' target='_blank'>https://arxiv.org/pdf/2409.17808.pdf</a></span>   <span><a href='https://github.com/bjing2016/mdgen' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Jing, Hannes StÃ¤rk, Tommi Jaakkola, Bonnie Berger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17808">Generative Modeling of Molecular Dynamics Trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular dynamics (MD) is a powerful technique for studying microscopic phenomena, but its computational cost has driven significant interest in the development of deep learning-based surrogate models. We introduce generative modeling of molecular trajectories as a paradigm for learning flexible multi-task surrogate models of MD from data. By conditioning on appropriately chosen frames of the trajectory, we show such generative models can be adapted to diverse tasks such as forward simulation, transition path sampling, and trajectory upsampling. By alternatively conditioning on part of the molecular system and inpainting the rest, we also demonstrate the first steps towards dynamics-conditioned molecular design. We validate the full set of these capabilities on tetrapeptide simulations and show that our model can produce reasonable ensembles of protein monomers. Altogether, our work illustrates how generative modeling can unlock value from MD data towards diverse downstream tasks that are not straightforward to address with existing methods or even MD itself. Code is available at https://github.com/bjing2016/mdgen.
<div id='section'>Paperid: <span id='pid'>107, <a href='https://arxiv.org/pdf/2409.17265.pdf' target='_blank'>https://arxiv.org/pdf/2409.17265.pdf</a></span>   <span><a href='https://github.com/HannesStark/CodonMPNN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hannes Stark, Umesh Padia, Julia Balla, Cameron Diao, George Church
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17265">CodonMPNN for Organism Specific and Codon Optimal Inverse Folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generating protein sequences conditioned on protein structures is an impactful technique for protein engineering. When synthesizing engineered proteins, they are commonly translated into DNA and expressed in an organism such as yeast. One difficulty in this process is that the expression rates can be low due to suboptimal codon sequences for expressing a protein in a host organism. We propose CodonMPNN, which generates a codon sequence conditioned on a protein backbone structure and an organism label. If naturally occurring DNA sequences are close to codon optimality, CodonMPNN could learn to generate codon sequences with higher expression yields than heuristic codon choices for generated amino acid sequences. Experiments show that CodonMPNN retains the performance of previous inverse folding approaches and recovers wild-type codons more frequently than baselines. Furthermore, CodonMPNN has a higher likelihood of generating high-fitness codon sequences than low-fitness codon sequences for the same protein sequence. Code is available at https://github.com/HannesStark/CodonMPNN.
<div id='section'>Paperid: <span id='pid'>108, <a href='https://arxiv.org/pdf/2408.13659.pdf' target='_blank'>https://arxiv.org/pdf/2408.13659.pdf</a></span>   <span><a href='https://github.com/WillHua127/ReactZyme' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenqing Hua, Bozitao Zhong, Sitao Luan, Liang Hong, Guy Wolf, Doina Precup, Shuangjia Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.13659">ReactZyme: A Benchmark for Enzyme-Reaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enzymes, with their specific catalyzed reactions, are necessary for all aspects of life, enabling diverse biological processes and adaptations. Predicting enzyme functions is essential for understanding biological pathways, guiding drug development, enhancing bioproduct yields, and facilitating evolutionary studies. Addressing the inherent complexities, we introduce a new approach to annotating enzymes based on their catalyzed reactions. This method provides detailed insights into specific reactions and is adaptable to newly discovered reactions, diverging from traditional classifications by protein family or expert-derived reaction classes. We employ machine learning algorithms to analyze enzyme reaction datasets, delivering a much more refined view on the functionality of enzymes. Our evaluation leverages the largest enzyme-reaction dataset to date, derived from the SwissProt and Rhea databases with entries up to January 8, 2024. We frame the enzyme-reaction prediction as a retrieval problem, aiming to rank enzymes by their catalytic ability for specific reactions. With our model, we can recruit proteins for novel reactions and predict reactions in novel proteins, facilitating enzyme discovery and function annotation (https://github.com/WillHua127/ReactZyme).
<div id='section'>Paperid: <span id='pid'>109, <a href='https://arxiv.org/pdf/2408.11363.pdf' target='_blank'>https://arxiv.org/pdf/2408.11363.pdf</a></span>   <span><a href='https://github.com/ProteinGPT/ProteinGPT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijia Xiao, Edward Sun, Yiqiao Jin, Qifan Wang, Wei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11363">ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding biological processes, drug development, and biotechnological advancements requires a detailed analysis of protein structures and functions, a task that is inherently complex and time-consuming in traditional protein research. To streamline this process, we introduce ProteinGPT, a state-of-the-art multimodal large language model for proteins that enables users to upload protein sequences and/or structures for comprehensive analysis and responsive inquiries. ProteinGPT integrates protein sequence and structure encoders with linear projection layers to ensure precise representation adaptation and leverages a large language model (LLM) to generate accurate, contextually relevant responses. To train ProteinGPT, we constructed a large-scale dataset of 132,092 proteins, each annotated with 20-30 property tags and 5-10 QA pairs per protein, and optimized the instruction-tuning process using GPT-4o. Experiments demonstrate that ProteinGPT effectively generates informative responses to protein-related questions, achieving high performance on both semantic and lexical metrics and significantly outperforming baseline models and general-purpose LLMs in understanding and responding to protein-related queries. Our code and data are available at https://github.com/ProteinGPT/ProteinGPT.
<div id='section'>Paperid: <span id='pid'>110, <a href='https://arxiv.org/pdf/2408.08252.pdf' target='_blank'>https://arxiv.org/pdf/2408.08252.pdf</a></span>   <span><a href='https://github.com/masa-ue/SVDD' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/masa-ue/SVDD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiner Li, Yulai Zhao, Chenyu Wang, Gabriele Scalia, Gokcen Eraslan, Surag Nair, Tommaso Biancalani, Shuiwang Ji, Aviv Regev, Sergey Levine, Masatoshi Uehara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.08252">Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models excel at capturing the natural design spaces of images, molecules, DNA, RNA, and protein sequences. However, rather than merely generating designs that are natural, we often aim to optimize downstream reward functions while preserving the naturalness of these design spaces. Existing methods for achieving this goal often require ``differentiable'' proxy models (\textit{e.g.}, classifier guidance or DPS) or involve computationally expensive fine-tuning of diffusion models (\textit{e.g.}, classifier-free guidance, RL-based fine-tuning). In our work, we propose a new method to address these challenges. Our algorithm is an iterative sampling method that integrates soft value functions, which looks ahead to how intermediate noisy states lead to high rewards in the future, into the standard inference procedure of pre-trained diffusion models. Notably, our approach avoids fine-tuning generative models and eliminates the need to construct differentiable models. This enables us to (1) directly utilize non-differentiable features/reward feedback, commonly used in many scientific domains, and (2) apply our method to recent discrete diffusion models in a principled way. Finally, we demonstrate the effectiveness of our algorithm across several domains, including image generation, molecule generation, and DNA/RNA sequence generation. The code is available at \href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}.
<div id='section'>Paperid: <span id='pid'>111, <a href='https://arxiv.org/pdf/2408.06050.pdf' target='_blank'>https://arxiv.org/pdf/2408.06050.pdf</a></span>   <span><a href='https://github.com/rafalkarczewski/SimpleSBDD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>RafaÅ Karczewski, Samuel Kaski, Markus Heinonen, Vikas Garg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.06050">What Ails Generative Structure-based Drug Design: Expressivity is Too Little or Too Much?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Several generative models with elaborate training and sampling procedures have been proposed to accelerate structure-based drug design (SBDD); however, their empirical performance turns out to be suboptimal. We seek to better understand this phenomenon from both theoretical and empirical perspectives. Since most of these models apply graph neural networks (GNNs), one may suspect that they inherit the representational limitations of GNNs. We analyze this aspect, establishing the first such results for protein-ligand complexes. A plausible counterview may attribute the underperformance of these models to their excessive parameterizations, inducing expressivity at the expense of generalization. We investigate this possibility with a simple metric-aware approach that learns an economical surrogate for affinity to infer an unlabelled molecular graph and optimizes for labels conditioned on this graph and molecular properties. The resulting model achieves state-of-the-art results using 100x fewer trainable parameters and affords up to 1000x speedup. Collectively, our findings underscore the need to reassess and redirect the existing paradigm and efforts for SBDD. Code is available at https://github.com/rafalkarczewski/SimpleSBDD.
<div id='section'>Paperid: <span id='pid'>112, <a href='https://arxiv.org/pdf/2407.18184.pdf' target='_blank'>https://arxiv.org/pdf/2407.18184.pdf</a></span>   <span><a href='https://github.com/biochunan/AsEP-dataset' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chunan Liu, Lilian Denzler, Yihong Chen, Andrew Martin, Brooks Paige
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.18184">AsEP: Benchmarking Deep Learning Methods for Antibody-specific Epitope Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Epitope identification is vital for antibody design yet challenging due to the inherent variability in antibodies. While many deep learning methods have been developed for general protein binding site prediction tasks, whether they work for epitope prediction remains an understudied research question. The challenge is also heightened by the lack of a consistent evaluation pipeline with sufficient dataset size and epitope diversity. We introduce a filtered antibody-antigen complex structure dataset, AsEP (Antibody-specific Epitope Prediction). AsEP is the largest of its kind and provides clustered epitope groups, allowing the community to develop and test novel epitope prediction methods and evaluate their generalisability. AsEP comes with an easy-to-use interface in Python and pre-built graph representations of each antibody-antigen complex while also supporting customizable embedding methods. Using this new dataset, we benchmark several representative general protein-binding site prediction methods and find that their performances fall short of expectations for epitope prediction. To address this, we propose a novel method, WALLE, which leverages both unstructured modeling from protein language models and structural modeling from graph neural networks. WALLE demonstrate up to 3-10X performance improvement over the baseline methods. Our empirical findings suggest that epitope prediction benefits from combining sequential features provided by language models with geometrical information from graph representations. This provides a guideline for future epitope prediction method design. In addition, we reformulate the task as bipartite link prediction, allowing convenient model performance attribution and interpretability. We open source our data and code at https://github.com/biochunan/AsEP-dataset.
<div id='section'>Paperid: <span id='pid'>113, <a href='https://arxiv.org/pdf/2407.16375.pdf' target='_blank'>https://arxiv.org/pdf/2407.16375.pdf</a></span>   <span><a href='https://github.com/haddocking/DeepRank-GNN-esm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaotong Xu, Alexandre M. J. J. Bonvin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16375">Ranking protein-protein models with large language models and graph neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interactions (PPIs) are associated with various diseases, including cancer, infections, and neurodegenerative disorders. Obtaining three-dimensional structural information on these PPIs serves as a foundation to interfere with those or to guide drug design. Various strategies can be followed to model those complexes, all typically resulting in a large number of models. A challenging step in this process is the identification of good models (near-native PPI conformations) from the large pool of generated models. To address this challenge, we previously developed DeepRank-GNN-esm, a graph-based deep learning algorithm for ranking modelled PPI structures harnessing the power of protein language models. Here, we detail the use of our software with examples. DeepRank-GNN-esm is freely available at https://github.com/haddocking/DeepRank-GNN-esm
<div id='section'>Paperid: <span id='pid'>114, <a href='https://arxiv.org/pdf/2407.13734.pdf' target='_blank'>https://arxiv.org/pdf/2407.13734.pdf</a></span>   <span><a href='https://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Masatoshi Uehara, Yulai Zhao, Tommaso Biancalani, Sergey Levine
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13734">Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This tutorial provides a comprehensive survey of methods for fine-tuning diffusion models to optimize downstream reward functions. While diffusion models are widely known to provide excellent generative modeling capability, practical applications in domains such as biology require generating samples that maximize some desired metric (e.g., translation efficiency in RNA, docking score in molecules, stability in protein). In these cases, the diffusion model can be optimized not only to generate realistic samples but also to explicitly maximize the measure of interest. Such methods are based on concepts from reinforcement learning (RL). We explain the application of various RL algorithms, including PPO, differentiable optimization, reward-weighted MLE, value-weighted sampling, and path consistency learning, tailored specifically for fine-tuning diffusion models. We aim to explore fundamental aspects such as the strengths and limitations of different RL-based fine-tuning algorithms across various scenarios, the benefits of RL-based fine-tuning compared to non-RL-based approaches, and the formal objectives of RL-based fine-tuning (target distributions). Additionally, we aim to examine their connections with related topics such as classifier guidance, Gflownets, flow-based diffusion models, path integral control theory, and sampling from unnormalized distributions such as MCMC. The code of this tutorial is available at https://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq
<div id='section'>Paperid: <span id='pid'>115, <a href='https://arxiv.org/pdf/2407.07443.pdf' target='_blank'>https://arxiv.org/pdf/2407.07443.pdf</a></span>   <span><a href='https://github.com/riacd/CPDiffusion-SS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yutong Hu, Yang Tan, Andi Han, Lirong Zheng, Liang Hong, Bingxin Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.07443">Secondary Structure-Guided Novel Protein Sequence Generation with Latent Graph Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The advent of deep learning has introduced efficient approaches for de novo protein sequence design, significantly improving success rates and reducing development costs compared to computational or experimental methods. However, existing methods face challenges in generating proteins with diverse lengths and shapes while maintaining key structural features. To address these challenges, we introduce CPDiffusion-SS, a latent graph diffusion model that generates protein sequences based on coarse-grained secondary structural information. CPDiffusion-SS offers greater flexibility in producing a variety of novel amino acid sequences while preserving overall structural constraints, thus enhancing the reliability and diversity of generated proteins. Experimental analyses demonstrate the significant superiority of the proposed method in producing diverse and novel sequences, with CPDiffusion-SS surpassing popular baseline methods on open benchmarks across various quantitative measurements. Furthermore, we provide a series of case studies to highlight the biological significance of the generation performance by the proposed method. The source code is publicly available at https://github.com/riacd/CPDiffusion-SS
<div id='section'>Paperid: <span id='pid'>116, <a href='https://arxiv.org/pdf/2407.01648.pdf' target='_blank'>https://arxiv.org/pdf/2407.01648.pdf</a></span>   <span><a href='https://github.com/MinkaiXu/AliDiff' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyi Gu, Minkai Xu, Alexander Powers, Weili Nie, Tomas Geffner, Karsten Kreis, Jure Leskovec, Arash Vahdat, Stefano Ermon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01648">Aligning Target-Aware Molecule Diffusion Models with Exact Energy Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generating ligand molecules for specific protein targets, known as structure-based drug design, is a fundamental problem in therapeutics development and biological discovery. Recently, target-aware generative models, especially diffusion models, have shown great promise in modeling protein-ligand interactions and generating candidate drugs. However, existing models primarily focus on learning the chemical distribution of all drug candidates, which lacks effective steerability on the chemical quality of model generations. In this paper, we propose a novel and general alignment framework to align pretrained target diffusion models with preferred functional properties, named AliDiff. AliDiff shifts the target-conditioned chemical distribution towards regions with higher binding affinity and structural rationality, specified by user-defined reward functions, via the preference optimization approach. To avoid the overfitting problem in common preference optimization objectives, we further develop an improved Exact Energy Preference Optimization method to yield an exact and efficient alignment of the diffusion models, and provide the closed-form expression for the converged distribution. Empirical studies on the CrossDocked2020 benchmark show that AliDiff can generate molecules with state-of-the-art binding energies with up to -7.07 Avg. Vina Score, while maintaining strong molecular properties. Code is available at https://github.com/MinkaiXu/AliDiff.
<div id='section'>Paperid: <span id='pid'>117, <a href='https://arxiv.org/pdf/2406.15669.pdf' target='_blank'>https://arxiv.org/pdf/2406.15669.pdf</a></span>   <span><a href='https://github.com/jsunn-y/CARE/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jason Yang, Ariane Mora, Shengchao Liu, Bruce J. Wittmann, Anima Anandkumar, Frances H. Arnold, Yisong Yue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.15669">CARE: a Benchmark Suite for the Classification and Retrieval of Enzymes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enzymes are important proteins that catalyze chemical reactions. In recent years, machine learning methods have emerged to predict enzyme function from sequence; however, there are no standardized benchmarks to evaluate these methods. We introduce CARE, a benchmark and dataset suite for the Classification And Retrieval of Enzymes (CARE). CARE centers on two tasks: (1) classification of a protein sequence by its enzyme commission (EC) number and (2) retrieval of an EC number given a chemical reaction. For each task, we design train-test splits to evaluate different kinds of out-of-distribution generalization that are relevant to real use cases. For the classification task, we provide baselines for state-of-the-art methods. Because the retrieval task has not been previously formalized, we propose a method called Contrastive Reaction-EnzymE Pretraining (CREEP) as one of the first baselines for this task and compare it to the recent method, CLIPZyme. CARE is available at https://github.com/jsunn-y/CARE/.
<div id='section'>Paperid: <span id='pid'>118, <a href='https://arxiv.org/pdf/2406.13839.pdf' target='_blank'>https://arxiv.org/pdf/2406.13839.pdf</a></span>   <span><a href='https://github.com/rish-16/rna-backbone-design' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Rishabh Anand, Chaitanya K. Joshi, Alex Morehead, Arian R. Jamasb, Charles Harris, Simon V. Mathis, Kieran Didi, Rex Ying, Bryan Hooi, Pietro LiÃ²
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.13839">RNA-FrameFlow: Flow Matching for de novo 3D RNA Backbone Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce RNA-FrameFlow, the first generative model for 3D RNA backbone design. We build upon SE(3) flow matching for protein backbone generation and establish protocols for data preparation and evaluation to address unique challenges posed by RNA modeling. We formulate RNA structures as a set of rigid-body frames and associated loss functions which account for larger, more conformationally flexible RNA backbones (13 atoms per nucleotide) vs. proteins (4 atoms per residue). Toward tackling the lack of diversity in 3D RNA datasets, we explore training with structural clustering and cropping augmentations. Additionally, we define a suite of evaluation metrics to measure whether the generated RNA structures are globally self-consistent (via inverse folding followed by forward folding) and locally recover RNA-specific structural descriptors. The most performant version of RNA-FrameFlow generates locally realistic RNA backbones of 40-150 nucleotides, over 40% of which pass our validity criteria as measured by a self-consistency TM-score >= 0.45, at which two RNAs have the same global fold. Open-source code: https://github.com/rish-16/rna-backbone-design
<div id='section'>Paperid: <span id='pid'>119, <a href='https://arxiv.org/pdf/2406.10840.pdf' target='_blank'>https://arxiv.org/pdf/2406.10840.pdf</a></span>   <span><a href='https://github.com/Edapinenut/CBGBench' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haitao Lin, Guojiang Zhao, Odin Zhang, Yufei Huang, Lirong Wu, Zicheng Liu, Siyuan Li, Cheng Tan, Zhifeng Gao, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10840">CBGBench: Fill in the Blank of Protein-Molecule Complex Binding Graph</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug design (SBDD) aims to generate potential drugs that can bind to a target protein and is greatly expedited by the aid of AI techniques in generative models. However, a lack of systematic understanding persists due to the diverse settings, complex implementation, difficult reproducibility, and task singularity. Firstly, the absence of standardization can lead to unfair comparisons and inconclusive insights. To address this dilemma, we propose CBGBench, a comprehensive benchmark for SBDD, that unifies the task as a generative heterogeneous graph completion, analogous to fill-in-the-blank of the 3D complex binding graph. By categorizing existing methods based on their attributes, CBGBench facilitates a modular and extensible framework that implements various cutting-edge methods. Secondly, a single task on \textit{de novo} molecule generation can hardly reflect their capabilities. To broaden the scope, we have adapted these models to a range of tasks essential in drug design, which are considered sub-tasks within the graph fill-in-the-blank tasks. These tasks include the generative designation of \textit{de novo} molecules, linkers, fragments, scaffolds, and sidechains, all conditioned on the structures of protein pockets. Our evaluations are conducted with fairness, encompassing comprehensive perspectives on interaction, chemical properties, geometry authenticity, and substructure validity. We further provide the pre-trained versions of the state-of-the-art models and deep insights with analysis from empirical studies. The codebase for CBGBench is publicly accessible at \url{https://github.com/Edapinenut/CBGBench}.
<div id='section'>Paperid: <span id='pid'>120, <a href='https://arxiv.org/pdf/2406.08649.pdf' target='_blank'>https://arxiv.org/pdf/2406.08649.pdf</a></span>   <span><a href='https://github.com/carpenter-singh-lab/motive' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>John Arevalo, Ellen Su, Anne E Carpenter, Shantanu Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.08649">MOTIVE: A Drug-Target Interaction Graph For Inductive Link Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drug-target interaction (DTI) prediction is crucial for identifying new therapeutics and detecting mechanisms of action. While structure-based methods accurately model physical interactions between a drug and its protein target, cell-based assays such as Cell Painting can better capture complex DTI interactions. This paper introduces MOTIVE, a Morphological cOmpound Target Interaction Graph dataset comprising Cell Painting features for 11,000 genes and 3,600 compounds, along with their relationships extracted from seven publicly available databases. We provide random, cold-source (new drugs), and cold-target (new genes) data splits to enable rigorous evaluation under realistic use cases. Our benchmark results show that graph neural networks that use Cell Painting features consistently outperform those that learn from graph structure alone, feature-based models, and topological heuristics. MOTIVE accelerates both graph ML research and drug discovery by promoting the development of more reliable DTI prediction models. MOTIVE resources are available at https://github.com/carpenter-singh-lab/motive.
<div id='section'>Paperid: <span id='pid'>121, <a href='https://arxiv.org/pdf/2406.07025.pdf' target='_blank'>https://arxiv.org/pdf/2406.07025.pdf</a></span>   <span><a href='https://github.com/xuefeng-cs/ERP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuefeng Liu, Chih-chan Tien, Peng Ding, Songhao Jiang, Rick L. Stevens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.07025">Entropy-Reinforced Planning with Large Language Models for Drug Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The objective of drug discovery is to identify chemical compounds that possess specific pharmaceutical properties toward a binding target. Existing large language models (LLMS) can achieve high token matching scores in terms of likelihood for molecule generation. However, relying solely on LLM decoding often results in the generation of molecules that are either invalid due to a single misused token, or suboptimal due to unbalanced exploration and exploitation as a consequence of the LLMs prior experience. Here we propose ERP, Entropy-Reinforced Planning for Transformer Decoding, which employs an entropy-reinforced planning algorithm to enhance the Transformer decoding process and strike a balance between exploitation and exploration. ERP aims to achieve improvements in multiple properties compared to direct sampling from the Transformer. We evaluated ERP on the SARS-CoV-2 virus (3CLPro) and human cancer cell target protein (RTCB) benchmarks and demonstrated that, in both benchmarks, ERP consistently outperforms the current state-of-the-art algorithm by 1-5 percent, and baselines by 5-10 percent, respectively. Moreover, such improvement is robust across Transformer models trained with different objectives. Finally, to further illustrate the capabilities of ERP, we tested our algorithm on three code generation benchmarks and outperformed the current state-of-the-art approach as well. Our code is publicly available at: https://github.com/xuefeng-cs/ERP.
<div id='section'>Paperid: <span id='pid'>122, <a href='https://arxiv.org/pdf/2406.06841.pdf' target='_blank'>https://arxiv.org/pdf/2406.06841.pdf</a></span>   <span><a href='https://github.com/BIMSBbioinfo/CompassDock' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmet Sarigun, Vedran Franke, Bora Uyar, Altuna Akalin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.06841">CompassDock: Comprehensive Accurate Assessment Approach for Deep Learning-Based Molecular Docking in Inference and Fine-Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Datasets used for molecular docking, such as PDBBind, contain technical variability - they are noisy. Although the origins of the noise have been discussed, a comprehensive analysis of the physical, chemical, and bioactivity characteristics of the datasets is still lacking. To address this gap, we introduce the Comprehensive Accurate Assessment (Compass). Compass integrates two key components: PoseCheck, which examines ligand strain energy, protein-ligand steric clashes, and interactions, and AA-Score, a new empirical scoring function for calculating binding affinity energy. Together, these form a unified workflow that assesses both the physical/chemical properties and bioactivity favorability of ligands and protein-ligand interactions. Our analysis of the PDBBind dataset using Compass reveals substantial noise in the ground truth data. Additionally, we propose CompassDock, which incorporates the Compass module with DiffDock, the state-of-the-art deep learning-based molecular docking method, to enable accurate assessment of docked ligands during inference. Finally, we present a new paradigm for enhancing molecular docking model performance by fine-tuning with Compass Scores, which encompass binding affinity energy, strain energy, and the number of steric clashes identified by Compass. Our results show that, while fine-tuning without Compass improves the percentage of docked poses with RMSD < 2Ã, it leads to a decrease in physical/chemical and bioactivity favorability. In contrast, fine-tuning with Compass shows a limited improvement in RMSD < 2Ã but enhances the physical/chemical and bioactivity favorability of the ligand conformation. The source code is available publicly at https://github.com/BIMSBbioinfo/CompassDock.
<div id='section'>Paperid: <span id='pid'>123, <a href='https://arxiv.org/pdf/2406.03403.pdf' target='_blank'>https://arxiv.org/pdf/2406.03403.pdf</a></span>   <span><a href='https://github.com/zkysfls/2024-sbdd-benchmark' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kangyu Zheng, Yingzhou Lu, Zaixi Zhang, Zhongwei Wan, Yao Ma, Marinka Zitnik, Tianfan Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03403">Structure-based Drug Design Benchmark: Do 3D Methods Really Dominate?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Currently, the field of structure-based drug design is dominated by three main types of algorithms: search-based algorithms, deep generative models, and reinforcement learning. While existing works have typically focused on comparing models within a single algorithmic category, cross-algorithm comparisons remain scarce. In this paper, to fill the gap, we establish a benchmark to evaluate the performance of sixteen models across these different algorithmic foundations by assessing the pharmaceutical properties of the generated molecules and their docking affinities with specified target proteins. We highlight the unique advantages of each algorithmic approach and offer recommendations for the design of future SBDD models. We emphasize that 1D/2D ligand-centric drug design methods can be used in SBDD by treating the docking function as a black-box oracle, which is typically neglected. The empirical results show that 1D/2D methods achieve competitive performance compared with 3D-based methods that use the 3D structure of the target protein explicitly. Also, AutoGrow4, a 2D molecular graph-based genetic algorithm, dominates SBDD in terms of optimization ability. The relevant code is available in https://github.com/zkysfls/2024-sbdd-benchmark.
<div id='section'>Paperid: <span id='pid'>124, <a href='https://arxiv.org/pdf/2406.03141.pdf' target='_blank'>https://arxiv.org/pdf/2406.03141.pdf</a></span>   <span><a href='https://github.com/aim-uofa/FADiff' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ke Liu, Weian Mao, Shuaike Shen, Xiaoran Jiao, Zheng Sun, Hao Chen, Chunhua Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03141">Floating Anchor Diffusion Model for Multi-motif Scaffolding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motif scaffolding seeks to design scaffold structures for constructing proteins with functions derived from the desired motif, which is crucial for the design of vaccines and enzymes. Previous works approach the problem by inpainting or conditional generation. Both of them can only scaffold motifs with fixed positions, and the conditional generation cannot guarantee the presence of motifs. However, prior knowledge of the relative motif positions in a protein is not readily available, and constructing a protein with multiple functions in one protein is more general and significant because of the synergies between functions. We propose a Floating Anchor Diffusion (FADiff) model. FADiff allows motifs to float rigidly and independently in the process of diffusion, which guarantees the presence of motifs and automates the motif position design. Our experiments demonstrate the efficacy of FADiff with high success rates and designable novel scaffolds. To the best of our knowledge, FADiff is the first work to tackle the challenge of scaffolding multiple motifs without relying on the expertise of relative motif positions in the protein. Code is available at https://github.com/aim-uofa/FADiff.
<div id='section'>Paperid: <span id='pid'>125, <a href='https://arxiv.org/pdf/2405.16381.pdf' target='_blank'>https://arxiv.org/pdf/2405.16381.pdf</a></span>   <span><a href='https://github.com/yuchen-zhu-zyc/TDM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuchen Zhu, Tianrong Chen, Lingkai Kong, Evangelos A. Theodorou, Molei Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16381">Trivialized Momentum Facilitates Diffusion Generative Modeling on Lie Groups</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The generative modeling of data on manifolds is an important task, for which diffusion models in flat spaces typically need nontrivial adaptations. This article demonstrates how a technique called `trivialization' can transfer the effectiveness of diffusion models in Euclidean spaces to Lie groups. In particular, an auxiliary momentum variable was algorithmically introduced to help transport the position variable between data distribution and a fixed, easy-to-sample distribution. Normally, this would incur further difficulty for manifold data because momentum lives in a space that changes with the position. However, our trivialization technique creates a new momentum variable that stays in a simple fixed vector space. This design, together with a manifold preserving integrator, simplifies implementation and avoids inaccuracies created by approximations such as projections to tangent space and manifold, which were typically used in prior work, hence facilitating generation with high-fidelity and efficiency. The resulting method achieves state-of-the-art performance on protein and RNA torsion angle generation and sophisticated torus datasets. We also, arguably for the first time, tackle the generation of data on high-dimensional Special Orthogonal and Unitary groups, the latter essential for quantum problems. Code is available at https://github.com/yuchen-zhu-zyc/TDM.
<div id='section'>Paperid: <span id='pid'>126, <a href='https://arxiv.org/pdf/2405.16206.pdf' target='_blank'>https://arxiv.org/pdf/2405.16206.pdf</a></span>   <span><a href='https://github.com/GlycanML/GlycanML' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Minghao Xu, Yunteng Geng, Yihang Zhang, Ling Yang, Jian Tang, Wentao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16206">GlycanML: A Multi-Task and Multi-Structure Benchmark for Glycan Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Glycans are basic biomolecules and perform essential functions within living organisms. The rapid increase of functional glycan data provides a good opportunity for machine learning solutions to glycan understanding. However, there still lacks a standard machine learning benchmark for glycan property and function prediction. In this work, we fill this blank by building a comprehensive benchmark for Glycan Machine Learning (GlycanML). The GlycanML benchmark consists of diverse types of tasks including glycan taxonomy prediction, glycan immunogenicity prediction, glycosylation type prediction, and protein-glycan interaction prediction. Glycans can be represented by both sequences and graphs in GlycanML, which enables us to extensively evaluate sequence-based models and graph neural networks (GNNs) on benchmark tasks. Furthermore, by concurrently performing eight glycan taxonomy prediction tasks, we introduce the GlycanML-MTL testbed for multi-task learning (MTL) algorithms. Also, we evaluate how taxonomy prediction can boost other three function prediction tasks by MTL. Experimental results show the superiority of modeling glycans with multi-relational GNNs, and suitable MTL methods can further boost model performance. We provide all datasets and source codes at https://github.com/GlycanML/GlycanML and maintain a leaderboard at https://GlycanML.github.io/project
<div id='section'>Paperid: <span id='pid'>127, <a href='https://arxiv.org/pdf/2405.15489.pdf' target='_blank'>https://arxiv.org/pdf/2405.15489.pdf</a></span>   <span><a href='https://github.com/aqlaboratory/genie2' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yeqing Lin, Minji Lee, Zhao Zhang, Mohammed AlQuraishi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15489">Out of Many, One: Designing and Scaffolding Proteins at the Scale of the Structural Universe with Genie 2</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein diffusion models have emerged as a promising approach for protein design. One such pioneering model is Genie, a method that asymmetrically represents protein structures during the forward and backward processes, using simple Gaussian noising for the former and expressive SE(3)-equivariant attention for the latter. In this work we introduce Genie 2, extending Genie to capture a larger and more diverse protein structure space through architectural innovations and massive data augmentation. Genie 2 adds motif scaffolding capabilities via a novel multi-motif framework that designs co-occurring motifs with unspecified inter-motif positions and orientations. This makes possible complex protein designs that engage multiple interaction partners and perform multiple functions. On both unconditional and conditional generation, Genie 2 achieves state-of-the-art performance, outperforming all known methods on key design metrics including designability, diversity, and novelty. Genie 2 also solves more motif scaffolding problems than other methods and does so with more unique and varied solutions. Taken together, these advances set a new standard for structure-based protein design. Genie 2 inference and training code, as well as model weights, are freely available at: https://github.com/aqlaboratory/genie2.
<div id='section'>Paperid: <span id='pid'>128, <a href='https://arxiv.org/pdf/2405.15158.pdf' target='_blank'>https://arxiv.org/pdf/2405.15158.pdf</a></span>   <span><a href='https://github.com/AI-HPC-Research-Team/ProtFAD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingqing Wang, Zhiwei Nie, Yonghong He, Athanasios V. Vasilakos, Zhixiang Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15158">ProtFAD: Introducing function-aware domains as implicit modality towards protein function prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein function prediction is currently achieved by encoding its sequence or structure, where the sequence-to-function transcendence and high-quality structural data scarcity lead to obvious performance bottlenecks. Protein domains are "building blocks" of proteins that are functionally independent, and their combinations determine the diverse biological functions. However, most existing studies have yet to thoroughly explore the intricate functional information contained in the protein domains. To fill this gap, we propose a synergistic integration approach for a function-aware domain representation, and a domain-joint contrastive learning strategy to distinguish different protein functions while aligning the modalities. Specifically, we align the domain semantics with GO terms and text description to pre-train domain embeddings. Furthermore, we partition proteins into multiple sub-views based on continuous joint domains for contrastive training under the supervision of a novel triplet InfoNCE loss. Our approach significantly and comprehensively outperforms the state-of-the-art methods on various benchmarks, and clearly differentiates proteins carrying distinct functions compared to the competitor. Our implementation is available at https://github.com/AI-HPC-Research-Team/ProtFAD.
<div id='section'>Paperid: <span id='pid'>129, <a href='https://arxiv.org/pdf/2405.14108.pdf' target='_blank'>https://arxiv.org/pdf/2405.14108.pdf</a></span>   <span><a href='https://github.com/BioinfoMachineLearning/PoseBench' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/BioinfoMachineLearning/PoseBench' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Morehead, Nabin Giri, Jian Liu, Pawan Neupane, Jianlin Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14108">Assessing the potential of deep learning for protein-ligand docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The effects of ligand binding on protein structures and their in vivo functions carry numerous implications for modern biomedical research and biotechnology development efforts such as drug discovery. Although several deep learning (DL) methods and benchmarks designed for protein-ligand docking have recently been introduced, to date no prior works have systematically studied the behavior of the latest docking and structure prediction methods within the broadly applicable context of (1) using predicted (apo) protein structures for docking (e.g., for applicability to new proteins); (2) binding multiple (cofactor) ligands concurrently to a given target protein (e.g., for enzyme design); and (3) having no prior knowledge of binding pockets (e.g., for generalization to unknown pockets). To enable a deeper understanding of docking methods' real-world utility, we introduce PoseBench, the first comprehensive benchmark for broadly applicable protein-ligand docking. PoseBench enables researchers to rigorously and systematically evaluate DL methods for apo-to-holo protein-ligand docking and protein-ligand structure prediction using both primary ligand and multi-ligand benchmark datasets, the latter of which we introduce for the first time to the DL community. Empirically, using PoseBench, we find that (1) DL co-folding methods generally outperform comparable conventional and DL docking baseline algorithms, yet popular methods such as AlphaFold 3 are still challenged by prediction targets with novel binding poses; (2) certain DL co-folding methods are highly sensitive to their input multiple sequence alignments, while others are not; and (3) DL methods struggle to strike a balance between structural accuracy and chemical specificity when predicting novel or multi-ligand protein targets. Code, data, tutorials, and benchmark results are available at https://github.com/BioinfoMachineLearning/PoseBench.
<div id='section'>Paperid: <span id='pid'>130, <a href='https://arxiv.org/pdf/2405.12564.pdf' target='_blank'>https://arxiv.org/pdf/2405.12564.pdf</a></span>   <span><a href='https://github.com/acharkq/ProtT3' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyuan Liu, An Zhang, Hao Fei, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, Tat-Seng Chua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12564">ProtT3: Protein-to-Text Generation for Text-based Protein Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Language Models (LMs) excel in understanding textual descriptions of proteins, as evident in biomedical question-answering tasks. However, their capability falters with raw protein data, such as amino acid sequences, due to a deficit in pretraining on such data. Conversely, Protein Language Models (PLMs) can understand and convert protein data into high-quality representations, but struggle to process texts. To address their limitations, we introduce ProtT3, a framework for Protein-to-Text Generation for Text-based Protein Understanding. ProtT3 empowers an LM to understand protein sequences of amino acids by incorporating a PLM as its protein understanding module, enabling effective protein-to-text generation. This collaboration between PLM and LM is facilitated by a cross-modal projector (i.e., Q-Former) that bridges the modality gap between the PLM's representation space and the LM's input space. Unlike previous studies focusing on protein property prediction and protein-text retrieval, we delve into the largely unexplored field of protein-to-text generation. To facilitate comprehensive benchmarks and promote future research, we establish quantitative evaluations for protein-text modeling tasks, including protein captioning, protein question-answering, and protein-text retrieval. Our experiments show that ProtT3 substantially surpasses current baselines, with ablation studies further highlighting the efficacy of its core components. Our code is available at https://github.com/acharkq/ProtT3.
<div id='section'>Paperid: <span id='pid'>131, <a href='https://arxiv.org/pdf/2405.06649.pdf' target='_blank'>https://arxiv.org/pdf/2405.06649.pdf</a></span>   <span><a href='https://github.com/MingyuJ666/ProLLM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingyu Jin, Haochen Xue, Zhenting Wang, Boming Kang, Ruosong Ye, Kaixiong Zhou, Mengnan Du, Yongfeng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06649">ProLLM: Protein Chain-of-Thoughts Enhanced LLM for Protein-Protein Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The prediction of protein-protein interactions (PPIs) is crucial for understanding biological functions and diseases. Previous machine learning approaches to PPI prediction mainly focus on direct physical interactions, ignoring the broader context of nonphysical connections through intermediate proteins, thus limiting their effectiveness. The emergence of Large Language Models (LLMs) provides a new opportunity for addressing this complex biological challenge. By transforming structured data into natural language prompts, we can map the relationships between proteins into texts. This approach allows LLMs to identify indirect connections between proteins, tracing the path from upstream to downstream. Therefore, we propose a novel framework ProLLM that employs an LLM tailored for PPI for the first time. Specifically, we propose Protein Chain of Thought (ProCoT), which replicates the biological mechanism of signaling pathways as natural language prompts. ProCoT considers a signaling pathway as a protein reasoning process, which starts from upstream proteins and passes through several intermediate proteins to transmit biological signals to downstream proteins. Thus, we can use ProCoT to predict the interaction between upstream proteins and downstream proteins. The training of ProLLM employs the ProCoT format, which enhances the model's understanding of complex biological problems. In addition to ProCoT, this paper also contributes to the exploration of embedding replacement of protein sites in natural language prompts, and instruction fine-tuning in protein knowledge datasets. We demonstrate the efficacy of ProLLM through rigorous validation against benchmark datasets, showing significant improvement over existing methods in terms of prediction accuracy and generalizability. The code is available at: https://github.com/MingyuJ666/ProLLM.
<div id='section'>Paperid: <span id='pid'>132, <a href='https://arxiv.org/pdf/2405.06645.pdf' target='_blank'>https://arxiv.org/pdf/2405.06645.pdf</a></span>   <span><a href='https://github.com/amirgroup-codes/InteractionRecovery' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Darin Tsui, Amirali Aghazadeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06645">On Recovering Higher-order Interactions from Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models leverage evolutionary information to perform state-of-the-art 3D structure and zero-shot variant prediction. Yet, extracting and explaining all the mutational interactions that govern model predictions remains difficult as it requires querying the entire amino acid space for $n$ sites using $20^n$ sequences, which is computationally expensive even for moderate values of $n$ (e.g., $n\sim10$). Although approaches to lower the sample complexity exist, they often limit the interpretability of the model to just single and pairwise interactions. Recently, computationally scalable algorithms relying on the assumption of sparsity in the Fourier domain have emerged to learn interactions from experimental data. However, extracting interactions from language models poses unique challenges: it's unclear if sparsity is always present or if it is the only metric needed to assess the utility of Fourier algorithms. Herein, we develop a framework to do a systematic Fourier analysis of the protein language model ESM2 applied on three proteins-green fluorescent protein (GFP), tumor protein P53 (TP53), and G domain B1 (GB1)-across various sites for 228 experiments. We demonstrate that ESM2 is dominated by three regions in the sparsity-ruggedness plane, two of which are better suited for sparse Fourier transforms. Validations on two sample proteins demonstrate recovery of all interactions with $R^2=0.72$ in the more sparse region and $R^2=0.66$ in the more dense region, using only 7 million out of $20^{10}\sim10^{13}$ ESM2 samples, reducing the computational time by a staggering factor of 15,000. All codes and data are available on our GitHub repository https://github.com/amirgroup-codes/InteractionRecovery.
<div id='section'>Paperid: <span id='pid'>133, <a href='https://arxiv.org/pdf/2405.03961.pdf' target='_blank'>https://arxiv.org/pdf/2405.03961.pdf</a></span>   <span><a href='https://github.com/genentech/voxbind/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro O. Pinheiro, Arian Jamasb, Omar Mahmood, Vishnu Sresht, Saeed Saremi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.03961">Structure-based drug design by denoising voxel grids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present VoxBind, a new score-based generative model for 3D molecules conditioned on protein structures. Our approach represents molecules as 3D atomic density grids and leverages a 3D voxel-denoising network for learning and generation. We extend the neural empirical Bayes formalism (Saremi & Hyvarinen, 2019) to the conditional setting and generate structure-conditioned molecules with a two-step procedure: (i) sample noisy molecules from the Gaussian-smoothed conditional distribution with underdamped Langevin MCMC using the learned score function and (ii) estimate clean molecules from the noisy samples with single-step denoising. Compared to the current state of the art, our model is simpler to train, significantly faster to sample from, and achieves better results on extensive in silico benchmarks -- the generated molecules are more diverse, exhibit fewer steric clashes, and bind with higher affinity to protein pockets. The code is available at https://github.com/genentech/voxbind/.
<div id='section'>Paperid: <span id='pid'>134, <a href='https://arxiv.org/pdf/2404.14858.pdf' target='_blank'>https://arxiv.org/pdf/2404.14858.pdf</a></span>   <span><a href='https://github.com/Advanced-Research-Centre/mRNA-CodonOpt' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongfeng Zhang, Aritra Sarkar, Koen Bertels
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14858">A resource-efficient variational quantum algorithm for mRNA codon optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optimizing the mRNA codon has an essential impact on gene expression for a specific target protein. It is an NP-hard problem; thus, exact solutions to such optimization problems become computationally intractable for realistic problem sizes on both classical and quantum computers. However, approximate solutions via heuristics can substantially impact the application they enable. Quantum approximate optimization is an alternative computation paradigm promising for tackling such problems. Recently, there has been some research in quantum algorithms for bioinformatics, specifically for mRNA codon optimization. This research presents a denser way to encode codons for implementing mRNA codon optimization via the variational quantum eigensolver algorithms on a gate-based quantum computer. This reduces the qubit requirement by half compared to the existing quantum approach, thus allowing longer sequences to be executed on existing quantum processors. The performance of the proposed algorithm is evaluated by comparing its results to exact solutions, showing well-matching results.
<div id='section'>Paperid: <span id='pid'>135, <a href='https://arxiv.org/pdf/2404.14850.pdf' target='_blank'>https://arxiv.org/pdf/2404.14850.pdf</a></span>   <span><a href='https://github.com/tyang816/SES-Adapter' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Tan, Mingchen Li, Bingxin Zhou, Bozitao Zhong, Lirong Zheng, Pan Tan, Ziyi Zhou, Huiqun Yu, Guisheng Fan, Liang Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14850">Simple, Efficient and Scalable Structure-aware Adapter Boosts Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fine-tuning Pre-trained protein language models (PLMs) has emerged as a prominent strategy for enhancing downstream prediction tasks, often outperforming traditional supervised learning approaches. As a widely applied powerful technique in natural language processing, employing Parameter-Efficient Fine-Tuning techniques could potentially enhance the performance of PLMs. However, the direct transfer to life science tasks is non-trivial due to the different training strategies and data forms. To address this gap, we introduce SES-Adapter, a simple, efficient, and scalable adapter method for enhancing the representation learning of PLMs. SES-Adapter incorporates PLM embeddings with structural sequence embeddings to create structure-aware representations. We show that the proposed method is compatible with different PLM architectures and across diverse tasks. Extensive evaluations are conducted on 2 types of folding structures with notable quality differences, 9 state-of-the-art baselines, and 9 benchmark datasets across distinct downstream tasks. Results show that compared to vanilla PLMs, SES-Adapter improves downstream task performance by a maximum of 11% and an average of 3%, with significantly accelerated training speed by a maximum of 1034% and an average of 362%, the convergence rate is also improved by approximately 2 times. Moreover, positive optimization is observed even with low-quality predicted structures. The source code for SES-Adapter is available at https://github.com/tyang816/SES-Adapter.
<div id='section'>Paperid: <span id='pid'>136, <a href='https://arxiv.org/pdf/2404.09738.pdf' target='_blank'>https://arxiv.org/pdf/2404.09738.pdf</a></span>   <span><a href='https://github.com/Kewei2023/AMPCliff-generation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kewei Li, Yuqian Wu, Yinheng Li, Yutong Guo, Yan Wang, Yiyang Liang, Yusi Fan, Lan Huang, Ruochi Zhang, Fengfeng Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.09738">AMPCliff: quantitative definition and benchmarking of activity cliffs in antimicrobial peptides</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since the mechanism of action of drug molecules in the human body is difficult to reproduce in the in vitro environment, it becomes difficult to reveal the causes of the activity cliff phenomenon of drug molecules. We found out the AC of small molecules has been extensively investigated but limited knowledge is accumulated about the AC phenomenon in peptides with canonical amino acids. Understanding the mechanism of AC in canonical amino acids might help understand the one in drug molecules. This study introduces a quantitative definition and benchmarking framework AMPCliff for the AC phenomenon in antimicrobial peptides (AMPs) composed by canonical amino acids. A comprehensive analysis of the existing AMP dataset reveals a significant prevalence of AC within AMPs. AMPCliff quantifies the activities of AMPs by the MIC, and defines 0.9 as the minimum threshold for the normalized BLOSUM62 similarity score between a pair of aligned peptides with at least two-fold MIC changes. This study establishes a benchmark dataset of paired AMPs in Staphylococcus aureus from the publicly available AMP dataset GRAMPA, and conducts a rigorous procedure to evaluate various AMP AC prediction models, including nine machine learning, four deep learning algorithms, four masked language models, and four generative language models. Our analysis reveals that these models are capable of detecting AMP AC events and the pre-trained protein language model ESM2 demonstrates superior performance across the evaluations. The predictive performance of AMP activity cliffs remains to be further improved, considering that ESM2 with 33 layers only achieves the Spearman correlation coefficient 0.4669 for the regression task of the MIC values on the benchmark dataset. Source code and additional resources are available at https://www.healthinformaticslab.org/supp/ or https://github.com/Kewei2023/AMPCliff-generation.
<div id='section'>Paperid: <span id='pid'>137, <a href='https://arxiv.org/pdf/2404.04299.pdf' target='_blank'>https://arxiv.org/pdf/2404.04299.pdf</a></span>   <span><a href='https://github.com/anath2110/GENEVIC.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Anindita Nath, Savannah Mwesigwa, Yulin Dai, Xiaoqian Jiang, Zhongming Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04299">GENEVIC: GENetic data Exploration and Visualization via Intelligent interactive Console</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Summary: The vast generation of genetic data poses a significant challenge in efficiently uncovering valuable knowledge. Introducing GENEVIC, an AI-driven chat framework that tackles this challenge by bridging the gap between genetic data generation and biomedical knowledge discovery. Leveraging generative AI, notably ChatGPT, it serves as a biologist's 'copilot'. It automates the analysis, retrieval, and visualization of customized domain-specific genetic information, and integrates functionalities to generate protein interaction networks, enrich gene sets, and search scientific literature from PubMed, Google Scholar, and arXiv, making it a comprehensive tool for biomedical research. In its pilot phase, GENEVIC is assessed using a curated database that ranks genetic variants associated with Alzheimer's disease, schizophrenia, and cognition, based on their effect weights from the Polygenic Score Catalog, thus enabling researchers to prioritize genetic variants in complex diseases. GENEVIC's operation is user-friendly, accessible without any specialized training, secured by Azure OpenAI's HIPAA-compliant infrastructure, and evaluated for its efficacy through real-time query testing. As a prototype, GENEVIC is set to advance genetic research, enabling informed biomedical decisions.
  Availability and implementation: GENEVIC is publicly accessible at https://genevic-anath2024.streamlit.app. The underlying code is open-source and available via GitHub at https://github.com/anath2110/GENEVIC.git.
<div id='section'>Paperid: <span id='pid'>138, <a href='https://arxiv.org/pdf/2403.14736.pdf' target='_blank'>https://arxiv.org/pdf/2403.14736.pdf</a></span>   <span><a href='https://github.com/r08b46009/Code_for_MIGU_NANA/tree/main' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi-Shan Lan, Pin-Yu Chen, Tsung-Yi Ho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14736">NaNa and MiGu: Semantic Data Augmentation Techniques to Enhance Protein Classification in Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein classification tasks are essential in drug discovery. Real-world protein structures are dynamic, which will determine the properties of proteins. However, the existing machine learning methods, like ProNet (Wang et al., 2022a), only access limited conformational characteristics and protein side-chain features, leading to impractical protein structure and inaccuracy of protein classes in their predictions. In this paper, we propose novel semantic data augmentation methods, Novel Augmentation of New Node Attributes (NaNa), and Molecular Interactions and Geometric Upgrading (MiGu) to incorporate backbone chemical and side-chain biophysical information into protein classification tasks and a co-embedding residual learning framework. Specifically, we leverage molecular biophysical, secondary structure, chemical bonds, and ionic features of proteins to facilitate protein classification tasks. Furthermore, our semantic augmentation methods and the co-embedding residual learning framework can improve the performance of GIN (Xu et al., 2019) on EC and Fold datasets (Bairoch, 2000; Andreeva et al., 2007) by 16.41% and 11.33% respectively. Our code is available at https://github.com/r08b46009/Code_for_MIGU_NANA/tree/main.
<div id='section'>Paperid: <span id='pid'>139, <a href='https://arxiv.org/pdf/2403.12995.pdf' target='_blank'>https://arxiv.org/pdf/2403.12995.pdf</a></span>   <span><a href='https://github.com/zhengkangjie/ESM-AA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kangjie Zheng, Siyu Long, Tianyu Lu, Junwei Yang, Xinyu Dai, Ming Zhang, Zaiqing Nie, Wei-Ying Ma, Hao Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.12995">ESM All-Atom: Multi-scale Protein Language Model for Unified Molecular Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models have demonstrated significant potential in the field of protein engineering. However, current protein language models primarily operate at the residue scale, which limits their ability to provide information at the atom level. This limitation prevents us from fully exploiting the capabilities of protein language models for applications involving both proteins and small molecules. In this paper, we propose ESM-AA (ESM All-Atom), a novel approach that enables atom-scale and residue-scale unified molecular modeling. ESM-AA achieves this by pre-training on multi-scale code-switch protein sequences and utilizing a multi-scale position encoding to capture relationships among residues and atoms. Experimental results indicate that ESM-AA surpasses previous methods in protein-molecule tasks, demonstrating the full utilization of protein language models. Further investigations reveal that through unified molecular modeling, ESM-AA not only gains molecular knowledge but also retains its understanding of proteins. The source codes of ESM-AA are publicly released at https://github.com/zhengkangjie/ESM-AA.
<div id='section'>Paperid: <span id='pid'>140, <a href='https://arxiv.org/pdf/2403.05602.pdf' target='_blank'>https://arxiv.org/pdf/2403.05602.pdf</a></span>   <span><a href='https://github.com/BNLNLP/PPI-Relation-Extraction' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Gilchan Park, Sean McCorkle, Carlos Soto, Ian Blaby, Shinjae Yoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.05602">Extracting Protein-Protein Interactions (PPIs) from Biomedical Literature using Attention-based Relational Context Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Because protein-protein interactions (PPIs) are crucial to understand living systems, harvesting these data is essential to probe disease development and discern gene/protein functions and biological processes. Some curated datasets contain PPI data derived from the literature and other sources (e.g., IntAct, BioGrid, DIP, and HPRD). However, they are far from exhaustive, and their maintenance is a labor-intensive process. On the other hand, machine learning methods to automate PPI knowledge extraction from the scientific literature have been limited by a shortage of appropriate annotated data. This work presents a unified, multi-source PPI corpora with vetted interaction definitions augmented by binary interaction type labels and a Transformer-based deep learning method that exploits entities' relational context information for relation representation to improve relation classification performance. The model's performance is evaluated on four widely studied biomedical relation extraction datasets, as well as this work's target PPI datasets, to observe the effectiveness of the representation to relation extraction tasks in various data. Results show the model outperforms prior state-of-the-art models. The code and data are available at: https://github.com/BNLNLP/PPI-Relation-Extraction
<div id='section'>Paperid: <span id='pid'>141, <a href='https://arxiv.org/pdf/2403.03726.pdf' target='_blank'>https://arxiv.org/pdf/2403.03726.pdf</a></span>   <span><a href='https://github.com/MeshchaninovViacheslav/DiMA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Viacheslav Meshchaninov, Pavel Strashnov, Andrey Shevtsov, Fedor Nikolaev, Nikita Ivanisenko, Olga Kardymon, Dmitry Vetrov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.03726">Diffusion on language model encodings for protein sequence generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein sequence design has seen significant advances through discrete diffusion and autoregressive approaches, yet the potential of continuous diffusion remains underexplored. Here, we present DiMA, a latent diffusion framework that operates on protein language model representations. Through systematic exploration of architectural choices and diffusion components, we develop a robust methodology that generalizes across multiple protein encoders ranging from 8M to 3B parameters. We demonstrate that our framework achieves consistently high performance across sequence-only (ESM-2, ESMc), dual-decodable (CHEAP), and multimodal (SaProt) representations using the same architecture and training approach. We extensively evaluate existing methods alongside DiMA using multiple metrics across two protein modalities, covering quality, diversity, novelty, and distribution matching of generated proteins. DiMA consistently produces novel, high-quality and diverse protein sequences and achieves strong results compared to baselines such as autoregressive, discrete diffusion and flow matching language models. The model demonstrates versatile functionality, supporting conditional generation tasks including protein family-generation, motif scaffolding and infilling, and fold-specific sequence design. This work provides a universal continuous diffusion framework for protein sequence generation, offering both architectural insights and practical applicability across various protein design scenarios. Code is released at \href{https://github.com/MeshchaninovViacheslav/DiMA}{GitHub}.
<div id='section'>Paperid: <span id='pid'>142, <a href='https://arxiv.org/pdf/2402.19009.pdf' target='_blank'>https://arxiv.org/pdf/2402.19009.pdf</a></span>   <span><a href='https://github.com/guangyliu/EDDPM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Guangyi Liu, Yu Wang, Zeyu Feng, Qiyu Wu, Liping Tang, Yuan Gao, Zhen Li, Shuguang Cui, Julian McAuley, Zichao Yang, Eric P. Xing, Zhiting Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.19009">Unified Generation, Reconstruction, and Representation: Generalized Diffusion with Adaptive Latent Encoding-Decoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The vast applications of deep generative models are anchored in three core capabilities -- generating new instances, reconstructing inputs, and learning compact representations -- across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like variational autoencoders (VAEs), generative adversarial networks (GANs), autoregressive models, and (latent) diffusion models, generally excel in specific capabilities and data types but fall short in others. We introduce Generalized Encoding-Decoding Diffusion Probabilistic Models (EDDPMs) which integrate the core capabilities for broad applicability and enhanced performance. EDDPMs generalize the Gaussian noising-denoising in standard diffusion by introducing parameterized encoding-decoding. Crucially, EDDPMs are compatible with the well-established diffusion model objective and training recipes, allowing effective learning of the encoder-decoder parameters jointly with diffusion. By choosing appropriate encoder/decoder (e.g., large language models), EDDPMs naturally apply to different data types. Extensive experiments on text, proteins, and images demonstrate the flexibility to handle diverse data and tasks and the strong improvement over various existing models.
<div id='section'>Paperid: <span id='pid'>143, <a href='https://arxiv.org/pdf/2402.18813.pdf' target='_blank'>https://arxiv.org/pdf/2402.18813.pdf</a></span>   <span><a href='https://github.com/zqgao22/PromptMSP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziqi Gao, Xiangguo Sun, Zijing Liu, Yu Li, Hong Cheng, Jia Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18813">Protein Multimer Structure Prediction via Prompt Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the 3D structures of protein multimers is crucial, as they play a vital role in regulating various cellular processes. It has been empirically confirmed that the multimer structure prediction~(MSP) can be well handled in a step-wise assembly fashion using provided dimer structures and predicted protein-protein interactions~(PPIs). However, due to the biological gap in the formation of dimers and larger multimers, directly applying PPI prediction techniques can often cause a \textit{poor generalization} to the MSP task. To address this challenge, we aim to extend the PPI knowledge to multimers of different scales~(i.e., chain numbers). Specifically, we propose \textbf{\textsc{PromptMSP}}, a pre-training and \textbf{Prompt} tuning framework for \textbf{M}ultimer \textbf{S}tructure \textbf{P}rediction. First, we tailor the source and target tasks for effective PPI knowledge learning and efficient inference, respectively. We design PPI-inspired prompt learning to narrow the gaps of two task formats and generalize the PPI knowledge to multimers of different scales. We provide a meta-learning strategy to learn a reliable initialization of the prompt model, enabling our prompting framework to effectively adapt to limited data for large-scale multimers. Empirically, we achieve both significant accuracy (RMSD and TM-Score) and efficiency improvements compared to advanced MSP models. The code, data and checkpoints are released at \url{https://github.com/zqgao22/PromptMSP}.
<div id='section'>Paperid: <span id='pid'>144, <a href='https://arxiv.org/pdf/2402.18583.pdf' target='_blank'>https://arxiv.org/pdf/2402.18583.pdf</a></span>   <span><a href='https://github.com/YangLing0818/BindDM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhilin Huang, Ling Yang, Zaixi Zhang, Xiangxin Zhou, Yu Bao, Xiawu Zheng, Yuwei Yang, Yu Wang, Wenming Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18583">Binding-Adaptive Diffusion Models for Structure-Based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug design (SBDD) aims to generate 3D ligand molecules that bind to specific protein targets. Existing 3D deep generative models including diffusion models have shown great promise for SBDD. However, it is complex to capture the essential protein-ligand interactions exactly in 3D space for molecular generation. To address this problem, we propose a novel framework, namely Binding-Adaptive Diffusion Models (BindDM). In BindDM, we adaptively extract subcomplex, the essential part of binding sites responsible for protein-ligand interactions. Then the selected protein-ligand subcomplex is processed with SE(3)-equivariant neural networks, and transmitted back to each atom of the complex for augmenting the target-aware 3D molecule diffusion generation with binding interaction information. We iterate this hierarchical complex-subcomplex process with cross-hierarchy interaction node for adequately fusing global binding context between the complex and its corresponding subcomplex. Empirical studies on the CrossDocked2020 dataset show BindDM can generate molecules with more realistic 3D structures and higher binding affinities towards the protein targets, with up to -5.92 Avg. Vina Score, while maintaining proper molecular properties. Our code is available at https://github.com/YangLing0818/BindDM
<div id='section'>Paperid: <span id='pid'>145, <a href='https://arxiv.org/pdf/2402.18567.pdf' target='_blank'>https://arxiv.org/pdf/2402.18567.pdf</a></span>   <span><a href='https://github.com/bytedance/dplm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18567">Diffusion Language Models Are Versatile Protein Learners</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces diffusion protein language model (DPLM), a versatile protein language model that demonstrates strong generative and predictive capabilities for protein sequences. We first pre-train scalable DPLMs from evolutionary-scale protein sequences within a generative self-supervised discrete diffusion probabilistic framework, which generalizes language modeling for proteins in a principled way. After pre-training, DPLM exhibits the ability to generate structurally plausible, novel, and diverse protein sequences for unconditional generation. We further demonstrate the proposed diffusion generative pre-training makes DPLM possess a better understanding of proteins, making it a superior representation learner, which can be fine-tuned for various predictive tasks, comparing favorably to ESM2 (Lin et al., 2022). Moreover, DPLM can be tailored for various needs, which showcases its prowess of conditional generation in several ways: (1) conditioning on partial peptide sequences, e.g., generating scaffolds for functional motifs with high success rate; (2) incorporating other modalities as conditioner, e.g., structure-conditioned generation for inverse folding; and (3) steering sequence generation towards desired properties, e.g., satisfying specified secondary structures, through a plug-and-play classifier guidance. Code is released at \url{https://github.com/bytedance/dplm}.
<div id='section'>Paperid: <span id='pid'>146, <a href='https://arxiv.org/pdf/2402.18028.pdf' target='_blank'>https://arxiv.org/pdf/2402.18028.pdf</a></span>   <span><a href='https://github.com/openmedlab' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/openmedlab' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaosong Wang, Xiaofan Zhang, Guotai Wang, Junjun He, Zhongyu Li, Wentao Zhu, Yi Guo, Qi Dou, Xiaoxiao Li, Dequan Wang, Liang Hong, Qicheng Lao, Tong Ruan, Yukun Zhou, Yixue Li, Jie Zhao, Kang Li, Xin Sun, Lifeng Zhu, Shaoting Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18028">OpenMEDLab: An Open-source Platform for Multi-modality Foundation Models in Medicine</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The emerging trend of advancing generalist artificial intelligence, such as GPTv4 and Gemini, has reshaped the landscape of research (academia and industry) in machine learning and many other research areas. However, domain-specific applications of such foundation models (e.g., in medicine) remain untouched or often at their very early stages. It will require an individual set of transfer learning and model adaptation techniques by further expanding and injecting these models with domain knowledge and data. The development of such technologies could be largely accelerated if the bundle of data, algorithms, and pre-trained foundation models were gathered together and open-sourced in an organized manner. In this work, we present OpenMEDLab, an open-source platform for multi-modality foundation models. It encapsulates not only solutions of pioneering attempts in prompting and fine-tuning large language and vision models for frontline clinical and bioinformatic applications but also building domain-specific foundation models with large-scale multi-modal medical data. Importantly, it opens access to a group of pre-trained foundation models for various medical image modalities, clinical text, protein engineering, etc. Inspiring and competitive results are also demonstrated for each collected approach and model in a variety of benchmarks for downstream tasks. We welcome researchers in the field of medical artificial intelligence to continuously contribute cutting-edge methods and models to OpenMEDLab, which can be accessed via https://github.com/openmedlab.
<div id='section'>Paperid: <span id='pid'>147, <a href='https://arxiv.org/pdf/2402.17156.pdf' target='_blank'>https://arxiv.org/pdf/2402.17156.pdf</a></span>   <span><a href='https://github.com/Linzy19/TaxDiff' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lin Zongying, Li Hao, Lv Liuzhenghao, Lin Bin, Zhang Junwu, Chen Calvin Yu-Chian, Yuan Li, Tian Yonghong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17156">TaxDiff: Taxonomic-Guided Diffusion Model for Protein Sequence Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing protein sequences with specific biological functions and structural stability is crucial in biology and chemistry. Generative models already demonstrated their capabilities for reliable protein design. However, previous models are limited to the unconditional generation of protein sequences and lack the controllable generation ability that is vital to biological tasks. In this work, we propose TaxDiff, a taxonomic-guided diffusion model for controllable protein sequence generation that combines biological species information with the generative capabilities of diffusion models to generate structurally stable proteins within the sequence space. Specifically, taxonomic control information is inserted into each layer of the transformer block to achieve fine-grained control. The combination of global and local attention ensures the sequence consistency and structural foldability of taxonomic-specific proteins. Extensive experiments demonstrate that TaxDiff can consistently achieve better performance on multiple protein sequence generation benchmarks in both taxonomic-guided controllable generation and unconditional generation. Remarkably, the sequences generated by TaxDiff even surpass those produced by direct-structure-generation models in terms of confidence based on predicted structures and require only a quarter of the time of models based on the diffusion model. The code for generating proteins and training new versions of TaxDiff is available at:https://github.com/Linzy19/TaxDiff.
<div id='section'>Paperid: <span id='pid'>148, <a href='https://arxiv.org/pdf/2402.16445.pdf' target='_blank'>https://arxiv.org/pdf/2402.16445.pdf</a></span>   <span><a href='https://github.com/PKU-YuanGroup/ProLLaMA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Liuzhenghao Lv, Zongying Lin, Hao Li, Yuyang Liu, Jiaxi Cui, Calvin Yu-Chian Chen, Li Yuan, Yonghong Tian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16445">ProLLaMA: A Protein Large Language Model for Multi-Task Protein Language Processing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in Protein Language Models (PLMs) have transformed protein engineering, yet unlike their counterparts in Natural Language Processing (NLP), current PLMs exhibit a fundamental limitation: they excel in either Protein Language Understanding (PLU) or Protein Language Generation (PLG), but rarely both. This fragmentation hinders progress in protein engineering. To bridge this gap, we introduce ProLLaMA, a multitask protein language model enhanced by the Evolutionary Protein Generation Framework (EPGF). We construct a comprehensive instruction dataset containing approximately 13 million samples with over 11,000 superfamily annotations to facilitate better modeling of sequence-function landscapes. We leverage a two-stage training approach to develop ProLLaMA, a multitask LLM with protein domain expertise. Our EPGF addresses the mismatch between statistic language modeling and biological constraints through three innovations: a multi-dimensional interpretable scorer, hierarchical efficient decoding, and a probabilistic-biophysical joint selection mechanism. Extensive experiments demonstrate that ProLLaMA excels in both unconditional and controllable protein generation tasks, achieving superior structural quality metrics compared to existing PLMs. Additionally, ProLLaMA demonstrates strong understanding capabilities with a 67.1% exact match rate in superfamily prediction. EPGF significantly enhances the biological viability of generated sequences, as evidenced by improved biophysical scores (+4.3%) and structural metrics (+14.5%). The project is available at https://github.com/PKU-YuanGroup/ProLLaMA.
<div id='section'>Paperid: <span id='pid'>149, <a href='https://arxiv.org/pdf/2402.13418.pdf' target='_blank'>https://arxiv.org/pdf/2402.13418.pdf</a></span>   <span><a href='https://github.com/zhiqiangzhongddu/EvolMPNN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiqiang Zhong, Davide Mottin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.13418">Efficiently Predicting Mutational Effect on Homologous Proteins by Evolution Encoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting protein properties is paramount for biological and medical advancements. Current protein engineering mutates on a typical protein, called the wild-type, to construct a family of homologous proteins and study their properties. Yet, existing methods easily neglect subtle mutations, failing to capture the effect on the protein properties. To this end, we propose EvolMPNN, Evolution-aware Message Passing Neural Network, an efficient model to learn evolution-aware protein embeddings. EvolMPNN samples sets of anchor proteins, computes evolutionary information by means of residues and employs a differentiable evolution-aware aggregation scheme over these sampled anchors. This way, EvolMPNN can efficiently utilise a novel message-passing method to capture the mutation effect on proteins with respect to the anchor proteins. Afterwards, the aggregated evolution-aware embeddings are integrated with sequence embeddings to generate final comprehensive protein embeddings. Our model shows up to 6.4% better than state-of-the-art methods and attains 36X inference speedup in comparison with large pre-trained models. Code and models are available at https://github.com/zhiqiangzhongddu/EvolMPNN.
<div id='section'>Paperid: <span id='pid'>150, <a href='https://arxiv.org/pdf/2402.11363.pdf' target='_blank'>https://arxiv.org/pdf/2402.11363.pdf</a></span>   <span><a href='https://github.com/Biocomputing-Research-Group/DiaTrans' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiva Ebrahimi, Xuan Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11363">Transformer-based de novo peptide sequencing for data-independent acquisition mass spectrometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tandem mass spectrometry (MS/MS) stands as the predominant high-throughput technique for comprehensively analyzing protein content within biological samples. This methodology is a cornerstone driving the advancement of proteomics. In recent years, substantial strides have been made in Data-Independent Acquisition (DIA) strategies, facilitating impartial and non-targeted fragmentation of precursor ions. The DIA-generated MS/MS spectra present a formidable obstacle due to their inherent high multiplexing nature. Each spectrum encapsulates fragmented product ions originating from multiple precursor peptides. This intricacy poses a particularly acute challenge in de novo peptide/protein sequencing, where current methods are ill-equipped to address the multiplexing conundrum. In this paper, we introduce DiaTrans, a deep-learning model based on transformer architecture. It deciphers peptide sequences from DIA mass spectrometry data. Our results show significant improvements over existing STOA methods, including DeepNovo-DIA and PepNet. Casanovo-DIA enhances precision by 15.14% to 34.8%, recall by 11.62% to 31.94% at the amino acid level, and boosts precision by 59% to 81.36% at the peptide level. Integrating DIA data and our DiaTrans model holds considerable promise to uncover novel peptides and more comprehensive profiling of biological samples. Casanovo-DIA is freely available under the GNU GPL license at https://github.com/Biocomputing-Research-Group/DiaTrans.
<div id='section'>Paperid: <span id='pid'>151, <a href='https://arxiv.org/pdf/2402.08703.pdf' target='_blank'>https://arxiv.org/pdf/2402.08703.pdf</a></span>   <span><a href='https://github.com/gersteinlab/GenAI4Drug' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangru Tang, Howard Dai, Elizabeth Knight, Fang Wu, Yunyang Li, Tianxiao Li, Mark Gerstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08703">A Survey of Generative AI for de novo Drug Design: New Frontiers in Molecule and Protein Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence (AI)-driven methods can vastly improve the historically costly drug design process, with various generative models already in widespread use. Generative models for de novo drug design, in particular, focus on the creation of novel biological compounds entirely from scratch, representing a promising future direction. Rapid development in the field, combined with the inherent complexity of the drug design process, creates a difficult landscape for new researchers to enter. In this survey, we organize de novo drug design into two overarching themes: small molecule and protein generation. Within each theme, we identify a variety of subtasks and applications, highlighting important datasets, benchmarks, and model architectures and comparing the performance of top models. We take a broad approach to AI-driven drug design, allowing for both micro-level comparisons of various methods within each subtask and macro-level observations across different fields. We discuss parallel challenges and approaches between the two applications and highlight future directions for AI-driven de novo drug design as a whole. An organized repository of all covered sources is available at https://github.com/gersteinlab/GenAI4Drug.
<div id='section'>Paperid: <span id='pid'>152, <a href='https://arxiv.org/pdf/2402.06532.pdf' target='_blank'>https://arxiv.org/pdf/2402.06532.pdf</a></span>   <span><a href='https://github.com/michael-s-yao/gabo' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael S. Yao, Yimeng Zeng, Hamsa Bastani, Jacob Gardner, James C. Gee, Osbert Bastani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06532">Generative Adversarial Model-Based Optimization via Source Critic Regularization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline model-based optimization seeks to optimize against a learned surrogate model without querying the true oracle objective function during optimization. Such tasks are commonly encountered in protein design, robotics, and clinical medicine where evaluating the oracle function is prohibitively expensive. However, inaccurate surrogate model predictions are frequently encountered along offline optimization trajectories. To address this limitation, we propose generative adversarial model-based optimization using adaptive source critic regularization (aSCR) -- a task- and optimizer- agnostic framework for constraining the optimization trajectory to regions of the design space where the surrogate function is reliable. We propose a computationally tractable algorithm to dynamically adjust the strength of this constraint, and show how leveraging aSCR with standard Bayesian optimization outperforms existing methods on a suite of offline generative design tasks. Our code is available at https://github.com/michael-s-yao/gabo
<div id='section'>Paperid: <span id='pid'>153, <a href='https://arxiv.org/pdf/2402.05856.pdf' target='_blank'>https://arxiv.org/pdf/2402.05856.pdf</a></span>   <span><a href='https://github.com/DeepGraphLearning/esm-s' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zuobai Zhang, Jiarui Lu, Vijil Chenthamarakshan, AurÃ©lie Lozano, Payel Das, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.05856">Structure-Informed Protein Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models are a powerful tool for learning protein representations through pre-training on vast protein sequence datasets. However, traditional protein language models lack explicit structural supervision, despite its relevance to protein function. To address this issue, we introduce the integration of remote homology detection to distill structural information into protein language models without requiring explicit protein structures as input. We evaluate the impact of this structure-informed training on downstream protein function prediction tasks. Experimental results reveal consistent improvements in function annotation accuracy for EC number and GO term prediction. Performance on mutant datasets, however, varies based on the relationship between targeted properties and protein structures. This underscores the importance of considering this relationship when applying structure-aware training to protein function prediction tasks. Code and model weights are available at https://github.com/DeepGraphLearning/esm-s.
<div id='section'>Paperid: <span id='pid'>154, <a href='https://arxiv.org/pdf/2402.04845.pdf' target='_blank'>https://arxiv.org/pdf/2402.04845.pdf</a></span>   <span><a href='https://github.com/bjing2016/alphaflow' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Jing, Bonnie Berger, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.04845">AlphaFold Meets Flow Matching for Generating Protein Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The biological functions of proteins often depend on dynamic structural ensembles. In this work, we develop a flow-based generative modeling approach for learning and sampling the conformational landscapes of proteins. We repurpose highly accurate single-state predictors such as AlphaFold and ESMFold and fine-tune them under a custom flow matching framework to obtain sequence-conditoned generative models of protein structure called AlphaFlow and ESMFlow. When trained and evaluated on the PDB, our method provides a superior combination of precision and diversity compared to AlphaFold with MSA subsampling. When further trained on ensembles from all-atom MD, our method accurately captures conformational flexibility, positional distributions, and higher-order ensemble observables for unseen proteins. Moreover, our method can diversify a static PDB structure with faster wall-clock convergence to certain equilibrium properties than replicate MD trajectories, demonstrating its potential as a proxy for expensive physics-based simulations. Code is available at https://github.com/bjing2016/alphaflow.
<div id='section'>Paperid: <span id='pid'>155, <a href='https://arxiv.org/pdf/2401.15721.pdf' target='_blank'>https://arxiv.org/pdf/2401.15721.pdf</a></span>   <span><a href='https://github.com/bonaventuredossou/ece526_course_project' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bonaventure F. P. Dossou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.15721">A Study of Acquisition Functions for Medical Imaging Deep Active Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Deep Learning revolution has enabled groundbreaking achievements in recent years. From breast cancer detection to protein folding, deep learning algorithms have been at the core of very important advancements. However, these modern advancements are becoming more and more data-hungry, especially on labeled data whose availability is scarce: this is even more prevalent in the medical context. In this work, we show how active learning could be very effective in data scarcity situations, where obtaining labeled data (or annotation budget is very limited). We compare several selection criteria (BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset. We also explored the effect of acquired pool size on the model's performance. Our results suggest that uncertainty is useful to the Melanoma detection task, and confirms the hypotheses of the author of the paper of interest, that \textit{bald} performs on average better than other acquisition functions. Our extended analyses however revealed that all acquisition functions perform badly on the positive (cancerous) samples, suggesting exploitation of class unbalance, which could be crucial in real-world settings. We finish by suggesting future work directions that would be useful to improve this current work. The code of our implementation is open-sourced at \url{https://github.com/bonaventuredossou/ece526_course_project}
<div id='section'>Paperid: <span id='pid'>156, <a href='https://arxiv.org/pdf/2401.15478.pdf' target='_blank'>https://arxiv.org/pdf/2401.15478.pdf</a></span>   <span><a href='https://github.com/mcneela/Mixed-Curvature-GCN' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/mcneela/Mixed-Curvature-Pathways' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel McNeela, Frederic Sala, Anthony Gitter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.15478">Product Manifold Representations for Learning on Biological Pathways</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models that embed graphs in non-Euclidean spaces have shown substantial benefits in a variety of contexts, but their application has not been studied extensively in the biological domain, particularly with respect to biological pathway graphs. Such graphs exhibit a variety of complex network structures, presenting challenges to existing embedding approaches. Learning high-quality embeddings for biological pathway graphs is important for researchers looking to understand the underpinnings of disease and train high-quality predictive models on these networks. In this work, we investigate the effects of embedding pathway graphs in non-Euclidean mixed-curvature spaces and compare against traditional Euclidean graph representation learning models. We then train a supervised model using the learned node embeddings to predict missing protein-protein interactions in pathway graphs. We find large reductions in distortion and boosts on in-distribution edge prediction performance as a result of using mixed-curvature embeddings and their corresponding graph neural network models. However, we find that mixed-curvature representations underperform existing baselines on out-of-distribution edge prediction performance suggesting that these representations may overfit to the training graph topology. We provide our Mixed-Curvature Product Graph Convolutional Network code at https://github.com/mcneela/Mixed-Curvature-GCN and our pathway analysis code at https://github.com/mcneela/Mixed-Curvature-Pathways.
<div id='section'>Paperid: <span id='pid'>157, <a href='https://arxiv.org/pdf/2401.14819.pdf' target='_blank'>https://arxiv.org/pdf/2401.14819.pdf</a></span>   <span><a href='https://github.com/BorgwardtLab/PST' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dexiong Chen, Philip Hartout, Paolo Pellizzoni, Carlos Oliver, Karsten Borgwardt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.14819">Endowing Protein Language Models with Structural Knowledge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the relationships between protein sequence, structure and function is a long-standing biological challenge with manifold implications from drug design to our understanding of evolution. Recently, protein language models have emerged as the preferred method for this challenge, thanks to their ability to harness large sequence databases. Yet, their reliance on expansive sequence data and parameter sets limits their flexibility and practicality in real-world scenarios. Concurrently, the recent surge in computationally predicted protein structures unlocks new opportunities in protein representation learning. While promising, the computational burden carried by such complex data still hinders widely-adopted practical applications. To address these limitations, we introduce a novel framework that enhances protein language models by integrating protein structural data. Drawing from recent advances in graph transformers, our approach refines the self-attention mechanisms of pretrained language transformers by integrating structural information with structure extractor modules. This refined model, termed Protein Structure Transformer (PST), is further pretrained on a small protein structure database, using the same masked language modeling objective as traditional protein language models. Empirical evaluations of PST demonstrate its superior parameter efficiency relative to protein language models, despite being pretrained on a dataset comprising only 542K structures. Notably, PST consistently outperforms the state-of-the-art foundation model for protein sequences, ESM-2, setting a new benchmark in protein function prediction. Our findings underscore the potential of integrating structural information into protein language models, paving the way for more effective and efficient protein modeling Code and pretrained models are available at https://github.com/BorgwardtLab/PST.
<div id='section'>Paperid: <span id='pid'>158, <a href='https://arxiv.org/pdf/2401.11360.pdf' target='_blank'>https://arxiv.org/pdf/2401.11360.pdf</a></span>   <span><a href='https://github.com/zhangruochi/PepHarmony' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruochi Zhang, Haoran Wu, Chang Liu, Huaping Li, Yuqian Wu, Kewei Li, Yifan Wang, Yifan Deng, Jiahui Chen, Fengfeng Zhou, Xin Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.11360">PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/.
<div id='section'>Paperid: <span id='pid'>159, <a href='https://arxiv.org/pdf/2401.10144.pdf' target='_blank'>https://arxiv.org/pdf/2401.10144.pdf</a></span>   <span><a href='https://github.com/xmed-lab/HCGNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiqun Lin, Liang Pan, Yi Li, Ziwei Liu, Xiaomeng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.10144">Exploiting Hierarchical Interactions for Protein Surface Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting interactions between proteins is one of the most important yet challenging problems in structural bioinformatics. Intrinsically, potential function sites in protein surfaces are determined by both geometric and chemical features. However, existing works only consider handcrafted or individually learned chemical features from the atom type and extract geometric features independently. Here, we identify two key properties of effective protein surface learning: 1) relationship among atoms: atoms are linked with each other by covalent bonds to form biomolecules instead of appearing alone, leading to the significance of modeling the relationship among atoms in chemical feature learning. 2) hierarchical feature interaction: the neighboring residue effect validates the significance of hierarchical feature interaction among atoms and between surface points and atoms (or residues). In this paper, we present a principled framework based on deep learning techniques, namely Hierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for protein surface analysis by bridging chemical and geometric features with hierarchical interactions. Extensive experiments demonstrate that our method outperforms the prior state-of-the-art method by 2.3% in site prediction task and 3.2% in interaction matching task, respectively. Our code is available at https://github.com/xmed-lab/HCGNet.
<div id='section'>Paperid: <span id='pid'>160, <a href='https://arxiv.org/pdf/2401.09176.pdf' target='_blank'>https://arxiv.org/pdf/2401.09176.pdf</a></span>   <span><a href='https://github.com/idrugLab/ADCNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Liye Chen, Biaoshun Li, Yihao Chen, Mujie Lin, Shipeng Zhang, Chenxin Li, Yu Pang, Ling Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.09176">ADCNet: a unified framework for predicting the activity of antibody-drug conjugates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibody-drug conjugate (ADC) has revolutionized the field of cancer treatment in the era of precision medicine due to their ability to precisely target cancer cells and release highly effective drug. Nevertheless, the realization of rational design of ADC is very difficult because the relationship between their structures and activities is difficult to understand. In the present study, we introduce a unified deep learning framework called ADCNet to help design potential ADCs. The ADCNet highly integrates the protein representation learning language model ESM-2 and small-molecule representation learning language model FG-BERT models to achieve activity prediction through learning meaningful features from antigen and antibody protein sequences of ADC, SMILES strings of linker and payload, and drug-antibody ratio (DAR) value. Based on a carefully designed and manually tailored ADC data set, extensive evaluation results reveal that ADCNet performs best on the test set compared to baseline machine learning models across all evaluation metrics. For example, it achieves an average prediction accuracy of 87.12%, a balanced accuracy of 0.8689, and an area under receiver operating characteristic curve of 0.9293 on the test set. In addition, cross-validation, ablation experiments, and external independent testing results further prove the stability, advancement, and robustness of the ADCNet architecture. For the convenience of the community, we develop the first online platform (https://ADCNet.idruglab.cn) for the prediction of ADCs activity based on the optimal ADCNet model, and the source code is publicly available at https://github.com/idrugLab/ADCNet.
<div id='section'>Paperid: <span id='pid'>161, <a href='https://arxiv.org/pdf/2401.06155.pdf' target='_blank'>https://arxiv.org/pdf/2401.06155.pdf</a></span>   <span><a href='https://github.com/HXYfighter/MolRL-MGPT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiuyuan Hu, Guoqing Liu, Yang Zhao, Hao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.06155">De novo Drug Design using Reinforcement Learning with Multiple GPT Agents</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>De novo drug design is a pivotal issue in pharmacology and a new area of focus in AI for science research. A central challenge in this field is to generate molecules with specific properties while also producing a wide range of diverse candidates. Although advanced technologies such as transformer models and reinforcement learning have been applied in drug design, their potential has not been fully realized. Therefore, we propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents for drug molecular generation. To promote molecular diversity, we encourage the agents to collaborate in searching for desirable molecules in diverse directions. Our algorithm has shown promising results on the GuacaMol benchmark and exhibits efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes are available at: https://github.com/HXYfighter/MolRL-MGPT.
<div id='section'>Paperid: <span id='pid'>162, <a href='https://arxiv.org/pdf/2401.06151.pdf' target='_blank'>https://arxiv.org/pdf/2401.06151.pdf</a></span>   <span><a href='https://github.com/Profluent-Internships/MMDiff' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/Profluent-Internships/MMDiff' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Morehead, Jeffrey Ruffolo, Aadyot Bhatnagar, Ali Madani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.06151">Towards Joint Sequence-Structure Generation of Nucleic Acid and Protein Complexes with SE(3)-Discrete Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative models of macromolecules carry abundant and impactful implications for industrial and biomedical efforts in protein engineering. However, existing methods are currently limited to modeling protein structures or sequences, independently or jointly, without regard to the interactions that commonly occur between proteins and other macromolecules. In this work, we introduce MMDiff, a generative model that jointly designs sequences and structures of nucleic acid and protein complexes, independently or in complex, using joint SE(3)-discrete diffusion noise. Such a model has important implications for emerging areas of macromolecular design including structure-based transcription factor design and design of noncoding RNA sequences. We demonstrate the utility of MMDiff through a rigorous new design benchmark for macromolecular complex generation that we introduce in this work. Our results demonstrate that MMDiff is able to successfully generate micro-RNA and single-stranded DNA molecules while being modestly capable of joint modeling DNA and RNA molecules in interaction with multi-chain protein complexes. Source code: https://github.com/Profluent-Internships/MMDiff.
<div id='section'>Paperid: <span id='pid'>163, <a href='https://arxiv.org/pdf/2401.04082.pdf' target='_blank'>https://arxiv.org/pdf/2401.04082.pdf</a></span>   <span><a href='https://github.com/microsoft/protein-frame-flow' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jason Yim, Andrew Campbell, Emile Mathieu, Andrew Y. K. Foong, Michael Gastegger, JosÃ© JimÃ©nez-Luna, Sarah Lewis, Victor Garcia Satorras, Bastiaan S. Veeling, Frank NoÃ©, Regina Barzilay, Tommi S. Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04082">Improved motif-scaffolding with SE(3) flow matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein design often begins with the knowledge of a desired function from a motif which motif-scaffolding aims to construct a functional protein around. Recently, generative models have achieved breakthrough success in designing scaffolds for a range of motifs. However, generated scaffolds tend to lack structural diversity, which can hinder success in wet-lab validation. In this work, we extend FrameFlow, an SE(3) flow matching model for protein backbone generation, to perform motif-scaffolding with two complementary approaches. The first is motif amortization, in which FrameFlow is trained with the motif as input using a data augmentation strategy. The second is motif guidance, which performs scaffolding using an estimate of the conditional score from FrameFlow without additional training. On a benchmark of 24 biologically meaningful motifs, we show our method achieves 2.5 times more designable and unique motif-scaffolds compared to state-of-the-art. Code: https://github.com/microsoft/protein-frame-flow
<div id='section'>Paperid: <span id='pid'>164, <a href='https://arxiv.org/pdf/2401.00529.pdf' target='_blank'>https://arxiv.org/pdf/2401.00529.pdf</a></span>   <span><a href='https://github.com/alibaba/graph-gpt' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qifang Zhao, Weidong Ren, Tianyu Li, Hong Liu, Xingsheng He, Xiaoxiao Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00529">GraphGPT: Generative Pre-trained Graph Eulerian Transformer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduceGraphGPT, a novel self-supervised generative pre-trained model for graph learning based on the Graph Eulerian Transformer (GET). First, we propose GET, which combines a standard transformer encoder or decoder architecture with an innovative graph-to-sequence transformation method. This method converts graphs or sampled subgraphs into sequences of tokens representing nodes, edges, and attributes in a reversible manner using Eulerian paths. We pre-train GET using either of the two self-supervised tasks: next-token prediction (NTP) and scheduled masked-token prediction (SMTP). The pre-trained model is then fine-tuned for downstream tasks such as graph-, edge-, and node-level prediction. Despite its simplicity, GraphGPT achieves performance comparable to or surpassing state-of-the-art methods on multiple large-scale Open Graph Benchmark (OGB) datasets. It demonstrates exceptional results on the molecular property prediction dataset PCQM4Mv2 and the protein-protein interaction dataset ogbl-ppa. Notably, generative pre-training enables scaling GraphGPT to 2 billion parameters while maintaining performance gains - a breakthrough that overcomes the scalability limitations of traditional Graph Neural Networks (GNNs) and prior graph transformers (GTs). To advance research in graph foundation models and facilitate scientific discovery in chemistry, materials science, and related fields, we will release the source code (https://github.com/alibaba/graph-gpt) and pre-trained checkpoints.
<div id='section'>Paperid: <span id='pid'>165, <a href='https://arxiv.org/pdf/2312.04323.pdf' target='_blank'>https://arxiv.org/pdf/2312.04323.pdf</a></span>   <span><a href='https://github.com/bjing2016/scalar-fields' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Jing, Tommi Jaakkola, Bonnie Berger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.04323">Equivariant Scalar Fields for Molecular Docking with Fast Fourier Transforms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking is critical to structure-based virtual screening, yet the throughput of such workflows is limited by the expensive optimization of scoring functions involved in most docking algorithms. We explore how machine learning can accelerate this process by learning a scoring function with a functional form that allows for more rapid optimization. Specifically, we define the scoring function to be the cross-correlation of multi-channel ligand and protein scalar fields parameterized by equivariant graph neural networks, enabling rapid optimization over rigid-body degrees of freedom with fast Fourier transforms. The runtime of our approach can be amortized at several levels of abstraction, and is particularly favorable for virtual screening settings with a common binding pocket. We benchmark our scoring functions on two simplified docking-related tasks: decoy pose scoring and rigid conformer docking. Our method attains similar but faster performance on crystal structures compared to the widely-used Vina and Gnina scoring functions, and is more robust on computationally predicted structures. Code is available at https://github.com/bjing2016/scalar-fields.
<div id='section'>Paperid: <span id='pid'>166, <a href='https://arxiv.org/pdf/2312.00842.pdf' target='_blank'>https://arxiv.org/pdf/2312.00842.pdf</a></span>   <span><a href='https://github.com/wwzll123/ESM-NBR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenwu Zeng, Dafeng Lv, Wenjuan Liu, Shaoliang Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00842">ESM-NBR: fast and accurate nucleic acid-binding residue prediction via protein language model feature representation and multi-task learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-nucleic acid interactions play a very important role in a variety of biological activities. Accurate identification of nucleic acid-binding residues is a critical step in understanding the interaction mechanisms. Although many computationally based methods have been developed to predict nucleic acid-binding residues, challenges remain. In this study, a fast and accurate sequence-based method, called ESM-NBR, is proposed. In ESM-NBR, we first use the large protein language model ESM2 to extract discriminative biological properties feature representation from protein primary sequences; then, a multi-task deep learning model composed of stacked bidirectional long short-term memory (BiLSTM) and multi-layer perceptron (MLP) networks is employed to explore common and private information of DNA- and RNA-binding residues with ESM2 feature as input. Experimental results on benchmark data sets demonstrate that the prediction performance of ESM2 feature representation comprehensively outperforms evolutionary information-based hidden Markov model (HMM) features. Meanwhile, the ESM-NBR obtains the MCC values for DNA-binding residues prediction of 0.427 and 0.391 on two independent test sets, which are 18.61 and 10.45% higher than those of the second-best methods, respectively. Moreover, by completely discarding the time-cost multiple sequence alignment process, the prediction speed of ESM-NBR far exceeds that of existing methods (5.52s for a protein sequence of length 500, which is about 16 times faster than the second-fastest method). A user-friendly standalone package and the data of ESM-NBR are freely available for academic use at: https://github.com/wwzll123/ESM-NBR.
<div id='section'>Paperid: <span id='pid'>167, <a href='https://arxiv.org/pdf/2312.00191.pdf' target='_blank'>https://arxiv.org/pdf/2312.00191.pdf</a></span>   <span><a href='https://github.com/drorlab/GLOW_IVES' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Patricia Suriana, Ron O. Dror
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00191">Enhancing Ligand Pose Sampling for Molecular Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning promises to dramatically improve scoring functions for molecular docking, leading to substantial advances in binding pose prediction and virtual screening. To train scoring functions-and to perform molecular docking-one must generate a set of candidate ligand binding poses. Unfortunately, the sampling protocols currently used to generate candidate poses frequently fail to produce any poses close to the correct, experimentally determined pose, unless information about the correct pose is provided. This limits the accuracy of learned scoring functions and molecular docking. Here, we describe two improved protocols for pose sampling: GLOW (auGmented sampLing with sOftened vdW potential) and a novel technique named IVES (IteratiVe Ensemble Sampling). Our benchmarking results demonstrate the effectiveness of our methods in improving the likelihood of sampling accurate poses, especially for binding pockets whose shape changes substantially when different ligands bind. This improvement is observed across both experimentally determined and AlphaFold-generated protein structures. Additionally, we present datasets of candidate ligand poses generated using our methods for each of around 5,000 protein-ligand cross-docking pairs, for training and testing scoring functions. To benefit the research community, we provide these cross-docking datasets and an open-source Python implementation of GLOW and IVES at https://github.com/drorlab/GLOW_IVES .
<div id='section'>Paperid: <span id='pid'>168, <a href='https://arxiv.org/pdf/2312.00080.pdf' target='_blank'>https://arxiv.org/pdf/2312.00080.pdf</a></span>   <span><a href='https://github.com/WANG-CR/PDB-Struct' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuanrui Wang, Bozitao Zhong, Zuobai Zhang, Narendra Chaudhary, Sanchit Misra, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00080">PDB-Struct: A Comprehensive Benchmark for Structure-based Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based protein design has attracted increasing interest, with numerous methods being introduced in recent years. However, a universally accepted method for evaluation has not been established, since the wet-lab validation can be overly time-consuming for the development of new algorithms, and the $\textit{in silico}$ validation with recovery and perplexity metrics is efficient but may not precisely reflect true foldability. To address this gap, we introduce two novel metrics: refoldability-based metric, which leverages high-accuracy protein structure prediction models as a proxy for wet lab experiments, and stability-based metric, which assesses whether models can assign high likelihoods to experimentally stable proteins. We curate datasets from high-quality CATH protein data, high-throughput $\textit{de novo}$ designed proteins, and mega-scale experimental mutagenesis experiments, and in doing so, present the $\textbf{PDB-Struct}$ benchmark that evaluates both recent and previously uncompared protein design methods. Experimental results indicate that ByProt, ProteinMPNN, and ESM-IF perform exceptionally well on our benchmark, while ESM-Design and AF-Design fall short on the refoldability metric. We also show that while some methods exhibit high sequence recovery, they do not perform as well on our new benchmark. Our proposed benchmark paves the way for a fair and comprehensive evaluation of protein design methods in the future. Code is available at https://github.com/WANG-CR/PDB-Struct.
<div id='section'>Paperid: <span id='pid'>169, <a href='https://arxiv.org/pdf/2311.12570.pdf' target='_blank'>https://arxiv.org/pdf/2311.12570.pdf</a></span>   <span><a href='https://github.com/frederikkemarin/BEND,' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/frederikkemarin/BEND' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Frederikke Isa Marin, Felix Teufel, Marc Horlacher, Dennis Madsen, Dennis Pultz, Ole Winther, Wouter Boomsma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12570">BEND: Benchmarking DNA Language Models on biologically meaningful tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The genome sequence contains the blueprint for governing cellular processes. While the availability of genomes has vastly increased over the last decades, experimental annotation of the various functional, non-coding and regulatory elements encoded in the DNA sequence remains both expensive and challenging. This has sparked interest in unsupervised language modeling of genomic DNA, a paradigm that has seen great success for protein sequence data. Although various DNA language models have been proposed, evaluation tasks often differ between individual works, and might not fully recapitulate the fundamental challenges of genome annotation, including the length, scale and sparsity of the data. In this study, we introduce BEND, a Benchmark for DNA language models, featuring a collection of realistic and biologically meaningful downstream tasks defined on the human genome. We find that embeddings from current DNA LMs can approach performance of expert methods on some tasks, but only capture limited information about long-range features. BEND is available at https://github.com/frederikkemarin/BEND.
<div id='section'>Paperid: <span id='pid'>170, <a href='https://arxiv.org/pdf/2311.06670.pdf' target='_blank'>https://arxiv.org/pdf/2311.06670.pdf</a></span>   <span><a href='https://github.com/issararab/EPSAPG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Issar Arab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.06670">EPSAPG: A Pipeline Combining MMseqs2 and PSI-BLAST to Quickly Generate Extensive Protein Sequence Alignment Profiles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Numerous machine learning (ML) models employed in protein function and structure prediction depend on evolutionary information, which is captured through multiple-sequence alignments (MSA) or position-specific scoring matrices (PSSM) as generated by PSI-BLAST. Consequently, these predictive methods are burdened by substantial computational demands and prolonged computing time requirements. The principal challenge stems from the necessity imposed on the PSI-BLAST software to load large sequence databases sequentially in batches and then search for sequence alignments akin to a given query sequence. In the case of batch queries, the runtime scales even linearly. The predicament at hand is becoming more challenging as the size of bio-sequence data repositories experiences exponential growth over time and as a consequence, this upward trend exerts a proportional strain on the runtime of PSI-BLAST. To address this issue, an eminent resolution lies in leveraging the MMseqs2 method, capable of expediting the search process by a magnitude of 100. However, MMseqs2 cannot be directly employed to generate the final output in the desired format of PSI-BLAST alignments and PSSM profiles. In this research work, I developed a comprehensive pipeline that synergistically integrates both MMseqs2 and PSI-BLAST, resulting in the creation of a robust, optimized, and highly efficient hybrid alignment pipeline. Notably, the hybrid tool exhibits a significant speed improvement, surpassing the runtime performance of PSI-BLAST in generating sequence alignment profiles by a factor of two orders of magnitude. It is implemented in C++ and is freely available under the MIT license at https://github.com/issararab/EPSAPG.
<div id='section'>Paperid: <span id='pid'>171, <a href='https://arxiv.org/pdf/2311.04419.pdf' target='_blank'>https://arxiv.org/pdf/2311.04419.pdf</a></span>   <span><a href='https://github.com/zhangruochi/pepland' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruochi Zhang, Haoran Wu, Yuting Xiu, Kewei Li, Ningning Chen, Yu Wang, Yan Wang, Xin Gao, Fengfeng Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.04419">PepLand: a large-scale pre-trained peptide representation model for a comprehensive landscape of both canonical and non-canonical amino acids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, the scientific community has become increasingly interested on peptides with non-canonical amino acids due to their superior stability and resistance to proteolytic degradation. These peptides present promising modifications to biological, pharmacological, and physiochemical attributes in both endogenous and engineered peptides. Notwithstanding their considerable advantages, the scientific community exhibits a conspicuous absence of an effective pre-trained model adept at distilling feature representations from such complex peptide sequences. We herein propose PepLand, a novel pre-training architecture for representation and property analysis of peptides spanning both canonical and non-canonical amino acids. In essence, PepLand leverages a comprehensive multi-view heterogeneous graph neural network tailored to unveil the subtle structural representations of peptides. Empirical validations underscore PepLand's effectiveness across an array of peptide property predictions, encompassing protein-protein interactions, permeability, solubility, and synthesizability. The rigorous evaluation confirms PepLand's unparalleled capability in capturing salient synthetic peptide features, thereby laying a robust foundation for transformative advances in peptide-centric research domains. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/pepland
<div id='section'>Paperid: <span id='pid'>172, <a href='https://arxiv.org/pdf/2310.17415.pdf' target='_blank'>https://arxiv.org/pdf/2310.17415.pdf</a></span>   <span><a href='https://github.com/ginnm/ProteinPretraining' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Tan, Mingchen Li, Pan Tan, Ziyi Zhou, Huiqun Yu, Guisheng Fan, Liang Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.17415">PETA: Evaluating the Impact of Protein Transfer Learning with Sub-word Tokenization on Downstream Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large protein language models are adept at capturing the underlying evolutionary information in primary structures, offering significant practical value for protein engineering. Compared to natural language models, protein amino acid sequences have a smaller data volume and a limited combinatorial space. Choosing an appropriate vocabulary size to optimize the pre-trained model is a pivotal issue. Moreover, despite the wealth of benchmarks and studies in the natural language community, there remains a lack of a comprehensive benchmark for systematically evaluating protein language model quality. Given these challenges, PETA trained language models with 14 different vocabulary sizes under three tokenization methods. It conducted thousands of tests on 33 diverse downstream datasets to assess the models' transfer learning capabilities, incorporating two classification heads and three random seeds to mitigate potential biases. Extensive experiments indicate that vocabulary sizes between 50 and 200 optimize the model, whereas sizes exceeding 800 detrimentally affect the model's representational performance. Our code, model weights and datasets are available at https://github.com/ginnm/ProteinPretraining.
<div id='section'>Paperid: <span id='pid'>173, <a href='https://arxiv.org/pdf/2310.10861.pdf' target='_blank'>https://arxiv.org/pdf/2310.10861.pdf</a></span>   <span><a href='https://github.com/JiajiaLi04/Soybean-Pod-Counting-from-UAV-Images' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiajia Li, Raju Thada Magar, Dong Chen, Feng Lin, Dechun Wang, Xiang Yin, Weichao Zhuang, Zhaojian Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.10861">SoybeanNet: Transformer-Based Convolutional Neural Network for Soybean Pod Counting from Unmanned Aerial Vehicle (UAV) Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Soybeans are a critical source of food, protein and oil, and thus have received extensive research aimed at enhancing their yield, refining cultivation practices, and advancing soybean breeding techniques. Within this context, soybean pod counting plays an essential role in understanding and optimizing production. Despite recent advancements, the development of a robust pod-counting algorithm capable of performing effectively in real-field conditions remains a significant challenge This paper presents a pioneering work of accurate soybean pod counting utilizing unmanned aerial vehicle (UAV) images captured from actual soybean fields in Michigan, USA. Specifically, this paper presents SoybeanNet, a novel point-based counting network that harnesses powerful transformer backbones for simultaneous soybean pod counting and localization with high accuracy. In addition, a new dataset of UAV-acquired images for soybean pod counting was created and open-sourced, consisting of 113 drone images with more than 260k manually annotated soybean pods captured under natural lighting conditions. Through comprehensive evaluations, SoybeanNet demonstrated superior performance over five state-of-the-art approaches when tested on the collected images. Remarkably, SoybeanNet achieved a counting accuracy of $84.51\%$ when tested on the testing dataset, attesting to its efficacy in real-world scenarios. The publication also provides both the source code (\url{https://github.com/JiajiaLi04/Soybean-Pod-Counting-from-UAV-Images}) and the labeled soybean dataset (\url{https://www.kaggle.com/datasets/jiajiali/uav-based-soybean-pod-images}), offering a valuable resource for future research endeavors in soybean pod counting and related fields.
<div id='section'>Paperid: <span id='pid'>174, <a href='https://arxiv.org/pdf/2310.06763.pdf' target='_blank'>https://arxiv.org/pdf/2310.06763.pdf</a></span>   <span><a href='https://github.com/QizhiPei/FABind' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qizhi Pei, Kaiyuan Gao, Lijun Wu, Jinhua Zhu, Yingce Xia, Shufang Xie, Tao Qin, Kun He, Tie-Yan Liu, Rui Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06763">FABind: Fast and Accurate Protein-Ligand Binding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling the interaction between proteins and ligands and accurately predicting their binding structures is a critical yet challenging task in drug discovery. Recent advancements in deep learning have shown promise in addressing this challenge, with sampling-based and regression-based methods emerging as two prominent approaches. However, these methods have notable limitations. Sampling-based methods often suffer from low efficiency due to the need for generating multiple candidate structures for selection. On the other hand, regression-based methods offer fast predictions but may experience decreased accuracy. Additionally, the variation in protein sizes often requires external modules for selecting suitable binding pockets, further impacting efficiency. In this work, we propose $\mathbf{FABind}$, an end-to-end model that combines pocket prediction and docking to achieve accurate and fast protein-ligand binding. $\mathbf{FABind}$ incorporates a unique ligand-informed pocket prediction module, which is also leveraged for docking pose estimation. The model further enhances the docking process by incrementally integrating the predicted pocket to optimize protein-ligand binding, reducing discrepancies between training and inference. Through extensive experiments on benchmark datasets, our proposed $\mathbf{FABind}$ demonstrates strong advantages in terms of effectiveness and efficiency compared to existing methods. Our code is available at https://github.com/QizhiPei/FABind
<div id='section'>Paperid: <span id='pid'>175, <a href='https://arxiv.org/pdf/2310.04017.pdf' target='_blank'>https://arxiv.org/pdf/2310.04017.pdf</a></span>   <span><a href='https://github.com/Yijia-Xiao/PgraphDTA/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Rakesh Bal, Yijia Xiao, Wei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.04017">PGraphDTA: Improving Drug Target Interaction Prediction using Protein Language Models and Contact Maps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing and discovering new drugs is a complex and resource-intensive endeavor that often involves substantial costs, time investment, and safety concerns. A key aspect of drug discovery involves identifying novel drug-target (DT) interactions. Existing computational methods for predicting DT interactions have primarily focused on binary classification tasks, aiming to determine whether a DT pair interacts or not. However, protein-ligand interactions exhibit a continuum of binding strengths, known as binding affinity, presenting a persistent challenge for accurate prediction. In this study, we investigate various techniques employed in Drug Target Interaction (DTI) prediction and propose novel enhancements to enhance their performance. Our approaches include the integration of Protein Language Models (PLMs) and the incorporation of Contact Map information as an inductive bias within current models. Through extensive experimentation, we demonstrate that our proposed approaches outperform the baseline models considered in this study, presenting a compelling case for further development in this direction. We anticipate that the insights gained from this work will significantly narrow the search space for potential drugs targeting specific proteins, thereby accelerating drug discovery. Code and data for PGraphDTA are available at https://github.com/Yijia-Xiao/PgraphDTA/.
<div id='section'>Paperid: <span id='pid'>176, <a href='https://arxiv.org/pdf/2310.03946.pdf' target='_blank'>https://arxiv.org/pdf/2310.03946.pdf</a></span>   <span><a href='https://github.com/Lee1701/Lee2023a' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ho-Joon Lee, Prashant S. Emani, Mark B. Gerstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03946">Improved prediction of ligand-protein binding affinities by meta-modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The accurate screening of candidate drug ligands against target proteins through computational approaches is of prime interest to drug development efforts. Such virtual screening depends in part on methods to predict the binding affinity between ligands and proteins. Many computational models for binding affinity prediction have been developed, but with varying results across targets. Given that ensembling or meta-modeling approaches have shown great promise in reducing model-specific biases, we develop a framework to integrate published force-field-based empirical docking and sequence-based deep learning models. In building this framework, we evaluate many combinations of individual base models, training databases, and several meta-modeling approaches. We show that many of our meta-models significantly improve affinity predictions over base models. Our best meta-models achieve comparable performance to state-of-the-art deep learning tools exclusively based on 3D structures, while allowing for improved database scalability and flexibility through the explicit inclusion of features such as physicochemical properties or molecular descriptors. We further demonstrate improved generalization capability by our models using a large-scale benchmark of affinity prediction as well as a virtual screening application benchmark. Overall, we demonstrate that diverse modeling approaches can be ensembled together to gain meaningful improvement in binding affinity prediction.
<div id='section'>Paperid: <span id='pid'>177, <a href='https://arxiv.org/pdf/2310.03221.pdf' target='_blank'>https://arxiv.org/pdf/2310.03221.pdf</a></span>   <span><a href='https://github.com/Yijia-Xiao/Know2BIO/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijia Xiao, Dylan Steinecke, Alexander Russell Pelletier, Yushi Bai, Peipei Ping, Wei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03221">Know2BIO: A Comprehensive Dual-View Benchmark for Evolving Biomedical Knowledge Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge graphs (KGs) have emerged as a powerful framework for representing and integrating complex biomedical information. However, assembling KGs from diverse sources remains a significant challenge in several aspects, including entity alignment, scalability, and the need for continuous updates to keep pace with scientific advancements. Moreover, the representative power of KGs is often limited by the scarcity of multi-modal data integration. To overcome these challenges, we propose Know2BIO, a general-purpose heterogeneous KG benchmark for the biomedical domain. Know2BIO integrates data from 30 diverse sources, capturing intricate relationships across 11 biomedical categories. It currently consists of ~219,000 nodes and ~6,200,000 edges. Know2BIO is capable of user-directed automated updating to reflect the latest knowledge in biomedical science. Furthermore, Know2BIO is accompanied by multi-modal data: node features including text descriptions, protein and compound sequences and structures, enabling the utilization of emerging natural language processing methods and multi-modal data integration strategies. We evaluate KG representation models on Know2BIO, demonstrating its effectiveness as a benchmark for KG representation learning in the biomedical field. Data and source code of Know2BIO are available at https://github.com/Yijia-Xiao/Know2BIO/.
<div id='section'>Paperid: <span id='pid'>178, <a href='https://arxiv.org/pdf/2310.02779.pdf' target='_blank'>https://arxiv.org/pdf/2310.02779.pdf</a></span>   <span><a href='https://github.com/GFNOrg/AdversarialFlowNetworks' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Marco Jiralerspong, Bilun Sun, Danilo Vucetic, Tianyu Zhang, Yoshua Bengio, Gauthier Gidel, Nikolay Malkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02779">Expected flow networks in stochastic environments and two-player zero-sum games</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative flow networks (GFlowNets) are sequential sampling models trained to match a given distribution. GFlowNets have been successfully applied to various structured object generation tasks, sampling a diverse set of high-reward objects quickly. We propose expected flow networks (EFlowNets), which extend GFlowNets to stochastic environments. We show that EFlowNets outperform other GFlowNet formulations in stochastic tasks such as protein design. We then extend the concept of EFlowNets to adversarial environments, proposing adversarial flow networks (AFlowNets) for two-player zero-sum games. We show that AFlowNets learn to find above 80% of optimal moves in Connect-4 via self-play and outperform AlphaZero in tournaments.
<div id='section'>Paperid: <span id='pid'>179, <a href='https://arxiv.org/pdf/2309.16685.pdf' target='_blank'>https://arxiv.org/pdf/2309.16685.pdf</a></span>   <span><a href='https://github.com/HySonLab/Ligand_Generation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nhat Khang Ngo, Truong Son Hy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16685">Target-aware Variational Auto-encoders for Ligand Generation with Multimodal Protein Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Without knowledge of specific pockets, generating ligands based on the global structure of a protein target plays a crucial role in drug discovery as it helps reduce the search space for potential drug-like candidates in the pipeline. However, contemporary methods require optimizing tailored networks for each protein, which is arduous and costly. To address this issue, we introduce TargetVAE, a target-aware variational auto-encoder that generates ligands with high binding affinities to arbitrary protein targets, guided by a novel multimodal deep neural network built based on graph Transformers as the prior for the generative model. This is the first effort to unify different representations of proteins (e.g., sequence of amino-acids, 3D structure) into a single model that we name as Protein Multimodal Network (PMN). Our multimodal architecture learns from the entire protein structures and is able to capture their sequential, topological and geometrical information. We showcase the superiority of our approach by conducting extensive experiments and evaluations, including the assessment of generative model quality, ligand generation for unseen targets, docking score computation, and binding affinity prediction. Empirical results demonstrate the promising performance of our proposed approach. Our software package is publicly available at https://github.com/HySonLab/Ligand_Generation
<div id='section'>Paperid: <span id='pid'>180, <a href='https://arxiv.org/pdf/2309.03631.pdf' target='_blank'>https://arxiv.org/pdf/2309.03631.pdf</a></span>   <span><a href='https://github.com/markuswenzel/xai-proteins' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Markus Wenzel, Erik GrÃ¼ner, Nils Strodthoff
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.03631">Insights Into the Inner Workings of Transformer Models for Protein Function Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motivation: We explored how explainable artificial intelligence (XAI) can help to shed light into the inner workings of neural networks for protein function prediction, by extending the widely used XAI method of integrated gradients such that latent representations inside of transformer models, which were finetuned to Gene Ontology term and Enzyme Commission number prediction, can be inspected too. Results: The approach enabled us to identify amino acids in the sequences that the transformers pay particular attention to, and to show that these relevant sequence parts reflect expectations from biology and chemistry, both in the embedding layer and inside of the model, where we identified transformer heads with a statistically significant correspondence of attribution maps with ground truth sequence annotations (e.g. transmembrane regions, active sites) across many proteins. Availability and Implementation: Source code can be accessed at https://github.com/markuswenzel/xai-proteins .
<div id='section'>Paperid: <span id='pid'>181, <a href='https://arxiv.org/pdf/2309.03099.pdf' target='_blank'>https://arxiv.org/pdf/2309.03099.pdf</a></span>   <span><a href='https://github.com/ChakradharG/PeptideBERT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chakradhar Guntuboina, Adrita Das, Parisa Mollaei, Seongwon Kim, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.03099">PeptideBERT: A Language Model based on Transformers for Peptide Property Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in Language Models have enabled the protein modeling community with a powerful tool since protein sequences can be represented as text. Specifically, by taking advantage of Transformers, sequence-to-property prediction will be amenable without the need for explicit structural data. In this work, inspired by recent progress in Large Language Models (LLMs), we introduce PeptideBERT, a protein language model for predicting three key properties of peptides (hemolysis, solubility, and non-fouling). The PeptideBert utilizes the ProtBERT pretrained transformer model with 12 attention heads and 12 hidden layers. We then finetuned the pretrained model for the three downstream tasks. Our model has achieved state of the art (SOTA) for predicting Hemolysis, which is a task for determining peptide's potential to induce red blood cell lysis. Our PeptideBert non-fouling model also achieved remarkable accuracy in predicting peptide's capacity to resist non-specific interactions. This model, trained predominantly on shorter sequences, benefits from the dataset where negative examples are largely associated with insoluble peptides. Codes, models, and data used in this study are freely available at: https://github.com/ChakradharG/PeptideBERT
<div id='section'>Paperid: <span id='pid'>182, <a href='https://arxiv.org/pdf/2308.09442.pdf' target='_blank'>https://arxiv.org/pdf/2308.09442.pdf</a></span>   <span><a href='https://github.com/PharMolix/OpenBioMed' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizhen Luo, Jiahuan Zhang, Siqi Fan, Kai Yang, Yushuai Wu, Mu Qiao, Zaiqing Nie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09442">BioMedGPT: Open Multimodal Generative Pre-trained Transformer for BioMedicine</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models (FMs) have exhibited remarkable performance across a wide range of downstream tasks in many domains. Nevertheless, general-purpose FMs often face challenges when confronted with domain-specific problems, due to their limited access to the proprietary training data in a particular domain. In biomedicine, there are various biological modalities, such as molecules, proteins, and cells, which are encoded by the language of life and exhibit significant modality gaps with human natural language. In this paper, we introduce BioMedGPT, an open multimodal generative pre-trained transformer (GPT) for biomedicine, to bridge the gap between the language of life and human natural language. BioMedGPT allows users to easily ``communicate'' with diverse biological modalities through free text, which is the first of its kind. BioMedGPT aligns different biological modalities with natural language via a large generative language model, namely, BioMedGPT-LM. We publish BioMedGPT-10B, which unifies the feature spaces of molecules, proteins, and natural language via encoding and alignment. Through fine-tuning, BioMedGPT-10B outperforms or is on par with human and significantly larger general-purpose foundation models on the biomedical QA task. It also demonstrates promising performance in the molecule QA and protein QA tasks, which could greatly accelerate the discovery of new drugs and therapeutic targets. In addition, BioMedGPT-LM-7B is the first large generative language model based on Llama2 in the biomedical domain, therefore is commercial friendly. Both BioMedGPT-10B and BioMedGPT-LM-7B are open-sourced to the research community. In addition, we publish the datasets that are meticulously curated for the alignment of multi-modalities, i.e., PubChemQA and UniProtQA. All the models, codes, and datasets are available at \url{https://github.com/PharMolix/OpenBioMed}.
<div id='section'>Paperid: <span id='pid'>183, <a href='https://arxiv.org/pdf/2308.08578.pdf' target='_blank'>https://arxiv.org/pdf/2308.08578.pdf</a></span>   <span><a href='https://github.com/issararab/PEvoLM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Issar Arab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08578">PEvoLM: Protein Sequence Evolutionary Information Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the exponential increase of the protein sequence databases over time, multiple-sequence alignment (MSA) methods, like PSI-BLAST, perform exhaustive and time-consuming database search to retrieve evolutionary information. The resulting position-specific scoring matrices (PSSMs) of such search engines represent a crucial input to many machine learning (ML) models in the field of bioinformatics and computational biology. A protein sequence is a collection of contiguous tokens or characters called amino acids (AAs). The analogy to natural language allowed us to exploit the recent advancements in the field of Natural Language Processing (NLP) and therefore transfer NLP state-of-the-art algorithms to bioinformatics. This research presents an Embedding Language Model (ELMo), converting a protein sequence to a numerical vector representation. While the original ELMo trained a 2-layer bidirectional Long Short-Term Memory (LSTMs) network following a two-path architecture, one for the forward and the second for the backward pass, by merging the idea of PSSMs with the concept of transfer-learning, this work introduces a novel bidirectional language model (bi-LM) with four times less free parameters and using rather a single path for both passes. The model was trained not only on predicting the next AA but also on the probability distribution of the next AA derived from similar, yet different sequences as summarized in a PSSM, simultaneously for multi-task learning, hence learning evolutionary information of protein sequences as well. The network architecture and the pre-trained model are made available as open source under the permissive MIT license on GitHub at https://github.com/issararab/PEvoLM.
<div id='section'>Paperid: <span id='pid'>184, <a href='https://arxiv.org/pdf/2308.05115.pdf' target='_blank'>https://arxiv.org/pdf/2308.05115.pdf</a></span>   <span><a href='https://github.com/StatXzy7/PTransIPs' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyang Xu, Haitian Zhong, Bingrui He, Xueying Wang, Tianchi Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.05115">PTransIPs: Identification of phosphorylation sites enhanced by protein PLM embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Phosphorylation is pivotal in numerous fundamental cellular processes and plays a significant role in the onset and progression of various diseases. The accurate identification of these phosphorylation sites is crucial for unraveling the molecular mechanisms within cells and during viral infections, potentially leading to the discovery of novel therapeutic targets. In this study, we develop PTransIPs, a new deep learning framework for the identification of phosphorylation sites. Independent testing results demonstrate that PTransIPs outperforms existing state-of-the-art (SOTA) methods, achieving AUCs of 0.9232 and 0.9660 for the identification of phosphorylated S/T and Y sites, respectively. PTransIPs contributes from three aspects. 1) PTransIPs is the first to apply protein pre-trained language model (PLM) embeddings to this task. It utilizes ProtTrans and EMBER2 to extract sequence and structure embeddings, respectively, as additional inputs into the model, effectively addressing issues of dataset size and overfitting, thus enhancing model performance; 2) PTransIPs is based on Transformer architecture, optimized through the integration of convolutional neural networks and TIM loss function, providing practical insights for model design and training; 3) The encoding of amino acids in PTransIPs enables it to serve as a universal framework for other peptide bioactivity tasks, with its excellent performance shown in extended experiments of this paper. Our code, data and models are publicly available at https://github.com/StatXzy7/PTransIPs.
<div id='section'>Paperid: <span id='pid'>185, <a href='https://arxiv.org/pdf/2307.10343.pdf' target='_blank'>https://arxiv.org/pdf/2307.10343.pdf</a></span>   <span><a href='https://github.com/tonytu16/protigeno' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tony Tu, Gautham Krishna, Amirali Aghazadeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.10343">ProtiGeno: a prokaryotic short gene finder using protein language models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prokaryotic gene prediction plays an important role in understanding the biology of organisms and their function with applications in medicine and biotechnology. Although the current gene finders are highly sensitive in finding long genes, their sensitivity decreases noticeably in finding shorter genes (<180 nts). The culprit is insufficient annotated gene data to identify distinguishing features in short open reading frames (ORFs). We develop a deep learning-based method called ProtiGeno, specifically targeting short prokaryotic genes using a protein language model trained on millions of evolved proteins. In systematic large-scale experiments on 4,288 prokaryotic genomes, we demonstrate that ProtiGeno predicts short coding and noncoding genes with higher accuracy and recall than the current state-of-the-art gene finders. We discuss the predictive features of ProtiGeno and possible limitations by visualizing the three-dimensional structure of the predicted short genes. Data, codes, and models are available at https://github.com/tonytu16/protigeno.
<div id='section'>Paperid: <span id='pid'>186, <a href='https://arxiv.org/pdf/2307.04603.pdf' target='_blank'>https://arxiv.org/pdf/2307.04603.pdf</a></span>   <span><a href='https://github.com/kakaobrain/solvent,' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaemyung Lee, Kyeongtak Han, Jaehoon Kim, Hasun Yu, Youhan Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.04603">Solvent: A Framework for Protein Folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Consistency and reliability are crucial for conducting AI research. Many famous research fields, such as object detection, have been compared and validated with solid benchmark frameworks. After AlphaFold2, the protein folding task has entered a new phase, and many methods are proposed based on the component of AlphaFold2. The importance of a unified research framework in protein folding contains implementations and benchmarks to consistently and fairly compare various approaches. To achieve this, we present Solvent, a protein folding framework that supports significant components of state-of-the-art models in the manner of an off-the-shelf interface Solvent contains different models implemented in a unified codebase and supports training and evaluation for defined models on the same dataset. We benchmark well-known algorithms and their components and provide experiments that give helpful insights into the protein structure modeling field. We hope that Solvent will increase the reliability and consistency of proposed models and give efficiency in both speed and costs, resulting in acceleration on protein folding modeling research. The code is available at https://github.com/kakaobrain/solvent, and the project will continue to be developed.
<div id='section'>Paperid: <span id='pid'>187, <a href='https://arxiv.org/pdf/2307.04351.pdf' target='_blank'>https://arxiv.org/pdf/2307.04351.pdf</a></span>   <span><a href='https://github.com/usccolumbia/MD-HIT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qin Li, Nihang Fu, Sadman Sadeed Omee, Jianjun Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.04351">MD-HIT: Machine learning for materials property prediction with dataset redundancy control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Materials datasets are usually featured by the existence of many redundant (highly similar) materials due to the tinkering material design practice over the history of materials research. For example, the materials project database has many perovskite cubic structure materials similar to SrTiO$_3$. This sample redundancy within the dataset makes the random splitting of machine learning model evaluation to fail so that the ML models tend to achieve over-estimated predictive performance which is misleading for the materials science community. This issue is well known in the field of bioinformatics for protein function prediction, in which a redundancy reduction procedure (CD-Hit) is always applied to reduce the sample redundancy by ensuring no pair of samples has a sequence similarity greater than a given threshold. This paper surveys the overestimated ML performance in the literature for both composition based and structure based material property prediction. We then propose a material dataset redundancy reduction algorithm called MD-HIT and evaluate it with several composition and structure based distance threshold sfor reducing data set sample redundancy. We show that with this control, the predicted performance tends to better reflect their true prediction capability. Our MD-hit code can be freely accessed at https://github.com/usccolumbia/MD-HIT
<div id='section'>Paperid: <span id='pid'>188, <a href='https://arxiv.org/pdf/2307.01646.pdf' target='_blank'>https://arxiv.org/pdf/2307.01646.pdf</a></span>   <span><a href='https://github.com/qiyan98/SwinGNN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Yan, Zhengyang Liang, Yang Song, Renjie Liao, Lele Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.01646">SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models based on permutation-equivariant networks can learn permutation-invariant distributions for graph data. However, in comparison to their non-invariant counterparts, we have found that these invariant models encounter greater learning challenges since 1) their effective target distributions exhibit more modes; 2) their optimal one-step denoising scores are the score functions of Gaussian mixtures with more components. Motivated by this analysis, we propose a non-invariant diffusion model, called $\textit{SwinGNN}$, which employs an efficient edge-to-edge 2-WL message passing network and utilizes shifted window based self-attention inspired by SwinTransformers. Further, through systematic ablations, we identify several critical training and sampling techniques that significantly improve the sample quality of graph generation. At last, we introduce a simple post-processing trick, $\textit{i.e.}$, randomly permuting the generated graphs, which provably converts any graph generative model to a permutation-invariant one. Extensive experiments on synthetic and real-world protein and molecule datasets show that our SwinGNN achieves state-of-the-art performances. Our code is released at https://github.com/qiyan98/SwinGNN.
<div id='section'>Paperid: <span id='pid'>189, <a href='https://arxiv.org/pdf/2307.00494.pdf' target='_blank'>https://arxiv.org/pdf/2307.00494.pdf</a></span>   <span><a href='https://github.com/kirjner/GGS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Kirjner, Jason Yim, Raman Samusevich, Shahar Bracha, Tommi Jaakkola, Regina Barzilay, Ila Fiete
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.00494">Improving Protein Optimization with Smoothed Fitness Landscapes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to engineer novel proteins with higher fitness for a desired property would be revolutionary for biotechnology and medicine. Modeling the combinatorially large space of sequences is infeasible; prior methods often constrain optimization to a small mutational radius, but this drastically limits the design space. Instead of heuristics, we propose smoothing the fitness landscape to facilitate protein optimization. First, we formulate protein fitness as a graph signal then use Tikunov regularization to smooth the fitness landscape. We find optimizing in this smoothed landscape leads to improved performance across multiple methods in the GFP and AAV benchmarks. Second, we achieve state-of-the-art results utilizing discrete energy-based models and MCMC in the smoothed landscape. Our method, called Gibbs sampling with Graph-based Smoothing (GGS), demonstrates a unique ability to achieve 2.5 fold fitness improvement (with in-silico evaluation) over its training set. GGS demonstrates potential to optimize proteins in the limited data regime. Code: https://github.com/kirjner/GGS
<div id='section'>Paperid: <span id='pid'>190, <a href='https://arxiv.org/pdf/2306.17775.pdf' target='_blank'>https://arxiv.org/pdf/2306.17775.pdf</a></span>   <span><a href='https://github.com/blt2114/twisted_diffusion_sampler' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Luhuan Wu, Brian L. Trippe, Christian A. Naesseth, David M. Blei, John P. Cunningham
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.17775">Practical and Asymptotically Exact Conditional Sampling in Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have been successful on a range of conditional generation tasks including molecular design and text-to-image generation. However, these achievements have primarily depended on task-specific conditional training or error-prone heuristic approximations. Ideally, a conditional generation method should provide exact samples for a broad range of conditional distributions without requiring task-specific training. To this end, we introduce the Twisted Diffusion Sampler, or TDS. TDS is a sequential Monte Carlo (SMC) algorithm that targets the conditional distributions of diffusion models through simulating a set of weighted particles. The main idea is to use twisting, an SMC technique that enjoys good computational efficiency, to incorporate heuristic approximations without compromising asymptotic exactness. We first find in simulation and in conditional image generation tasks that TDS provides a computational statistical trade-off, yielding more accurate approximations with many particles but with empirical improvements over heuristics with as few as two particles. We then turn to motif-scaffolding, a core task in protein design, using a TDS extension to Riemannian diffusion models. On benchmark test cases, TDS allows flexible conditioning criteria and often outperforms the state of the art.
<div id='section'>Paperid: <span id='pid'>191, <a href='https://arxiv.org/pdf/2306.15794.pdf' target='_blank'>https://arxiv.org/pdf/2306.15794.pdf</a></span>   <span><a href='https://github.com/HazyResearch/hyena-dna' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Eric Nguyen, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow, Aman Patel, Clayton Rabideau, Stefano Massaroli, Yoshua Bengio, Stefano Ermon, Stephen A. Baccus, Chris RÃ©
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.15794">HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Genomic (DNA) sequences encode an enormous amount of information for gene regulation and protein synthesis. Similar to natural language models, researchers have proposed foundation models in genomics to learn generalizable features from unlabeled genome data that can then be fine-tuned for downstream tasks such as identifying regulatory elements. Due to the quadratic scaling of attention, previous Transformer-based genomic models have used 512 to 4k tokens as context (<0.001% of the human genome), significantly limiting the modeling of long-range interactions in DNA. In addition, these methods rely on tokenizers or fixed k-mers to aggregate meaningful DNA units, losing single nucleotide resolution where subtle genetic variations can completely alter protein function via single nucleotide polymorphisms (SNPs). Recently, Hyena, a large language model based on implicit convolutions was shown to match attention in quality while allowing longer context lengths and lower time complexity. Leveraging Hyena's new long-range capabilities, we present HyenaDNA, a genomic foundation model pretrained on the human reference genome with context lengths of up to 1 million tokens at the single nucleotide-level - an up to 500x increase over previous dense attention-based models. HyenaDNA scales sub-quadratically in sequence length (training up to 160x faster than Transformer), uses single nucleotide tokens, and has full global context at each layer. We explore what longer context enables - including the first use of in-context learning in genomics. On fine-tuned benchmarks from the Nucleotide Transformer, HyenaDNA reaches state-of-the-art (SotA) on 12 of 18 datasets using a model with orders of magnitude less parameters and pretraining data. On the GenomicBenchmarks, HyenaDNA surpasses SotA on 7 of 8 datasets on average by +10 accuracy points. Code at https://github.com/HazyResearch/hyena-dna.
<div id='section'>Paperid: <span id='pid'>192, <a href='https://arxiv.org/pdf/2306.12231.pdf' target='_blank'>https://arxiv.org/pdf/2306.12231.pdf</a></span>   <span><a href='https://github.com/semiluna/partIII-amino-acid-prediction' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Antonia Boca, Simon Mathis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.12231">Predicting protein variants with equivariant graph neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained models have been successful in many protein engineering tasks. Most notably, sequence-based models have achieved state-of-the-art performance on protein fitness prediction while structure-based models have been used experimentally to develop proteins with enhanced functions. However, there is a research gap in comparing structure- and sequence-based methods for predicting protein variants that are better than the wildtype protein. This paper aims to address this gap by conducting a comparative study between the abilities of equivariant graph neural networks (EGNNs) and sequence-based approaches to identify promising amino-acid mutations. The results show that our proposed structural approach achieves a competitive performance to sequence-based methods while being trained on significantly fewer molecules. Additionally, we find that combining assay labelled data with structure pre-trained models yields similar trends as with sequence pre-trained models.
  Our code and trained models can be found at: https://github.com/semiluna/partIII-amino-acid-prediction.
<div id='section'>Paperid: <span id='pid'>193, <a href='https://arxiv.org/pdf/2306.11768.pdf' target='_blank'>https://arxiv.org/pdf/2306.11768.pdf</a></span>   <span><a href='https://github.com/zaixizhang/Awesome-SBDD},' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zaixi Zhang, Jiaxian Yan, Yining Huang, Qi Liu, Enhong Chen, Mengdi Wang, Marinka Zitnik
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.11768">Geometric Deep Learning for Structure-Based Drug Design: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug design (SBDD) leverages the three-dimensional geometry of proteins to identify potential drug candidates. Traditional approaches, rooted in physicochemical modeling and domain expertise, are often resource-intensive. Recent advancements in geometric deep learning, which effectively integrate and process 3D geometric data, alongside breakthroughs in accurate protein structure predictions from tools like AlphaFold, have significantly propelled the field forward. This paper systematically reviews the state-of-the-art in geometric deep learning for SBDD. We begin by outlining foundational tasks in SBDD, discussing prevalent 3D protein representations, and highlighting representative predictive and generative models. Next, we provide an in-depth review of key tasks, including binding site prediction, binding pose generation, de novo molecule generation, linker design, protein pocket generation, and binding affinity prediction. For each task, we present formal problem definitions, key methods, datasets, evaluation metrics, and performance benchmarks. Lastly, we explore current challenges and future opportunities in SBDD. Challenges include oversimplified problem formulations, limited out-of-distribution generalization, biosecurity concerns related to the misuse of structural data, insufficient evaluation metrics and large-scale benchmarks, and the need for experimental validation and enhanced model interpretability. Opportunities lie in leveraging multimodal datasets, integrating domain knowledge, developing comprehensive benchmarks, establishing criteria aligned with clinical outcomes, and designing foundation models to expand the scope of design tasks. We also curate \url{https://github.com/zaixizhang/Awesome-SBDD}, reflecting ongoing contributions and new datasets in SBDD.
<div id='section'>Paperid: <span id='pid'>194, <a href='https://arxiv.org/pdf/2306.11189.pdf' target='_blank'>https://arxiv.org/pdf/2306.11189.pdf</a></span>   <span><a href='https://github.com/ncbi/BioREx' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Po-Ting Lai, Chih-Hsuan Wei, Ling Luo, Qingyu Chen, Zhiyong Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.11189">BioREx: Improving Biomedical Relation Extraction by Leveraging Heterogeneous Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biomedical relation extraction (RE) is the task of automatically identifying and characterizing relations between biomedical concepts from free text. RE is a central task in biomedical natural language processing (NLP) research and plays a critical role in many downstream applications, such as literature-based discovery and knowledge graph construction. State-of-the-art methods were used primarily to train machine learning models on individual RE datasets, such as protein-protein interaction and chemical-induced disease relation. Manual dataset annotation, however, is highly expensive and time-consuming, as it requires domain knowledge. Existing RE datasets are usually domain-specific or small, which limits the development of generalized and high-performing RE models. In this work, we present a novel framework for systematically addressing the data heterogeneity of individual datasets and combining them into a large dataset. Based on the framework and dataset, we report on BioREx, a data-centric approach for extracting relations. Our evaluation shows that BioREx achieves significantly higher performance than the benchmark system trained on the individual dataset, setting a new SOTA from 74.4% to 79.6% in F-1 measure on the recently released BioRED corpus. We further demonstrate that the combined dataset can improve performance for five different RE tasks. In addition, we show that on average BioREx compares favorably to current best-performing methods such as transfer learning and multi-task learning. Finally, we demonstrate BioREx's robustness and generalizability in two independent RE tasks not previously seen in training data: drug-drug N-ary combination and document-level gene-disease RE. The integrated dataset and optimized method have been packaged as a stand-alone tool available at https://github.com/ncbi/BioREx.
<div id='section'>Paperid: <span id='pid'>195, <a href='https://arxiv.org/pdf/2306.09121.pdf' target='_blank'>https://arxiv.org/pdf/2306.09121.pdf</a></span>   <span><a href='https://github.com/Foisunt/FMMs-in-GNNs' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicolas Lell, Ansgar Scherp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09121">The Split Matters: Flat Minima Methods for Improving the Performance of GNNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When training a Neural Network, it is optimized using the available training data with the hope that it generalizes well to new or unseen testing data. At the same absolute value, a flat minimum in the loss landscape is presumed to generalize better than a sharp minimum. Methods for determining flat minima have been mostly researched for independent and identically distributed (i. i. d.) data such as images. Graphs are inherently non-i. i. d. since the vertices are edge-connected. We investigate flat minima methods and combinations of those methods for training graph neural networks (GNNs). We use GCN and GAT as well as extend Graph-MLP to work with more layers and larger graphs. We conduct experiments on small and large citation, co-purchase, and protein datasets with different train-test splits in both the transductive and inductive training procedure. Results show that flat minima methods can improve the performance of GNN models by over 2 points, if the train-test split is randomized. Following Shchur et al., randomized splits are essential for a fair evaluation of GNNs, as other (fixed) splits like 'Planetoid' are biased. Overall, we provide important insights for improving and fairly evaluating flat minima methods on GNNs. We recommend practitioners to always use weight averaging techniques, in particular EWA when using early stopping. While weight averaging techniques are only sometimes the best performing method, they are less sensitive to hyperparameters, need no additional training, and keep the original model unchanged. All source code is available in https://github.com/Foisunt/FMMs-in-GNNs.
<div id='section'>Paperid: <span id='pid'>196, <a href='https://arxiv.org/pdf/2306.08166.pdf' target='_blank'>https://arxiv.org/pdf/2306.08166.pdf</a></span>   <span><a href='https://github.com/aivant/ShapeLinker' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Rebecca M. Neeser, Mehmet Akdel, Daniel Kovtun, Luca Naef
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.08166">Reinforcement Learning-Driven Linker Design via Fast Attention-based Point Cloud Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteolysis-Targeting Chimeras (PROTACs) represent a novel class of small molecules which are designed to act as a bridge between an E3 ligase and a disease-relevant protein, thereby promoting its subsequent degradation. PROTACs are composed of two protein binding "active" domains, linked by a "linker" domain. The design of the linker domain is challenging due to geometric and chemical constraints given by its interactions, and the need to maximize drug-likeness. To tackle these challenges, we introduce ShapeLinker, a method for de novo design of linkers. It performs fragment-linking using reinforcement learning on an autoregressive SMILES generator. The method optimizes for a composite score combining relevant physicochemical properties and a novel, attention-based point cloud alignment score. This new method successfully generates linkers that satisfy both relevant 2D and 3D requirements, and achieves state-of-the-art results in producing novel linkers assuming a target linker conformation. This allows for more rational and efficient PROTAC design and optimization. Code and data are available at https://github.com/aivant/ShapeLinker.
<div id='section'>Paperid: <span id='pid'>197, <a href='https://arxiv.org/pdf/2306.08018.pdf' target='_blank'>https://arxiv.org/pdf/2306.08018.pdf</a></span>   <span><a href='https://github.com/zjunlp/Mol-Instructions' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, Huajun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.08018">Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a comprehensive instruction dataset designed for the biomolecular domain. Mol-Instructions encompasses three key components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions. Each component aims to improve the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on LLMs, we demonstrate the effectiveness of Mol-Instructions in enhancing large models' performance in the intricate realm of biomolecular studies, thus fostering progress in the biomolecular research community. Mol-Instructions is publicly available for ongoing research and will undergo regular updates to enhance its applicability.
<div id='section'>Paperid: <span id='pid'>198, <a href='https://arxiv.org/pdf/2306.03606.pdf' target='_blank'>https://arxiv.org/pdf/2306.03606.pdf</a></span>   <span><a href='https://github.com/elsevier-AI-Lab/BioBLP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Daza, Dimitrios Alivanistos, Payal Mitra, Thom Pijnenburg, Michael Cochez, Paul Groth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03606">BioBLP: A Modular Framework for Learning on Multimodal Biomedical Knowledge Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge graphs (KGs) are an important tool for representing complex relationships between entities in the biomedical domain. Several methods have been proposed for learning embeddings that can be used to predict new links in such graphs. Some methods ignore valuable attribute data associated with entities in biomedical KGs, such as protein sequences, or molecular graphs. Other works incorporate such data, but assume that entities can be represented with the same data modality. This is not always the case for biomedical KGs, where entities exhibit heterogeneous modalities that are central to their representation in the subject domain.
  We propose a modular framework for learning embeddings in KGs with entity attributes, that allows encoding attribute data of different modalities while also supporting entities with missing attributes. We additionally propose an efficient pretraining strategy for reducing the required training runtime. We train models using a biomedical KG containing approximately 2 million triples, and evaluate the performance of the resulting entity embeddings on the tasks of link prediction, and drug-protein interaction prediction, comparing against methods that do not take attribute data into account. In the standard link prediction evaluation, the proposed method results in competitive, yet lower performance than baselines that do not use attribute data. When evaluated in the task of drug-protein interaction prediction, the method compares favorably with the baselines. We find settings involving low degree entities, which make up for a substantial amount of the set of entities in the KG, where our method outperforms the baselines. Our proposed pretraining strategy yields significantly higher performance while reducing the required training runtime.
  Our implementation is available at https://github.com/elsevier-AI-Lab/BioBLP .
<div id='section'>Paperid: <span id='pid'>199, <a href='https://arxiv.org/pdf/2306.03117.pdf' target='_blank'>https://arxiv.org/pdf/2306.03117.pdf</a></span>   <span><a href='https://github.com/lujiarui/Str2Str' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiarui Lu, Bozitao Zhong, Zuobai Zhang, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03117">Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The dynamic nature of proteins is crucial for determining their biological functions and properties, for which Monte Carlo (MC) and molecular dynamics (MD) simulations stand as predominant tools to study such phenomena. By utilizing empirically derived force fields, MC or MD simulations explore the conformational space through numerically evolving the system via Markov chain or Newtonian mechanics. However, the high-energy barrier of the force fields can hamper the exploration of both methods by the rare event, resulting in inadequately sampled ensemble without exhaustive running. Existing learning-based approaches perform direct sampling yet heavily rely on target-specific simulation data for training, which suffers from high data acquisition cost and poor generalizability. Inspired by simulated annealing, we propose Str2Str, a novel structure-to-structure translation framework capable of zero-shot conformation sampling with roto-translation equivariant property. Our method leverages an amortized denoising score matching objective trained on general crystal structures and has no reliance on simulation data during both training and inference. Experimental results across several benchmarking protein systems demonstrate that Str2Str outperforms previous state-of-the-art generative structure prediction models and can be orders of magnitude faster compared to long MD simulations. Our open-source implementation is available at https://github.com/lujiarui/Str2Str
<div id='section'>Paperid: <span id='pid'>200, <a href='https://arxiv.org/pdf/2306.01794.pdf' target='_blank'>https://arxiv.org/pdf/2306.01794.pdf</a></span>   <span><a href='https://github.com/DeepGraphLearning/DiffPack' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangtian Zhang, Zuobai Zhang, Bozitao Zhong, Sanchit Misra, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.01794">DiffPack: A Torsional Diffusion Model for Autoregressive Protein Side-Chain Packing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins play a critical role in carrying out biological functions, and their 3D structures are essential in determining their functions. Accurately predicting the conformation of protein side-chains given their backbones is important for applications in protein structure prediction, design and protein-protein interactions. Traditional methods are computationally intensive and have limited accuracy, while existing machine learning methods treat the problem as a regression task and overlook the restrictions imposed by the constant covalent bond lengths and angles. In this work, we present DiffPack, a torsional diffusion model that learns the joint distribution of side-chain torsional angles, the only degrees of freedom in side-chain packing, by diffusing and denoising on the torsional space. To avoid issues arising from simultaneous perturbation of all four torsional angles, we propose autoregressively generating the four torsional angles from $Ï_1$ to $Ï_4$ and training diffusion models for each torsional angle. We evaluate the method on several benchmarks for protein side-chain packing and show that our method achieves improvements of $11.9\%$ and $13.5\%$ in angle accuracy on CASP13 and CASP14, respectively, with a significantly smaller model size ($60\times$ fewer parameters). Additionally, we show the effectiveness of our method in enhancing side-chain predictions in the AlphaFold2 model. Code is available at https://github.com/DeepGraphLearning/DiffPack.
<div id='section'>Paperid: <span id='pid'>201, <a href='https://arxiv.org/pdf/2305.13650.pdf' target='_blank'>https://arxiv.org/pdf/2305.13650.pdf</a></span>   <span><a href='https://github.com/sabagh1994/PGVAE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saba Ghaffari, Ehsan Saleh, Alexander G. Schwing, Yu-Xiong Wang, Martin D. Burke, Saurabh Sinha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.13650">Robust Model-Based Optimization for Challenging Fitness Landscapes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein design, a grand challenge of the day, involves optimization on a fitness landscape, and leading methods adopt a model-based approach where a model is trained on a training set (protein sequences and fitness) and proposes candidates to explore next. These methods are challenged by sparsity of high-fitness samples in the training set, a problem that has been in the literature. A less recognized but equally important problem stems from the distribution of training samples in the design space: leading methods are not designed for scenarios where the desired optimum is in a region that is not only poorly represented in training data, but also relatively far from the highly represented low-fitness regions. We show that this problem of "separation" in the design space is a significant bottleneck in existing model-based optimization tools and propose a new approach that uses a novel VAE as its search model to overcome the problem. We demonstrate its advantage over prior methods in robustly finding improved samples, regardless of the imbalance and separation between low- and high-fitness samples. Our comprehensive benchmark on real and semi-synthetic protein datasets as well as solution design for physics-informed neural networks, showcases the generality of our approach in discrete and continuous design spaces. Our implementation is available at https://github.com/sabagh1994/PGVAE.
<div id='section'>Paperid: <span id='pid'>202, <a href='https://arxiv.org/pdf/2305.11194.pdf' target='_blank'>https://arxiv.org/pdf/2305.11194.pdf</a></span>   <span><a href='https://github.com/aryopg/vaxformer' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Aryo Pradipta Gema, MichaÅ Kobiela, Achille Fraisse, Ajitha Rajan, Diego A. OyarzÃºn, Javier Antonio Alfaro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.11194">Vaxformer: Antigenicity-controlled Transformer for Vaccine Design Against SARS-CoV-2</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The SARS-CoV-2 pandemic has emphasised the importance of developing a universal vaccine that can protect against current and future variants of the virus. The present study proposes a novel conditional protein Language Model architecture, called Vaxformer, which is designed to produce natural-looking antigenicity-controlled SARS-CoV-2 spike proteins. We evaluate the generated protein sequences of the Vaxformer model using DDGun protein stability measure, netMHCpan antigenicity score, and a structure fidelity score with AlphaFold to gauge its viability for vaccine development. Our results show that Vaxformer outperforms the existing state-of-the-art Conditional Variational Autoencoder model to generate antigenicity-controlled SARS-CoV-2 spike proteins. These findings suggest promising opportunities for conditional Transformer models to expand our understanding of vaccine design and their role in mitigating global health challenges. The code used in this study is available at https://github.com/aryopg/vaxformer .
<div id='section'>Paperid: <span id='pid'>203, <a href='https://arxiv.org/pdf/2305.04120.pdf' target='_blank'>https://arxiv.org/pdf/2305.04120.pdf</a></span>   <span><a href='https://github.com/divelab/AIRS/tree/main/OpenProt/LatentDiff' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Cong Fu, Keqiang Yan, Limei Wang, Wing Yee Au, Michael McThrow, Tao Komikado, Koji Maruhashi, Kanji Uchino, Xiaoning Qian, Shuiwang Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.04120">A Latent Diffusion Model for Protein Structure Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are complex biomolecules that perform a variety of crucial functions within living organisms. Designing and generating novel proteins can pave the way for many future synthetic biology applications, including drug discovery. However, it remains a challenging computational task due to the large modeling space of protein structures. In this study, we propose a latent diffusion model that can reduce the complexity of protein modeling while flexibly capturing the distribution of natural protein structures in a condensed latent space. Specifically, we propose an equivariant protein autoencoder that embeds proteins into a latent space and then uses an equivariant diffusion model to learn the distribution of the latent protein representations. Experimental results demonstrate that our method can effectively generate novel protein backbone structures with high designability and efficiency. The code will be made publicly available at https://github.com/divelab/AIRS/tree/main/OpenProt/LatentDiff
<div id='section'>Paperid: <span id='pid'>204, <a href='https://arxiv.org/pdf/2304.12825.pdf' target='_blank'>https://arxiv.org/pdf/2304.12825.pdf</a></span>   <span><a href='https://github.com/Franco-Solis/GraphVF-code' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Fang Sun, Zhihao Zhan, Hongyu Guo, Ming Zhang, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.12825">GraphVF: Controllable Protein-Specific 3D Molecule Generation with Variational Flow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing molecules that bind to specific target proteins is a fundamental task in drug discovery. Recent models leverage geometric constraints to generate ligand molecules that bind cohesively with specific protein pockets. However, these models cannot effectively generate 3D molecules with 2D skeletal curtailments and property constraints, which are pivotal to drug potency and development. To tackle this challenge, we propose GraphVF, a variational flow-based framework that combines 2D topology and 3D geometry, for controllable generation of binding 3D molecules. Empirically, our method achieves state-of-the-art binding affinity and realistic sub-structural layouts for protein-specific generation. In particular, GraphVF represents the first controllable geometry-aware, protein-specific molecule generation method, which can generate binding 3D molecules with tailored sub-structures and physio-chemical properties. Our code is available at https://github.com/Franco-Solis/GraphVF-code.
<div id='section'>Paperid: <span id='pid'>205, <a href='https://arxiv.org/pdf/2304.03889.pdf' target='_blank'>https://arxiv.org/pdf/2304.03889.pdf</a></span>   <span><a href='https://github.com/ketatam/DiffDock-PP}$' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamed Amine Ketata, Cedrik Laue, Ruslan Mammadov, Hannes StÃ¤rk, Menghua Wu, Gabriele Corso, CÃ©line Marquet, Regina Barzilay, Tommi S. Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.03889">DiffDock-PP: Rigid Protein-Protein Docking with Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding how proteins structurally interact is crucial to modern biology, with applications in drug discovery and protein design. Recent machine learning methods have formulated protein-small molecule docking as a generative problem with significant performance boosts over both traditional and deep learning baselines. In this work, we propose a similar approach for rigid protein-protein docking: DiffDock-PP is a diffusion generative model that learns to translate and rotate unbound protein structures into their bound conformations. We achieve state-of-the-art performance on DIPS with a median C-RMSD of 4.85, outperforming all considered baselines. Additionally, DiffDock-PP is faster than all search-based methods and generates reliable confidence estimates for its predictions. Our code is publicly available at $\texttt{https://github.com/ketatam/DiffDock-PP}$
<div id='section'>Paperid: <span id='pid'>206, <a href='https://arxiv.org/pdf/2304.02198.pdf' target='_blank'>https://arxiv.org/pdf/2304.02198.pdf</a></span>   <span><a href='https://github.com/bjing2016/EigenFold' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Jing, Ezra Erives, Peter Pao-Huang, Gabriele Corso, Bonnie Berger, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.02198">EigenFold: Generative Protein Structure Prediction with Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structure prediction has reached revolutionary levels of accuracy on single structures, yet distributional modeling paradigms are needed to capture the conformational ensembles and flexibility that underlie biological function. Towards this goal, we develop EigenFold, a diffusion generative modeling framework for sampling a distribution of structures from a given protein sequence. We define a diffusion process that models the structure as a system of harmonic oscillators and which naturally induces a cascading-resolution generative process along the eigenmodes of the system. On recent CAMEO targets, EigenFold achieves a median TMScore of 0.84, while providing a more comprehensive picture of model uncertainty via the ensemble of sampled structures relative to existing methods. We then assess EigenFold's ability to model and predict conformational heterogeneity for fold-switching proteins and ligand-induced conformational change. Code is available at https://github.com/bjing2016/EigenFold.
<div id='section'>Paperid: <span id='pid'>207, <a href='https://arxiv.org/pdf/2304.01344.pdf' target='_blank'>https://arxiv.org/pdf/2304.01344.pdf</a></span>   <span><a href='https://github.com/bionlproc/end-to-end-ChemProt' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuguang Ai, Ramakanth Kavuluru
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.01344">End-to-End Models for Chemical-Protein Interaction Extraction: Better Tokenization and Span-Based Pipeline Strategies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>End-to-end relation extraction (E2ERE) is an important task in information extraction, more so for biomedicine as scientific literature continues to grow exponentially. E2ERE typically involves identifying entities (or named entity recognition (NER)) and associated relations, while most RE tasks simply assume that the entities are provided upfront and end up performing relation classification. E2ERE is inherently more difficult than RE alone given the potential snowball effect of errors from NER leading to more errors in RE. A complex dataset in biomedical E2ERE is the ChemProt dataset (BioCreative VI, 2017) that identifies relations between chemical compounds and genes/proteins in scientific literature. ChemProt is included in all recent biomedical natural language processing benchmarks including BLUE, BLURB, and BigBio. However, its treatment in these benchmarks and in other separate efforts is typically not end-to-end, with few exceptions. In this effort, we employ a span-based pipeline approach to produce a new state-of-the-art E2ERE performance on the ChemProt dataset, resulting in $> 4\%$ improvement in F1-score over the prior best effort. Our results indicate that a straightforward fine-grained tokenization scheme helps span-based approaches excel in E2ERE, especially with regards to handling complex named entities. Our error analysis also identifies a few key failure modes in E2ERE for ChemProt.
<div id='section'>Paperid: <span id='pid'>208, <a href='https://arxiv.org/pdf/2303.06275.pdf' target='_blank'>https://arxiv.org/pdf/2303.06275.pdf</a></span>   <span><a href='https://github.com/DeepGraphLearning/ESM-GearNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zuobai Zhang, Chuanrui Wang, Minghao Xu, Vijil Chenthamarakshan, AurÃ©lie Lozano, Payel Das, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.06275">A Systematic Study of Joint Representation Learning on Protein Sequences and Structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning effective protein representations is critical in a variety of tasks in biology such as predicting protein functions. Recent sequence representation learning methods based on Protein Language Models (PLMs) excel in sequence-based tasks, but their direct adaptation to tasks involving protein structures remains a challenge. In contrast, structure-based methods leverage 3D structural information with graph neural networks and geometric pre-training methods show potential in function prediction tasks, but still suffers from the limited number of available structures. To bridge this gap, our study undertakes a comprehensive exploration of joint protein representation learning by integrating a state-of-the-art PLM (ESM-2) with distinct structure encoders (GVP, GearNet, CDConv). We introduce three representation fusion strategies and explore different pre-training techniques. Our method achieves significant improvements over existing sequence- and structure-based methods, setting new state-of-the-art for function annotation. This study underscores several important design choices for fusing protein sequence and structure information. Our implementation is available at https://github.com/DeepGraphLearning/ESM-GearNet.
<div id='section'>Paperid: <span id='pid'>209, <a href='https://arxiv.org/pdf/2303.04562.pdf' target='_blank'>https://arxiv.org/pdf/2303.04562.pdf</a></span>   <span><a href='https://github.com/vishakhpk/iter-extrapolation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Vishakh Padmakumar, Richard Yuanzhe Pang, He He, Ankur P. Parikh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.04562">Extrapolative Controlled Sequence Generation via Iterative Refinement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the problem of extrapolative controlled generation, i.e., generating sequences with attribute values beyond the range seen in training. This task is of significant importance in automated design, especially drug discovery, where the goal is to design novel proteins that are \textit{better} (e.g., more stable) than existing sequences. Thus, by definition, the target sequences and their attribute values are out of the training distribution, posing challenges to existing methods that aim to directly generate the target sequence. Instead, in this work, we propose Iterative Controlled Extrapolation (ICE) which iteratively makes local edits to a sequence to enable extrapolation. We train the model on synthetically generated sequence pairs that demonstrate small improvement in the attribute value. Results on one natural language task (sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV fitness) show that ICE considerably outperforms state-of-the-art approaches despite its simplicity. Our code and models are available at: https://github.com/vishakhpk/iter-extrapolation.
<div id='section'>Paperid: <span id='pid'>210, <a href='https://arxiv.org/pdf/2302.13271.pdf' target='_blank'>https://arxiv.org/pdf/2302.13271.pdf</a></span>   <span><a href='https://github.com/MathBioCU/WENDy' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>David M. Bortz, Daniel A. Messenger, Vanja Dukic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.13271">Direct Estimation of Parameters in ODE Models Using WENDy: Weak-form Estimation of Nonlinear Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce the Weak-form Estimation of Nonlinear Dynamics (WENDy) method for estimating model parameters for non-linear systems of ODEs. Without relying on any numerical differential equation solvers, WENDy computes accurate estimates and is robust to large (biologically relevant) levels of measurement noise. For low dimensional systems with modest amounts of data, WENDy is competitive with conventional forward solver-based nonlinear least squares methods in terms of speed and accuracy. For both higher dimensional systems and stiff systems, WENDy is typically both faster (often by orders of magnitude) and more accurate than forward solver-based approaches.
  The core mathematical idea involves an efficient conversion of the strong form representation of a model to its weak form, and then solving a regression problem to perform parameter inference. The core statistical idea rests on the Errors-In-Variables framework, which necessitates the use of the iteratively reweighted least squares algorithm. Further improvements are obtained by using orthonormal test functions, created from a set of C-infinity bump functions of varying support sizes.
  We demonstrate the high robustness and computational efficiency by applying WENDy to estimate parameters in some common models from population biology, neuroscience, and biochemistry, including logistic growth, Lotka-Volterra, FitzHugh-Nagumo, Hindmarsh-Rose, and a Protein Transduction Benchmark model. Software and code for reproducing the examples is available at (https://github.com/MathBioCU/WENDy).
<div id='section'>Paperid: <span id='pid'>211, <a href='https://arxiv.org/pdf/2302.12563.pdf' target='_blank'>https://arxiv.org/pdf/2302.12563.pdf</a></span>   <span><a href='https://github.com/HKUNLP/RSA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chang Ma, Haiteng Zhao, Lin Zheng, Jiayi Xin, Qintong Li, Lijun Wu, Zhihong Deng, Yang Lu, Qi Liu, Lingpeng Kong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12563">Retrieved Sequence Augmentation for Protein Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models have excelled in a variety of tasks, ranging from structure prediction to protein engineering. However, proteins are highly diverse in functions and structures, and current state-of-the-art models including the latest version of AlphaFold rely on Multiple Sequence Alignments (MSA) to feed in the evolutionary knowledge. Despite their success, heavy computational overheads, as well as the de novo and orphan proteins remain great challenges in protein representation learning. In this work, we show that MSAaugmented models inherently belong to retrievalaugmented methods. Motivated by this finding, we introduce Retrieved Sequence Augmentation(RSA) for protein representation learning without additional alignment or pre-processing. RSA links query protein sequences to a set of sequences with similar structures or properties in the database and combines these sequences for downstream prediction. We show that protein language models benefit from the retrieval enhancement on both structure prediction and property prediction tasks, with a 5% improvement on MSA Transformer on average while being 373 times faster. In addition, we show that our model can transfer to new protein domains better and outperforms MSA Transformer on de novo protein prediction. Our study fills a much-encountered gap in protein prediction and brings us a step closer to demystifying the domain knowledge needed to understand protein sequences. Code is available on https://github.com/HKUNLP/RSA.
<div id='section'>Paperid: <span id='pid'>212, <a href='https://arxiv.org/pdf/2302.08680.pdf' target='_blank'>https://arxiv.org/pdf/2302.08680.pdf</a></span>   <span><a href='https://github.com/HySonLab/drug-interactions' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nhat Khang Ngo, Truong Son Hy, Risi Kondor
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08680">Modeling Polypharmacy and Predicting Drug-Drug Interactions using Deep Generative Models on Multimodal Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Latent representations of drugs and their targets produced by contemporary graph autoencoder models have proved useful in predicting many types of node-pair interactions on large networks, including drug-drug, drug-target, and target-target interactions. However, most existing approaches model either the node's latent spaces in which node distributions are rigid or do not effectively capture the interrelations between drugs; these limitations hinder the methods from accurately predicting drug-pair interactions. In this paper, we present the effectiveness of variational graph autoencoders (VGAE) in modeling latent node representations on multimodal networks. Our approach can produce flexible latent spaces for each node type of the multimodal graph; the embeddings are used later for predicting links among node pairs under different edge types. To further enhance the models' performance, we suggest a new method that concatenates Morgan fingerprints, which capture the molecular structures of each drug, with their latent embeddings before preceding them to the decoding stage for link prediction. Our proposed model shows competitive results on three multimodal networks: (1) a multimodal graph consisting of drug and protein nodes, (2) a multimodal graph constructed from a subset of the DrugBank database involving drug nodes under different interaction types, and (3) a multimodal graph consisting of drug and cell line nodes. Our source code is publicly available at https://github.com/HySonLab/drug-interactions.
<div id='section'>Paperid: <span id='pid'>213, <a href='https://arxiv.org/pdf/2302.08511.pdf' target='_blank'>https://arxiv.org/pdf/2302.08511.pdf</a></span>   <span><a href='https://github.com/aramis-lab/miccai2022-stratifiad.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Jimenez, Anuradha Kar, Mehdi Ounissi, LÃ©a Ingrassia, Susana Boluda, BenoÃ®t Delatour, Lev Stimmer, Daniel Racoceanu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08511">Visual deep learning-based explanation for neuritic plaques segmentation in Alzheimer's Disease using weakly annotated whole slide histopathological images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantifying the distribution and morphology of tau protein structures in brain tissues is key to diagnosing Alzheimer's Disease (AD) and its subtypes. Recently, deep learning (DL) models such as UNet have been successfully used for automatic segmentation of histopathological whole slide images (WSI) of biological tissues. In this study, we propose a DL-based methodology for semantic segmentation of tau lesions (i.e., neuritic plaques) in WSI of postmortem patients with AD. The state of the art in semantic segmentation of neuritic plaques in human WSI is very limited. Our study proposes a baseline able to generate a significant advantage for morphological analysis of these tauopathies for further stratification of AD patients. Essential discussions concerning biomarkers (ALZ50 versus AT8 tau antibodies), the imaging modality (different slide scanner resolutions), and the challenge of weak annotations are addressed within this seminal study. The analysis of the impact of context in plaque segmentation is important to understand the role of the micro-environment for reliable tau protein segmentation. In addition, by integrating visual interpretability, we are able to explain how the network focuses on a region of interest (ROI), giving additional insights to pathologists. Finally, the release of a new expert-annotated database and the code (\url{https://github.com/aramis-lab/miccai2022-stratifiad.git}) will be helpful for the scientific community to accelerate the development of new pipelines for human WSI processing in AD.
<div id='section'>Paperid: <span id='pid'>214, <a href='https://arxiv.org/pdf/2302.06120.pdf' target='_blank'>https://arxiv.org/pdf/2302.06120.pdf</a></span>   <span><a href='https://github.com/yiren-jian/CoT-RNA-Transfer' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiren Jian, Chongyang Gao, Chen Zeng, Yunjie Zhao, Soroush Vosoughi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.06120">Knowledge from Large-Scale Protein Contact Prediction Models Can Be Transferred to the Data-Scarce RNA Contact Prediction Task</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>RNA, whose functionality is largely determined by its structure, plays an important role in many biological activities. The prediction of pairwise structural proximity between each nucleotide of an RNA sequence can characterize the structural information of the RNA. Historically, this problem has been tackled by machine learning models using expert-engineered features and trained on scarce labeled datasets. Here, we find that the knowledge learned by a protein-coevolution Transformer-based deep neural network can be transferred to the RNA contact prediction task. As protein datasets are orders of magnitude larger than those for RNA contact prediction, our findings and the subsequent framework greatly reduce the data scarcity bottleneck. Experiments confirm that RNA contact prediction through transfer learning using a publicly available protein model is greatly improved. Our findings indicate that the learned structural patterns of proteins can be transferred to RNAs, opening up potential new avenues for research.
<div id='section'>Paperid: <span id='pid'>215, <a href='https://arxiv.org/pdf/2302.04313.pdf' target='_blank'>https://arxiv.org/pdf/2302.04313.pdf</a></span>   <span><a href='https://github.com/BioinfoMachineLearning/Bio-Diffusion' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/BioinfoMachineLearning/Bio-Diffusion' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Morehead, Jianlin Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.04313">Geometry-Complete Diffusion for 3D Molecule Generation and Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Denoising diffusion probabilistic models (DDPMs) have pioneered new state-of-the-art results in disciplines such as computer vision and computational biology for diverse tasks ranging from text-guided image generation to structure-guided protein design. Along this latter line of research, methods have recently been proposed for generating 3D molecules using equivariant graph neural networks (GNNs) within a DDPM framework. However, such methods are unable to learn important geometric properties of 3D molecules, as they adopt molecule-agnostic and non-geometric GNNs as their 3D graph denoising networks, which notably hinders their ability to generate valid large 3D molecules. In this work, we address these gaps by introducing the Geometry-Complete Diffusion Model (GCDM) for 3D molecule generation, which outperforms existing 3D molecular diffusion models by significant margins across conditional and unconditional settings for the QM9 dataset and the larger GEOM-Drugs dataset, respectively, and generates more novel and unique unconditional 3D molecules for the QM9 dataset compared to previous methods. Importantly, we demonstrate that the geometry-complete denoising process of GCDM learned for 3D molecule generation enables the model to generate a significant proportion of valid and energetically-stable large molecules at the scale of GEOM-Drugs, whereas previous methods fail to do so with the features they learn. Additionally, we show that extensions of GCDM can not only effectively design 3D molecules for specific protein pockets but also that GCDM's geometric features can be repurposed to consistently optimize the geometry and chemical composition of existing 3D molecules for molecular stability and property specificity, demonstrating new versatility of molecular diffusion models. Our source code and data are freely available at https://github.com/BioinfoMachineLearning/Bio-Diffusion.
<div id='section'>Paperid: <span id='pid'>216, <a href='https://arxiv.org/pdf/2302.02591.pdf' target='_blank'>https://arxiv.org/pdf/2302.02591.pdf</a></span>   <span><a href='https://github.com/ChengyiLIU-cs/Generative-Diffusion-Models-on-Graphs' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chengyi Liu, Wenqi Fan, Yunqing Liu, Jiatong Li, Hang Li, Hui Liu, Jiliang Tang, Qing Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.02591">Generative Diffusion Models on Graphs: Methods and Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models, as a novel generative paradigm, have achieved remarkable success in various image generation tasks such as image inpainting, image-to-text translation, and video generation. Graph generation is a crucial computational task on graphs with numerous real-world applications. It aims to learn the distribution of given graphs and then generate new graphs. Given the great success of diffusion models in image generation, increasing efforts have been made to leverage these techniques to advance graph generation in recent years. In this paper, we first provide a comprehensive overview of generative diffusion models on graphs, In particular, we review representative algorithms for three variants of graph diffusion models, i.e., Score Matching with Langevin Dynamics (SMLD), Denoising Diffusion Probabilistic Model (DDPM), and Score-based Generative Model (SGM). Then, we summarize the major applications of generative diffusion models on graphs with a specific focus on molecule and protein modeling. Finally, we discuss promising directions in generative diffusion models on graph-structured data. For this survey, we also created a GitHub project website by collecting the supporting resources for generative diffusion models on graphs, at the link: https://github.com/ChengyiLIU-cs/Generative-Diffusion-Models-on-Graphs
<div id='section'>Paperid: <span id='pid'>217, <a href='https://arxiv.org/pdf/2301.13154.pdf' target='_blank'>https://arxiv.org/pdf/2301.13154.pdf</a></span>   <span><a href='https://github.com/RL4M/KeAP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong-Yu Zhou, Yunxiang Fu, Zhicheng Zhang, Cheng Bian, Yizhou Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.13154">Protein Representation Learning via Knowledge Enhanced Primary Structure Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein representation learning has primarily benefited from the remarkable development of language models (LMs). Accordingly, pre-trained protein models also suffer from a problem in LMs: a lack of factual knowledge. The recent solution models the relationships between protein and associated knowledge terms as the knowledge encoding objective. However, it fails to explore the relationships at a more granular level, i.e., the token level. To mitigate this, we propose Knowledge-exploited Auto-encoder for Protein (KeAP), which performs token-level knowledge graph exploration for protein representation learning. In practice, non-masked amino acids iteratively query the associated knowledge tokens to extract and integrate helpful information for restoring masked amino acids via attention. We show that KeAP can consistently outperform the previous counterpart on 9 representative downstream applications, sometimes surpassing it by large margins. These results suggest that KeAP provides an alternative yet effective way to perform knowledge enhanced protein representation learning.
<div id='section'>Paperid: <span id='pid'>218, <a href='https://arxiv.org/pdf/2301.12485.pdf' target='_blank'>https://arxiv.org/pdf/2301.12485.pdf</a></span>   <span><a href='https://github.com/aqlaboratory/genie' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yeqing Lin, Mohammed AlQuraishi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12485">Generating Novel, Designable, and Diverse Protein Structures by Equivariantly Diffusing Oriented Residue Clouds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins power a vast array of functional processes in living cells. The capability to create new proteins with designed structures and functions would thus enable the engineering of cellular behavior and development of protein-based therapeutics and materials. Structure-based protein design aims to find structures that are designable (can be realized by a protein sequence), novel (have dissimilar geometry from natural proteins), and diverse (span a wide range of geometries). While advances in protein structure prediction have made it possible to predict structures of novel protein sequences, the combinatorially large space of sequences and structures limits the practicality of search-based methods. Generative models provide a compelling alternative, by implicitly learning the low-dimensional structure of complex data distributions. Here, we leverage recent advances in denoising diffusion probabilistic models and equivariant neural networks to develop Genie, a generative model of protein structures that performs discrete-time diffusion using a cloud of oriented reference frames in 3D space. Through in silico evaluations, we demonstrate that Genie generates protein backbones that are more designable, novel, and diverse than existing models. This indicates that Genie is capturing key aspects of the distribution of protein structure space and facilitates protein design with high success rates. Code for generating new proteins and training new versions of Genie is available at https://github.com/aqlaboratory/genie.
<div id='section'>Paperid: <span id='pid'>219, <a href='https://arxiv.org/pdf/2301.12112.pdf' target='_blank'>https://arxiv.org/pdf/2301.12112.pdf</a></span>   <span><a href='https://github.com/dqwang122/EATLM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Danqing Wang, Fei Ye, Hao Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12112">On Pre-trained Language Models for Antibody</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibodies are vital proteins offering robust protection for the human body from pathogens. The development of general protein and antibody-specific pre-trained language models both facilitate antibody prediction tasks. However, there have been limited studies that comprehensively explore the representation capability of distinct pre-trained language models on different antibody tasks. To investigate the problem, we aim to answer several key questions in this paper, such as how pre-trained language models perform in antibody tasks with different specificity and how introducing specific biological mechanisms to the pre-training process can benefit the model. Additionally, we evaluate if the learned antibody pre-trained representations can be applied to real-world antibody problems, like drug discovery and immune process understanding. Previously, no benchmark available largely hindered the study to answer these questions. To aid in our investigation, we provide an AnTibody Understanding Evaluation (ATUE) benchmark. We comprehensively evaluate the performance of protein pre-trained language models by empirical study along with conclusions and new insights. Our ATUE and code are released at https://github.com/dqwang122/EATLM.
<div id='section'>Paperid: <span id='pid'>220, <a href='https://arxiv.org/pdf/2301.12068.pdf' target='_blank'>https://arxiv.org/pdf/2301.12068.pdf</a></span>   <span><a href='https://github.com/DeepGraphLearning/SiamDiff' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zuobai Zhang, Minghao Xu, AurÃ©lie Lozano, Vijil Chenthamarakshan, Payel Das, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12068">Pre-Training Protein Encoder via Siamese Sequence-Structure Diffusion Trajectory Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised pre-training methods on proteins have recently gained attention, with most approaches focusing on either protein sequences or structures, neglecting the exploration of their joint distribution, which is crucial for a comprehensive understanding of protein functions by integrating co-evolutionary information and structural characteristics. In this work, inspired by the success of denoising diffusion models in generative tasks, we propose the DiffPreT approach to pre-train a protein encoder by sequence-structure joint diffusion modeling. DiffPreT guides the encoder to recover the native protein sequences and structures from the perturbed ones along the joint diffusion trajectory, which acquires the joint distribution of sequences and structures. Considering the essential protein conformational variations, we enhance DiffPreT by a method called Siamese Diffusion Trajectory Prediction (SiamDiff) to capture the correlation between different conformers of a protein. SiamDiff attains this goal by maximizing the mutual information between representations of diffusion trajectories of structurally-correlated conformers. We study the effectiveness of DiffPreT and SiamDiff on both atom- and residue-level structure-based protein understanding tasks. Experimental results show that the performance of DiffPreT is consistently competitive on all tasks, and SiamDiff achieves new state-of-the-art performance, considering the mean ranks on all tasks. Our implementation is available at https://github.com/DeepGraphLearning/SiamDiff.
<div id='section'>Paperid: <span id='pid'>221, <a href='https://arxiv.org/pdf/2301.10774.pdf' target='_blank'>https://arxiv.org/pdf/2301.10774.pdf</a></span>   <span><a href='https://github.com/A4Bio/RDesign' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng Tan, Yijie Zhang, Zhangyang Gao, Bozhen Hu, Siyuan Li, Zicheng Liu, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.10774">RDesign: Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While artificial intelligence has made remarkable strides in revealing the relationship between biological macromolecules' primary sequence and tertiary structure, designing RNA sequences based on specified tertiary structures remains challenging. Though existing approaches in protein design have thoroughly explored structure-to-sequence dependencies in proteins, RNA design still confronts difficulties due to structural complexity and data scarcity. Moreover, direct transplantation of protein design methodologies into RNA design fails to achieve satisfactory outcomes although sharing similar structural components. In this study, we aim to systematically construct a data-driven RNA design pipeline. We crafted a large, well-curated benchmark dataset and designed a comprehensive structural modeling approach to represent the complex RNA tertiary structure. More importantly, we proposed a hierarchical data-efficient representation learning framework that learns structural representations through contrastive learning at both cluster-level and sample-level to fully leverage the limited data. By constraining data representations within a limited hyperspherical space, the intrinsic relationships between data points could be explicitly imposed. Moreover, we incorporated extracted secondary structures with base pairs as prior knowledge to facilitate the RNA design process. Extensive experiments demonstrate the effectiveness of our proposed method, providing a reliable baseline for future RNA design tasks. The source code and benchmark dataset are available at https://github.com/A4Bio/RDesign.
<div id='section'>Paperid: <span id='pid'>222, <a href='https://arxiv.org/pdf/2301.06454.pdf' target='_blank'>https://arxiv.org/pdf/2301.06454.pdf</a></span>   <span><a href='https://github.com/msmdev/PlasmoFAB' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas Christian Ditz, Jacqueline Wistuba-Hamprecht, Timo Maier, Rolf Fendel, Nico Pfeifer, Bernhard Reuter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.06454">PlasmoFAB: A Benchmark to Foster Machine Learning for Plasmodium falciparum Protein Antigen Candidate Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motivation: Machine learning methods can be used to support scientific discovery in healthcare-related research fields. However, these methods can only be reliably used if they can be trained on high-quality and curated datasets. Currently, no such dataset for the exploration of Plasmodium falciparum protein antigen candidates exists. The parasite Plasmodium falciparum causes the infectious disease malaria. Thus, identifying potential antigens is of utmost importance for the development of antimalarial drugs and vaccines. Since exploring antigen candidates experimentally is an expensive and time-consuming process, applying machine learning methods to support this process has the potential to accelerate the development of drugs and vaccines, which are needed for fighting and controlling malaria. Results: We developed PlasmoFAB, a curated benchmark that can be used to train machine learning methods for the exploration of Plasmodium falciparum protein antigen candidates. We combined an extensive literature search with domain expertise to create high-quality labels for Plasmodium falciparum specific proteins that distinguish between antigen candidates and intracellular proteins. Additionally, we used our benchmark to compare different well-known prediction models and available protein localization prediction services on the task of identifying protein antigen candidates. We show that available general-purpose services are unable to provide sufficient performance on identifying protein antigen candidates and are outperformed by our models that were trained on this tailored data. Availability: PlasmoFAB is publicly available on Zenodo with DOI 10.5281/zenodo.7433087. Furthermore, all scripts that were used in the creation of PlasmoFAB and the training and evaluation of machine learning models are open source and publicly available on GitHub here: https://github.com/msmdev/PlasmoFAB.
<div id='section'>Paperid: <span id='pid'>223, <a href='https://arxiv.org/pdf/2301.00813.pdf' target='_blank'>https://arxiv.org/pdf/2301.00813.pdf</a></span>   <span><a href='https://github.com/LirongWu/awesome-protein-representation-learning' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lirong Wu, Yufei Huang, Haitao Lin, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.00813">A Survey on Protein Representation Learning: Retrospect and Prospect</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are fundamental biological entities that play a key role in life activities. The amino acid sequences of proteins can be folded into stable 3D structures in the real physicochemical world, forming a special kind of sequence-structure data. With the development of Artificial Intelligence (AI) techniques, Protein Representation Learning (PRL) has recently emerged as a promising research topic for extracting informative knowledge from massive protein sequences or structures. To pave the way for AI researchers with little bioinformatics background, we present a timely and comprehensive review of PRL formulations and existing PRL methods from the perspective of model architectures, pretext tasks, and downstream applications. We first briefly introduce the motivations for protein representation learning and formulate it in a general and unified framework. Next, we divide existing PRL methods into three main categories: sequence-based, structure-based, and sequence-structure co-modeling. Finally, we discuss some technical challenges and potential directions for improving protein representation learning. The latest advances in PRL methods are summarized in a GitHub repository https://github.com/LirongWu/awesome-protein-representation-learning.
<div id='section'>Paperid: <span id='pid'>224, <a href='https://arxiv.org/pdf/2212.12440.pdf' target='_blank'>https://arxiv.org/pdf/2212.12440.pdf</a></span>   <span><a href='https://github.com/gregory-kyro/HAC-Net/,' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Gregory W. Kyro, Rafael I. Brent, Victor S. Batista
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.12440">HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Applying deep learning concepts from image detection and graph theory has greatly advanced protein-ligand binding affinity prediction, a challenge with enormous ramifications for both drug discovery and protein engineering. We build upon these advances by designing a novel deep learning architecture consisting of a 3-dimensional convolutional neural network utilizing channel-wise attention and two graph convolutional networks utilizing attention-based aggregation of node features. HAC-Net (Hybrid Attention-Based Convolutional Neural Network) obtains state-of-the-art results on the PDBbind v.2016 core set, the most widely recognized benchmark in the field. We extensively assess the generalizability of our model using multiple train-test splits, each of which maximizes differences between either protein structures, protein sequences, or ligand extended-connectivity fingerprints of complexes in the training and test sets. Furthermore, we perform 10-fold cross-validation with a similarity cutoff between SMILES strings of ligands in the training and test sets, and also evaluate the performance of HAC-Net on lower-quality data. We envision that this model can be extended to a broad range of supervised learning problems related to structure-based biomolecular property prediction. All of our software is available as open source at https://github.com/gregory-kyro/HAC-Net/, and the HACNet Python package is available through PyPI.
<div id='section'>Paperid: <span id='pid'>225, <a href='https://arxiv.org/pdf/2212.09925.pdf' target='_blank'>https://arxiv.org/pdf/2212.09925.pdf</a></span>   <span><a href='https://github.com/pemami4911/ppde' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Patrick Emami, Aidan Perreault, Jeffrey Law, David Biagioni, Peter C. St. John
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.09925">Plug & Play Directed Evolution of Proteins with Gradient-based Discrete MCMC</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A long-standing goal of machine-learning-based protein engineering is to accelerate the discovery of novel mutations that improve the function of a known protein. We introduce a sampling framework for evolving proteins in silico that supports mixing and matching a variety of unsupervised models, such as protein language models, and supervised models that predict protein function from sequence. By composing these models, we aim to improve our ability to evaluate unseen mutations and constrain search to regions of sequence space likely to contain functional proteins. Our framework achieves this without any model fine-tuning or re-training by constructing a product of experts distribution directly in discrete protein space. Instead of resorting to brute force search or random sampling, which is typical of classic directed evolution, we introduce a fast MCMC sampler that uses gradients to propose promising mutations. We conduct in silico directed evolution experiments on wide fitness landscapes and across a range of different pre-trained unsupervised models, including a 650M parameter protein language model. Our results demonstrate an ability to efficiently discover variants with high evolutionary likelihood as well as estimated activity multiple mutations away from a wild type protein, suggesting our sampler provides a practical and effective new paradigm for machine-learning-based protein engineering.
<div id='section'>Paperid: <span id='pid'>226, <a href='https://arxiv.org/pdf/2211.02504.pdf' target='_blank'>https://arxiv.org/pdf/2211.02504.pdf</a></span>   <span><a href='https://github.com/BioinfoMachineLearning/GCPNet' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/BioinfoMachineLearning/GCPNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Morehead, Jianlin Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.02504">Geometry-Complete Perceptron Networks for 3D Molecular Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The field of geometric deep learning has had a profound impact on the development of innovative and powerful graph neural network architectures. Disciplines such as computer vision and computational biology have benefited significantly from such methodological advances, which has led to breakthroughs in scientific domains such as protein structure prediction and design. In this work, we introduce GCPNet, a new geometry-complete, SE(3)-equivariant graph neural network designed for 3D molecular graph representation learning. Rigorous experiments across four distinct geometric tasks demonstrate that GCPNet's predictions (1) for protein-ligand binding affinity achieve a statistically significant correlation of 0.608, more than 5% greater than current state-of-the-art methods; (2) for protein structure ranking achieve statistically significant target-local and dataset-global correlations of 0.616 and 0.871, respectively; (3) for Newtownian many-body systems modeling achieve a task-averaged mean squared error less than 0.01, more than 15% better than current methods; and (4) for molecular chirality recognition achieve a state-of-the-art prediction accuracy of 98.7%, better than any other machine learning method to date. The source code, data, and instructions to train new models or reproduce our results are freely available at https://github.com/BioinfoMachineLearning/GCPNet.
<div id='section'>Paperid: <span id='pid'>227, <a href='https://arxiv.org/pdf/2210.07144.pdf' target='_blank'>https://arxiv.org/pdf/2210.07144.pdf</a></span>   <span><a href='https://github.com/IBM/ReprogBERT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Igor Melnyk, Vijil Chenthamarakshan, Pin-Yu Chen, Payel Das, Amit Dhurandhar, Inkit Padhi, Devleena Das
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.07144">Reprogramming Pretrained Language Models for Antibody Sequence Infilling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibodies comprise the most versatile class of binding molecules, with numerous applications in biomedicine. Computational design of antibodies involves generating novel and diverse sequences, while maintaining structural consistency. Unique to antibodies, designing the complementarity-determining region (CDR), which determines the antigen binding affinity and specificity, creates its own unique challenges. Recent deep learning models have shown impressive results, however the limited number of known antibody sequence/structure pairs frequently leads to degraded performance, particularly lacking diversity in the generated sequences. In our work we address this challenge by leveraging Model Reprogramming (MR), which repurposes pretrained models on a source language to adapt to the tasks that are in a different language and have scarce data - where it may be difficult to train a high-performing model from scratch or effectively fine-tune an existing pre-trained model on the specific task. Specifically, we introduce ReprogBert in which a pretrained English language model is repurposed for protein sequence infilling - thus considers cross-language adaptation using less data. Results on antibody design benchmarks show that our model on low-resourced antibody sequence dataset provides highly diverse CDR sequences, up to more than a two-fold increase of diversity over the baselines, without losing structural integrity and naturalness. The generated sequences also demonstrate enhanced antigen binding specificity and virus neutralization ability. Code is available at https://github.com/IBM/ReprogBERT
<div id='section'>Paperid: <span id='pid'>228, <a href='https://arxiv.org/pdf/2210.03488.pdf' target='_blank'>https://arxiv.org/pdf/2210.03488.pdf</a></span>   <span><a href='https://github.com/IBM/AFDistill' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Igor Melnyk, Aurelie Lozano, Payel Das, Vijil Chenthamarakshan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.03488">AlphaFold Distillation for Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse protein folding, the process of designing sequences that fold into a specific 3D structure, is crucial in bio-engineering and drug discovery. Traditional methods rely on experimentally resolved structures, but these cover only a small fraction of protein sequences. Forward folding models like AlphaFold offer a potential solution by accurately predicting structures from sequences. However, these models are too slow for integration into the optimization loop of inverse folding models during training. To address this, we propose using knowledge distillation on folding model confidence metrics, such as pTM or pLDDT scores, to create a faster and end-to-end differentiable distilled model. This model can then be used as a structure consistency regularizer in training the inverse folding model. Our technique is versatile and can be applied to other design tasks, such as sequence-based protein infilling. Experimental results show that our method outperforms non-regularized baselines, yielding up to 3% improvement in sequence recovery and up to 45% improvement in protein diversity while maintaining structural consistency in generated sequences. Code is available at https://github.com/IBM/AFDistill
<div id='section'>Paperid: <span id='pid'>229, <a href='https://arxiv.org/pdf/2209.12643.pdf' target='_blank'>https://arxiv.org/pdf/2209.12643.pdf</a></span>   <span><a href='https://github.com/A4Bio/PiFold' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangyang Gao, Cheng Tan, Pablo ChacÃ³n, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.12643">PiFold: Toward effective and efficient protein inverse folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>How can we design protein sequences folding into the desired structures effectively and efficiently? AI methods for structure-based protein design have attracted increasing attention in recent years; however, few methods can simultaneously improve the accuracy and efficiency due to the lack of expressive features and autoregressive sequence decoder. To address these issues, we propose PiFold, which contains a novel residue featurizer and PiGNN layers to generate protein sequences in a one-shot way with improved recovery. Experiments show that PiFold could achieve 51.66\% recovery on CATH 4.2, while the inference speed is 70 times faster than the autoregressive competitors. In addition, PiFold achieves 58.72\% and 60.42\% recovery scores on TS50 and TS500, respectively. We conduct comprehensive ablation studies to reveal the role of different types of protein features and model designs, inspiring further simplification and improvement. The PyTorch code is available at \href{https://github.com/A4Bio/PiFold}{GitHub}.
<div id='section'>Paperid: <span id='pid'>230, <a href='https://arxiv.org/pdf/2207.13921.pdf' target='_blank'>https://arxiv.org/pdf/2207.13921.pdf</a></span>   <span><a href='https://github.com/PaddlePaddle/PaddleHelix/tree/dev/apps/protein_folding/helixfold-single,' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaomin Fang, Fan Wang, Lihang Liu, Jingzhou He, Dayong Lin, Yingfei Xiang, Xiaonan Zhang, Hua Wu, Hui Li, Le Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.13921">HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein Language Model as an Alternative</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI-based protein structure prediction pipelines, such as AlphaFold2, have achieved near-experimental accuracy. These advanced pipelines mainly rely on Multiple Sequence Alignments (MSAs) as inputs to learn the co-evolution information from the homologous sequences. Nonetheless, searching MSAs from protein databases is time-consuming, usually taking dozens of minutes. Consequently, we attempt to explore the limits of fast protein structure prediction by using only primary sequences of proteins. HelixFold-Single is proposed to combine a large-scale protein language model with the superior geometric learning capability of AlphaFold2. Our proposed method, HelixFold-Single, first pre-trains a large-scale protein language model (PLM) with thousands of millions of primary sequences utilizing the self-supervised learning paradigm, which will be used as an alternative to MSAs for learning the co-evolution information. Then, by combining the pre-trained PLM and the essential components of AlphaFold2, we obtain an end-to-end differentiable model to predict the 3D coordinates of atoms from only the primary sequence. HelixFold-Single is validated in datasets CASP14 and CAMEO, achieving competitive accuracy with the MSA-based methods on the targets with large homologous families. Furthermore, HelixFold-Single consumes much less time than the mainstream pipelines for protein structure prediction, demonstrating its potential in tasks requiring many predictions. The code of HelixFold-Single is available at https://github.com/PaddlePaddle/PaddleHelix/tree/dev/apps/protein_folding/helixfold-single, and we also provide stable web services on https://paddlehelix.baidu.com/app/drug/protein-single/forecast.
<div id='section'>Paperid: <span id='pid'>231, <a href='https://arxiv.org/pdf/2207.12600.pdf' target='_blank'>https://arxiv.org/pdf/2207.12600.pdf</a></span>   <span><a href='https://github.com/divelab/DIG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Limei Wang, Haoran Liu, Yi Liu, Jerry Kurtin, Shuiwang Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.12600">Learning Hierarchical Protein Representations via Complete 3D Graph Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider representation learning for proteins with 3D structures. We build 3D graphs based on protein structures and develop graph networks to learn their representations. Depending on the levels of details that we wish to capture, protein representations can be computed at different levels, \emph{e.g.}, the amino acid, backbone, or all-atom levels. Importantly, there exist hierarchical relations among different levels. In this work, we propose to develop a novel hierarchical graph network, known as ProNet, to capture the relations. Our ProNet is very flexible and can be used to compute protein representations at different levels of granularity. By treating each amino acid as a node in graph modeling as well as harnessing the inherent hierarchies, our ProNet is more effective and efficient than existing methods. We also show that, given a base 3D graph network that is complete, our ProNet representations are also complete at all levels. Experimental results show that ProNet outperforms recent methods on most datasets. In addition, results indicate that different downstream tasks may require representations at different levels. Our code is publicly available as part of the DIG library (\url{https://github.com/divelab/DIG}).
<div id='section'>Paperid: <span id='pid'>232, <a href='https://arxiv.org/pdf/2207.02968.pdf' target='_blank'>https://arxiv.org/pdf/2207.02968.pdf</a></span>   <span><a href='https://github.com/BorgwardtLab/JointMDS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dexiong Chen, Bowen Fan, Carlos Oliver, Karsten Borgwardt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.02968">Unsupervised Manifold Alignment with Joint Multidimensional Scaling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Joint Multidimensional Scaling, a novel approach for unsupervised manifold alignment, which maps datasets from two different domains, without any known correspondences between data instances across the datasets, to a common low-dimensional Euclidean space. Our approach integrates Multidimensional Scaling (MDS) and Wasserstein Procrustes analysis into a joint optimization problem to simultaneously generate isometric embeddings of data and learn correspondences between instances from two different datasets, while only requiring intra-dataset pairwise dissimilarities as input. This unique characteristic makes our approach applicable to datasets without access to the input features, such as solving the inexact graph matching problem. We propose an alternating optimization scheme to solve the problem that can fully benefit from the optimization techniques for MDS and Wasserstein Procrustes. We demonstrate the effectiveness of our approach in several applications, including joint visualization of two datasets, unsupervised heterogeneous domain adaptation, graph matching, and protein structure alignment. The implementation of our work is available at https://github.com/BorgwardtLab/JointMDS
<div id='section'>Paperid: <span id='pid'>233, <a href='https://arxiv.org/pdf/2206.07632.pdf' target='_blank'>https://arxiv.org/pdf/2206.07632.pdf</a></span>   <span><a href='https://github.com/SeulLee05/MOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Seul Lee, Jaehyeong Jo, Sung Ju Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.07632">Exploring Chemical Space with Score-based Out-of-distribution Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A well-known limitation of existing molecular generative models is that the generated molecules highly resemble those in the training set. To generate truly novel molecules that may have even better properties for de novo drug discovery, more powerful exploration in the chemical space is necessary. To this end, we propose Molecular Out-Of-distribution Diffusion(MOOD), a score-based diffusion scheme that incorporates out-of-distribution (OOD) control in the generative stochastic differential equation (SDE) with simple control of a hyperparameter, thus requires no additional costs. Since some novel molecules may not meet the basic requirements of real-world drugs, MOOD performs conditional generation by utilizing the gradients from a property predictor that guides the reverse-time diffusion process to high-scoring regions according to target properties such as protein-ligand interactions, drug-likeness, and synthesizability. This allows MOOD to search for novel and meaningful molecules rather than generating unseen yet trivial ones. We experimentally validate that MOOD is able to explore the chemical space beyond the training distribution, generating molecules that outscore ones found with existing methods, and even the top 0.01% of the original training pool. Our code is available at https://github.com/SeulLee05/MOOD.
<div id='section'>Paperid: <span id='pid'>234, <a href='https://arxiv.org/pdf/2206.02789.pdf' target='_blank'>https://arxiv.org/pdf/2206.02789.pdf</a></span>   <span><a href='https://github.com/zetayue/Physics-aware-Multiplex-GNN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuo Zhang, Yang Liu, Lei Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.02789">Efficient and Accurate Physics-aware Multiplex Graph Neural Networks for 3D Small Molecules and Macromolecule Complexes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in applying Graph Neural Networks (GNNs) to molecular science have showcased the power of learning three-dimensional (3D) structure representations with GNNs. However, most existing GNNs suffer from the limitations of insufficient modeling of diverse interactions, computational expensive operations, and ignorance of vectorial values. Here, we tackle these limitations by proposing a novel GNN model, Physics-aware Multiplex Graph Neural Network (PaxNet), to efficiently and accurately learn the representations of 3D molecules for both small organic compounds and macromolecule complexes. PaxNet separates the modeling of local and non-local interactions inspired by molecular mechanics, and reduces the expensive angle-related computations. Besides scalar properties, PaxNet can also predict vectorial properties by learning an associated vector for each atom. To evaluate the performance of PaxNet, we compare it with state-of-the-art baselines in two tasks. On small molecule dataset for predicting quantum chemical properties, PaxNet reduces the prediction error by 15% and uses 73% less memory than the best baseline. On macromolecule dataset for predicting protein-ligand binding affinities, PaxNet outperforms the best baseline while reducing the memory consumption by 33% and the inference time by 85%. Thus, PaxNet provides a universal, robust and accurate method for large-scale machine learning of molecules. Our code is available at https://github.com/zetayue/Physics-aware-Multiplex-GNN.
<div id='section'>Paperid: <span id='pid'>235, <a href='https://arxiv.org/pdf/2204.09486.pdf' target='_blank'>https://arxiv.org/pdf/2204.09486.pdf</a></span>   <span><a href='https://github.com/zshicode/GNN-AttCL-protein' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuangwei Shi, Bo Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.09486">Graph neural networks and attention-based CNN-LSTM for protein classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper focuses on three critical problems on protein classification. Firstly, Carbohydrate-active enzyme (CAZyme) classification can help people to understand the properties of enzymes. However, one CAZyme may belong to several classes. This leads to Multi-label CAZyme classification. Secondly, to capture information from the secondary structure of protein, protein classification is modeled as graph classification problem. Thirdly, compound-protein interactions prediction employs graph learning for compound with sequential embedding for protein. This can be seen as classification task for compound-protein pairs. This paper proposes three models for protein classification. Firstly, this paper proposes a Multi-label CAZyme classification model using CNN-LSTM with Attention mechanism. Secondly, this paper proposes a variational graph autoencoder based subspace learning model for protein graph classification. Thirdly, this paper proposes graph isomorphism networks (GIN) and Attention-based CNN-LSTM for compound-protein interactions prediction, as well as comparing GIN with graph convolution networks (GCN) and graph attention networks (GAT) in this task. The proposed models are effective for protein classification. Source code and data are available at https://github.com/zshicode/GNN-AttCL-protein. Besides, this repository collects and collates the benchmark datasets with respect to above problems, including CAZyme classification, enzyme protein graph classification, compound-protein interactions prediction, drug-target affinities prediction and drug-drug interactions prediction. Hence, the usage for evaluation by benchmark datasets can be more conveniently.
<div id='section'>Paperid: <span id='pid'>236, <a href='https://arxiv.org/pdf/2204.04213.pdf' target='_blank'>https://arxiv.org/pdf/2204.04213.pdf</a></span>   <span><a href='https://github.com/GGchen1997/STEPS_Bioinformatics' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Chen, Jingbo Zhou, Fan Wang, Xue Liu, Dejing Dou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.04213">Structure-aware Protein Self-supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein representation learning methods have shown great potential to yield useful representation for many downstream tasks, especially on protein classification. Moreover, a few recent studies have shown great promise in addressing insufficient labels of proteins with self-supervised learning methods. However, existing protein language models are usually pretrained on protein sequences without considering the important protein structural information. To this end, we propose a novel structure-aware protein self-supervised learning method to effectively capture structural information of proteins. In particular, a well-designed graph neural network (GNN) model is pretrained to preserve the protein structural information with self-supervised tasks from a pairwise residue distance perspective and a dihedral angle perspective, respectively. Furthermore, we propose to leverage the available protein language model pretrained on protein sequences to enhance the self-supervised learning. Specifically, we identify the relation between the sequential information in the protein language model and the structural information in the specially designed GNN model via a novel pseudo bi-level optimization scheme. Experiments on several supervised downstream tasks verify the effectiveness of our proposed method.The code of the proposed method is available in \url{https://github.com/GGchen1997/STEPS_Bioinformatics}.
<div id='section'>Paperid: <span id='pid'>237, <a href='https://arxiv.org/pdf/2203.06125.pdf' target='_blank'>https://arxiv.org/pdf/2203.06125.pdf</a></span>   <span><a href='https://github.com/DeepGraphLearning/GearNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zuobai Zhang, Minghao Xu, Arian Jamasb, Vijil Chenthamarakshan, Aurelie Lozano, Payel Das, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.06125">Protein Representation Learning by Geometric Structure Pretraining</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning effective protein representations is critical in a variety of tasks in biology such as predicting protein function or structure. Existing approaches usually pretrain protein language models on a large number of unlabeled amino acid sequences and then finetune the models with some labeled data in downstream tasks. Despite the effectiveness of sequence-based approaches, the power of pretraining on known protein structures, which are available in smaller numbers only, has not been explored for protein property prediction, though protein structures are known to be determinants of protein function. In this paper, we propose to pretrain protein representations according to their 3D structures. We first present a simple yet effective encoder to learn the geometric features of a protein. We pretrain the protein graph encoder by leveraging multiview contrastive learning and different self-prediction tasks. Experimental results on both function prediction and fold classification tasks show that our proposed pretraining methods outperform or are on par with the state-of-the-art sequence-based methods, while using much less pretraining data. Our implementation is available at https://github.com/DeepGraphLearning/GearNet.
<div id='section'>Paperid: <span id='pid'>238, <a href='https://arxiv.org/pdf/2203.04115.pdf' target='_blank'>https://arxiv.org/pdf/2203.04115.pdf</a></span>   <span><a href='https://github.com/MJ10/BioSeq-GFN-AL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Moksh Jain, Emmanuel Bengio, Alex-Hernandez Garcia, Jarrid Rector-Brooks, Bonaventure F. P. Dossou, Chanakya Ekbote, Jie Fu, Tianyu Zhang, Micheal Kilgour, Dinghuai Zhang, Lena Simine, Payel Das, Yoshua Bengio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.04115">Biological Sequence Design with GFlowNets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Design of de novo biological sequences with desired properties, like protein and DNA sequences, often involves an active loop with several rounds of molecule ideation and expensive wet-lab evaluations. These experiments can consist of multiple stages, with increasing levels of precision and cost of evaluation, where candidates are filtered. This makes the diversity of proposed candidates a key consideration in the ideation phase. In this work, we propose an active learning algorithm leveraging epistemic uncertainty estimation and the recently proposed GFlowNets as a generator of diverse candidate solutions, with the objective to obtain a diverse batch of useful (as defined by some utility function, for example, the predicted anti-microbial activity of a peptide) and informative candidates after each round. We also propose a scheme to incorporate existing labeled datasets of candidates, in addition to a reward function, to speed up learning in GFlowNets. We present empirical results on several biological sequence design tasks, and we find that our method generates more diverse and novel batches with high scoring candidates compared to existing approaches.
<div id='section'>Paperid: <span id='pid'>239, <a href='https://arxiv.org/pdf/2202.03613.pdf' target='_blank'>https://arxiv.org/pdf/2202.03613.pdf</a></span>   <span><a href='https://github.com/clarafy/conformal-for-design' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Clara Fannjiang, Stephen Bates, Anastasios N. Angelopoulos, Jennifer Listgarten, Michael I. Jordan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.03613">Conformal Prediction Under Feedback Covariate Shift for Biomolecular Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many applications of machine learning methods involve an iterative protocol in which data are collected, a model is trained, and then outputs of that model are used to choose what data to consider next. For example, one data-driven approach for designing proteins is to train a regression model to predict the fitness of protein sequences, then use it to propose new sequences believed to exhibit greater fitness than observed in the training data. Since validating designed sequences in the wet lab is typically costly, it is important to quantify the uncertainty in the model's predictions. This is challenging because of a characteristic type of distribution shift between the training and test data in the design setting -- one in which the training and test data are statistically dependent, as the latter is chosen based on the former. Consequently, the model's error on the test data -- that is, the designed sequences -- has an unknown and possibly complex relationship with its error on the training data. We introduce a method to quantify predictive uncertainty in such settings. We do so by constructing confidence sets for predictions that account for the dependence between the training and test data. The confidence sets we construct have finite-sample guarantees that hold for any prediction algorithm, even when a trained model chooses the test-time input distribution. As a motivating use case, we demonstrate with several real data sets how our method quantifies uncertainty for the predicted fitness of designed proteins, and can therefore be used to select design algorithms that achieve acceptable trade-offs between high predicted fitness and low predictive uncertainty.
<div id='section'>Paperid: <span id='pid'>240, <a href='https://arxiv.org/pdf/2202.01338.pdf' target='_blank'>https://arxiv.org/pdf/2202.01338.pdf</a></span>   <span><a href='https://github.com/IBM/regression-transformer' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jannis Born, Matteo Manica
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.01338">Regression Transformer: Concurrent sequence regression and generation for molecular language modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite significant progress of generative models in the natural sciences, their controllability remains challenging. One fundamentally missing aspect of molecular or protein generative models is an inductive bias that can reflect continuous properties of interest. To that end, we propose the Regression Transformer (RT), a novel method that abstracts regression as a conditional sequence modeling problem. This introduces a new paradigm of multitask language models which seamlessly bridge sequence regression and conditional sequence generation.
  We thoroughly demonstrate that, despite using a nominal-scale training objective, the RT matches or surpasses the performance of conventional regression models in property prediction tasks of small molecules, proteins and chemical reactions. Critically, priming the same model with continuous properties yields a highly competitive conditional generative model that outperforms specialized approaches in a substructure-constrained, property-driven molecule generation benchmark. Our dichotomous approach is facilitated by a novel, alternating training scheme that enables the model to decorate seed sequences by desired properties, e.g., to optimize reaction yield.
  In sum, the RT is the first report of a multitask model that concurrently excels at predictive and generative tasks in biochemistry. This finds particular application in property-driven, local exploration of the chemical or protein space and could pave the road toward foundation models in material design.
  The code to reproduce all experiments of the paper is available at: https://github.com/IBM/regression-transformer
<div id='section'>Paperid: <span id='pid'>241, <a href='https://arxiv.org/pdf/2201.13299.pdf' target='_blank'>https://arxiv.org/pdf/2201.13299.pdf</a></span>   <span><a href='https://github.com/Ced3-han/OAGNN/tree/main' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahan Li, Shitong Luo, Congyue Deng, Chaoran Cheng, Jiaqi Guan, Leonidas Guibas, Jian Peng, Jianzhu Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.13299">Orientation-Aware Graph Neural Networks for Protein Structure Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>By folding into particular 3D structures, proteins play a key role in living beings. To learn meaningful representation from a protein structure for downstream tasks, not only the global backbone topology but the local fine-grained orientational relations between amino acids should also be considered. In this work, we propose the Orientation-Aware Graph Neural Networks (OAGNNs) to better sense the geometric characteristics in protein structure (e.g. inner-residue torsion angles, inter-residue orientations). Extending a single weight from a scalar to a 3D vector, we construct a rich set of geometric-meaningful operations to process both the classical and SO(3) representations of a given structure. To plug our designed perceptron unit into existing Graph Neural Networks, we further introduce an equivariant message passing paradigm, showing superior versatility in maintaining SO(3)-equivariance at the global scale. Experiments have shown that our OAGNNs have a remarkable ability to sense geometric orientational features compared to classical networks. OAGNNs have also achieved state-of-the-art performance on various computational biology applications related to protein 3D structures. The code is available at https://github.com/Ced3-han/OAGNN/tree/main.
<div id='section'>Paperid: <span id='pid'>242, <a href='https://arxiv.org/pdf/2006.16955.pdf' target='_blank'>https://arxiv.org/pdf/2006.16955.pdf</a></span>   <span><a href='https://github.com/cieplinski-tobiasz/smina-docking-benchmark' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tobiasz Cieplinski, Tomasz Danel, Sabina Podlewska, Stanislaw Jastrzebski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2006.16955">We Should at Least Be Able to Design Molecules That Dock Well</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing compounds with desired properties is a key element of the drug discovery process. However, measuring progress in the field has been challenging due to the lack of realistic retrospective benchmarks, and the large cost of prospective validation. To close this gap, we propose a benchmark based on docking, a popular computational method for assessing molecule binding to a protein. Concretely, the goal is to generate drug-like molecules that are scored highly by SMINA, a popular docking software. We observe that popular graph-based generative models fail to generate molecules with a high docking score when trained using a realistically sized training set. This suggests a limitation of the current incarnation of models for de novo drug design. Finally, we propose a simplified version of the benchmark based on a simpler scoring function, and show that the tested models are able to partially solve it. We release the benchmark as an easy to use package available at https://github.com/cieplinski-tobiasz/smina-docking-benchmark. We hope that our benchmark will serve as a stepping stone towards the goal of automatically generating promising drug candidates.
<div id='section'>Paperid: <span id='pid'>243, <a href='https://arxiv.org/pdf/2507.08920.pdf' target='_blank'>https://arxiv.org/pdf/2507.08920.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Changze Lv, Jiang Zhou, Siyu Long, Lihao Wang, Jiangtao Feng, Dongyu Xue, Yu Pei, Hao Wang, Zherui Zhang, Yuchen Cai, Zhiqiang Gao, Ziyuan Ma, Jiakai Hu, Chaochen Gao, Jingjing Gong, Yuxuan Song, Shuyi Zhang, Xiaoqing Zheng, Deyi Xiong, Lei Bai, Wanli Ouyang, Ya-Qin Zhang, Wei-Ying Ma, Bowen Zhou, Hao Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08920">AMix-1: A Pathway to Test-Time Scalable Protein Foundation Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce AMix-1, a powerful protein foundation model built on Bayesian Flow Networks and empowered by a systematic training methodology, encompassing pretraining scaling laws, emergent capability analysis, in-context learning mechanism, and test-time scaling algorithm. To guarantee robust scalability, we establish a predictive scaling law and reveal the progressive emergence of structural understanding via loss perspective, culminating in a strong 1.7-billion model. Building on this foundation, we devise a multiple sequence alignment (MSA)-based in-context learning strategy to unify protein design into a general framework, where AMix-1 recognizes deep evolutionary signals among MSAs and consistently generates structurally and functionally coherent proteins. This framework enables the successful design of a dramatically improved AmeR variant with an up to $50\times$ activity increase over its wild type. Pushing the boundaries of protein engineering, we further empower AMix-1 with an evolutionary test-time scaling algorithm for in silico directed evolution that delivers substantial, scalable performance gains as verification budgets are intensified, laying the groundwork for next-generation lab-in-the-loop protein design.
<div id='section'>Paperid: <span id='pid'>244, <a href='https://arxiv.org/pdf/2401.06199.pdf' target='_blank'>https://arxiv.org/pdf/2401.06199.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Chen, Xingyi Cheng, Pan Li, Yangli-ao Geng, Jing Gong, Shen Li, Zhilei Bei, Xu Tan, Boyan Wang, Xin Zeng, Chiming Liu, Aohan Zeng, Yuxiao Dong, Jie Tang, Le Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.06199">xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering the Language of Protein</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models have shown remarkable success in learning biological information from protein sequences. However, most existing models are limited by either autoencoding or autoregressive pre-training objectives, which makes them struggle to handle protein understanding and generation tasks concurrently. We propose a unified protein language model, xTrimoPGLM, to address these two types of tasks simultaneously through an innovative pre-training framework. Our key technical contribution is an exploration of the compatibility and the potential for joint optimization of the two types of objectives, which has led to a strategy for training xTrimoPGLM at an unprecedented scale of 100 billion parameters and 1 trillion training tokens. Our extensive experiments reveal that 1) xTrimoPGLM significantly outperforms other advanced baselines in 18 protein understanding benchmarks across four categories. The model also facilitates an atomic-resolution view of protein structures, leading to an advanced 3D structural prediction model that surpasses existing language model-based tools. 2) xTrimoPGLM not only can generate de novo protein sequences following the principles of natural ones, but also can perform programmable generation after supervised fine-tuning (SFT) on curated sequences. These results highlight the substantial capability and versatility of xTrimoPGLM in understanding and generating protein sequences, contributing to the evolving landscape of foundation models in protein science.
<div id='section'>Paperid: <span id='pid'>245, <a href='https://arxiv.org/pdf/2503.03989.pdf' target='_blank'>https://arxiv.org/pdf/2503.03989.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangxin Zhou, Yi Xiao, Haowei Lin, Xinheng He, Jiaqi Guan, Yang Wang, Qiang Liu, Feng Zhou, Liang Wang, Jianzhu Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.03989">Integrating Protein Dynamics into Structure-Based Drug Design via Full-Atom Stochastic Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The dynamic nature of proteins, influenced by ligand interactions, is essential for comprehending protein function and progressing drug discovery. Traditional structure-based drug design (SBDD) approaches typically target binding sites with rigid structures, limiting their practical application in drug development. While molecular dynamics simulation can theoretically capture all the biologically relevant conformations, the transition rate is dictated by the intrinsic energy barrier between them, making the sampling process computationally expensive. To overcome the aforementioned challenges, we propose to use generative modeling for SBDD considering conformational changes of protein pockets. We curate a dataset of apo and multiple holo states of protein-ligand complexes, simulated by molecular dynamics, and propose a full-atom flow model (and a stochastic version), named DynamicFlow, that learns to transform apo pockets and noisy ligands into holo pockets and corresponding 3D ligand molecules. Our method uncovers promising ligand molecules and corresponding holo conformations of pockets. Additionally, the resultant holo-like states provide superior inputs for traditional SBDD approaches, playing a significant role in practical drug discovery.
<div id='section'>Paperid: <span id='pid'>246, <a href='https://arxiv.org/pdf/2509.11782.pdf' target='_blank'>https://arxiv.org/pdf/2509.11782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bozhen Hu, Cheng Tan, Siyuan Li, Jiangbin Zheng, Sizhe Qiu, Jun Xia, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11782">Multimodal Regression for Enzyme Turnover Rates Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The enzyme turnover rate is a fundamental parameter in enzyme kinetics, reflecting the catalytic efficiency of enzymes. However, enzyme turnover rates remain scarce across most organisms due to the high cost and complexity of experimental measurements. To address this gap, we propose a multimodal framework for predicting the enzyme turnover rate by integrating enzyme sequences, substrate structures, and environmental factors. Our model combines a pre-trained language model and a convolutional neural network to extract features from protein sequences, while a graph neural network captures informative representations from substrate molecules. An attention mechanism is incorporated to enhance interactions between enzyme and substrate representations. Furthermore, we leverage symbolic regression via Kolmogorov-Arnold Networks to explicitly learn mathematical formulas that govern the enzyme turnover rate, enabling interpretable and accurate predictions. Extensive experiments demonstrate that our framework outperforms both traditional and state-of-the-art deep learning approaches. This work provides a robust tool for studying enzyme kinetics and holds promise for applications in enzyme engineering, biotechnology, and industrial biocatalysis.
<div id='section'>Paperid: <span id='pid'>247, <a href='https://arxiv.org/pdf/2506.08365.pdf' target='_blank'>https://arxiv.org/pdf/2506.08365.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng Tan, Zhenxiao Cao, Zhangyang Gao, Siyuan Li, Yufei Huang, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08365">AlphaFold Database Debiasing for Robust Inverse Folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The AlphaFold Protein Structure Database (AFDB) offers unparalleled structural coverage at near-experimental accuracy, positioning it as a valuable resource for data-driven protein design. However, its direct use in training deep models that are sensitive to fine-grained atomic geometry, such as inverse folding, exposes a critical limitation. Comparative analysis of structural feature distributions reveals that AFDB structures exhibit distinct statistical regularities, reflecting a systematic geometric bias that deviates from the conformational diversity found in experimentally determined structures from the Protein Data Bank (PDB). While AFDB structures are cleaner and more idealized, PDB structures capture the intrinsic variability and physical realism essential for generalization in downstream tasks. To address this discrepancy, we introduce a Debiasing Structure AutoEncoder (DeSAE) that learns to reconstruct native-like conformations from intentionally corrupted backbone geometries. By training the model to recover plausible structural states, DeSAE implicitly captures a more robust and natural structural manifold. At inference, applying DeSAE to AFDB structures produces debiased structures that significantly improve inverse folding performance across multiple benchmarks. This work highlights the critical impact of subtle systematic biases in predicted structures and presents a principled framework for debiasing, significantly boosting the performance of structure-based learning tasks like inverse folding.
<div id='section'>Paperid: <span id='pid'>248, <a href='https://arxiv.org/pdf/2501.06485.pdf' target='_blank'>https://arxiv.org/pdf/2501.06485.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>En Xu, Can Rong, Jingtao Ding, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06485">A Diffusive Data Augmentation Framework for Reconstruction of Complex Network Evolutionary History</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The evolutionary processes of complex systems contain critical information regarding their functional characteristics. The generation time of edges provides insights into the historical evolution of various networked complex systems, such as protein-protein interaction networks, ecosystems, and social networks. Recovering these evolutionary processes holds significant scientific value, including aiding in the interpretation of the evolution of protein-protein interaction networks. However, existing methods are capable of predicting the generation times of remaining edges given a partial temporal network but often perform poorly in cross-network prediction tasks. These methods frequently fail in edge generation time recovery tasks for static networks that lack timestamps. In this work, we adopt a comparative paradigm-based framework that fuses multiple networks for training, enabling cross-network learning of the relationship between network structure and edge generation times. Compared to separate training, this approach yields an average accuracy improvement of 16.98%. Furthermore, given the difficulty in collecting temporal networks, we propose a novel diffusion-model-based generation method to produce a large number of temporal networks. By combining real temporal networks with generated ones for training, we achieve an additional average accuracy improvement of 5.46% through joint training.
<div id='section'>Paperid: <span id='pid'>249, <a href='https://arxiv.org/pdf/2410.15010.pdf' target='_blank'>https://arxiv.org/pdf/2410.15010.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sizhe Liu, Jun Xia, Lecheng Zhang, Yuchen Liu, Yue Liu, Wenjie Du, Zhangyang Gao, Bozhen Hu, Cheng Tan, Hongxin Xiang, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15010">FlexMol: A Flexible Toolkit for Benchmarking Molecular Relational Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular relational learning (MRL) is crucial for understanding the interaction behaviors between molecular pairs, a critical aspect of drug discovery and development. However, the large feasible model space of MRL poses significant challenges to benchmarking, and existing MRL frameworks face limitations in flexibility and scope. To address these challenges, avoid repetitive coding efforts, and ensure fair comparison of models, we introduce FlexMol, a comprehensive toolkit designed to facilitate the construction and evaluation of diverse model architectures across various datasets and performance metrics. FlexMol offers a robust suite of preset model components, including 16 drug encoders, 13 protein sequence encoders, 9 protein structure encoders, and 7 interaction layers. With its easy-to-use API and flexibility, FlexMol supports the dynamic construction of over 70, 000 distinct combinations of model architectures. Additionally, we provide detailed benchmark results and code examples to demonstrate FlexMol's effectiveness in simplifying and standardizing MRL model development and comparison.
<div id='section'>Paperid: <span id='pid'>250, <a href='https://arxiv.org/pdf/2407.00050.pdf' target='_blank'>https://arxiv.org/pdf/2407.00050.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangyang Gao, Cheng Tan, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.00050">FoldToken2: Learning compact, invariant and generative protein structure language</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The equivalent nature of 3D coordinates has posed long term challenges in protein structure representation learning, alignment, and generation. Can we create a compact and invariant language that equivalently represents protein structures? Towards this goal, we propose FoldToken2 to transfer equivariant structures into discrete tokens, while maintaining the recoverability of the original structures. From FoldToken1 to FoldToken2, we improve three key components: (1) invariant structure encoder, (2) vector-quantized compressor, and (3) equivalent structure decoder. We evaluate FoldToken2 on the protein structure reconstruction task and show that it outperforms previous FoldToken1 by 20\% in TMScore and 81\% in RMSD. FoldToken2 probably be the first method that works well on both single-chain and multi-chain protein structures quantization. We believe that FoldToken2 will inspire further improvement in protein structure representation learning, structure alignment, and structure generation tasks.
<div id='section'>Paperid: <span id='pid'>251, <a href='https://arxiv.org/pdf/2405.18968.pdf' target='_blank'>https://arxiv.org/pdf/2405.18968.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangyang Gao, Jue Wang, Cheng Tan, Lirong Wu, Yufei Huang, Siyuan Li, Zhirui Ye, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18968">UniIF: Unified Molecule Inverse Folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecule inverse folding has been a long-standing challenge in chemistry and biology, with the potential to revolutionize drug discovery and material science. Despite specified models have been proposed for different small- or macro-molecules, few have attempted to unify the learning process, resulting in redundant efforts. Complementary to recent advancements in molecular structure prediction, such as RoseTTAFold All-Atom and AlphaFold3, we propose the unified model UniIF for the inverse folding of all molecules. We do such unification in two levels: 1) Data-Level: We propose a unified block graph data form for all molecules, including the local frame building and geometric feature initialization. 2) Model-Level: We introduce a geometric block attention network, comprising a geometric interaction, interactive attention and virtual long-term dependency modules, to capture the 3D interactions of all molecules. Through comprehensive evaluations across various tasks such as protein design, RNA design, and material design, we demonstrate that our proposed method surpasses state-of-the-art methods on all tasks. UniIF offers a versatile and effective solution for general molecule inverse folding.
<div id='section'>Paperid: <span id='pid'>252, <a href='https://arxiv.org/pdf/2403.09673.pdf' target='_blank'>https://arxiv.org/pdf/2403.09673.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangyang Gao, Cheng Tan, Jue Wang, Yufei Huang, Lirong Wu, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.09673">FoldToken: Learning Protein Language via Vector Quantization and Beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Is there a foreign language describing protein sequences and structures simultaneously? Protein structures, represented by continuous 3D points, have long posed a challenge due to the contrasting modeling paradigms of discrete sequences. We introduce \textbf{FoldTokenizer} to represent protein sequence-structure as discrete symbols. This innovative approach involves projecting residue types and structures into a discrete space, guided by a reconstruction loss for information preservation. We refer to the learned discrete symbols as \textbf{FoldToken}, and the sequence of FoldTokens serves as a new protein language, transforming the protein sequence-structure into a unified modality. We apply the created protein language on general backbone inpainting and antibody design tasks, building the first GPT-style model (\textbf{FoldGPT}) for sequence-structure co-generation with promising results. Key to our success is the substantial enhancement of the vector quantization module, Soft Conditional Vector Quantization (\textbf{SoftCVQ}).
<div id='section'>Paperid: <span id='pid'>253, <a href='https://arxiv.org/pdf/2402.09416.pdf' target='_blank'>https://arxiv.org/pdf/2402.09416.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bozhen Hu, Zelin Zang, Cheng Tan, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.09416">Deep Manifold Transformation for Protein Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein representation learning is critical in various tasks in biology, such as drug design and protein structure or function prediction, which has primarily benefited from protein language models and graph neural networks. These models can capture intrinsic patterns from protein sequences and structures through masking and task-related losses. However, the learned protein representations are usually not well optimized, leading to performance degradation due to limited data, difficulty adapting to new tasks, etc. To address this, we propose a new \underline{d}eep \underline{m}anifold \underline{t}ransformation approach for universal \underline{p}rotein \underline{r}epresentation \underline{l}earning (DMTPRL). It employs manifold learning strategies to improve the quality and adaptability of the learned embeddings. Specifically, we apply a novel manifold learning loss during training based on the graph inter-node similarity. Our proposed DMTPRL method outperforms state-of-the-art baselines on diverse downstream tasks across popular datasets. This validates our approach for learning universal and robust protein representations. We promise to release the code after acceptance.
<div id='section'>Paperid: <span id='pid'>254, <a href='https://arxiv.org/pdf/2402.08198.pdf' target='_blank'>https://arxiv.org/pdf/2402.08198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lirong Wu, Yufei Huang, Cheng Tan, Zhangyang Gao, Bozhen Hu, Haitao Lin, Zicheng Liu, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08198">PSC-CPI: Multi-Scale Protein Sequence-Structure Contrasting for Efficient and Generalizable Compound-Protein Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Compound-Protein Interaction (CPI) prediction aims to predict the pattern and strength of compound-protein interactions for rational drug discovery. Existing deep learning-based methods utilize only the single modality of protein sequences or structures and lack the co-modeling of the joint distribution of the two modalities, which may lead to significant performance drops in complex real-world scenarios due to various factors, e.g., modality missing and domain shifting. More importantly, these methods only model protein sequences and structures at a single fixed scale, neglecting more fine-grained multi-scale information, such as those embedded in key protein fragments. In this paper, we propose a novel multi-scale Protein Sequence-structure Contrasting framework for CPI prediction (PSC-CPI), which captures the dependencies between protein sequences and structures through both intra-modality and cross-modality contrasting. We further apply length-variable protein augmentation to allow contrasting to be performed at different scales, from the amino acid level to the sequence level. Finally, in order to more fairly evaluate the model generalizability, we split the test data into four settings based on whether compounds and proteins have been observed during the training stage. Extensive experiments have shown that PSC-CPI generalizes well in all four settings, particularly in the more challenging ``Unseen-Both" setting, where neither compounds nor proteins have been observed during training. Furthermore, even when encountering a situation of modality missing, i.e., inference with only single-modality protein data, PSC-CPI still exhibits comparable or even better performance than previous approaches.
<div id='section'>Paperid: <span id='pid'>255, <a href='https://arxiv.org/pdf/2312.04019.pdf' target='_blank'>https://arxiv.org/pdf/2312.04019.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijie Zhang, Zhangyang Gao, Cheng Tan, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.04019">Efficiently Predicting Protein Stability Changes Upon Single-point Mutation with Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting protein stability changes induced by single-point mutations has been a persistent challenge over the years, attracting immense interest from numerous researchers. The ability to precisely predict protein thermostability is pivotal for various subfields and applications in biochemistry, including drug development, protein evolution analysis, and enzyme synthesis. Despite the proposition of multiple methodologies aimed at addressing this issue, few approaches have successfully achieved optimal performance coupled with high computational efficiency. Two principal hurdles contribute to the existing challenges in this domain. The first is the complexity of extracting and aggregating sufficiently representative features from proteins. The second refers to the limited availability of experimental data for protein mutation analysis, further complicating the comprehensive evaluation of model performance on unseen data samples. With the advent of Large Language Models(LLM), such as the ESM models in protein research, profound interpretation of protein features is now accessibly aided by enormous training data. Therefore, LLMs are indeed to facilitate a wide range of protein research. In our study, we introduce an ESM-assisted efficient approach that integrates protein sequence and structural features to predict the thermostability changes in protein upon single-point mutations. Furthermore, we have curated a dataset meticulously designed to preclude data leakage, corresponding to two extensively employed test datasets, to facilitate a more equitable model comparison.
<div id='section'>Paperid: <span id='pid'>256, <a href='https://arxiv.org/pdf/2310.04985.pdf' target='_blank'>https://arxiv.org/pdf/2310.04985.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangyang Gao, Cheng Tan, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.04985">VQPL: Vector Quantized Protein Language</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Is there a foreign language describing protein sequences and structures simultaneously? Protein structures, represented by continuous 3D points, have long posed a challenge due to the contrasting modeling paradigms of discrete sequences. To represent protein sequence-structure as discrete symbols, we propose a VQProteinformer to project residue types and structures into a discrete space, supervised by a reconstruction loss to ensure information preservation. The sequential latent codes of residues introduce a new quantized protein language, transforming the protein sequence-structure into a unified modality. We demonstrate the potential of the created protein language on predictive and generative tasks, which may not only advance protein research but also establish a connection between the protein-related and NLP-related fields. The proposed method will be continually improved to unify more protein modalities, including text and point cloud.
<div id='section'>Paperid: <span id='pid'>257, <a href='https://arxiv.org/pdf/2305.15151.pdf' target='_blank'>https://arxiv.org/pdf/2305.15151.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangyang Gao, Cheng Tan, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.15151">Knowledge-Design: Pushing the Limit of Protein Design via Knowledge Refinement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent studies have shown competitive performance in protein design that aims to find the amino acid sequence folding into the desired structure. However, most of them disregard the importance of predictive confidence, fail to cover the vast protein space, and do not incorporate common protein knowledge. After witnessing the great success of pretrained models on diverse protein-related tasks and the fact that recovery is highly correlated with confidence, we wonder whether this knowledge can push the limits of protein design further. As a solution, we propose a knowledge-aware module that refines low-quality residues. We also introduce a memory-retrieval mechanism to save more than 50\% of the training time. We extensively evaluate our proposed method on the CATH, TS50, and TS500 datasets and our results show that our Knowledge-Design method outperforms the previous PiFold method by approximately 9\% on the CATH dataset. Specifically, Knowledge-Design is the first method that achieves 60+\% recovery on CATH, TS50 and TS500 benchmarks. We also provide additional analysis to demonstrate the effectiveness of our proposed method. The code will be publicly available.
<div id='section'>Paperid: <span id='pid'>258, <a href='https://arxiv.org/pdf/2305.09480.pdf' target='_blank'>https://arxiv.org/pdf/2305.09480.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng Tan, Zhangyang Gao, Lirong Wu, Jun Xia, Jiangbin Zheng, Xihong Yang, Yue Liu, Bozhen Hu, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09480">Cross-Gate MLP with Protein Complex Invariant Embedding is A One-Shot Antibody Designer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibodies are crucial proteins produced by the immune system in response to foreign substances or antigens. The specificity of an antibody is determined by its complementarity-determining regions (CDRs), which are located in the variable domains of the antibody chains and form the antigen-binding site. Previous studies have utilized complex techniques to generate CDRs, but they suffer from inadequate geometric modeling. Moreover, the common iterative refinement strategies lead to an inefficient inference. In this paper, we propose a \textit{simple yet effective} model that can co-design 1D sequences and 3D structures of CDRs in a one-shot manner. To achieve this, we decouple the antibody CDR design problem into two stages: (i) geometric modeling of protein complex structures and (ii) sequence-structure co-learning. We develop a novel macromolecular structure invariant embedding, typically for protein complexes, that captures both intra- and inter-component interactions among the backbone atoms, including C$Î±$, N, C, and O atoms, to achieve comprehensive geometric modeling. Then, we introduce a simple cross-gate MLP for sequence-structure co-learning, allowing sequence and structure representations to implicitly refine each other. This enables our model to design desired sequences and structures in a one-shot manner. Extensive experiments are conducted to evaluate our results at both the sequence and structure levels, which demonstrate that our model achieves superior performance compared to the state-of-the-art antibody CDR design methods.
<div id='section'>Paperid: <span id='pid'>259, <a href='https://arxiv.org/pdf/2301.09642.pdf' target='_blank'>https://arxiv.org/pdf/2301.09642.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangyang Gao, Cheng Tan, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.09642">DiffSDS: A language diffusion model for protein backbone inpainting under geometric conditions and constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Have you ever been troubled by the complexity and computational cost of SE(3) protein structure modeling and been amazed by the simplicity and power of language modeling? Recent work has shown promise in simplifying protein structures as sequences of protein angles; therefore, language models could be used for unconstrained protein backbone generation. Unfortunately, such simplification is unsuitable for the constrained protein inpainting problem, where the model needs to recover masked structures conditioned on unmasked ones, as it dramatically increases the computing cost of geometric constraints. To overcome this dilemma, we suggest inserting a hidden \textbf{a}tomic \textbf{d}irection \textbf{s}pace (\textbf{ADS}) upon the language model, converting invariant backbone angles into equivalent direction vectors and preserving the simplicity, called Seq2Direct encoder ($\text{Enc}_{s2d}$). Geometric constraints could be efficiently imposed on the newly introduced direction space. A Direct2Seq decoder ($\text{Dec}_{d2s}$) with mathematical guarantees is also introduced to develop a \textbf{SDS} ($\text{Enc}_{s2d}$+$\text{Dec}_{d2s}$) model. We apply the SDS model as the denoising neural network during the conditional diffusion process, resulting in a constrained generative model--\textbf{DiffSDS}. Extensive experiments show that the plug-and-play ADS could transform the language model into a strong structural model without loss of simplicity. More importantly, the proposed DiffSDS outperforms previous strong baselines by a large margin on the task of protein inpainting.
<div id='section'>Paperid: <span id='pid'>260, <a href='https://arxiv.org/pdf/2204.10673.pdf' target='_blank'>https://arxiv.org/pdf/2204.10673.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng Tan, Zhangyang Gao, Jun Xia, Bozhen Hu, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.10673">Generative De Novo Protein Design with Global Context</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The linear sequence of amino acids determines protein structure and function. Protein design, known as the inverse of protein structure prediction, aims to obtain a novel protein sequence that will fold into the defined structure. Recent works on computational protein design have studied designing sequences for the desired backbone structure with local positional information and achieved competitive performance. However, similar local environments in different backbone structures may result in different amino acids, indicating that protein structure's global context matters. Thus, we propose the Global-Context Aware generative de novo protein design method (GCA), consisting of local and global modules. While local modules focus on relationships between neighbor amino acids, global modules explicitly capture non-local contexts. Experimental results demonstrate that the proposed GCA method outperforms state-of-the-arts on de novo protein design. Our code and pretrained model will be released.
<div id='section'>Paperid: <span id='pid'>261, <a href='https://arxiv.org/pdf/2404.13506.pdf' target='_blank'>https://arxiv.org/pdf/2404.13506.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Charith Chandra Sai Balne, Sreyoshi Bhaduri, Tamoghna Roy, Vinija Jain, Aman Chadha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.13506">Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rise of deep learning has marked significant progress in fields such as computer vision, natural language processing, and medical imaging, primarily through the adaptation of pre-trained models for specific tasks. Traditional fine-tuning methods, involving adjustments to all parameters, face challenges due to high computational and memory demands. This has led to the development of Parameter Efficient Fine-Tuning (PEFT) techniques, which selectively update parameters to balance computational efficiency with performance. This review examines PEFT approaches, offering a detailed comparison of various strategies highlighting applications across different domains, including text generation, medical imaging, protein modeling, and speech synthesis. By assessing the effectiveness of PEFT methods in reducing computational load, speeding up training, and lowering memory usage, this paper contributes to making deep learning more accessible and adaptable, facilitating its wider application and encouraging innovation in model optimization. Ultimately, the paper aims to contribute towards insights into PEFT's evolving landscape, guiding researchers and practitioners in overcoming the limitations of conventional fine-tuning approaches.
<div id='section'>Paperid: <span id='pid'>262, <a href='https://arxiv.org/pdf/2410.09543.pdf' target='_blank'>https://arxiv.org/pdf/2410.09543.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoran Jiao, Weian Mao, Wengong Jin, Peiyuan Yang, Hao Chen, Chunhua Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.09543">Boltzmann-Aligned Inverse Folding Model as a Predictor of Mutational Effects on Protein-Protein Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the change in binding free energy ($ÎÎG$) is crucial for understanding and modulating protein-protein interactions, which are critical in drug design. Due to the scarcity of experimental $ÎÎG$ data, existing methods focus on pre-training, while neglecting the importance of alignment. In this work, we propose the Boltzmann Alignment technique to transfer knowledge from pre-trained inverse folding models to $ÎÎG$ prediction. We begin by analyzing the thermodynamic definition of $ÎÎG$ and introducing the Boltzmann distribution to connect energy with protein conformational distribution. However, the protein conformational distribution is intractable; therefore, we employ Bayes' theorem to circumvent direct estimation and instead utilize the log-likelihood provided by protein inverse folding models for $ÎÎG$ estimation. Compared to previous inverse folding-based methods, our method explicitly accounts for the unbound state of protein complex in the $ÎÎG$ thermodynamic cycle, introducing a physical inductive bias and achieving both supervised and unsupervised state-of-the-art (SoTA) performance. Experimental results on SKEMPI v2 indicate that our method achieves Spearman coefficients of 0.3201 (unsupervised) and 0.5134 (supervised), significantly surpassing the previously reported SoTA values of 0.2632 and 0.4324, respectively. Futhermore, we demonstrate the capability of our method on binding energy prediction, protein-protein docking and antibody optimization tasks.
<div id='section'>Paperid: <span id='pid'>263, <a href='https://arxiv.org/pdf/2310.11802.pdf' target='_blank'>https://arxiv.org/pdf/2310.11802.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weian Mao, Muzhi Zhu, Zheng Sun, Shuaike Shen, Lin Yuanbo Wu, Hao Chen, Chunhua Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11802">De novo protein design using geometric vector field networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Innovations like protein diffusion have enabled significant progress in de novo protein design, which is a vital topic in life science. These methods typically depend on protein structure encoders to model residue backbone frames, where atoms do not exist. Most prior encoders rely on atom-wise features, such as angles and distances between atoms, which are not available in this context. Thus far, only several simple encoders, such as IPA, have been proposed for this scenario, exposing the frame modeling as a bottleneck. In this work, we proffer the Vector Field Network (VFN), which enables network layers to perform learnable vector computations between coordinates of frame-anchored virtual atoms, thus achieving a higher capability for modeling frames. The vector computation operates in a manner similar to a linear layer, with each input channel receiving 3D virtual atom coordinates instead of scalar values. The multiple feature vectors output by the vector computation are then used to update the residue representations and virtual atom coordinates via attention aggregation. Remarkably, VFN also excels in modeling both frames and atoms, as the real atoms can be treated as the virtual atoms for modeling, positioning VFN as a potential universal encoder. In protein diffusion (frame modeling), VFN exhibits an impressive performance advantage over IPA, excelling in terms of both designability (67.04% vs. 53.58%) and diversity (66.54% vs. 51.98%). In inverse folding (frame and atom modeling), VFN outperforms the previous SoTA model, PiFold (54.7% vs. 51.66%), on sequence recovery rate. We also propose a method of equipping VFN with the ESM model, which significantly surpasses the previous ESM-based SoTA (62.67% vs. 55.65%), LM-Design, by a substantial margin.
<div id='section'>Paperid: <span id='pid'>264, <a href='https://arxiv.org/pdf/2404.01693.pdf' target='_blank'>https://arxiv.org/pdf/2404.01693.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rong Han, Wenbing Huang, Lingxiao Luo, Xinyan Han, Jiaming Shen, Zhiqiang Zhang, Jun Zhou, Ting Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.01693">HeMeNet: Heterogeneous Multichannel Equivariant Network for Protein Multitask Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding and leveraging the 3D structures of proteins is central to a variety of biological and drug discovery tasks. While deep learning has been applied successfully for structure-based protein function prediction tasks, current methods usually employ distinct training for each task. However, each of the tasks is of small size, and such a single-task strategy hinders the models' performance and generalization ability. As some labeled 3D protein datasets are biologically related, combining multi-source datasets for larger-scale multi-task learning is one way to overcome this problem. In this paper, we propose a neural network model to address multiple tasks jointly upon the input of 3D protein structures. In particular, we first construct a standard structure-based multi-task benchmark called Protein-MT, consisting of 6 biologically relevant tasks, including affinity prediction and property prediction, integrated from 4 public datasets. Then, we develop a novel graph neural network for multi-task learning, dubbed Heterogeneous Multichannel Equivariant Network (HeMeNet), which is E(3) equivariant and able to capture heterogeneous relationships between different atoms. Besides, HeMeNet can achieve task-specific learning via the task-aware readout mechanism. Extensive evaluations on our benchmark verify the effectiveness of multi-task learning, and our model generally surpasses state-of-the-art models.
<div id='section'>Paperid: <span id='pid'>265, <a href='https://arxiv.org/pdf/2303.16254.pdf' target='_blank'>https://arxiv.org/pdf/2303.16254.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinhang Liu, Yan Zeng, Yifan Qin, Hao Li, Jiakai Zhang, Lan Xu, Jingyi Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.16254">CryoFormer: Continuous Heterogeneous Cryo-EM Reconstruction using Transformer-based Neural Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryo-electron microscopy (cryo-EM) allows for the high-resolution reconstruction of 3D structures of proteins and other biomolecules. Successful reconstruction of both shape and movement greatly helps understand the fundamental processes of life. However, it is still challenging to reconstruct the continuous motions of 3D structures from hundreds of thousands of noisy and randomly oriented 2D cryo-EM images. Recent advancements use Fourier domain coordinate-based neural networks to continuously model 3D conformations, yet they often struggle to capture local flexible regions accurately. We propose CryoFormer, a new approach for continuous heterogeneous cryo-EM reconstruction. Our approach leverages an implicit feature volume directly in the real domain as the 3D representation. We further introduce a novel query-based deformation transformer decoder to improve the reconstruction quality. Our approach is capable of refining pre-computed pose estimations and locating flexible regions. In experiments, our method outperforms current approaches on three public datasets (1 synthetic and 2 experimental) and a new synthetic dataset of PEDV spike protein. The code and new synthetic dataset will be released for better reproducibility of our results. Project page: https://cryoformer.github.io.
<div id='section'>Paperid: <span id='pid'>266, <a href='https://arxiv.org/pdf/2502.07299.pdf' target='_blank'>https://arxiv.org/pdf/2502.07299.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zicheng Liu, Siyuan Li, Zhiyuan Chen, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Xiaoming Zhang, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07299">Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The interactions between DNA, RNA, and proteins are fundamental to biological processes, as illustrated by the central dogma of molecular biology. Although modern biological pre-trained models have achieved great success in analyzing these macromolecules individually, their interconnected nature remains underexplored. This paper follows the guidance of the central dogma to redesign both the data and model pipeline and offers a comprehensive framework, Life-Code, that spans different biological functions. As for data flow, we propose a unified pipeline to integrate multi-omics data by reverse-transcribing RNA and reverse-translating amino acids into nucleotide-based sequences. As for the model, we design a codon tokenizer and a hybrid long-sequence architecture to encode the interactions between coding and non-coding regions through masked modeling pre-training. To model the translation and folding process with coding sequences, Life-Code learns protein structures of the corresponding amino acids by knowledge distillation from off-the-shelf protein language models. Such designs enable Life-Code to capture complex interactions within genetic sequences, providing a more comprehensive understanding of multi-omics with the central dogma. Extensive experiments show that Life-Code achieves state-of-the-art results on various tasks across three omics, highlighting its potential for advancing multi-omics analysis and interpretation.
<div id='section'>Paperid: <span id='pid'>267, <a href='https://arxiv.org/pdf/2405.10348.pdf' target='_blank'>https://arxiv.org/pdf/2405.10348.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lirong Wu, Yijun Tian, Haitao Lin, Yufei Huang, Siyuan Li, Nitesh V Chawla, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.10348">Learning to Predict Mutation Effects of Protein-Protein Interactions by Microenvironment-aware Hierarchical Prompt Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein bindings play a key role in a variety of fundamental biological processes, and thus predicting the effects of amino acid mutations on protein-protein binding is crucial. To tackle the scarcity of annotated mutation data, pre-training with massive unlabeled data has emerged as a promising solution. However, this process faces a series of challenges: (1) complex higher-order dependencies among multiple (more than paired) structural scales have not yet been fully captured; (2) it is rarely explored how mutations alter the local conformation of the surrounding microenvironment; (3) pre-training is costly, both in data size and computational burden. In this paper, we first construct a hierarchical prompt codebook to record common microenvironmental patterns at different structural scales independently. Then, we develop a novel codebook pre-training task, namely masked microenvironment modeling, to model the joint distribution of each mutation with their residue types, angular statistics, and local conformational changes in the microenvironment. With the constructed prompt codebook, we encode the microenvironment around each mutation into multiple hierarchical prompts and combine them to flexibly provide information to wild-type and mutated protein complexes about their microenvironmental differences. Such a hierarchical prompt learning framework has demonstrated superior performance and training efficiency over state-of-the-art pre-training-based methods in mutation effect prediction and a case study of optimizing human antibodies against SARS-CoV-2.
<div id='section'>Paperid: <span id='pid'>268, <a href='https://arxiv.org/pdf/2402.16901.pdf' target='_blank'>https://arxiv.org/pdf/2402.16901.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>ChenRui Duan, Zelin Zang, Yongjie Xu, Hang He, Zihan Liu, Siyuan Li, Zijia Song, Ju-Sheng Zheng, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16901">FGBERT: Function-Driven Pre-trained Gene Language Model for Metagenomics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Metagenomic data, comprising mixed multi-species genomes, are prevalent in diverse environments like oceans and soils, significantly impacting human health and ecological functions. However, current research relies on K-mer, which limits the capture of structurally and functionally relevant gene contexts. Moreover, these approaches struggle with encoding biologically meaningful genes and fail to address the One-to-Many and Many-to-One relationships inherent in metagenomic data. To overcome these challenges, we introduce FGBERT, a novel metagenomic pre-trained model that employs a protein-based gene representation as a context-aware and structure-relevant tokenizer. FGBERT incorporates Masked Gene Modeling (MGM) to enhance the understanding of inter-gene contextual relationships and Triplet Enhanced Metagenomic Contrastive Learning (TMC) to elucidate gene sequence-function relationships. Pre-trained on over 100 million metagenomic sequences, FGBERT demonstrates superior performance on metagenomic datasets at four levels, spanning gene, functional, bacterial, and environmental levels and ranging from 1k to 213k input sequences. Case studies of ATP Synthase and Gene Operons highlight FGBERT's capability for functional recognition and its biological relevance in metagenomic research.
<div id='section'>Paperid: <span id='pid'>269, <a href='https://arxiv.org/pdf/2402.14391.pdf' target='_blank'>https://arxiv.org/pdf/2402.14391.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lirong Wu, Yijun Tian, Yufei Huang, Siyuan Li, Haitao Lin, Nitesh V Chawla, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14391">MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-Protein Interactions (PPIs) are fundamental in various biological processes and play a key role in life activities. The growing demand and cost of experimental PPI assays require computational methods for efficient PPI prediction. While existing methods rely heavily on protein sequence for PPI prediction, it is the protein structure that is the key to determine the interactions. To take both protein modalities into account, we define the microenvironment of an amino acid residue by its sequence and structural contexts, which describe the surrounding chemical properties and geometric features. In addition, microenvironments defined in previous work are largely based on experimentally assayed physicochemical properties, for which the "vocabulary" is usually extremely small. This makes it difficult to cover the diversity and complexity of microenvironments. In this paper, we propose Microenvironment-Aware Protein Embedding for PPI prediction (MPAE-PPI), which encodes microenvironments into chemically meaningful discrete codes via a sufficiently large microenvironment "vocabulary" (i.e., codebook). Moreover, we propose a novel pre-training strategy, namely Masked Codebook Modeling (MCM), to capture the dependencies between different microenvironments by randomly masking the codebook and reconstructing the input. With the learned microenvironment codebook, we can reuse it as an off-the-shelf tool to efficiently and effectively encode proteins of different sizes and functions for large-scale PPI prediction. Extensive experiments show that MAPE-PPI can scale to PPI prediction with millions of PPIs with superior trade-offs between effectiveness and computational efficiency than the state-of-the-art competitors.
<div id='section'>Paperid: <span id='pid'>270, <a href='https://arxiv.org/pdf/2306.13769.pdf' target='_blank'>https://arxiv.org/pdf/2306.13769.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haitao Lin, Yufei Huang, Odin Zhang, Lirong Wu, Siyuan Li, Zhiyuan Chen, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13769">Functional-Group-Based Diffusion for Pocket-Specific Molecule Generation and Elaboration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, AI-assisted drug design methods have been proposed to generate molecules given the pockets' structures of target proteins. Most of them are atom-level-based methods, which consider atoms as basic components and generate atom positions and types. In this way, however, it is hard to generate realistic fragments with complicated structures. To solve this, we propose D3FG, a functional-group-based diffusion model for pocket-specific molecule generation and elaboration. D3FG decomposes molecules into two categories of components: functional groups defined as rigid bodies and linkers as mass points. And the two kinds of components can together form complicated fragments that enhance ligand-protein interactions.
  To be specific, in the diffusion process, D3FG diffuses the data distribution of the positions, orientations, and types of the components into a prior distribution; In the generative process, the noise is gradually removed from the three variables by denoisers parameterized with designed equivariant graph neural networks. In the experiments, our method can generate molecules with more realistic 3D structures, competitive affinities toward the protein targets, and better drug properties. Besides, D3FG as a solution to a new task of molecule elaboration, could generate molecules with high affinities based on existing ligands and the hotspots of target proteins.
<div id='section'>Paperid: <span id='pid'>271, <a href='https://arxiv.org/pdf/2210.11879.pdf' target='_blank'>https://arxiv.org/pdf/2210.11879.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Ju, Yiyang Gu, Binqi Chen, Gongbo Sun, Yifang Qin, Xingyuming Liu, Xiao Luo, Ming Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.11879">GLCC: A General Framework for Graph-Level Clustering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper studies the problem of graph-level clustering, which is a novel yet challenging task. This problem is critical in a variety of real-world applications such as protein clustering and genome analysis in bioinformatics. Recent years have witnessed the success of deep clustering coupled with graph neural networks (GNNs). However, existing methods focus on clustering among nodes given a single graph, while exploring clustering on multiple graphs is still under-explored. In this paper, we propose a general graph-level clustering framework named Graph-Level Contrastive Clustering (GLCC) given multiple graphs. Specifically, GLCC first constructs an adaptive affinity graph to explore instance- and cluster-level contrastive learning (CL). Instance-level CL leverages graph Laplacian based contrastive loss to learn clustering-friendly representations while cluster-level CL captures discriminative cluster representations incorporating neighbor information of each sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the optimization of representation learning. The two steps can be alternatively trained to collaborate and benefit each other. Experiments on a range of well-known datasets demonstrate the superiority of our proposed GLCC over competitive baselines.
<div id='section'>Paperid: <span id='pid'>272, <a href='https://arxiv.org/pdf/2506.00925.pdf' target='_blank'>https://arxiv.org/pdf/2506.00925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengdi Liu, Xiaoxue Cheng, Zhangyang Gao, Hong Chang, Cheng Tan, Shiguang Shan, Xilin Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00925">ProtInvTree: Deliberate Protein Inverse Folding with Reward-guided Tree Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing protein sequences that fold into a target 3D structure, known as protein inverse folding, is a fundamental challenge in protein engineering. While recent deep learning methods have achieved impressive performance by recovering native sequences, they often overlook the one-to-many nature of the problem: multiple diverse sequences can fold into the same structure. This motivates the need for a generative model capable of designing diverse sequences while preserving structural consistency. To address this trade-off, we introduce ProtInvTree, the first reward-guided tree-search framework for protein inverse folding. ProtInvTree reformulates sequence generation as a deliberate, step-wise decision-making process, enabling the exploration of multiple design paths and exploitation of promising candidates through self-evaluation, lookahead, and backtracking. We propose a two-stage focus-and-grounding action mechanism that decouples position selection and residue generation. To efficiently evaluate intermediate states, we introduce a jumpy denoising strategy that avoids full rollouts. Built upon pretrained protein language models, ProtInvTree supports flexible test-time scaling by expanding the search depth and breadth without retraining. Empirically, ProtInvTree outperforms state-of-the-art baselines across multiple benchmarks, generating structurally consistent yet diverse sequences, including those far from the native ground truth.
<div id='section'>Paperid: <span id='pid'>273, <a href='https://arxiv.org/pdf/2402.11459.pdf' target='_blank'>https://arxiv.org/pdf/2402.11459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufei Huang, Odin Zhang, Lirong Wu, Cheng Tan, Haitao Lin, Zhangyang Gao, Siyuan Li, Stan. Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11459">Re-Dock: Towards Flexible and Realistic Molecular Docking with Diffusion Bridge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of protein-ligand binding structures, a task known as molecular docking is crucial for drug design but remains challenging. While deep learning has shown promise, existing methods often depend on holo-protein structures (docked, and not accessible in realistic tasks) or neglect pocket sidechain conformations, leading to limited practical utility and unrealistic conformation predictions. To fill these gaps, we introduce an under-explored task, named flexible docking to predict poses of ligand and pocket sidechains simultaneously and introduce Re-Dock, a novel diffusion bridge generative model extended to geometric manifolds. Specifically, we propose energy-to-geometry mapping inspired by the Newton-Euler equation to co-model the binding energy and conformations for reflecting the energy-constrained docking generative process. Comprehensive experiments on designed benchmark datasets including apo-dock and cross-dock demonstrate our model's superior effectiveness and efficiency over current methods.
<div id='section'>Paperid: <span id='pid'>274, <a href='https://arxiv.org/pdf/2202.02575.pdf' target='_blank'>https://arxiv.org/pdf/2202.02575.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tamara T. Mueller, Johannes C. Paetzold, Chinmay Prabhakar, Dmitrii Usynin, Daniel Rueckert, Georgios Kaissis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.02575">Differentially Private Graph Classification with GNNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) have established themselves as the state-of-the-art models for many machine learning applications such as the analysis of social networks, protein interactions and molecules. Several among these datasets contain privacy-sensitive data. Machine learning with differential privacy is a promising technique to allow deriving insight from sensitive data while offering formal guarantees of privacy protection. However, the differentially private training of GNNs has so far remained under-explored due to the challenges presented by the intrinsic structural connectivity of graphs. In this work, we introduce differential privacy for graph-level classification, one of the key applications of machine learning on graphs. Our method is applicable to deep learning on multi-graph datasets and relies on differentially private stochastic gradient descent (DP-SGD). We show results on a variety of synthetic and public datasets and evaluate the impact of different GNN architectures and training hyperparameters on model performance for differentially private graph classification. Finally, we apply explainability techniques to assess whether similar representations are learned in the private and non-private settings and establish robust baselines for future work in this area.
<div id='section'>Paperid: <span id='pid'>275, <a href='https://arxiv.org/pdf/2506.06294.pdf' target='_blank'>https://arxiv.org/pdf/2506.06294.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunqing Liu, Wenqi Fan, Xiaoyong Wei, Qing Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06294">GLProtein: Global-and-Local Structure Aware Protein Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are central to biological systems, participating as building blocks across all forms of life. Despite advancements in understanding protein functions through protein sequence analysis, there remains potential for further exploration in integrating protein structural information. We argue that the structural information of proteins is not only limited to their 3D information but also encompasses information from amino acid molecules (local information) to protein-protein structure similarity (global information). To address this, we propose \textbf{GLProtein}, the first framework in protein pre-training that incorporates both global structural similarity and local amino acid details to enhance prediction accuracy and functional insights. GLProtein innovatively combines protein-masked modelling with triplet structure similarity scoring, protein 3D distance encoding and substructure-based amino acid molecule encoding. Experimental results demonstrate that GLProtein outperforms previous methods in several bioinformatics tasks, including predicting protein-protein interaction, contact prediction, and so on.
<div id='section'>Paperid: <span id='pid'>276, <a href='https://arxiv.org/pdf/2501.10282.pdf' target='_blank'>https://arxiv.org/pdf/2501.10282.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenqi Fan, Yi Zhou, Shijie Wang, Yuyao Yan, Hui Liu, Qian Zhao, Le Song, Qing Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.10282">Computational Protein Science in the Era of Large Language Models (LLMs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Considering the significance of proteins, computational protein science has always been a critical scientific field, dedicated to revealing knowledge and developing applications within the protein sequence-structure-function paradigm. In the last few decades, Artificial Intelligence (AI) has made significant impacts in computational protein science, leading to notable successes in specific protein modeling tasks. However, those previous AI models still meet limitations, such as the difficulty in comprehending the semantics of protein sequences, and the inability to generalize across a wide range of protein modeling tasks. Recently, LLMs have emerged as a milestone in AI due to their unprecedented language processing & generalization capability. They can promote comprehensive progress in fields rather than solving individual tasks. As a result, researchers have actively introduced LLM techniques in computational protein science, developing protein Language Models (pLMs) that skillfully grasp the foundational knowledge of proteins and can be effectively generalized to solve a diversity of sequence-structure-function reasoning problems. While witnessing prosperous developments, it's necessary to present a systematic overview of computational protein science empowered by LLM techniques. First, we summarize existing pLMs into categories based on their mastered protein knowledge, i.e., underlying sequence patterns, explicit structural and functional information, and external scientific languages. Second, we introduce the utilization and adaptation of pLMs, highlighting their remarkable achievements in promoting protein structure prediction, protein function prediction, and protein design studies. Then, we describe the practical application of pLMs in antibody design, enzyme design, and drug discovery. Finally, we specifically discuss the promising future directions in this fast-growing field.
<div id='section'>Paperid: <span id='pid'>277, <a href='https://arxiv.org/pdf/2412.19198.pdf' target='_blank'>https://arxiv.org/pdf/2412.19198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashutosh Baheti, Debanjana Chakraborty, Faeze Brahman, Ronan Le Bras, Ximing Lu, Nouha Dziri, Yejin Choi, Mark Riedl, Maarten Sap
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.19198">Multi-Attribute Constraint Satisfaction via Language Model Rewriting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Obeying precise constraints on top of multiple external attributes is a common computational problem underlying seemingly different domains, from controlled text generation to protein engineering. Existing language model (LM) controllability methods for multi-attribute constraint satisfaction often rely on specialized architectures or gradient-based classifiers, limiting their flexibility to work with arbitrary black-box evaluators and pretrained models. Current general-purpose large language models, while capable, cannot achieve fine-grained multi-attribute control over external attributes. Thus, we create Multi-Attribute Constraint Satisfaction (MACS), a generalized method capable of finetuning language models on any sequential domain to satisfy user-specified constraints on multiple external real-value attributes. Our method trains LMs as editors by sampling diverse multi-attribute edit pairs from an initial set of paraphrased outputs. During inference, LM iteratively improves upon its previous solution to satisfy constraints for all attributes by leveraging our designed constraint satisfaction reward. We additionally experiment with reward-weighted behavior cloning to further improve the constraint satisfaction rate of LMs. To evaluate our approach, we present a new Fine-grained Constraint Satisfaction (FineCS) benchmark, featuring two challenging tasks: (1) Text Style Transfer, where the goal is to simultaneously modify the sentiment and complexity of reviews, and (2) Protein Design, focusing on modulating fluorescence and stability of Green Fluorescent Proteins (GFP). Our empirical results show that MACS achieves the highest threshold satisfaction in both FineCS tasks, outperforming strong domain-specific baselines. Our work opens new avenues for generalized and real-value multi-attribute control, with implications for diverse applications spanning NLP and bioinformatics.
<div id='section'>Paperid: <span id='pid'>278, <a href='https://arxiv.org/pdf/2406.16268.pdf' target='_blank'>https://arxiv.org/pdf/2406.16268.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lantian Xu, Rong-Hua Li, Dong Wen, Qiangqiang Dai, Guoren Wang, Lu Qin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16268">Efficient Antagonistic k-plex Enumeration in Signed Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A signed graph is a graph where each edge receives a sign, positive or negative. The signed graph model has been used in many real applications, such as protein complex discovery and social network analysis. Finding cohesive subgraphs in signed graphs is a fundamental problem. A k-plex is a common model for cohesive subgraphs in which every vertex is adjacent to all but at most k vertices within the subgraph. In this paper, we propose the model of size-constrained antagonistic k-plex in a signed graph. The proposed model guarantees that the resulting subgraph is a k-plex and can be divided into two sub-k-plexes, both of which have positive inner edges and negative outer edges. This paper aims to identify all maximal antagonistic k-plexes in a signed graph. Through rigorous analysis, we show that the problem is NP-Hardness. We propose a novel framework for maximal antagonistic k-plexes utilizing set enumeration. Efficiency is improved through pivot pruning and early termination based on the color bound. Preprocessing techniques based on degree and dichromatic graphs effectively narrow the search space before enumeration. Extensive experiments on real-world datasets demonstrate our algorithm's efficiency, effectiveness, and scalability.
<div id='section'>Paperid: <span id='pid'>279, <a href='https://arxiv.org/pdf/2505.19014.pdf' target='_blank'>https://arxiv.org/pdf/2505.19014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haitao Lin, Odin Zhang, Jia Xu, Yunfan Liu, Zheng Cheng, Lirong Wu, Yufei Huang, Zhifeng Gao, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19014">Tokenizing Electron Cloud in Protein-Ligand Interaction Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The affinity and specificity of protein-molecule binding directly impact functional outcomes, uncovering the mechanisms underlying biological regulation and signal transduction. Most deep-learning-based prediction approaches focus on structures of atoms or fragments. However, quantum chemical properties, such as electronic structures, are the key to unveiling interaction patterns but remain largely underexplored. To bridge this gap, we propose ECBind, a method for tokenizing electron cloud signals into quantized embeddings, enabling their integration into downstream tasks such as binding affinity prediction. By incorporating electron densities, ECBind helps uncover binding modes that cannot be fully represented by atom-level models. Specifically, to remove the redundancy inherent in electron cloud signals, a structure-aware transformer and hierarchical codebooks encode 3D binding sites enriched with electron structures into tokens. These tokenized codes are then used for specific tasks with labels. To extend its applicability to a wider range of scenarios, we utilize knowledge distillation to develop an electron-cloud-agnostic prediction model. Experimentally, ECBind demonstrates state-of-the-art performance across multiple tasks, achieving improvements of 6.42\% and 15.58\% in per-structure Pearson and Spearman correlation coefficients, respectively.
<div id='section'>Paperid: <span id='pid'>280, <a href='https://arxiv.org/pdf/2502.06913.pdf' target='_blank'>https://arxiv.org/pdf/2502.06913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lirong Wu, Yunfan Liu, Haitao Lin, Yufei Huang, Guojiang Zhao, Zhifeng Gao, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06913">A Simple yet Effective DDG Predictor is An Unsupervised Antibody Optimizer and Explainer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The proteins that exist today have been optimized over billions of years of natural evolution, during which nature creates random mutations and selects them. The discovery of functionally promising mutations is challenged by the limited evolutionary accessible regions, i.e., only a small region on the fitness landscape is beneficial. There have been numerous priors used to constrain protein evolution to regions of landscapes with high-fitness variants, among which the change in binding free energy (DDG) of protein complexes upon mutations is one of the most commonly used priors. However, the huge mutation space poses two challenges: (1) how to improve the efficiency of DDG prediction for fast mutation screening; and (2) how to explain mutation preferences and efficiently explore accessible evolutionary regions. To address these challenges, we propose a lightweight DDG predictor (Light-DDG), which adopts a structure-aware Transformer as the backbone and enhances it by knowledge distilled from existing powerful but computationally heavy DDG predictors. Additionally, we augmented, annotated, and released a large-scale dataset containing millions of mutation data for pre-training Light-DDG. We find that such a simple yet effective Light-DDG can serve as a good unsupervised antibody optimizer and explainer. For the target antibody, we propose a novel Mutation Explainer to learn mutation preferences, which accounts for the marginal benefit of each mutation per residue. To further explore accessible evolutionary regions, we conduct preference-guided antibody optimization and evaluate antibody candidates quickly using Light-DDG to identify desirable mutations.
<div id='section'>Paperid: <span id='pid'>281, <a href='https://arxiv.org/pdf/2405.06642.pdf' target='_blank'>https://arxiv.org/pdf/2405.06642.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haitao Lin, Odin Zhang, Huifeng Zhao, Dejun Jiang, Lirong Wu, Zicheng Liu, Yufei Huang, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06642">PPFlow: Target-aware Peptide Design with Torsional Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Therapeutic peptides have proven to have great pharmaceutical value and potential in recent decades. However, methods of AI-assisted peptide drug discovery are not fully explored. To fill the gap, we propose a target-aware peptide design method called \textsc{PPFlow}, based on conditional flow matching on torus manifolds, to model the internal geometries of torsion angles for the peptide structure design. Besides, we establish a protein-peptide binding dataset named PPBench2024 to fill the void of massive data for the task of structure-based peptide drug design and to allow the training of deep learning methods. Extensive experiments show that PPFlow reaches state-of-the-art performance in tasks of peptide drug generation and optimization in comparison with baseline models, and can be generalized to other tasks including docking and side-chain packing.
<div id='section'>Paperid: <span id='pid'>282, <a href='https://arxiv.org/pdf/2404.00254.pdf' target='_blank'>https://arxiv.org/pdf/2404.00254.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruijie Quan, Wenguan Wang, Fan Ma, Hehe Fan, Yi Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00254">Clustering for Protein Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein representation learning is a challenging task that aims to capture the structure and function of proteins from their amino acid sequences. Previous methods largely ignored the fact that not all amino acids are equally important for protein folding and activity. In this article, we propose a neural clustering framework that can automatically discover the critical components of a protein by considering both its primary and tertiary structure information. Our framework treats a protein as a graph, where each node represents an amino acid and each edge represents a spatial or sequential connection between amino acids. We then apply an iterative clustering strategy to group the nodes into clusters based on their 1D and 3D positions and assign scores to each cluster. We select the highest-scoring clusters and use their medoid nodes for the next iteration of clustering, until we obtain a hierarchical and informative representation of the protein. We evaluate on four protein-related tasks: protein fold classification, enzyme reaction classification, gene ontology term prediction, and enzyme commission number prediction. Experimental results demonstrate that our method achieves state-of-the-art performance.
<div id='section'>Paperid: <span id='pid'>283, <a href='https://arxiv.org/pdf/2403.00875.pdf' target='_blank'>https://arxiv.org/pdf/2403.00875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Sun, Lirong Wu, Haitao Lin, Yufei Huang, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.00875">Enhancing Protein Predictive Models via Proteins Data Augmentation: A Benchmark and New Directions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Augmentation is an effective alternative to utilize the small amount of labeled protein data. However, most of the existing work focuses on design-ing new architectures or pre-training tasks, and relatively little work has studied data augmentation for proteins. This paper extends data augmentation techniques previously used for images and texts to proteins and then benchmarks these techniques on a variety of protein-related tasks, providing the first comprehensive evaluation of protein augmentation. Furthermore, we propose two novel semantic-level protein augmentation methods, namely Integrated Gradients Substitution and Back Translation Substitution, which enable protein semantic-aware augmentation through saliency detection and biological knowledge. Finally, we integrate extended and proposed augmentations into an augmentation pool and propose a simple but effective framework, namely Automated Protein Augmentation (APA), which can adaptively select the most suitable augmentation combinations for different tasks. Extensive experiments have shown that APA enhances the performance of five protein related tasks by an average of 10.55% across three architectures compared to vanilla implementations without augmentation, highlighting its potential to make a great impact on the field.
<div id='section'>Paperid: <span id='pid'>284, <a href='https://arxiv.org/pdf/2310.00793.pdf' target='_blank'>https://arxiv.org/pdf/2310.00793.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haitao Mao, Juanhui Li, Harry Shomer, Bingheng Li, Wenqi Fan, Yao Ma, Tong Zhao, Neil Shah, Jiliang Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.00793">Revisiting Link Prediction: A Data Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Link prediction, a fundamental task on graphs, has proven indispensable in various applications, e.g., friend recommendation, protein analysis, and drug interaction prediction. However, since datasets span a multitude of domains, they could have distinct underlying mechanisms of link formation. Evidence in existing literature underscores the absence of a universally best algorithm suitable for all datasets. In this paper, we endeavor to explore principles of link prediction across diverse datasets from a data-centric perspective. We recognize three fundamental factors critical to link prediction: local structural proximity, global structural proximity, and feature proximity. We then unearth relationships among those factors where (i) global structural proximity only shows effectiveness when local structural proximity is deficient. (ii) The incompatibility can be found between feature and structural proximity. Such incompatibility leads to GNNs for Link Prediction (GNN4LP) consistently underperforming on edges where the feature proximity factor dominates. Inspired by these new insights from a data perspective, we offer practical instruction for GNN4LP model design and guidelines for selecting appropriate benchmark datasets for more comprehensive evaluations.
<div id='section'>Paperid: <span id='pid'>285, <a href='https://arxiv.org/pdf/2302.10888.pdf' target='_blank'>https://arxiv.org/pdf/2302.10888.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufei Huang, Lirong Wu, Haitao Lin, Jiangbin Zheng, Ge Wang, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10888">Data-Efficient Protein 3D Geometric Pretraining via Refinement of Diffused Protein Structure Decoy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning meaningful protein representation is important for a variety of biological downstream tasks such as structure-based drug design. Having witnessed the success of protein sequence pretraining, pretraining for structural data which is more informative has become a promising research topic. However, there are three major challenges facing protein structure pretraining: insufficient sample diversity, physically unrealistic modeling, and the lack of protein-specific pretext tasks. To try to address these challenges, we present the 3D Geometric Pretraining. In this paper, we propose a unified framework for protein pretraining and a 3D geometric-based, data-efficient, and protein-specific pretext task: RefineDiff (Refine the Diffused Protein Structure Decoy). After pretraining our geometric-aware model with this task on limited data(less than 1% of SOTA models), we obtained informative protein representations that can achieve comparable performance for various downstream tasks.
<div id='section'>Paperid: <span id='pid'>286, <a href='https://arxiv.org/pdf/2212.03447.pdf' target='_blank'>https://arxiv.org/pdf/2212.03447.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fang Wu, Lirong Wu, Dragomir Radev, Jinbo Xu, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.03447">Integration of Pre-trained Protein Language Models into Geometric Deep Learning Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geometric deep learning has recently achieved great success in non-Euclidean domains, and learning on 3D structures of large biomolecules is emerging as a distinct research area. However, its efficacy is largely constrained due to the limited quantity of structural data. Meanwhile, protein language models trained on substantial 1D sequences have shown burgeoning capabilities with scale in a broad range of applications. Several previous studies consider combining these different protein modalities to promote the representation power of geometric neural networks, but fail to present a comprehensive understanding of their benefits. In this work, we integrate the knowledge learned by well-trained protein language models into several state-of-the-art geometric networks and evaluate a variety of protein representation learning benchmarks, including protein-protein interface prediction, model quality assessment, protein-protein rigid-body docking, and binding affinity prediction. Our findings show an overall improvement of 20% over baselines. Strong evidence indicates that the incorporation of protein language models' knowledge enhances geometric networks' capacity by a significant margin and can be generalized to complex tasks.
<div id='section'>Paperid: <span id='pid'>287, <a href='https://arxiv.org/pdf/2211.11214.pdf' target='_blank'>https://arxiv.org/pdf/2211.11214.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haitao Lin, Yufei Huang, Odin Zhang, Siqi Ma, Meng Liu, Xuanjing Li, Lirong Wu, Jishui Wang, Tingjun Hou, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.11214">DiffBP: Generative Diffusion of 3D Molecules for Target Protein Binding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generating molecules that bind to specific proteins is an important but challenging task in drug discovery. Previous works usually generate atoms in an auto-regressive way, where element types and 3D coordinates of atoms are generated one by one. However, in real-world molecular systems, the interactions among atoms in an entire molecule are global, leading to the energy function pair-coupled among atoms. With such energy-based consideration, the modeling of probability should be based on joint distributions, rather than sequentially conditional ones. Thus, the unnatural sequentially auto-regressive modeling of molecule generation is likely to violate the physical rules, thus resulting in poor properties of the generated molecules. In this work, a generative diffusion model for molecular 3D structures based on target proteins as contextual constraints is established, at a full-atom level in a non-autoregressive way. Given a designated 3D protein binding site, our model learns the generative process that denoises both element types and 3D coordinates of an entire molecule, with an equivariant network. Experimentally, the proposed method shows competitive performance compared with prevailing works in terms of high affinity with proteins and appropriate molecule sizes as well as other drug properties such as drug-likeness of the generated molecules.
<div id='section'>Paperid: <span id='pid'>288, <a href='https://arxiv.org/pdf/2505.00364.pdf' target='_blank'>https://arxiv.org/pdf/2505.00364.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jie Yang, Yuwen Wang, Kaixuan Chen, Tongya Zheng, Yihe Zhou, Zhenbang Xiao, Ji Cao, Mingli Song, Shunyu Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.00364">From GNNs to Trees: Multi-Granular Interpretability for Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Interpretable Graph Neural Networks (GNNs) aim to reveal the underlying reasoning behind model predictions, attributing their decisions to specific subgraphs that are informative. However, existing subgraph-based interpretable methods suffer from an overemphasis on local structure, potentially overlooking long-range dependencies within the entire graphs. Although recent efforts that rely on graph coarsening have proven beneficial for global interpretability, they inevitably reduce the graphs to a fixed granularity. Such an inflexible way can only capture graph connectivity at a specific level, whereas real-world graph tasks often exhibit relationships at varying granularities (e.g., relevant interactions in proteins span from functional groups, to amino acids, and up to protein domains). In this paper, we introduce a novel Tree-like Interpretable Framework (TIF) for graph classification, where plain GNNs are transformed into hierarchical trees, with each level featuring coarsened graphs of different granularity as tree nodes. Specifically, TIF iteratively adopts a graph coarsening module to compress original graphs (i.e., root nodes of trees) into increasingly coarser ones (i.e., child nodes of trees), while preserving diversity among tree nodes within different branches through a dedicated graph perturbation module. Finally, we propose an adaptive routing module to identify the most informative root-to-leaf paths, providing not only the final prediction but also the multi-granular interpretability for the decision-making process. Extensive experiments on the graph classification benchmarks with both synthetic and real-world datasets demonstrate the superiority of TIF in interpretability, while also delivering a competitive prediction performance akin to the state-of-the-art counterparts.
<div id='section'>Paperid: <span id='pid'>289, <a href='https://arxiv.org/pdf/2503.13522.pdf' target='_blank'>https://arxiv.org/pdf/2503.13522.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yichao Zhang, Ningyuan Deng, Xinyuan Song, Ziqian Bi, Tianyang Wang, Zheyu Yao, Keyu Chen, Ming Li, Qian Niu, Junyu Liu, Benji Peng, Sen Zhang, Ming Liu, Li Zhang, Xuanhe Pan, Jinlang Wang, Pohsun Feng, Yizhu Wen, Lawrence KQ Yan, Hongming Tseng, Yan Zhong, Yunze Wang, Ziyuan Qin, Bowen Jing, Junjie Yang, Jun Zhou, Chia Xin Liang, Junhao Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13522">Advanced Deep Learning Methods for Protein Structure Prediction and Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>After AlphaFold won the Nobel Prize, protein prediction with deep learning once again became a hot topic. We comprehensively explore advanced deep learning methods applied to protein structure prediction and design. It begins by examining recent innovations in prediction architectures, with detailed discussions on improvements such as diffusion based frameworks and novel pairwise attention modules. The text analyses key components including structure generation, evaluation metrics, multiple sequence alignment processing, and network architecture, thereby illustrating the current state of the art in computational protein modelling. Subsequent chapters focus on practical applications, presenting case studies that range from individual protein predictions to complex biomolecular interactions. Strategies for enhancing prediction accuracy and integrating deep learning techniques with experimental validation are thoroughly explored. The later sections review the industry landscape of protein design, highlighting the transformative role of artificial intelligence in biotechnology and discussing emerging market trends and future challenges. Supplementary appendices provide essential resources such as databases and open source tools, making this volume a valuable reference for researchers and students.
<div id='section'>Paperid: <span id='pid'>290, <a href='https://arxiv.org/pdf/2502.03478.pdf' target='_blank'>https://arxiv.org/pdf/2502.03478.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianyang Wang, Silin Chen, Yunze Wang, Yichao Zhang, Xinyuan Song, Ziqian Bi, Ming Liu, Qian Niu, Junyu Liu, Pohsun Feng, Xintian Sun, Benji Peng, Charles Zhang, Keyu Chen, Ming Li, Cheng Fei, Lawrence KQ Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03478">From In Silico to In Vitro: A Comprehensive Guide to Validating Bioinformatics Findings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The integration of bioinformatics predictions and experimental validation plays a pivotal role in advancing biological research, from understanding molecular mechanisms to developing therapeutic strategies. Bioinformatics tools and methods offer powerful means for predicting gene functions, protein interactions, and regulatory networks, but these predictions must be validated through experimental approaches to ensure their biological relevance. This review explores the various methods and technologies used for experimental validation, including gene expression analysis, protein-protein interaction verification, and pathway validation. We also discuss the challenges involved in translating computational predictions to experimental settings and highlight the importance of collaboration between bioinformatics and experimental research. Finally, emerging technologies, such as CRISPR gene editing, next-generation sequencing, and artificial intelligence, are shaping the future of bioinformatics validation and driving more accurate and efficient biological discoveries.
<div id='section'>Paperid: <span id='pid'>291, <a href='https://arxiv.org/pdf/2412.20014.pdf' target='_blank'>https://arxiv.org/pdf/2412.20014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanjing Zhou, Mingze Yin, Wei Wu, Mingyang Li, Kun Fu, Jintai Chen, Jian Wu, Zheng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20014">ProtCLIP: Function-Informed Protein Multi-Modal Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-modality pre-training paradigm that aligns protein sequences and biological descriptions has learned general protein representations and achieved promising performance in various downstream applications. However, these works were still unable to replicate the extraordinary success of language-supervised visual foundation models due to the ineffective usage of aligned protein-text paired data and the lack of an effective function-informed pre-training paradigm. To address these issues, this paper curates a large-scale protein-text paired dataset called ProtAnno with a property-driven sampling strategy, and introduces a novel function-informed protein pre-training paradigm. Specifically, the sampling strategy determines selecting probability based on the sample confidence and property coverage, balancing the data quality and data quantity in face of large-scale noisy data. Furthermore, motivated by significance of the protein specific functional mechanism, the proposed paradigm explicitly model protein static and dynamic functional segments by two segment-wise pre-training objectives, injecting fine-grained information in a function-informed manner. Leveraging all these innovations, we develop ProtCLIP, a multi-modality foundation model that comprehensively represents function-aware protein embeddings. On 22 different protein benchmarks within 5 types, including protein functionality classification, mutation effect prediction, cross-modal transformation, semantic similarity inference and protein-protein interaction prediction, our ProtCLIP consistently achieves SOTA performance, with remarkable improvements of 75% on average in five cross-modal transformation benchmarks, 59.9% in GO-CC and 39.7% in GO-BP protein function prediction. The experimental results verify the extraordinary potential of ProtCLIP serving as the protein multi-modality foundation model.
<div id='section'>Paperid: <span id='pid'>292, <a href='https://arxiv.org/pdf/2407.19296.pdf' target='_blank'>https://arxiv.org/pdf/2407.19296.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingze Yin, Hanjing Zhou, Yiheng Zhu, Miao Lin, Yixuan Wu, Jialu Wu, Hongxia Xu, Chang-Yu Hsieh, Tingjun Hou, Jintai Chen, Jian Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.19296">Multi-Modal CLIP-Informed Protein Editing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins govern most biological functions essential for life, but achieving controllable protein discovery and optimization remains challenging. Recently, machine learning-assisted protein editing (MLPE) has shown promise in accelerating optimization cycles and reducing experimental workloads. However, current methods struggle with the vast combinatorial space of potential protein edits and cannot explicitly conduct protein editing using biotext instructions, limiting their interactivity with human feedback. To fill these gaps, we propose a novel method called ProtET for efficient CLIP-informed protein editing through multi-modality learning. Our approach comprises two stages: in the pretraining stage, contrastive learning aligns protein-biotext representations encoded by two large language models (LLMs), respectively. Subsequently, during the protein editing stage, the fused features from editing instruction texts and original protein sequences serve as the final editing condition for generating target protein sequences. Comprehensive experiments demonstrated the superiority of ProtET in editing proteins to enhance human-expected functionality across multiple attribute domains, including enzyme catalytic activity, protein stability and antibody specific binding ability. And ProtET improves the state-of-the-art results by a large margin, leading to significant stability improvements of 16.67% and 16.90%. This capability positions ProtET to advance real-world artificial protein editing, potentially addressing unmet academic, industrial, and clinical needs.
<div id='section'>Paperid: <span id='pid'>293, <a href='https://arxiv.org/pdf/2502.01383.pdf' target='_blank'>https://arxiv.org/pdf/2502.01383.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sergei Kholkin, Ivan Butakov, Evgeny Burnaev, Nikita Gushchin, Alexander Korotin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01383">InfoBridge: Mutual Information estimation via Bridge Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion bridge models have recently become a powerful tool in the field of generative modeling. In this work, we leverage their power to address another important problem in machine learning and information theory, the estimation of the mutual information (MI) between two random variables. We show that by using the theory of diffusion bridges, one can construct an unbiased estimator for data posing difficulties for conventional MI estimators. We showcase the performance of our estimator on two standard MI estimation benchmarks, i.e., low-dimensional and image-based, and on real-world data, i.e., protein language model embeddings.
<div id='section'>Paperid: <span id='pid'>294, <a href='https://arxiv.org/pdf/2311.18173.pdf' target='_blank'>https://arxiv.org/pdf/2311.18173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhao Zhang, Xiwen Chen, William Richardson, Bruce Z. Gao, Abolfazl Razi, Tong Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18173">Quantification of cardiac capillarization in single-immunostained myocardial slices using weakly supervised instance segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Decreased myocardial capillary density has been reported as an important histopathological feature associated with various heart disorders. Quantitative assessment of cardiac capillarization typically involves double immunostaining of cardiomyocytes (CMs) and capillaries in myocardial slices. In contrast, single immunostaining of basement membrane components is a straightforward approach to simultaneously label CMs and capillaries, presenting fewer challenges in background staining. However, subsequent image analysis always requires manual work in identifying and segmenting CMs and capillaries. Here, we developed an image analysis tool, AutoQC, to automatically identify and segment CMs and capillaries in immunofluorescence images of collagen type IV, a predominant basement membrane protein within the myocardium. In addition, commonly used capillarization-related measurements can be derived from segmentation masks. AutoQC features a weakly supervised instance segmentation algorithm by leveraging the power of a pre-trained segmentation model via prompt engineering. AutoQC outperformed YOLOv8-Seg, a state-of-the-art instance segmentation model, in both instance segmentation and capillarization assessment. Furthermore, the training of AutoQC required only a small dataset with bounding box annotations instead of pixel-wise annotations, leading to a reduced workload during network training. AutoQC provides an automated solution for quantifying cardiac capillarization in basement-membrane-immunostained myocardial slices, eliminating the need for manual image analysis once it is trained.
<div id='section'>Paperid: <span id='pid'>295, <a href='https://arxiv.org/pdf/2410.11224.pdf' target='_blank'>https://arxiv.org/pdf/2410.11224.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxian Yan, Zaixi Zhang, Jintao Zhu, Kai Zhang, Jianfeng Pei, Qi Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.11224">DeltaDock: A Unified Framework for Accurate, Efficient, and Physically Reliable Molecular Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking, a technique for predicting ligand binding poses, is crucial in structure-based drug design for understanding protein-ligand interactions. Recent advancements in docking methods, particularly those leveraging geometric deep learning (GDL), have demonstrated significant efficiency and accuracy advantages over traditional sampling methods. Despite these advancements, current methods are often tailored for specific docking settings, and limitations such as the neglect of protein side-chain structures, difficulties in handling large binding pockets, and challenges in predicting physically valid structures exist. To accommodate various docking settings and achieve accurate, efficient, and physically reliable docking, we propose a novel two-stage docking framework, DeltaDock, consisting of pocket prediction and site-specific docking. We innovatively reframe the pocket prediction task as a pocket-ligand alignment problem rather than direct prediction in the first stage. Then we follow a bi-level coarse-to-fine iterative refinement process to perform site-specific docking. Comprehensive experiments demonstrate the superior performance of DeltaDock. Notably, in the blind docking setting, DeltaDock achieves a 31\% relative improvement over the docking success rate compared with the previous state-of-the-art GDL model. With the consideration of physical validity, this improvement increases to about 300\%.
<div id='section'>Paperid: <span id='pid'>296, <a href='https://arxiv.org/pdf/2406.11906.pdf' target='_blank'>https://arxiv.org/pdf/2406.11906.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingbo Zhou, Shaorong Chen, Jun Xia, Sizhe Liu, Tianze Ling, Wenjie Du, Yue Liu, Jianwei Yin, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11906">NovoBench: Benchmarking Deep Learning-based De Novo Peptide Sequencing Methods in Proteomics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tandem mass spectrometry has played a pivotal role in advancing proteomics, enabling the high-throughput analysis of protein composition in biological tissues. Many deep learning methods have been developed for \emph{de novo} peptide sequencing task, i.e., predicting the peptide sequence for the observed mass spectrum. However, two key challenges seriously hinder the further advancement of this important task. Firstly, since there is no consensus for the evaluation datasets, the empirical results in different research papers are often not comparable, leading to unfair comparison. Secondly, the current methods are usually limited to amino acid-level or peptide-level precision and recall metrics. In this work, we present the first unified benchmark NovoBench for \emph{de novo} peptide sequencing, which comprises diverse mass spectrum data, integrated models, and comprehensive evaluation metrics. Recent impressive methods, including DeepNovo, PointNovo, Casanovo, InstaNovo, AdaNovo and $Ï$-HelixNovo are integrated into our framework. In addition to amino acid-level and peptide-level precision and recall, we evaluate the models' performance in terms of identifying post-tranlational modifications (PTMs), efficiency and robustness to peptide length, noise peaks and missing fragment ratio, which are important influencing factors while seldom be considered. Leveraging this benchmark, we conduct a large-scale study of current methods, report many insightful findings that open up new possibilities for future development.
<div id='section'>Paperid: <span id='pid'>297, <a href='https://arxiv.org/pdf/2403.07013.pdf' target='_blank'>https://arxiv.org/pdf/2403.07013.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Xia, Shaorong Chen, Jingbo Zhou, Tianze Ling, Wenjie Du, Sizhe Liu, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.07013">AdaNovo: Adaptive \emph{De Novo} Peptide Sequencing with Conditional Mutual Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tandem mass spectrometry has played a pivotal role in advancing proteomics, enabling the analysis of protein composition in biological samples. Despite the development of various deep learning methods for identifying amino acid sequences (peptides) responsible for observed spectra, challenges persist in \emph{de novo} peptide sequencing. Firstly, prior methods struggle to identify amino acids with post-translational modifications (PTMs) due to their lower frequency in training data compared to canonical amino acids, further resulting in decreased peptide-level identification precision. Secondly, diverse types of noise and missing peaks in mass spectra reduce the reliability of training data (peptide-spectrum matches, PSMs). To address these challenges, we propose AdaNovo, a novel framework that calculates conditional mutual information (CMI) between the spectrum and each amino acid/peptide, using CMI for adaptive model training. Extensive experiments demonstrate AdaNovo's state-of-the-art performance on a 9-species benchmark, where the peptides in the training set are almost completely disjoint from the peptides of the test sets. Moreover, AdaNovo excels in identifying amino acids with PTMs and exhibits robustness against data noise. The supplementary materials contain the official code.
<div id='section'>Paperid: <span id='pid'>298, <a href='https://arxiv.org/pdf/2401.02713.pdf' target='_blank'>https://arxiv.org/pdf/2401.02713.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ge Wang, Zelin Zang, Jiangbin Zheng, Jun Xia, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02713">Graph-level Protein Representation Learning by Structure Knowledge Refinement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper focuses on learning representation on the whole graph level in an unsupervised manner. Learning graph-level representation plays an important role in a variety of real-world issues such as molecule property prediction, protein structure feature extraction, and social network analysis. The mainstream method is utilizing contrastive learning to facilitate graph feature extraction, known as Graph Contrastive Learning (GCL). GCL, although effective, suffers from some complications in contrastive learning, such as the effect of false negative pairs. Moreover, augmentation strategies in GCL are weakly adaptive to diverse graph datasets. Motivated by these problems, we propose a novel framework called Structure Knowledge Refinement (SKR) which uses data structure to determine the probability of whether a pair is positive or negative. Meanwhile, we propose an augmentation strategy that naturally preserves the semantic meaning of the original data and is compatible with our SKR framework. Furthermore, we illustrate the effectiveness of our SKR framework through intuition and experiments. The experimental results on the tasks of graph-level classification demonstrate that our SKR framework is superior to most state-of-the-art baselines.
<div id='section'>Paperid: <span id='pid'>299, <a href='https://arxiv.org/pdf/2311.18574.pdf' target='_blank'>https://arxiv.org/pdf/2311.18574.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxian Yan, Zaixi Zhang, Kai Zhang, Qi Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18574">Multi-scale Iterative Refinement towards Robust and Versatile Molecular Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking is a key computational tool utilized to predict the binding conformations of small molecules to protein targets, which is fundamental in the design of novel drugs. Despite recent advancements in geometric deep learning-based approaches leading to improvements in blind docking efficiency, these methods have encountered notable challenges, such as limited generalization performance on unseen proteins, the inability to concurrently address the settings of blind docking and site-specific docking, and the frequent occurrence of physical implausibilities such as inter-molecular steric clash. In this study, we introduce DeltaDock, a robust and versatile framework designed for efficient molecular docking to overcome these challenges. DeltaDock operates in a two-step process: rapid initial complex structures sampling followed by multi-scale iterative refinement of the initial structures. In the initial stage, to sample accurate structures with high efficiency, we develop a ligand-dependent binding site prediction model founded on large protein models and graph neural networks. This model is then paired with GPU-accelerated sampling algorithms. The sampled structures are updated using a multi-scale iterative refinement module that captures both protein-ligand atom-atom interactions and residue-atom interactions in the following stage. Distinct from previous geometric deep learning methods that are conditioned on the blind docking setting, DeltaDock demonstrates superior performance in both blind docking and site-specific docking settings. Comprehensive experimental results reveal that DeltaDock consistently surpasses baseline methods in terms of docking accuracy. Furthermore, it displays remarkable generalization capabilities and proficiency for predicting physically valid structures, thereby attesting to its robustness and reliability in various scenarios.
<div id='section'>Paperid: <span id='pid'>300, <a href='https://arxiv.org/pdf/2311.17104.pdf' target='_blank'>https://arxiv.org/pdf/2311.17104.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dayu Hu, Ke Liang, Hao Yu, Xinwang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.17104">Single-Cell Deep Clustering Method Assisted by Exogenous Gene Information: A Novel Approach to Identifying Cell Types</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, the field of single-cell data analysis has seen a marked advancement in the development of clustering methods. Despite advancements, most of these algorithms still concentrate on analyzing the provided single-cell matrix data. However, in medical applications, single-cell data often involves a wealth of exogenous information, including gene networks. Overlooking this aspect could lead to information loss and clustering results devoid of significant clinical relevance. An innovative single-cell deep clustering method, incorporating exogenous gene information, has been proposed to overcome this limitation. This model leverages exogenous gene network information to facilitate the clustering process, generating discriminative representations. Specifically, we have developed an attention-enhanced graph autoencoder, which is designed to efficiently capture the topological features between cells. Concurrently, we conducted a random walk on an exogenous Protein-Protein Interaction (PPI) network, thereby acquiring the gene's topological features. Ultimately, during the clustering process, we integrated both sets of information and reconstructed the features of both cells and genes to generate a discriminative representation. Extensive experiments have validated the effectiveness of our proposed method. This research offers enhanced insights into the characteristics and distribution of cells, thereby laying the groundwork for early diagnosis and treatment of diseases.
<div id='section'>Paperid: <span id='pid'>301, <a href='https://arxiv.org/pdf/2307.00067.pdf' target='_blank'>https://arxiv.org/pdf/2307.00067.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Subhash Nerella, Sabyasachi Bandyopadhyay, Jiaqing Zhang, Miguel Contreras, Scott Siegel, Aysegul Bumin, Brandon Silva, Jessica Sena, Benjamin Shickel, Azra Bihorac, Kia Khezeli, Parisa Rashidi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.00067">Transformers in Healthcare: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With Artificial Intelligence (AI) increasingly permeating various aspects of society, including healthcare, the adoption of the Transformers neural network architecture is rapidly changing many applications. Transformer is a type of deep learning architecture initially developed to solve general-purpose Natural Language Processing (NLP) tasks and has subsequently been adapted in many fields, including healthcare. In this survey paper, we provide an overview of how this architecture has been adopted to analyze various forms of data, including medical imaging, structured and unstructured Electronic Health Records (EHR), social media, physiological signals, and biomolecular sequences. Those models could help in clinical diagnosis, report generation, data reconstruction, and drug/protein synthesis. We identified relevant studies using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. We also discuss the benefits and limitations of using transformers in healthcare and examine issues such as computational cost, model interpretability, fairness, alignment with human values, ethical implications, and environmental impact.
<div id='section'>Paperid: <span id='pid'>302, <a href='https://arxiv.org/pdf/2509.05309.pdf' target='_blank'>https://arxiv.org/pdf/2509.05309.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangyu Liu, Haodi Lei, Yi Liu, Yang Liu, Wei Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05309">ProtSAE: Disentangling and Interpreting Protein Language Models via Semantically-Guided Sparse Autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sparse Autoencoder (SAE) has emerged as a powerful tool for mechanistic interpretability of large language models. Recent works apply SAE to protein language models (PLMs), aiming to extract and analyze biologically meaningful features from their latent spaces. However, SAE suffers from semantic entanglement, where individual neurons often mix multiple nonlinear concepts, making it difficult to reliably interpret or manipulate model behaviors. In this paper, we propose a semantically-guided SAE, called ProtSAE. Unlike existing SAE which requires annotation datasets to filter and interpret activations, we guide semantic disentanglement during training using both annotation datasets and domain knowledge to mitigate the effects of entangled attributes. We design interpretability experiments showing that ProtSAE learns more biologically relevant and interpretable hidden features compared to previous methods. Performance analyses further demonstrate that ProtSAE maintains high reconstruction fidelity while achieving better results in interpretable probing. We also show the potential of ProtSAE in steering PLMs for downstream generation tasks.
<div id='section'>Paperid: <span id='pid'>303, <a href='https://arxiv.org/pdf/2310.07100.pdf' target='_blank'>https://arxiv.org/pdf/2310.07100.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yixin Liu, Chenrui Fan, Xun Chen, Pan Zhou, Lichao Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.07100">GraphCloak: Safeguarding Task-specific Knowledge within Graph-structured Data from Unauthorized Exploitation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As Graph Neural Networks (GNNs) become increasingly prevalent in a variety of fields, from social network analysis to protein-protein interaction studies, growing concerns have emerged regarding the unauthorized utilization of personal data. Recent studies have shown that imperceptible poisoning attacks are an effective method of protecting image data from such misuse. However, the efficacy of this approach in the graph domain remains unexplored. To bridge this gap, this paper introduces GraphCloak to safeguard against the unauthorized usage of graph data. Compared with prior work, GraphCloak offers unique significant innovations: (1) graph-oriented, the perturbations are applied to both topological structures and descriptive features of the graph; (2) effective and stealthy, our cloaking method can bypass various inspections while causing a significant performance drop in GNNs trained on the cloaked graphs; and (3) stable across settings, our methods consistently perform effectively under a range of practical settings with limited knowledge. To address the intractable bi-level optimization problem, we propose two error-minimizing-based poisoning methods that target perturbations on the structural and feature space, along with a subgraph injection poisoning method. Our comprehensive evaluation of these methods underscores their effectiveness, stealthiness, and stability. We also delve into potential countermeasures and provide analytical justification for their effectiveness, paving the way for intriguing future research.
<div id='section'>Paperid: <span id='pid'>304, <a href='https://arxiv.org/pdf/2310.11466.pdf' target='_blank'>https://arxiv.org/pdf/2310.11466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufei Huang, Siyuan Li, Jin Su, Lirong Wu, Odin Zhang, Haitao Lin, Jingqi Qi, Zihan Liu, Zhangyang Gao, Yuyang Liu, Jiangbin Zheng, Stan. ZQ. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11466">Protein 3D Graph Structure Learning for Robust Structure-based Protein Property Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structure-based property prediction has emerged as a promising approach for various biological tasks, such as protein function prediction and sub-cellular location estimation. The existing methods highly rely on experimental protein structure data and fail in scenarios where these data are unavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were utilized as alternatives. However, we observed that current practices, which simply employ accurately predicted structures during inference, suffer from notable degradation in prediction accuracy. While similar phenomena have been extensively studied in general fields (e.g., Computer Vision) as model robustness, their impact on protein property prediction remains unexplored. In this paper, we first investigate the reason behind the performance decrease when utilizing predicted structures, attributing it to the structure embedding bias from the perspective of structure representation learning. To study this problem, we identify a Protein 3D Graph Structure Learning Problem for Robust Protein Property Prediction (PGSL-RP3), collect benchmark datasets, and present a protein Structure embedding Alignment Optimization framework (SAO) to mitigate the problem of structure embedding bias between the predicted and experimental protein structures. Extensive experiments have shown that our framework is model-agnostic and effective in improving the property prediction of both predicted structures and experimental structures. The benchmark datasets and codes will be released to benefit the community.
<div id='section'>Paperid: <span id='pid'>305, <a href='https://arxiv.org/pdf/2306.06470.pdf' target='_blank'>https://arxiv.org/pdf/2306.06470.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zefeng Chen, Wensheng Gan, Gengsen Huang, Zhenlian Qi, Yan Li, Philip S. Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06470">TALENT: Targeted Mining of Non-overlapping Sequential Patterns</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the widespread application of efficient pattern mining algorithms, sequential patterns that allow gap constraints have become a valuable tool to discover knowledge from biological data such as DNA and protein sequences. Among all kinds of gap-constrained mining, non-overlapping sequence mining can mine interesting patterns and satisfy the anti-monotonic property (the Apriori property). However, existing algorithms do not search for targeted sequential patterns, resulting in unnecessary and redundant pattern generation. Targeted pattern mining can not only mine patterns that are more interesting to users but also reduce the unnecessary redundant sequence generated, which can greatly avoid irrelevant computation. In this paper, we define and formalize the problem of targeted non-overlapping sequential pattern mining and propose an algorithm named TALENT (TArgeted mining of sequentiaL pattErN with consTraints). Two search methods including breadth-first and depth-first searching are designed to troubleshoot the generation of patterns. Furthermore, several pruning strategies to reduce the reading of sequences and items in the data and terminate redundant pattern extensions are presented. Finally, we select a series of datasets with different characteristics and conduct extensive experiments to compare the TALENT algorithm with the existing algorithms for mining non-overlapping sequential patterns. The experimental results demonstrate that the proposed targeted mining algorithm, TALENT, has excellent mining efficiency and can deal efficiently with many different query settings.
<div id='section'>Paperid: <span id='pid'>306, <a href='https://arxiv.org/pdf/2212.00735.pdf' target='_blank'>https://arxiv.org/pdf/2212.00735.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yining Wang, Xumeng Gong, Shaochuan Li, Bing Yang, YiWu Sun, Chuan Shi, Yangang Wang, Cheng Yang, Hui Li, Le Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.00735">xTrimoABFold: De novo Antibody Structure Prediction without MSA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of antibody engineering, an essential task is to design a novel antibody whose paratopes bind to a specific antigen with correct epitopes. Understanding antibody structure and its paratope can facilitate a mechanistic understanding of its function. Therefore, antibody structure prediction from its sequence alone has always been a highly valuable problem for de novo antibody design. AlphaFold2, a breakthrough in the field of structural biology, provides a solution to predict protein structure based on protein sequences and computationally expensive coevolutionary multiple sequence alignments (MSAs). However, the computational efficiency and undesirable prediction accuracy of antibodies, especially on the complementarity-determining regions (CDRs) of antibodies limit their applications in the industrially high-throughput drug design. To learn an informative representation of antibodies, we employed a deep antibody language model (ALM) on curated sequences from the observed antibody space database via a transformer model. We also developed a novel model named xTrimoABFold to predict antibody structure from antibody sequence based on the pretrained ALM as well as efficient evoformers and structural modules. The model was trained end-to-end on the antibody structures in PDB by minimizing the ensemble loss of domain-specific focal loss on CDR and the frame-aligned point loss. xTrimoABFold outperforms AlphaFold2 and other protein language model based SOTAs, e.g., OmegaFold, HelixFold-Single, and IgFold with a large significant margin (30+\% improvement on RMSD) while performing 151 times faster than AlphaFold2. To the best of our knowledge, xTrimoABFold achieved state-of-the-art antibody structure prediction. Its improvement in both accuracy and efficiency makes it a valuable tool for de novo antibody design and could make further improvements in immuno-theory.
<div id='section'>Paperid: <span id='pid'>307, <a href='https://arxiv.org/pdf/2504.10983.pdf' target='_blank'>https://arxiv.org/pdf/2504.10983.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zitai Kong, Yiheng Zhu, Yinlong Xu, Hanjing Zhou, Mingzhe Yin, Jialu Wu, Hongxia Xu, Chang-Yu Hsieh, Tingjun Hou, Jian Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.10983">ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed Protein Language Model Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The design of protein sequences with desired functionalities is a fundamental task in protein engineering. Deep generative methods, such as autoregressive models and diffusion models, have greatly accelerated the discovery of novel protein sequences. However, these methods mainly focus on local or shallow residual semantics and suffer from low inference efficiency, large modeling space and high training cost. To address these challenges, we introduce ProtFlow, a fast flow matching-based protein sequence design framework that operates on embeddings derived from semantically meaningful latent space of protein language models. By compressing and smoothing the latent space, ProtFlow enhances performance while training on limited computational resources. Leveraging reflow techniques, ProtFlow enables high-quality single-step sequence generation. Additionally, we develop a joint design pipeline for the design scene of multichain proteins. We evaluate ProtFlow across diverse protein design tasks, including general peptides and long-chain proteins, antimicrobial peptides, and antibodies. Experimental results demonstrate that ProtFlow outperforms task-specific methods in these applications, underscoring its potential and broad applicability in computational protein sequence design and analysis.
<div id='section'>Paperid: <span id='pid'>308, <a href='https://arxiv.org/pdf/2408.15299.pdf' target='_blank'>https://arxiv.org/pdf/2408.15299.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiqing Shen, Zan Chen, Michail Mamalakis, Yungeng Liu, Tianbin Li, Yanzhou Su, Junjun He, Pietro LiÃ², Yu Guang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15299">TourSynbio: A Multi-Modal Large Model and Agent Framework to Bridge Text and Protein Sequences for Protein Engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The structural similarities between protein sequences and natural languages have led to parallel advancements in deep learning across both domains. While large language models (LLMs) have achieved much progress in the domain of natural language processing, their potential in protein engineering remains largely unexplored. Previous approaches have equipped LLMs with protein understanding capabilities by incorporating external protein encoders, but this fails to fully leverage the inherent similarities between protein sequences and natural languages, resulting in sub-optimal performance and increased model complexity. To address this gap, we present TourSynbio-7B, the first multi-modal large model specifically designed for protein engineering tasks without external protein encoders. TourSynbio-7B demonstrates that LLMs can inherently learn to understand proteins as language. The model is post-trained and instruction fine-tuned on InternLM2-7B using ProteinLMDataset, a dataset comprising 17.46 billion tokens of text and protein sequence for self-supervised pretraining and 893K instructions for supervised fine-tuning. TourSynbio-7B outperforms GPT-4 on the ProteinLMBench, a benchmark of 944 manually verified multiple-choice questions, with 62.18% accuracy. Leveraging TourSynbio-7B's enhanced protein sequence understanding capability, we introduce TourSynbio-Agent, an innovative framework capable of performing various protein engineering tasks, including mutation analysis, inverse folding, protein folding, and visualization. TourSynbio-Agent integrates previously disconnected deep learning models in the protein engineering domain, offering a unified conversational user interface for improved usability. Finally, we demonstrate the efficacy of TourSynbio-7B and TourSynbio-Agent through two wet lab case studies on vanilla key enzyme modification and steroid compound catalysis.
<div id='section'>Paperid: <span id='pid'>309, <a href='https://arxiv.org/pdf/2406.05540.pdf' target='_blank'>https://arxiv.org/pdf/2406.05540.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiqing Shen, Zan Chen, Michail Mamalakis, Luhan He, Haiyang Xia, Tianbin Li, Yanzhou Su, Junjun He, Yu Guang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.05540">A Fine-tuning Dataset and Benchmark for Large Language Models for Protein Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The parallels between protein sequences and natural language in their sequential structures have inspired the application of large language models (LLMs) to protein understanding. Despite the success of LLMs in NLP, their effectiveness in comprehending protein sequences remains an open question, largely due to the absence of datasets linking protein sequences to descriptive text. Researchers have then attempted to adapt LLMs for protein understanding by integrating a protein sequence encoder with a pre-trained LLM. However, this adaptation raises a fundamental question: "Can LLMs, originally designed for NLP, effectively comprehend protein sequences as a form of language?" Current datasets fall short in addressing this question due to the lack of a direct correlation between protein sequences and corresponding text descriptions, limiting the ability to train and evaluate LLMs for protein understanding effectively. To bridge this gap, we introduce ProteinLMDataset, a dataset specifically designed for further self-supervised pretraining and supervised fine-tuning (SFT) of LLMs to enhance their capability for protein sequence comprehension. Specifically, ProteinLMDataset includes 17.46 billion tokens for pretraining and 893,000 instructions for SFT. Additionally, we present ProteinLMBench, the first benchmark dataset consisting of 944 manually verified multiple-choice questions for assessing the protein understanding capabilities of LLMs. ProteinLMBench incorporates protein-related details and sequences in multiple languages, establishing a new standard for evaluating LLMs' abilities in protein comprehension. The large language model InternLM2-7B, pretrained and fine-tuned on the ProteinLMDataset, outperforms GPT-4 on ProteinLMBench, achieving the highest accuracy score.
<div id='section'>Paperid: <span id='pid'>310, <a href='https://arxiv.org/pdf/2508.10696.pdf' target='_blank'>https://arxiv.org/pdf/2508.10696.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Jiang, Shuzhou Sun, Biqing Qi, Yuchen Fu, Xiaohua Xu, Yuqiang Li, Dongzhan Zhou, Tianfan Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10696">Chem3DLLM: 3D Multimodal Large Language Models for Chemistry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the real world, a molecule is a 3D geometric structure. Compared to 1D SMILES sequences and 2D molecular graphs, 3D molecules represent the most informative molecular modality. Despite the rapid progress of autoregressive-based language models, they cannot handle the generation of 3D molecular conformation due to several challenges: 1) 3D molecular structures are incompatible with LLMs' discrete token space, 2) integrating heterogeneous inputs like proteins, ligands, and text remains difficult within a unified model, and 3) LLMs lack essential scientific priors, hindering the enforcement of physical and chemical constraints during generation. To tackle these issues, we present Chem3DLLM, a unified protein-conditioned multimodal large language model. Our approach designs a novel reversible text encoding for 3D molecular structures using run-length compression, achieving 3x size reduction while preserving complete structural information. This enables seamless integration of molecular geometry with protein pocket features in a single LLM architecture. We employ reinforcement learning with stability-based rewards to optimize chemical validity and incorporate a lightweight protein embedding projector for end-to-end training. Experimental results on structure-based drug design demonstrate state-of-the-art performance with a Vina score of -7.21, validating our unified multimodal approach for practical drug discovery applications.
<div id='section'>Paperid: <span id='pid'>311, <a href='https://arxiv.org/pdf/2507.10955.pdf' target='_blank'>https://arxiv.org/pdf/2507.10955.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chi-en Amy Tai, Alexander Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10955">Diffusion Decoding for Peptide De Novo Sequencing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Peptide de novo sequencing is a method used to reconstruct amino acid sequences from tandem mass spectrometry data without relying on existing protein sequence databases. Traditional deep learning approaches, such as Casanovo, mainly utilize autoregressive decoders and predict amino acids sequentially. Subsequently, they encounter cascading errors and fail to leverage high-confidence regions effectively. To address these issues, this paper investigates using diffusion decoders adapted for the discrete data domain. These decoders provide a different approach, allowing sequence generation to start from any peptide segment, thereby enhancing prediction accuracy. We experiment with three different diffusion decoder designs, knapsack beam search, and various loss functions. We find knapsack beam search did not improve performance metrics and simply replacing the transformer decoder with a diffusion decoder lowered performance. Although peptide precision and recall were still 0, the best diffusion decoder design with the DINOISER loss function obtained a statistically significant improvement in amino acid recall by 0.373 compared to the baseline autoregressive decoder-based Casanovo model. These findings highlight the potential of diffusion decoders to not only enhance model sensitivity but also drive significant advancements in peptide de novo sequencing.
<div id='section'>Paperid: <span id='pid'>312, <a href='https://arxiv.org/pdf/2507.07048.pdf' target='_blank'>https://arxiv.org/pdf/2507.07048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bruce Coburn, Jiangpeng He, Megan E. Rollo, Satvinder S. Dhaliwal, Deborah A. Kerr, Fengqing Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07048">Evaluating Large Multimodal Models for Nutrition Analysis: A Benchmark Enriched with Contextual Metadata</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Multimodal Models (LMMs) are increasingly applied to meal images for nutrition analysis. However, existing work primarily evaluates proprietary models, such as GPT-4. This leaves the broad range of LLMs underexplored. Additionally, the influence of integrating contextual metadata and its interaction with various reasoning modifiers remains largely uncharted. This work investigates how interpreting contextual metadata derived from GPS coordinates (converted to location/venue type), timestamps (transformed into meal/day type), and the food items present can enhance LMM performance in estimating key nutritional values. These values include calories, macronutrients (protein, carbohydrates, fat), and portion sizes. We also introduce ACETADA, a new food-image dataset slated for public release. This open dataset provides nutrition information verified by the dietitian and serves as the foundation for our analysis. Our evaluation across eight LMMs (four open-weight and four closed-weight) first establishes the benefit of contextual metadata integration over straightforward prompting with images alone. We then demonstrate how this incorporation of contextual information enhances the efficacy of reasoning modifiers, such as Chain-of-Thought, Multimodal Chain-of-Thought, Scale Hint, Few-Shot, and Expert Persona. Empirical results show that integrating metadata intelligently, when applied through straightforward prompting strategies, can significantly reduce the Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) in predicted nutritional values. This work highlights the potential of context-aware LMMs for improved nutrition analysis.
<div id='section'>Paperid: <span id='pid'>313, <a href='https://arxiv.org/pdf/2502.00831.pdf' target='_blank'>https://arxiv.org/pdf/2502.00831.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maike Scherer, Lukas Brand, Louis Wolf, Teena tom Dieck, Maximilian SchÃ¤fer, Sebastian Lotter, Andreas Burkovski, Heinrich Sticht, Robert Schober, Kathrin Castiglione
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00831">Closed-Loop Long-Term Experimental Molecular Communication System</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a fluid-based experimental molecular communication (MC) testbed which uses media modulation. Motivated by the natural human cardiovascular system, the testbed operates in a closed-loop tube system. The proposed system is designed to be biocompatible, resource-efficient, and controllable from outside the tube. As signaling molecule, the testbed employs the green fluorescent protein variant "Dreiklang" (GFPD). GFPDs can be reversibly switched via light of different wavelengths between a bright fluorescent state and a less fluorescent state. GFPDs in solution are filled into the testbed prior to the start of information transmission and remain there for an entire experiment. For information transmission, an optical transmitter (TX) and an optical eraser (EX), which are located outside the tube, are used to write and erase the information encoded in the state of the GFPDs, respectively. At the receiver (RX), the state of the GFPDs is read out by fluorescence detection. In our testbed, due to the closed-loop setup, we observe new forms of inter-symbol interferences (ISI), which do not occur in short experiments and open-loop systems. For the testbed, we developed a communication scheme, which includes blind transmission start detection, symbol-by-symbol synchronization, and adaptive threshold detection. We comprehensively analyze our MC experiments using different performance metrics. Moreover, we experimentally demonstrate the error-free transmission of 5370 bit at a data rate of 36 $\textrm{bit}\, \textrm{min}^{\boldsymbol{-1}}$ using 8-ary modulation and the error-free binary transmission of around 90000 bit at a data rate of 12 $\textrm{bit}\, \textrm{min}^{\boldsymbol{-1}}$. For the latter experiment, data was transmitted for a period of 125 hours. All signals recorded and parts of the evaluation code are publicly available on Zenodo and Github, respectively.
<div id='section'>Paperid: <span id='pid'>314, <a href='https://arxiv.org/pdf/2410.12126.pdf' target='_blank'>https://arxiv.org/pdf/2410.12126.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dongqi Fu, Liri Fang, Zihao Li, Hanghang Tong, Vetle I. Torvik, Jingrui He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12126">What Do LLMs Need to Understand Graphs: A Survey of Parametric Representation of Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graphs, as a relational data structure, have been widely used for various application scenarios, like molecule design and recommender systems. Recently, large language models (LLMs) are reorganizing in the AI community for their expected reasoning and inference abilities. Making LLMs understand graph-based relational data has great potential, including but not limited to (1) distillate external knowledge base for eliminating hallucination and breaking the context window limit for LLMs' inference during the retrieval augmentation generation process; (2) taking graph data as the input and directly solve the graph-based research tasks like protein design and drug discovery. However, inputting the entire graph data to LLMs is not practical due to its complex topological structure, data size, and the lack of effective and efficient semantic graph representations. A natural question arises: Is there a kind of graph representation that can be described by natural language for LLM's understanding and is also easy to require to serve as the raw input for LLMs? Based on statistical computation, graph laws pre-define a set of parameters (e.g., degree, time, diameter) and identifie their relationships and values by observing the topological distribution of plenty of real-world graph data. We believe this kind of parametric representation of graphs, graph laws, can be a solution for making LLMs understand graph data as the input. In this survey, we first review the previous study of graph laws from multiple perspectives, i.e., macroscope and microscope of graphs, low-order and high-order graphs, static and dynamic graphs, different observation spaces, and newly proposed graph parameters. After we review various real-world applications benefiting from the guidance of graph laws, we conclude the paper with current challenges and future research directions.
<div id='section'>Paperid: <span id='pid'>315, <a href='https://arxiv.org/pdf/2405.07814.pdf' target='_blank'>https://arxiv.org/pdf/2405.07814.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew Keller, Chi-en Amy Tai, Yuhao Chen, Pengcheng Xi, Alexander Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.07814">NutritionVerse-Direct: Exploring Deep Neural Networks for Multitask Nutrition Prediction from Food Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many aging individuals encounter challenges in effectively tracking their dietary intake, exacerbating their susceptibility to nutrition-related health complications. Self-reporting methods are often inaccurate and suffer from substantial bias; however, leveraging intelligent prediction methods can automate and enhance precision in this process. Recent work has explored using computer vision prediction systems to predict nutritional information from food images. Still, these methods are often tailored to specific situations, require other inputs in addition to a food image, or do not provide comprehensive nutritional information.
  This paper aims to enhance the efficacy of dietary intake estimation by leveraging various neural network architectures to directly predict a meal's nutritional content from its image. Through comprehensive experimentation and evaluation, we present NutritionVerse-Direct, a model utilizing a vision transformer base architecture with three fully connected layers that lead to five regression heads predicting calories (kcal), mass (g), protein (g), fat (g), and carbohydrates (g) present in a meal. NutritionVerse-Direct yields a combined mean average error score on the NutritionVerse-Real dataset of 412.6, an improvement of 25.5% over the Inception-ResNet model, demonstrating its potential for improving dietary intake estimation accuracy.
<div id='section'>Paperid: <span id='pid'>316, <a href='https://arxiv.org/pdf/2405.01616.pdf' target='_blank'>https://arxiv.org/pdf/2405.01616.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maksym Korablyov, Cheng-Hao Liu, Moksh Jain, Almer M. van der Sloot, Eric Jolicoeur, Edward Ruediger, Andrei Cristian Nica, Emmanuel Bengio, Kostiantyn Lapchevskyi, Daniel St-Cyr, Doris Alexandra Schuetz, Victor Ion Butoi, Jarrid Rector-Brooks, Simon Blackburn, Leo Feng, Hadi Nekoei, SaiKrishna Gottipati, Priyesh Vijayan, Prateek Gupta, Ladislav RampÃ¡Å¡ek, Sasikanth Avancha, Pierre-Luc Bacon, William L. Hamilton, Brooks Paige, Sanchit Misra, Stanislaw Kamil Jastrzebski, Bharat Kaul, Doina Precup, JosÃ© Miguel HernÃ¡ndez-Lobato, Marwin Segler, Michael Bronstein, Anne Marinier, Mike Tyers, Yoshua Bengio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01616">Generative Active Learning for the Search of Small-molecule Protein Binders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite substantial progress in machine learning for scientific discovery in recent years, truly de novo design of small molecules which exhibit a property of interest remains a significant challenge. We introduce LambdaZero, a generative active learning approach to search for synthesizable molecules. Powered by deep reinforcement learning, LambdaZero learns to search over the vast space of molecules to discover candidates with a desired property. We apply LambdaZero with molecular docking to design novel small molecules that inhibit the enzyme soluble Epoxide Hydrolase 2 (sEH), while enforcing constraints on synthesizability and drug-likeliness. LambdaZero provides an exponential speedup in terms of the number of calls to the expensive molecular docking oracle, and LambdaZero de novo designed molecules reach docking scores that would otherwise require the virtual screening of a hundred billion molecules. Importantly, LambdaZero discovers novel scaffolds of synthesizable, drug-like inhibitors for sEH. In in vitro experimental validation, a series of ligands from a generated quinazoline-based scaffold were synthesized, and the lead inhibitor N-(4,6-di(pyrrolidin-1-yl)quinazolin-2-yl)-N-methylbenzamide (UM0152893) displayed sub-micromolar enzyme inhibition of sEH.
<div id='section'>Paperid: <span id='pid'>317, <a href='https://arxiv.org/pdf/2404.10094.pdf' target='_blank'>https://arxiv.org/pdf/2404.10094.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>MichaÅ Koziarski, Mohammed Abukalam, Vedant Shah, Louis Vaillancourt, Doris Alexandra Schuetz, Moksh Jain, Almer van der Sloot, Mathieu Bourgey, Anne Marinier, Yoshua Bengio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10094">Towards DNA-Encoded Library Generation with GFlowNets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>DNA-encoded libraries (DELs) are a powerful approach for rapidly screening large numbers of diverse compounds. One of the key challenges in using DELs is library design, which involves choosing the building blocks that will be combinatorially combined to produce the final library. In this paper we consider the task of protein-protein interaction (PPI) biased DEL design. To this end, we evaluate several machine learning algorithms on the PPI modulation task and use them as a reward for the proposed GFlowNet-based generative approach. We additionally investigate the possibility of using structural information about building blocks to design a hierarchical action space for the GFlowNet. The observed results indicate that GFlowNets are a promising approach for generating diverse combinatorial library candidates.
<div id='section'>Paperid: <span id='pid'>318, <a href='https://arxiv.org/pdf/2404.00014.pdf' target='_blank'>https://arxiv.org/pdf/2404.00014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Odin Zhang, Yufei Huang, Shichen Cheng, Mengyao Yu, Xujun Zhang, Haitao Lin, Yundian Zeng, Mingyang Wang, Zhenxing Wu, Huifeng Zhao, Zaixi Zhang, Chenqing Hua, Yu Kang, Sunliang Cui, Peichen Pan, Chang-Yu Hsieh, Tingjun Hou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00014">Deep Geometry Handling and Fragment-wise Molecular 3D Graph Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most earlier 3D structure-based molecular generation approaches follow an atom-wise paradigm, incrementally adding atoms to a partially built molecular fragment within protein pockets. These methods, while effective in designing tightly bound ligands, often overlook other essential properties such as synthesizability. The fragment-wise generation paradigm offers a promising solution. However, a common challenge across both atom-wise and fragment-wise methods lies in their limited ability to co-design plausible chemical and geometrical structures, resulting in distorted conformations. In response to this challenge, we introduce the Deep Geometry Handling protocol, a more abstract design that extends the design focus beyond the model architecture. Through a comprehensive review of existing geometry-related models and their protocols, we propose a novel hybrid strategy, culminating in the development of FragGen - a geometry-reliable, fragment-wise molecular generation method. FragGen marks a significant leap forward in the quality of generated geometry and the synthesis accessibility of molecules. The efficacy of FragGen is further validated by its successful application in designing type II kinase inhibitors at the nanomolar level.
<div id='section'>Paperid: <span id='pid'>319, <a href='https://arxiv.org/pdf/2310.15588.pdf' target='_blank'>https://arxiv.org/pdf/2310.15588.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Brand, Maike Scherer, Teena tom Dieck, Sebastian Lotter, Maximilian SchÃ¤fer, Andreas Burkovski, Heinrich Sticht, Kathrin Castiglione, Robert Schober
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.15588">Closed Loop Molecular Communication Testbed: Setup, Interference Analysis, and Experimental Results</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present a fluid-based experimental molecular communication (MC) testbed that, similar to the human cardiovascular system, operates in a closed circuit tube system. The proposed system is designed to be biocompatible, resource-efficient, and controllable from outside the tube. As signaling molecule, the testbed employs the green fluorescent protein variant "Dreiklang" (GFPD). GFPDs can be reversibly switched via light of different wavelengths between a bright fluorescent state and a less fluorescent state. Hence, this property allows for writing and erasing information encoded in the state of the GFPDs already present in the fluid via radiation from outside the tube. The concept of modulating the GFPDs existing in the channel at the transmitter for information transmission, instead of releasing new molecules, is a form of media modulation. In our testbed, due to the closed loop setup and the long experiment durations of up to 250 min, we observe new forms of inter-symbol interferences (ISI), which do not occur in short experiments and open loop systems. In particular, up to four different forms of ISI, namely channel ISI, inter-loop ISI, offset ISI, and permanent ISI, occur in the considered system. To mitigate inter-loop ISI and offset ISI, we propose a light based eraser unit. We experimentally demonstrate reliable information transmission in our testbed achieving error-free transmission of 500 bit at a data rate of 6 bit/min based on a sub-optimal low-complexity detection scheme.
<div id='section'>Paperid: <span id='pid'>320, <a href='https://arxiv.org/pdf/2309.14907.pdf' target='_blank'>https://arxiv.org/pdf/2309.14907.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhihao Shi, Jie Wang, Fanghua Lu, Hanzhu Chen, Defu Lian, Zheng Wang, Jieping Ye, Feng Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.14907">Label Deconvolution for Node Representation Learning on Large-scale Attributed Graphs against Learning Bias</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Node representation learning on attributed graphs -- whose nodes are associated with rich attributes (e.g., texts and protein sequences) -- plays a crucial role in many important downstream tasks. To encode the attributes and graph structures simultaneously, recent studies integrate pre-trained models with graph neural networks (GNNs), where pre-trained models serve as node encoders (NEs) to encode the attributes. As jointly training large NEs and GNNs on large-scale graphs suffers from severe scalability issues, many methods propose to train NEs and GNNs separately. Consequently, they do not take feature convolutions in GNNs into consideration in the training phase of NEs, leading to a significant learning bias relative to the joint training. To address this challenge, we propose an efficient label regularization technique, namely Label Deconvolution (LD), to alleviate the learning bias by a novel and highly scalable approximation to the inverse mapping of GNNs. The inverse mapping leads to an objective function that is equivalent to that by the joint training, while it can effectively incorporate GNNs in the training phase of NEs against the learning bias. More importantly, we show that LD converges to the optimal objective function values by the joint training under mild assumptions. Experiments demonstrate LD significantly outperforms state-of-the-art methods on Open Graph Benchmark datasets.
<div id='section'>Paperid: <span id='pid'>321, <a href='https://arxiv.org/pdf/2305.18410.pdf' target='_blank'>https://arxiv.org/pdf/2305.18410.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mugariya Farooq, Shahad Hardan, Aigerim Zhumbhayeva, Yujia Zheng, Preslav Nakov, Kun Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.18410">Understanding Breast Cancer Survival: Using Causality and Language Models on Multi-omics Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The need for more usable and explainable machine learning models in healthcare increases the importance of developing and utilizing causal discovery algorithms, which aim to discover causal relations by analyzing observational data. Explainable approaches aid clinicians and biologists in predicting the prognosis of diseases and suggesting proper treatments. However, very little research has been conducted at the crossroads between causal discovery, genomics, and breast cancer, and we aim to bridge this gap. Moreover, evaluation of causal discovery methods on real data is in general notoriously difficult because ground-truth causal relations are usually unknown, and accordingly, in this paper, we also propose to address the evaluation problem with large language models. In particular, we exploit suitable causal discovery algorithms to investigate how various perturbations in the genome can affect the survival of patients diagnosed with breast cancer. We used three main causal discovery algorithms: PC, Greedy Equivalence Search (GES), and a Generalized Precision Matrix-based one. We experiment with a subset of The Cancer Genome Atlas, which contains information about mutations, copy number variations, protein levels, and gene expressions for 705 breast cancer patients. Our findings reveal important factors related to the vital status of patients using causal discovery algorithms. However, the reliability of these results remains a concern in the medical domain. Accordingly, as another contribution of the work, the results are validated through language models trained on biomedical literature, such as BlueBERT and other large language models trained on medical corpora. Our results profess proper utilization of causal discovery algorithms and language models for revealing reliable causal relations for clinical applications.
<div id='section'>Paperid: <span id='pid'>322, <a href='https://arxiv.org/pdf/2302.10356.pdf' target='_blank'>https://arxiv.org/pdf/2302.10356.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Brand, Maike Scherer, Sebastian Lotter, Teena tom Dieck, Maximilian SchÃ¤fer, Andreas Burkovski, Heinrich Sticht, Kathrin Castiglione, Robert Schober
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10356">Switchable Signaling Molecules for Media Modulation: Fundamentals, Applications, and Research Directions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although visionary applications of molecular communication (MC), such as long-term continuous health monitoring by cooperative in-body nanomachines, have been proposed, MC is still in its infancy when it comes to practical implementation. In particular, long-term experiments and applications face issues such as depletion of signaling molecules (SMs) at the transmitter (TX) and inter-symbol interference (ISI) at the receiver (RX). To overcome these practical challenges, a new class of SMs with switchable states seems to be promising for future MC applications. In this work, we provide an overview of existing switchable SMs, and classify them according to their properties. Furthermore, we highlight how switchable SMs can be utilized as information carriers for media modulation. In addition, we present theoretical and experimental results for an end-to-end MC system employing the green fluorescent protein variant "Dreiklang" (GFPD) as switchable SM. Our experimental results show, for the first time, successful information transmission in a closed-loop pipe system using media modulation. Finally, we discuss media modulation specific challenges and opportunities.
<div id='section'>Paperid: <span id='pid'>323, <a href='https://arxiv.org/pdf/2507.04832.pdf' target='_blank'>https://arxiv.org/pdf/2507.04832.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaqi Han, Austin Wang, Minkai Xu, Wenda Chu, Meihua Dang, Yisong Yue, Stefano Ermon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04832">Discrete Diffusion Trajectory Alignment via Stepwise Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discrete diffusion models have demonstrated great promise in modeling various sequence data, ranging from human language to biological sequences. Inspired by the success of RL in language models, there is growing interest in further improving the models by alignment with a certain reward. In this work, we propose a novel preference optimization method for masked discrete diffusion models through a principled diffusion trajectory alignment. Instead of applying the reward on the final output and backpropagating the gradient to the entire discrete denoising process, we decompose the problem into a set of stepwise alignment objectives. This framework enables efficient diffusion optimization, is compatible with arbitrary reward functions, and importantly, guarantees an equivalent optimal solution under additive factorization of the trajectory reward. Experiments across multiple domains including DNA sequence design, protein inverse folding, and language modeling consistently demonstrate the superiority of our approach. Notably, it achieves an up to 12\% improvement over the most competitive RL-based baseline in terms of predicted activity on DNA sequence design, and further improves the GSM8K score from 78.6 to 80.7 on LLaDA-8B-Instruct for language modeling.
<div id='section'>Paperid: <span id='pid'>324, <a href='https://arxiv.org/pdf/2503.14574.pdf' target='_blank'>https://arxiv.org/pdf/2503.14574.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taslim Murad, Sarwan Ali, Murray Patterson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14574">Sequence Analysis Using the Bezier Curve</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The analysis of sequences (e.g., protein, DNA, and SMILES string) is essential for disease diagnosis, biomaterial engineering, genetic engineering, and drug discovery domains. Conventional analytical methods focus on transforming sequences into numerical representations for applying machine learning/deep learning-based sequence characterization. However, their efficacy is constrained by the intrinsic nature of deep learning (DL) models, which tend to exhibit suboptimal performance when applied to tabular data. An alternative group of methodologies endeavors to convert biological sequences into image forms by applying the concept of Chaos Game Representation (CGR). However, a noteworthy drawback of these methods lies in their tendency to map individual elements of the sequence onto a relatively small subset of designated pixels within the generated image. The resulting sparse image representation may not adequately encapsulate the comprehensive sequence information, potentially resulting in suboptimal predictions. In this study, we introduce a novel approach to transform sequences into images using the BÃ©zier curve concept for element mapping. Mapping the elements onto a curve enhances the sequence information representation in the respective images, hence yielding better DL-based classification performance. We employed different sequence datasets to validate our system by using different classification tasks, and the results illustrate that our BÃ©zier curve method is able to achieve good performance for all the tasks.
<div id='section'>Paperid: <span id='pid'>325, <a href='https://arxiv.org/pdf/2501.14746.pdf' target='_blank'>https://arxiv.org/pdf/2501.14746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taslim Murad, Prakash Chourasia, Sarwan Ali, Imdad Ullah Khan, Murray Patterson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.14746">Neuromorphic Spiking Neural Network Based Classification of COVID-19 Spike Sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The availability of SARS-CoV-2 (severe acute respiratory syndrome coronavirus 2) virus data post-COVID has reached exponentially to an enormous magnitude, opening research doors to analyze its behavior. Various studies are conducted by researchers to gain a deeper understanding of the virus, like genomic surveillance, etc, so that efficient prevention mechanisms can be developed. However, the unstable nature of the virus (rapid mutations, multiple hosts, etc) creates challenges in designing analytical systems for it. Therefore, we propose a neural network-based (NN) mechanism to perform an efficient analysis of the SARS-CoV-2 data, as NN portrays generalized behavior upon training. Moreover, rather than using the full-length genome of the virus, we apply our method to its spike region, as this region is known to have predominant mutations and is used to attach to the host cell membrane. In this paper, we introduce a pipeline that first converts the spike protein sequences into a fixed-length numerical representation and then uses Neuromorphic Spiking Neural Network to classify those sequences. We compare the performance of our method with various baselines using real-world SARS-CoV-2 spike sequence data and show that our method is able to achieve higher predictive accuracy compared to the recent baselines.
<div id='section'>Paperid: <span id='pid'>326, <a href='https://arxiv.org/pdf/2410.13027.pdf' target='_blank'>https://arxiv.org/pdf/2410.13027.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaqi Han, Minkai Xu, Aaron Lou, Haotian Ye, Stefano Ermon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13027">Geometric Trajectory Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative models have shown great promise in generating 3D geometric systems, which is a fundamental problem in many natural science domains such as molecule and protein design. However, existing approaches only operate on static structures, neglecting the fact that physical systems are always dynamic in nature. In this work, we propose geometric trajectory diffusion models (GeoTDM), the first diffusion model for modeling the temporal distribution of 3D geometric trajectories. Modeling such distribution is challenging as it requires capturing both the complex spatial interactions with physical symmetries and temporal correspondence encapsulated in the dynamics. We theoretically justify that diffusion models with equivariant temporal kernels can lead to density with desired symmetry, and develop a novel transition kernel leveraging SE(3)-equivariant spatial convolution and temporal attention. Furthermore, to induce an expressive trajectory distribution for conditional generation, we introduce a generalized learnable geometric prior into the forward diffusion process to enhance temporal conditioning. We conduct extensive experiments on both unconditional and conditional generation in various scenarios, including physical simulation, molecular dynamics, and pedestrian motion. Empirical results on a wide suite of metrics demonstrate that GeoTDM can generate realistic geometric trajectories with significantly higher quality.
<div id='section'>Paperid: <span id='pid'>327, <a href='https://arxiv.org/pdf/2410.12655.pdf' target='_blank'>https://arxiv.org/pdf/2410.12655.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarwan Ali, Taslim Murad, Prakash Chourasia, Haris Mansoor, Imdad Ullah Khan, Pin-Yu Chen, Murray Patterson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12655">Position Specific Scoring Is All You Need? Revisiting Protein Sequence Classification Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the structural and functional characteristics of proteins are crucial for developing preventative and curative strategies that impact fields from drug discovery to policy development. An important and popular technique for examining how amino acids make up these characteristics of the protein sequences with position-specific scoring (PSS). While the string kernel is crucial in natural language processing (NLP), it is unclear if string kernels can extract biologically meaningful information from protein sequences, despite the fact that they have been shown to be effective in the general sequence analysis tasks. In this work, we propose a weighted PSS kernel matrix (or W-PSSKM), that combines a PSS representation of protein sequences, which encodes the frequency information of each amino acid in a sequence, with the notion of the string kernel. This results in a novel kernel function that outperforms many other approaches for protein sequence classification. We perform extensive experimentation to evaluate the proposed method. Our findings demonstrate that the W-PSSKM significantly outperforms existing baselines and state-of-the-art methods and achieves up to 45.1\% improvement in classification accuracy.
<div id='section'>Paperid: <span id='pid'>328, <a href='https://arxiv.org/pdf/2409.06694.pdf' target='_blank'>https://arxiv.org/pdf/2409.06694.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taslim Murad, Prakash Chourasia, Sarwan Ali, Imdad Ullah Khan, Murray Patterson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06694">DANCE: Deep Learning-Assisted Analysis of Protein Sequences Using Chaos Enhanced Kaleidoscopic Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cancer is a complex disease characterized by uncontrolled cell growth. T cell receptors (TCRs), crucial proteins in the immune system, play a key role in recognizing antigens, including those associated with cancer. Recent advancements in sequencing technologies have facilitated comprehensive profiling of TCR repertoires, uncovering TCRs with potent anti-cancer activity and enabling TCR-based immunotherapies. However, analyzing these intricate biomolecules necessitates efficient representations that capture their structural and functional information. T-cell protein sequences pose unique challenges due to their relatively smaller lengths compared to other biomolecules. An image-based representation approach becomes a preferred choice for efficient embeddings, allowing for the preservation of essential details and enabling comprehensive analysis of T-cell protein sequences. In this paper, we propose to generate images from the protein sequences using the idea of Chaos Game Representation (CGR) using the Kaleidoscopic images approach. This Deep Learning Assisted Analysis of Protein Sequences Using Chaos Enhanced Kaleidoscopic Images (called DANCE) provides a unique way to visualize protein sequences by recursively applying chaos game rules around a central seed point. we perform the classification of the T cell receptors (TCRs) protein sequences in terms of their respective target cancer cells, as TCRs are known for their immune response against cancer disease. The TCR sequences are converted into images using the DANCE method. We employ deep-learning vision models to perform the classification to obtain insights into the relationship between the visual patterns observed in the generated kaleidoscopic images and the underlying protein properties. By combining CGR-based image generation with deep learning classification, this study opens novel possibilities in the protein analysis domain.
<div id='section'>Paperid: <span id='pid'>329, <a href='https://arxiv.org/pdf/2409.04922.pdf' target='_blank'>https://arxiv.org/pdf/2409.04922.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarwan Ali, Prakash Chourasia, Bipin Koirala, Murray Patterson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04922">Nearest Neighbor CCP-Based Molecular Sequence Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular sequence analysis is crucial for comprehending several biological processes, including protein-protein interactions, functional annotation, and disease classification. The large number of sequences and the inherently complicated nature of protein structures make it challenging to analyze such data. Finding patterns and enhancing subsequent research requires the use of dimensionality reduction and feature selection approaches. Recently, a method called Correlated Clustering and Projection (CCP) has been proposed as an effective method for biological sequencing data. The CCP technique is still costly to compute even though it is effective for sequence visualization. Furthermore, its utility for classifying molecular sequences is still uncertain. To solve these two problems, we present a Nearest Neighbor Correlated Clustering and Projection (CCP-NN)-based technique for efficiently preprocessing molecular sequence data. To group related molecular sequences and produce representative supersequences, CCP makes use of sequence-to-sequence correlations. As opposed to conventional methods, CCP doesn't rely on matrix diagonalization, therefore it can be applied to a range of machine-learning problems. We estimate the density map and compute the correlation using a nearest-neighbor search technique. We performed molecular sequence classification using CCP and CCP-NN representations to assess the efficacy of our proposed approach. Our findings show that CCP-NN considerably improves classification task accuracy as well as significantly outperforms CCP in terms of computational runtime.
<div id='section'>Paperid: <span id='pid'>330, <a href='https://arxiv.org/pdf/2405.08197.pdf' target='_blank'>https://arxiv.org/pdf/2405.08197.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Wang, Yu Mao, Yufei Cui, Nan Guan, Chun Jason Xue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08197">IHC Matters: Incorporating IHC analysis to H&E Whole Slide Image Analysis for Improved Cancer Grading via Two-stage Multimodal Bilinear Pooling Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Immunohistochemistry (IHC) plays a crucial role in pathology as it detects the over-expression of protein in tissue samples. However, there are still fewer machine learning model studies on IHC's impact on accurate cancer grading. We discovered that IHC and H\&E possess distinct advantages and disadvantages while possessing certain complementary qualities. Building on this observation, we developed a two-stage multi-modal bilinear model with a feature pooling module. This model aims to maximize the potential of both IHC and HE's feature representation, resulting in improved performance compared to their individual use. Our experiments demonstrate that incorporating IHC data into machine learning models, alongside H\&E stained images, leads to superior predictive results for cancer grading. The proposed framework achieves an impressive ACC higher of 0.953 on the public dataset BCI.
<div id='section'>Paperid: <span id='pid'>331, <a href='https://arxiv.org/pdf/2304.13145.pdf' target='_blank'>https://arxiv.org/pdf/2304.13145.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zahra Tayebi, Sarwan Ali, Prakash Chourasia, Taslim Murad, Murray Patterson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.13145">T Cell Receptor Protein Sequences and Sparse Coding: A Novel Approach to Cancer Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cancer is a complex disease characterized by uncontrolled cell growth and proliferation. T cell receptors (TCRs) are essential proteins for the adaptive immune system, and their specific recognition of antigens plays a crucial role in the immune response against diseases, including cancer. The diversity and specificity of TCRs make them ideal for targeting cancer cells, and recent advancements in sequencing technologies have enabled the comprehensive profiling of TCR repertoires. This has led to the discovery of TCRs with potent anti-cancer activity and the development of TCR-based immunotherapies. In this study, we investigate the use of sparse coding for the multi-class classification of TCR protein sequences with cancer categories as target labels. Sparse coding is a popular technique in machine learning that enables the representation of data with a set of informative features and can capture complex relationships between amino acids and identify subtle patterns in the sequence that might be missed by low-dimensional methods. We first compute the k-mers from the TCR sequences and then apply sparse coding to capture the essential features of the data. To improve the predictive performance of the final embeddings, we integrate domain knowledge regarding different types of cancer properties. We then train different machine learning (linear and non-linear) classifiers on the embeddings of TCR sequences for the purpose of supervised analysis. Our proposed embedding method on a benchmark dataset of TCR sequences significantly outperforms the baselines in terms of predictive performance, achieving an accuracy of 99.8\%. Our study highlights the potential of sparse coding for the analysis of TCR protein sequences in cancer research and other related fields.
<div id='section'>Paperid: <span id='pid'>332, <a href='https://arxiv.org/pdf/2304.12328.pdf' target='_blank'>https://arxiv.org/pdf/2304.12328.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarwan Ali, Babatunde Bello, Prakash Chourasia, Ria Thazhe Punathil, Pin-Yu Chen, Imdad Ullah Khan, Murray Patterson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.12328">Virus2Vec: Viral Sequence Classification Using Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the host-specificity of different families of viruses sheds light on the origin of, e.g., SARS-CoV-2, rabies, and other such zoonotic pathogens in humans. It enables epidemiologists, medical professionals, and policymakers to curb existing epidemics and prevent future ones promptly. In the family Coronaviridae (of which SARS-CoV-2 is a member), it is well-known that the spike protein is the point of contact between the virus and the host cell membrane. On the other hand, the two traditional mammalian orders, Carnivora (carnivores) and Chiroptera (bats) are recognized to be responsible for maintaining and spreading the Rabies Lyssavirus (RABV). We propose Virus2Vec, a feature-vector representation for viral (nucleotide or amino acid) sequences that enable vector-space-based machine learning models to identify viral hosts. Virus2Vec generates numerical feature vectors for unaligned sequences, allowing us to forego the computationally expensive sequence alignment step from the pipeline. Virus2Vec leverages the power of both the \emph{minimizer} and position weight matrix (PWM) to generate compact feature vectors. Using several classifiers, we empirically evaluate Virus2Vec on real-world spike sequences of Coronaviridae and rabies virus sequence data to predict the host (identifying the reservoirs of infection). Our results demonstrate that Virus2Vec outperforms the predictive accuracies of baseline and state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>333, <a href='https://arxiv.org/pdf/2304.06731.pdf' target='_blank'>https://arxiv.org/pdf/2304.06731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarwan Ali, Taslim Murad, Murray Patterson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06731">PCD2Vec: A Poisson Correction Distance-Based Approach for Viral Host Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Coronaviruses are membrane-enveloped, non-segmented positive-strand RNA viruses belonging to the Coronaviridae family. Various animal species, mainly mammalian and avian, are severely infected by various coronaviruses, causing serious concerns like the recent pandemic (COVID-19). Therefore, building a deeper understanding of these viruses is essential to devise prevention and mitigation mechanisms. In the Coronavirus genome, an essential structural region is the spike region, and it's responsible for attaching the virus to the host cell membrane. Therefore, the usage of only the spike protein, instead of the full genome, provides most of the essential information for performing analyses such as host classification. In this paper, we propose a novel method for predicting the host specificity of coronaviruses by analyzing spike protein sequences from different viral subgenera and species. Our method involves using the Poisson correction distance to generate a distance matrix, followed by using a radial basis function (RBF) kernel and kernel principal component analysis (PCA) to generate a low-dimensional embedding. Finally, we apply classification algorithms to the low-dimensional embedding to generate the resulting predictions of the host specificity of coronaviruses. We provide theoretical proofs for the non-negativity, symmetry, and triangle inequality properties of the Poisson correction distance metric, which are important properties in a machine-learning setting. By encoding the spike protein structure and sequences using this comprehensive approach, we aim to uncover hidden patterns in the biological sequences to make accurate predictions about host specificity. Finally, our classification results illustrate that our method can achieve higher predictive accuracy and improve performance over existing baselines.
<div id='section'>Paperid: <span id='pid'>334, <a href='https://arxiv.org/pdf/2301.02931.pdf' target='_blank'>https://arxiv.org/pdf/2301.02931.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Chen, Yingxue Zhang, Xue Liu, Mark Coates
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.02931">Bidirectional Learning for Offline Model-based Biological Sequence Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline model-based optimization aims to maximize a black-box objective function with a static dataset of designs and their scores. In this paper, we focus on biological sequence design to maximize some sequence score. A recent approach employs bidirectional learning, combining a forward mapping for exploitation and a backward mapping for constraint, and it relies on the neural tangent kernel (NTK) of an infinitely wide network to build a proxy model. Though effective, the NTK cannot learn features because of its parametrization, and its use prevents the incorporation of powerful pre-trained Language Models (LMs) that can capture the rich biophysical information in millions of biological sequences. We adopt an alternative proxy model, adding a linear head to a pre-trained LM, and propose a linearization scheme. This yields a closed-form loss and also takes into account the biophysical information in the pre-trained LM. In addition, the forward mapping and the backward mapping play different roles and thus deserve different weights during sequence optimization. To achieve this, we train an auxiliary model and leverage its weak supervision signal via a bi-level optimization framework to effectively learn how to balance the two mappings. Further, by extending the framework, we develop the first learning rate adaptation module \textit{Adaptive}-$Î·$, which is compatible with all gradient-based algorithms for offline model-based optimization. Experimental results on DNA/protein sequence design tasks verify the effectiveness of our algorithm. Our code is available~\href{https://anonymous.4open.science/r/BIB-ICLR2023-Submission/README.md}{here.}
<div id='section'>Paperid: <span id='pid'>335, <a href='https://arxiv.org/pdf/2409.09828.pdf' target='_blank'>https://arxiv.org/pdf/2409.09828.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaixuan Huang, Yukang Yang, Kaidi Fu, Yanyi Chu, Le Cong, Mengdi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.09828">Latent Diffusion Models for Controllable RNA Sequence Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents RNAdiffusion, a latent diffusion model for generating and optimizing discrete RNA sequences of variable lengths. RNA is a key intermediary between DNA and protein, exhibiting high sequence diversity and complex three-dimensional structures to support a wide range of functions. We utilize pretrained BERT-type models to encode raw RNA sequences into token-level, biologically meaningful representations. A Query Transformer is employed to compress such representations into a set of fixed-length latent vectors, with an autoregressive decoder trained to reconstruct RNA sequences from these latent variables. We then develop a continuous diffusion model within this latent space. To enable optimization, we integrate the gradients of reward models--surrogates for RNA functional properties--into the backward diffusion process, thereby generating RNAs with high reward scores. Empirical results confirm that RNAdiffusion generates non-coding RNAs that align with natural distributions across various biological metrics. Further, we fine-tune the diffusion model on mRNA 5' untranslated regions (5'-UTRs) and optimize sequences for high translation efficiencies. Our guided diffusion model effectively generates diverse 5'-UTRs with high Mean Ribosome Loading (MRL) and Translation Efficiency (TE), outperforming baselines in balancing rewards and structural stability trade-off. Our findings hold potential for advancing RNA sequence-function research and therapeutic RNA design.
<div id='section'>Paperid: <span id='pid'>336, <a href='https://arxiv.org/pdf/2402.12558.pdf' target='_blank'>https://arxiv.org/pdf/2402.12558.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>MarÃ­a Teresa GarcÃ­a-OrdÃ¡s, Natalia Arias, Carmen Benavides, Oscar GarcÃ­a-Olalla, JosÃ© Alberto BenÃ­tez-Andrades
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12558">Evaluation of Country Dietary Habits Using Machine Learning Techniques in Relation to Deaths from COVID-19</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>COVID-19 disease has affected almost every country in the world. The large number of infected people and the different mortality rates between countries has given rise to many hypotheses about the key points that make the virus so lethal in some places. In this study, the eating habits of 170 countries were evaluated in order to find correlations between these habits and mortality rates caused by COVID-19 using machine learning techniques that group the countries together according to the different distribution of fat, energy, and protein across 23 different types of food, as well as the amount ingested in kilograms. Results shown how obesity and the high consumption of fats appear in countries with the highest death rates, whereas countries with a lower rate have a higher level of cereal consumption accompanied by a lower total average intake of kilocalories.
<div id='section'>Paperid: <span id='pid'>337, <a href='https://arxiv.org/pdf/2402.09649.pdf' target='_blank'>https://arxiv.org/pdf/2402.09649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Wang, Hehe Fan, Ruijie Quan, Yi Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.09649">ProtChatGPT: Towards Understanding Proteins with Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein research is crucial in various fundamental disciplines, but understanding their intricate structure-function relationships remains challenging. Recent Large Language Models (LLMs) have made significant strides in comprehending task-specific knowledge, suggesting the potential for ChatGPT-like systems specialized in protein to facilitate basic research. In this work, we introduce ProtChatGPT, which aims at learning and understanding protein structures via natural languages. ProtChatGPT enables users to upload proteins, ask questions, and engage in interactive conversations to produce comprehensive answers. The system comprises protein encoders, a Protein-Language Pertaining Transformer (PLP-former), a projection adapter, and an LLM. The protein first undergoes protein encoders and PLP-former to produce protein embeddings, which are then projected by the adapter to conform with the LLM. The LLM finally combines user questions with projected embeddings to generate informative answers. Experiments show that ProtChatGPT can produce promising responses to proteins and their corresponding questions. We hope that ProtChatGPT could form the basis for further exploration and application in protein research. Code and our pre-trained model will be publicly available.
<div id='section'>Paperid: <span id='pid'>338, <a href='https://arxiv.org/pdf/2310.03281.pdf' target='_blank'>https://arxiv.org/pdf/2310.03281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanyi Chu, Dan Yu, Yupeng Li, Kaixuan Huang, Yue Shen, Le Cong, Jason Zhang, Mengdi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03281">A 5' UTR Language Model for Decoding Untranslated Regions of mRNA and Function Predictions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The 5' UTR, a regulatory region at the beginning of an mRNA molecule, plays a crucial role in regulating the translation process and impacts the protein expression level. Language models have showcased their effectiveness in decoding the functions of protein and genome sequences. Here, we introduced a language model for 5' UTR, which we refer to as the UTR-LM. The UTR-LM is pre-trained on endogenous 5' UTRs from multiple species and is further augmented with supervised information including secondary structure and minimum free energy. We fine-tuned the UTR-LM in a variety of downstream tasks. The model outperformed the best-known benchmark by up to 42% for predicting the Mean Ribosome Loading, and by up to 60% for predicting the Translation Efficiency and the mRNA Expression Level. The model also applies to identifying unannotated Internal Ribosome Entry Sites within the untranslated region and improves the AUPR from 0.37 to 0.52 compared to the best baseline. Further, we designed a library of 211 novel 5' UTRs with high predicted values of translation efficiency and evaluated them via a wet-lab assay. Experiment results confirmed that our top designs achieved a 32.5% increase in protein production level relative to well-established 5' UTR optimized for therapeutics.
<div id='section'>Paperid: <span id='pid'>339, <a href='https://arxiv.org/pdf/2305.09617.pdf' target='_blank'>https://arxiv.org/pdf/2305.09617.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal, Mike Schaekermann, Amy Wang, Mohamed Amin, Sami Lachgar, Philip Mansfield, Sushant Prakash, Bradley Green, Ewa Dominowska, Blaise Aguera y Arcas, Nenad Tomasev, Yun Liu, Renee Wong, Christopher Semturs, S. Sara Mahdavi, Joelle Barral, Dale Webster, Greg S. Corrado, Yossi Matias, Shekoofeh Azizi, Alan Karthikesalingam, Vivek Natarajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09617">Towards Expert-Level Medical Question Answering with Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent artificial intelligence (AI) systems have reached milestones in "grand challenges" ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge.
  Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a "passing" score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach.
  Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLM by over 19% and setting a new state-of-the-art. We also observed performance approaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU clinical topics datasets.
  We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions, physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p < 0.001). We also observed significant improvements compared to Med-PaLM on every evaluation axis (p < 0.001) on newly introduced datasets of 240 long-form "adversarial" questions to probe LLM limitations.
  While further studies are necessary to validate the efficacy of these models in real-world settings, these results highlight rapid progress towards physician-level performance in medical question answering.
<div id='section'>Paperid: <span id='pid'>340, <a href='https://arxiv.org/pdf/2301.01743.pdf' target='_blank'>https://arxiv.org/pdf/2301.01743.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Noever, Forrest McKee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.01743">Chatbots as Problem Solvers: Playing Twenty Questions with Role Reversals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>New chat AI applications like ChatGPT offer an advanced understanding of question context and memory across multi-step tasks, such that experiments can test its deductive reasoning. This paper proposes a multi-role and multi-step challenge, where ChatGPT plays the classic twenty-questions game but innovatively switches roles from the questioner to the answerer. The main empirical result establishes that this generation of chat applications can guess random object names in fewer than twenty questions (average, 12) and correctly guess 94% of the time across sixteen different experimental setups. The research introduces four novel cases where the chatbot fields the questions, asks the questions, both question-answer roles, and finally tries to guess appropriate contextual emotions. One task that humans typically fail but trained chat applications complete involves playing bilingual games of twenty questions (English answers to Spanish questions). Future variations address direct problem-solving using a similar inquisitive format to arrive at novel outcomes deductively, such as patentable inventions or combination thinking. Featured applications of this dialogue format include complex protein designs, neuroscience metadata, and child development educational materials.
<div id='section'>Paperid: <span id='pid'>341, <a href='https://arxiv.org/pdf/2505.21928.pdf' target='_blank'>https://arxiv.org/pdf/2505.21928.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lianghui Zhu, Xitong Ling, Minxi Ouyang, Xiaoping Liu, Tian Guan, Mingxi Fu, Zhiqiang Cheng, Fanglei Fu, Maomao Zeng, Liming Liu, Song Duan, Qiang Huang, Ying Xiao, Jianming Li, Shanming Lu, Zhenghua Piao, Mingxi Zhu, Yibo Jin, Shan Xu, Qiming He, Yizhi Wang, Junru Cheng, Xuanyu Wang, Luxi Xie, Houqiang Li, Sufang Tian, Yonghong He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21928">Subspecialty-Specific Foundation Model for Intelligent Gastrointestinal Pathology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gastrointestinal (GI) diseases represent a clinically significant burden, necessitating precise diagnostic approaches to optimize patient outcomes. Conventional histopathological diagnosis suffers from limited reproducibility and diagnostic variability. To overcome these limitations, we develop Digepath, a specialized foundation model for GI pathology. Our framework introduces a dual-phase iterative optimization strategy combining pretraining with fine-screening, specifically designed to address the detection of sparsely distributed lesion areas in whole-slide images. Digepath is pretrained on over 353 million multi-scale images from 210,043 H&E-stained slides of GI diseases. It attains state-of-the-art performance on 33 out of 34 tasks related to GI pathology, including pathological diagnosis, protein expression status prediction, gene mutation prediction, and prognosis evaluation. We further translate the intelligent screening module for early GI cancer and achieve near-perfect 99.70% sensitivity across nine independent medical institutions. This work not only advances AI-driven precision pathology for GI diseases but also bridge critical gaps in histopathological practice.
<div id='section'>Paperid: <span id='pid'>342, <a href='https://arxiv.org/pdf/2502.07527.pdf' target='_blank'>https://arxiv.org/pdf/2502.07527.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingce Xia, Peiran Jin, Shufang Xie, Liang He, Chuan Cao, Renqian Luo, Guoqing Liu, Yue Wang, Zequn Liu, Yuan-Jyue Chen, Zekun Guo, Yeqi Bai, Pan Deng, Yaosen Min, Ziheng Lu, Hongxia Hao, Han Yang, Jielan Li, Chang Liu, Jia Zhang, Jianwei Zhu, Ran Bi, Kehan Wu, Wei Zhang, Kaiyuan Gao, Qizhi Pei, Qian Wang, Xixian Liu, Yanting Li, Houtian Zhu, Yeqing Lu, Mingqian Ma, Zun Wang, Tian Xie, Krzysztof Maziarz, Marwin Segler, Zhao Yang, Zilong Chen, Yu Shi, Shuxin Zheng, Lijun Wu, Chen Hu, Peggy Dai, Tie-Yan Liu, Haiguang Liu, Tao Qin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07527">Nature Language Model: Deciphering the Language of Nature for Scientific Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models have revolutionized natural language processing and artificial intelligence, significantly enhancing how machines comprehend and generate human languages. Inspired by the success of these foundation models, researchers have developed foundation models for individual scientific domains, including small molecules, materials, proteins, DNA, RNA and even cells. However, these models are typically trained in isolation, lacking the ability to integrate across different scientific domains. Recognizing that entities within these domains can all be represented as sequences, which together form the "language of nature", we introduce Nature Language Model (NatureLM), a sequence-based science foundation model designed for scientific discovery. Pre-trained with data from multiple scientific domains, NatureLM offers a unified, versatile model that enables various applications including: (i) generating and optimizing small molecules, proteins, RNA, and materials using text instructions; (ii) cross-domain generation/design, such as protein-to-molecule and protein-to-RNA generation; and (iii) top performance across different domains, matching or surpassing state-of-the-art specialist models. NatureLM offers a promising generalist approach for various scientific tasks, including drug discovery (hit generation/optimization, ADMET optimization, synthesis), novel material design, and the development of therapeutic proteins or nucleotides. We have developed NatureLM models in different sizes (1 billion, 8 billion, and 46.7 billion parameters) and observed a clear improvement in performance as the model size increases.
<div id='section'>Paperid: <span id='pid'>343, <a href='https://arxiv.org/pdf/2507.00445.pdf' target='_blank'>https://arxiv.org/pdf/2507.00445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyu Su, Xiner Li, Masatoshi Uehara, Sunwoo Kim, Yulai Zhao, Gabriele Scalia, Ehsan Hajiramezanali, Tommaso Biancalani, Degui Zhi, Shuiwang Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00445">Iterative Distillation for Reward-Guided Fine-Tuning of Diffusion Models in Biomolecular Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We address the problem of fine-tuning diffusion models for reward-guided generation in biomolecular design. While diffusion models have proven highly effective in modeling complex, high-dimensional data distributions, real-world applications often demand more than high-fidelity generation, requiring optimization with respect to potentially non-differentiable reward functions such as physics-based simulation or rewards based on scientific knowledge. Although RL methods have been explored to fine-tune diffusion models for such objectives, they often suffer from instability, low sample efficiency, and mode collapse due to their on-policy nature. In this work, we propose an iterative distillation-based fine-tuning framework that enables diffusion models to optimize for arbitrary reward functions. Our method casts the problem as policy distillation: it collects off-policy data during the roll-in phase, simulates reward-based soft-optimal policies during roll-out, and updates the model by minimizing the KL divergence between the simulated soft-optimal policy and the current model policy. Our off-policy formulation, combined with KL divergence minimization, enhances training stability and sample efficiency compared to existing RL-based methods. Empirical results demonstrate the effectiveness and superior reward optimization of our approach across diverse tasks in protein, small molecule, and regulatory DNA design.
<div id='section'>Paperid: <span id='pid'>344, <a href='https://arxiv.org/pdf/2506.19862.pdf' target='_blank'>https://arxiv.org/pdf/2506.19862.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junjie Xu, Jiahao Zhang, Mangal Prakash, Xiang Zhang, Suhang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19862">DualEquiNet: A Dual-Space Hierarchical Equivariant Network for Large Biomolecules</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geometric graph neural networks (GNNs) that respect E(3) symmetries have achieved strong performance on small molecule modeling, but they face scalability and expressiveness challenges when applied to large biomolecules such as RNA and proteins. These systems require models that can simultaneously capture fine-grained atomic interactions, long-range dependencies across spatially distant components, and biologically relevant hierarchical structure, such as atoms forming residues, which in turn form higher-order domains. Existing geometric GNNs, which typically operate exclusively in either Euclidean or Spherical Harmonics space, are limited in their ability to capture both the fine-scale atomic details and the long-range, symmetry-aware dependencies required for modeling the multi-scale structure of large biomolecules. We introduce DualEquiNet, a Dual-Space Hierarchical Equivariant Network that constructs complementary representations in both Euclidean and Spherical Harmonics spaces to capture local geometry and global symmetry-aware features. DualEquiNet employs bidirectional cross-space message passing and a novel Cross-Space Interaction Pooling mechanism to hierarchically aggregate atomic features into biologically meaningful units, such as residues, enabling efficient and expressive multi-scale modeling for large biomolecular systems. DualEquiNet achieves state-of-the-art performance on multiple existing benchmarks for RNA property prediction and protein modeling, and outperforms prior methods on two newly introduced 3D structural benchmarks demonstrating its broad effectiveness across a range of large biomolecule modeling tasks.
<div id='section'>Paperid: <span id='pid'>345, <a href='https://arxiv.org/pdf/2410.06211.pdf' target='_blank'>https://arxiv.org/pdf/2410.06211.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex M. Tseng, Gokcen Eraslan, Tommaso Biancalani, Gabriele Scalia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06211">A mechanistically interpretable neural network for regulatory genomics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks excel in mapping genomic DNA sequences to associated readouts (e.g., protein-DNA binding). Beyond prediction, the goal of these networks is to reveal to scientists the underlying motifs (and their syntax) which drive genome regulation. Traditional methods that extract motifs from convolutional filters suffer from the uninterpretable dispersion of information across filters and layers. Other methods which rely on importance scores can be unstable and unreliable. Instead, we designed a novel mechanistically interpretable architecture for regulatory genomics, where motifs and their syntax are directly encoded and readable from the learned weights and activations. We provide theoretical and empirical evidence of our architecture's full expressivity, while still being highly interpretable. Through several experiments, we show that our architecture excels in de novo motif discovery and motif instance calling, is robust to variable sequence contexts, and enables fully interpretable generation of novel functional sequences.
<div id='section'>Paperid: <span id='pid'>346, <a href='https://arxiv.org/pdf/2409.07462.pdf' target='_blank'>https://arxiv.org/pdf/2409.07462.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gengmo Zhou, Zhen Wang, Feng Yu, Guolin Ke, Zhewei Wei, Zhifeng Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.07462">S-MolSearch: 3D Semi-supervised Contrastive Learning for Bioactive Molecule Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Virtual Screening is an essential technique in the early phases of drug discovery, aimed at identifying promising drug candidates from vast molecular libraries. Recently, ligand-based virtual screening has garnered significant attention due to its efficacy in conducting extensive database screenings without relying on specific protein-binding site information. Obtaining binding affinity data for complexes is highly expensive, resulting in a limited amount of available data that covers a relatively small chemical space. Moreover, these datasets contain a significant amount of inconsistent noise. It is challenging to identify an inductive bias that consistently maintains the integrity of molecular activity during data augmentation. To tackle these challenges, we propose S-MolSearch, the first framework to our knowledge, that leverages molecular 3D information and affinity information in semi-supervised contrastive learning for ligand-based virtual screening. Drawing on the principles of inverse optimal transport, S-MolSearch efficiently processes both labeled and unlabeled data, training molecular structural encoders while generating soft labels for the unlabeled data. This design allows S-MolSearch to adaptively utilize unlabeled data within the learning process. Empirically, S-MolSearch demonstrates superior performance on widely-used benchmarks LIT-PCBA and DUD-E. It surpasses both structure-based and ligand-based virtual screening methods for AUROC, BEDROC and EF.
<div id='section'>Paperid: <span id='pid'>347, <a href='https://arxiv.org/pdf/2408.05196.pdf' target='_blank'>https://arxiv.org/pdf/2408.05196.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stephen Zhewen Lu, Ziqing Lu, Ehsan Hajiramezanali, Tommaso Biancalani, Yoshua Bengio, Gabriele Scalia, MichaÅ Koziarski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.05196">Cell Morphology-Guided Small Molecule Generation with GFlowNets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-content phenotypic screening, including high-content imaging (HCI), has gained popularity in the last few years for its ability to characterize novel therapeutics without prior knowledge of the protein target. When combined with deep learning techniques to predict and represent molecular-phenotype interactions, these advancements hold the potential to significantly accelerate and enhance drug discovery applications. This work focuses on the novel task of HCI-guided molecular design. Generative models for molecule design could be guided by HCI data, for example with a supervised model that links molecules to phenotypes of interest as a reward function. However, limited labeled data, combined with the high-dimensional readouts, can make training these methods challenging and impractical. We consider an alternative approach in which we leverage an unsupervised multimodal joint embedding to define a latent similarity as a reward for GFlowNets. The proposed model learns to generate new molecules that could produce phenotypic effects similar to those of the given image target, without relying on pre-annotated phenotypic labels. We demonstrate that the proposed method generates molecules with high morphological and structural similarity to the target, increasing the likelihood of similar biological activity, as confirmed by an independent oracle model.
<div id='section'>Paperid: <span id='pid'>348, <a href='https://arxiv.org/pdf/2405.19673.pdf' target='_blank'>https://arxiv.org/pdf/2405.19673.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Masatoshi Uehara, Yulai Zhao, Ehsan Hajiramezanali, Gabriele Scalia, GÃ¶kcen Eraslan, Avantika Lal, Sergey Levine, Tommaso Biancalani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.19673">Bridging Model-Based Optimization and Generative Modeling via Conservative Fine-Tuning of Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI-driven design problems, such as DNA/protein sequence design, are commonly tackled from two angles: generative modeling, which efficiently captures the feasible design space (e.g., natural images or biological sequences), and model-based optimization, which utilizes reward models for extrapolation. To combine the strengths of both approaches, we adopt a hybrid method that fine-tunes cutting-edge diffusion models by optimizing reward models through RL. Although prior work has explored similar avenues, they primarily focus on scenarios where accurate reward models are accessible. In contrast, we concentrate on an offline setting where a reward model is unknown, and we must learn from static offline datasets, a common scenario in scientific domains. In offline scenarios, existing approaches tend to suffer from overoptimization, as they may be misled by the reward model in out-of-distribution regions. To address this, we introduce a conservative fine-tuning approach, BRAID, by optimizing a conservative reward model, which includes additional penalization outside of offline data distributions. Through empirical and theoretical analysis, we demonstrate the capability of our approach to outperform the best designs in offline data, leveraging the extrapolation capabilities of reward models while avoiding the generation of invalid designs through pre-trained diffusion models.
<div id='section'>Paperid: <span id='pid'>349, <a href='https://arxiv.org/pdf/2405.14545.pdf' target='_blank'>https://arxiv.org/pdf/2405.14545.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongzhi Zhang, Xiuwen Gong, Shirui Pan, Jia Wu, Bo Du, Wenbin Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14545">A Cross-Field Fusion Strategy for Drug-Target Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drug-target interaction (DTI) prediction is a critical component of the drug discovery process. In the drug development engineering field, predicting novel drug-target interactions is extremely crucial.However, although existing methods have achieved high accuracy levels in predicting known drugs and drug targets, they fail to utilize global protein information during DTI prediction. This leads to an inability to effectively predict interaction the interactions between novel drugs and their targets. As a result, the cross-field information fusion strategy is employed to acquire local and global protein information. Thus, we propose the siamese drug-target interaction SiamDTI prediction method, which utilizes a double channel network structure for cross-field supervised learning.Experimental results on three benchmark datasets demonstrate that SiamDTI achieves higher accuracy levels than other state-of-the-art (SOTA) methods on novel drugs and targets.Additionally, SiamDTI's performance with known drugs and targets is comparable to that of SOTA approachs. The code is available at https://anonymous.4open.science/r/DDDTI-434D.
<div id='section'>Paperid: <span id='pid'>350, <a href='https://arxiv.org/pdf/2404.15805.pdf' target='_blank'>https://arxiv.org/pdf/2404.15805.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shujian Jiao, Bingxuan Li, Lei Wang, Xiaojin Zhang, Wei Chen, Jiajie Peng, Zhongyu Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.15805">Beyond ESM2: Graph-Enhanced Protein Sequence Modeling with Efficient Clustering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are essential to life's processes, underpinning evolution and diversity. Advances in sequencing technology have revealed millions of proteins, underscoring the need for sophisticated pre-trained protein models for biological analysis and AI development. Facebook's ESM2, the most advanced protein language model to date, leverages a masked prediction task for unsupervised learning, crafting amino acid representations with notable biochemical accuracy. Yet, it lacks in delivering functional protein insights, signaling an opportunity for enhancing representation quality.Our study addresses this gap by incorporating protein family classification into ESM2's training.This approach, augmented with Community Propagation-Based Clustering Algorithm, improves global protein representations, while a contextual prediction task fine-tunes local amino acid accuracy. Significantly, our model achieved state-of-the-art results in several downstream experiments, demonstrating the power of combining global and local methodologies to substantially boost protein representation quality.
<div id='section'>Paperid: <span id='pid'>351, <a href='https://arxiv.org/pdf/2403.07920.pdf' target='_blank'>https://arxiv.org/pdf/2403.07920.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Le Zhuo, Zewen Chi, Minghao Xu, Heyan Huang, Heqi Zheng, Conghui He, Xian-Ling Mao, Wentao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.07920">ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose ProtLLM, a versatile cross-modal large language model (LLM) for both protein-centric and protein-language tasks. ProtLLM features a unique dynamic protein mounting mechanism, enabling it to handle complex inputs where the natural language text is interspersed with an arbitrary number of proteins. Besides, we propose the protein-as-word language modeling approach to train ProtLLM. By developing a specialized protein vocabulary, we equip the model with the capability to predict not just natural language but also proteins from a vast pool of candidates. Additionally, we construct a large-scale interleaved protein-text dataset, named InterPT, for pre-training. This dataset comprehensively encompasses both (1) structured data sources like protein annotations and (2) unstructured data sources like biological research papers, thereby endowing ProtLLM with crucial knowledge for understanding proteins. We evaluate ProtLLM on classic supervised protein-centric tasks and explore its novel protein-language applications. Experimental results demonstrate that ProtLLM not only achieves superior performance against protein-specialized baselines on protein-centric tasks but also induces zero-shot and in-context learning capabilities on protein-language tasks.
<div id='section'>Paperid: <span id='pid'>352, <a href='https://arxiv.org/pdf/2302.07134.pdf' target='_blank'>https://arxiv.org/pdf/2302.07134.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuejiang Yu, Shuqi Lu, Zhifeng Gao, Hang Zheng, Guolin Ke
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.07134">Do Deep Learning Models Really Outperform Traditional Approaches in Molecular Docking?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking, given a ligand molecule and a ligand binding site (called ``pocket'') on a protein, predicting the binding mode of the protein-ligand complex, is a widely used technique in drug design. Many deep learning models have been developed for molecular docking, while most existing deep learning models perform docking on the whole protein, rather than on a given pocket as the traditional molecular docking approaches, which does not match common needs. What's more, they claim to perform better than traditional molecular docking, but the approach of comparison is not fair, since traditional methods are not designed for docking on the whole protein without a given pocket. In this paper, we design a series of experiments to examine the actual performance of these deep learning models and traditional methods. For a fair comparison, we decompose the docking on the whole protein into two steps, pocket searching and docking on a given pocket, and build pipelines to evaluate traditional methods and deep learning methods respectively. We find that deep learning models are actually good at pocket searching, but traditional methods are better than deep learning models at docking on given pockets. Overall, our work explicitly reveals some potential problems in current deep learning models for molecular docking and provides several suggestions for future works.
<div id='section'>Paperid: <span id='pid'>353, <a href='https://arxiv.org/pdf/2209.15171.pdf' target='_blank'>https://arxiv.org/pdf/2209.15171.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoran Qiao, Weili Nie, Arash Vahdat, Thomas F. Miller, Anima Anandkumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.15171">State-specific protein-ligand complex structure prediction with a multi-scale deep generative model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The binding complexes formed by proteins and small molecule ligands are ubiquitous and critical to life. Despite recent advancements in protein structure prediction, existing algorithms are so far unable to systematically predict the binding ligand structures along with their regulatory effects on protein folding. To address this discrepancy, we present NeuralPLexer, a computational approach that can directly predict protein-ligand complex structures solely using protein sequence and ligand molecular graph inputs. NeuralPLexer adopts a deep generative model to sample the 3D structures of the binding complex and their conformational changes at an atomistic resolution. The model is based on a diffusion process that incorporates essential biophysical constraints and a multi-scale geometric deep learning system to iteratively sample residue-level contact maps and all heavy-atom coordinates in a hierarchical manner. NeuralPLexer achieves state-of-the-art performance compared to all existing methods on benchmarks for both protein-ligand blind docking and flexible binding site structure recovery. Moreover, owing to its specificity in sampling both ligand-free-state and ligand-bound-state ensembles, NeuralPLexer consistently outperforms AlphaFold2 in terms of global protein structure accuracy on both representative structure pairs with large conformational changes (average TM-score=0.93) and recently determined ligand-binding proteins (average TM-score=0.89). Case studies reveal that the predicted conformational variations are consistent with structure determination experiments for important targets, including human KRAS$^\textrm{G12C}$, ketol-acid reductoisomerase, and purine GPCRs. Our study suggests that a data-driven approach can capture the structural cooperativity between proteins and small molecules, showing promise in accelerating the design of enzymes, drug molecules, and beyond.
<div id='section'>Paperid: <span id='pid'>354, <a href='https://arxiv.org/pdf/2207.09765.pdf' target='_blank'>https://arxiv.org/pdf/2207.09765.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Firtina, Kamlesh Pillai, Gurpreet S. Kalsi, Bharathwaj Suresh, Damla Senol Cali, Jeremie Kim, Taha Shahroodi, Meryem Banu Cavlak, Joel Lindegger, Mohammed Alser, Juan GÃ³mez Luna, Sreenivas Subramoney, Onur Mutlu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.09765">ApHMM: Accelerating Profile Hidden Markov Models for Fast and Energy-Efficient Genome Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Profile hidden Markov models (pHMMs) are widely employed in various bioinformatics applications to identify similarities between biological sequences, such as DNA or protein sequences. In pHMMs, sequences are represented as graph structures. These probabilities are subsequently used to compute the similarity score between a sequence and a pHMM graph. The Baum-Welch algorithm, a prevalent and highly accurate method, utilizes these probabilities to optimize and compute similarity scores. However, the Baum-Welch algorithm is computationally intensive, and existing solutions offer either software-only or hardware-only approaches with fixed pHMM designs. We identify an urgent need for a flexible, high-performance, and energy-efficient HW/SW co-design to address the major inefficiencies in the Baum-Welch algorithm for pHMMs.
  We introduce ApHMM, the first flexible acceleration framework designed to significantly reduce both computational and energy overheads associated with the Baum-Welch algorithm for pHMMs. ApHMM tackles the major inefficiencies in the Baum-Welch algorithm by 1) designing flexible hardware to accommodate various pHMM designs, 2) exploiting predictable data dependency patterns through on-chip memory with memoization techniques, 3) rapidly filtering out negligible computations using a hardware-based filter, and 4) minimizing redundant computations.
  ApHMM achieves substantial speedups of 15.55x - 260.03x, 1.83x - 5.34x, and 27.97x when compared to CPU, GPU, and FPGA implementations of the Baum-Welch algorithm, respectively. ApHMM outperforms state-of-the-art CPU implementations in three key bioinformatics applications: 1) error correction, 2) protein family search, and 3) multiple sequence alignment, by 1.29x - 59.94x, 1.03x - 1.75x, and 1.03x - 1.95x, respectively, while improving their energy efficiency by 64.24x - 115.46x, 1.75x, 1.96x.
<div id='section'>Paperid: <span id='pid'>355, <a href='https://arxiv.org/pdf/2509.18153.pdf' target='_blank'>https://arxiv.org/pdf/2509.18153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanqun Cao, Marcelo D. T. Torres, Jingjie Zhang, Zijun Gao, Fang Wu, Chunbin Gu, Jure Leskovec, Yejin Choi, Cesar de la Fuente-Nunez, Guangyong Chen, Pheng-Ann Heng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18153">A deep reinforcement learning platform for antibiotic discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antimicrobial resistance (AMR) is projected to cause up to 10 million deaths annually by 2050, underscoring the urgent need for new antibiotics. Here we present ApexAmphion, a deep-learning framework for de novo design of antibiotics that couples a 6.4-billion-parameter protein language model with reinforcement learning. The model is first fine-tuned on curated peptide data to capture antimicrobial sequence regularities, then optimised with proximal policy optimization against a composite reward that combines predictions from a learned minimum inhibitory concentration (MIC) classifier with differentiable physicochemical objectives. In vitro evaluation of 100 designed peptides showed low MIC values (nanomolar range in some cases) for all candidates (100% hit rate). Moreover, 99 our of 100 compounds exhibited broad-spectrum antimicrobial activity against at least two clinically relevant bacteria. The lead molecules killed bacteria primarily by potently targeting the cytoplasmic membrane. By unifying generation, scoring and multi-objective optimization with deep reinforcement learning in a single pipeline, our approach rapidly produces diverse, potent candidates, offering a scalable route to peptide antibiotics and a platform for iterative steering toward potency and developability within hours.
<div id='section'>Paperid: <span id='pid'>356, <a href='https://arxiv.org/pdf/2506.03028.pdf' target='_blank'>https://arxiv.org/pdf/2506.03028.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junde Xu, Zijun Gao, Xinyi Zhou, Jie Hu, Xingyi Cheng, Le Song, Guangyong Chen, Pheng-Ann Heng, Jiezhong Qiu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.03028">Protein Inverse Folding From Structure Feedback</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The inverse folding problem, aiming to design amino acid sequences that fold into desired three-dimensional structures, is pivotal for various biotechnological applications. Here, we introduce a novel approach leveraging Direct Preference Optimization (DPO) to fine-tune an inverse folding model using feedback from a protein folding model. Given a target protein structure, we begin by sampling candidate sequences from the inverse-folding model, then predict the three-dimensional structure of each sequence with the folding model to generate pairwise structural-preference labels. These labels are used to fine-tune the inverse-folding model under the DPO objective. Our results on the CATH 4.2 test set demonstrate that DPO fine-tuning not only improves sequence recovery of baseline models but also leads to a significant improvement in average TM-Score from 0.77 to 0.81, indicating enhanced structure similarity. Furthermore, iterative application of our DPO-based method on challenging protein structures yields substantial gains, with an average TM-Score increase of 79.5\% with regard to the baseline model. This work establishes a promising direction for enhancing protein sequence design ability from structure feedback by effectively utilizing preference optimization.
<div id='section'>Paperid: <span id='pid'>357, <a href='https://arxiv.org/pdf/2410.13106.pdf' target='_blank'>https://arxiv.org/pdf/2410.13106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jakub Grudzien Kuba, Pieter Abbeel, Sergey Levine
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13106">Cliqueformer: Model-Based Optimization with Structured Transformers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large neural networks excel at prediction tasks, but their application to design problems, such as protein engineering or materials discovery, requires solving offline model-based optimization (MBO) problems. While predictive models may not directly translate to effective design, recent MBO algorithms incorporate reinforcement learning and generative modeling approaches. Meanwhile, theoretical work suggests that exploiting the target function's structure can enhance MBO performance. We present Cliqueformer, a transformer-based architecture that learns the black-box function's structure through functional graphical models (FGM), addressing distribution shift without relying on explicit conservative approaches. Across various domains, including chemical and genetic design tasks, Cliqueformer demonstrates superior performance compared to existing methods.
<div id='section'>Paperid: <span id='pid'>358, <a href='https://arxiv.org/pdf/2410.04461.pdf' target='_blank'>https://arxiv.org/pdf/2410.04461.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyeonah Kim, Minsu Kim, Taeyoung Yun, Sanghyeok Choi, Emmanuel Bengio, Alex HernÃ¡ndez-GarcÃ­a, Jinkyoo Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04461">Improved Off-policy Reinforcement Learning in Biological Sequence Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing biological sequences with desired properties is challenging due to vast search spaces and limited evaluation budgets. Although reinforcement learning methods use proxy models for rapid reward evaluation, insufficient training data can cause proxy misspecification on out-of-distribution inputs. To address this, we propose a novel off-policy search, $Î´$-Conservative Search, that enhances robustness by restricting policy exploration to reliable regions. Starting from high-score offline sequences, we inject noise by randomly masking tokens with probability $Î´$, then denoise them using our policy. We further adapt $Î´$ based on proxy uncertainty on each data point, aligning the level of conservativeness with model confidence. Experimental results show that our conservative search consistently enhances the off-policy training, outperforming existing machine learning methods in discovering high-score sequences across diverse tasks, including DNA, RNA, protein, and peptide design.
<div id='section'>Paperid: <span id='pid'>359, <a href='https://arxiv.org/pdf/2401.06173.pdf' target='_blank'>https://arxiv.org/pdf/2401.06173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahao Qiu, Hui Yuan, Jinghong Zhang, Wentao Chen, Huazheng Wang, Mengdi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.06173">Tree Search-Based Evolutionary Bandits for Protein Sequence Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While modern biotechnologies allow synthesizing new proteins and function measurements at scale, efficiently exploring a protein sequence space and engineering it remains a daunting task due to the vast sequence space of any given protein. Protein engineering is typically conducted through an iterative process of adding mutations to the wild-type or lead sequences, recombination of mutations, and running new rounds of screening. To enhance the efficiency of such a process, we propose a tree search-based bandit learning method, which expands a tree starting from the initial sequence with the guidance of a bandit machine learning model. Under simplified assumptions and a Gaussian Process prior, we provide theoretical analysis and a Bayesian regret bound, demonstrating that the combination of local search and bandit learning method can efficiently discover a near-optimal design. The full algorithm is compatible with a suite of randomized tree search heuristics, machine learning models, pre-trained embeddings, and bandit techniques. We test various instances of the algorithm across benchmark protein datasets using simulated screens. Experiment results demonstrate that the algorithm is both sample-efficient and able to find top designs using reasonably small mutation counts.
<div id='section'>Paperid: <span id='pid'>360, <a href='https://arxiv.org/pdf/2401.05442.pdf' target='_blank'>https://arxiv.org/pdf/2401.05442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jakub Grudzien Kuba, Masatoshi Uehara, Pieter Abbeel, Sergey Levine
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05442">Functional Graphical Models: Structure Enables Offline Data-Driven Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While machine learning models are typically trained to solve prediction problems, we might often want to use them for optimization problems. For example, given a dataset of proteins and their corresponding fluorescence levels, we might want to optimize for a new protein with the highest possible fluorescence. This kind of data-driven optimization (DDO) presents a range of challenges beyond those in standard prediction problems, since we need models that successfully predict the performance of new designs that are better than the best designs seen in the training set. It is not clear theoretically when existing approaches can even perform better than the naive approach that simply selects the best design in the dataset. In this paper, we study how structure can enable sample-efficient data-driven optimization. To formalize the notion of structure, we introduce functional graphical models (FGMs) and show theoretically how they can provide for principled data-driven optimization by decomposing the original high-dimensional optimization problem into smaller sub-problems. This allows us to derive much more practical regret bounds for DDO, and the result implies that DDO with FGMs can achieve nearly optimal designs in situations where naive approaches fail due to insufficient coverage of the offline data. We further present a data-driven optimization algorithm that inferes the FGM structure itself, either over the original input variables or a latent variable representation of the inputs.
<div id='section'>Paperid: <span id='pid'>361, <a href='https://arxiv.org/pdf/2508.15480.pdf' target='_blank'>https://arxiv.org/pdf/2508.15480.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianhui Wang, Wenyu Zhu, Bowen Gao, Xin Hong, Ya-Qin Zhang, Wei-Ying Ma, Yanyan Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15480">Learning Protein-Ligand Binding in Hyperbolic Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-ligand binding prediction is central to virtual screening and affinity ranking, two fundamental tasks in drug discovery. While recent retrieval-based methods embed ligands and protein pockets into Euclidean space for similarity-based search, the geometry of Euclidean embeddings often fails to capture the hierarchical structure and fine-grained affinity variations intrinsic to molecular interactions. In this work, we propose HypSeek, a hyperbolic representation learning framework that embeds ligands, protein pockets, and sequences into Lorentz-model hyperbolic space. By leveraging the exponential geometry and negative curvature of hyperbolic space, HypSeek enables expressive, affinity-sensitive embeddings that can effectively model both global activity and subtle functional differences-particularly in challenging cases such as activity cliffs, where structurally similar ligands exhibit large affinity gaps. Our mode unifies virtual screening and affinity ranking in a single framework, introducing a protein-guided three-tower architecture to enhance representational structure. HypSeek improves early enrichment in virtual screening on DUD-E from 42.63 to 51.44 (+20.7%) and affinity ranking correlation on JACS from 0.5774 to 0.7239 (+25.4%), demonstrating the benefits of hyperbolic geometry across both tasks and highlighting its potential as a powerful inductive bias for protein-ligand modeling.
<div id='section'>Paperid: <span id='pid'>362, <a href='https://arxiv.org/pdf/2507.20280.pdf' target='_blank'>https://arxiv.org/pdf/2507.20280.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keyan Ding, Jing Yu, Junjie Huang, Yuchen Yang, Qiang Zhang, Huajun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.20280">SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific research increasingly relies on specialized computational tools, yet effectively utilizing these tools demands substantial domain expertise. While Large Language Models (LLMs) show promise in tool automation, they struggle to seamlessly integrate and orchestrate multiple tools for complex scientific workflows. Here, we present SciToolAgent, an LLM-powered agent that automates hundreds of scientific tools across biology, chemistry, and materials science. At its core, SciToolAgent leverages a scientific tool knowledge graph that enables intelligent tool selection and execution through graph-based retrieval-augmented generation. The agent also incorporates a comprehensive safety-checking module to ensure responsible and ethical tool usage. Extensive evaluations on a curated benchmark demonstrate that SciToolAgent significantly outperforms existing approaches. Case studies in protein engineering, chemical reactivity prediction, chemical synthesis, and metal-organic framework screening further demonstrate SciToolAgent's capability to automate complex scientific workflows, making advanced research tools accessible to both experts and non-experts.
<div id='section'>Paperid: <span id='pid'>363, <a href='https://arxiv.org/pdf/2507.10923.pdf' target='_blank'>https://arxiv.org/pdf/2507.10923.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhao Wang, Keyan Ding, Kehua Feng, Zeyuan Wang, Ming Qin, Xiaotong Li, Qiang Zhang, Huajun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10923">Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models have emerged as powerful tools for sequence generation, offering substantial advantages in functional optimization and denovo design. However, these models also present significant risks of generating harmful protein sequences, such as those that enhance viral transmissibility or evade immune responses. These concerns underscore critical biosafety and ethical challenges. To address these issues, we propose a Knowledge-guided Preference Optimization (KPO) framework that integrates prior knowledge via a Protein Safety Knowledge Graph. This framework utilizes an efficient graph pruning strategy to identify preferred sequences and employs reinforcement learning to minimize the risk of generating harmful proteins. Experimental results demonstrate that KPO effectively reduces the likelihood of producing hazardous sequences while maintaining high functionality, offering a robust safety assurance framework for applying generative models in biotechnology.
<div id='section'>Paperid: <span id='pid'>364, <a href='https://arxiv.org/pdf/2506.19820.pdf' target='_blank'>https://arxiv.org/pdf/2506.19820.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felix Faltings, Hannes Stark, Regina Barzilay, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19820">ProxelGen: Generating Proteins as 3D Densities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop ProxelGen, a protein structure generative model that operates on 3D densities as opposed to the prevailing 3D point cloud representations. Representing proteins as voxelized densities, or proxels, enables new tasks and conditioning capabilities. We generate proteins encoded as proxels via a 3D CNN-based VAE in conjunction with a diffusion model operating on its latent space. Compared to state-of-the-art models, ProxelGen's samples achieve higher novelty, better FID scores, and the same level of designability as the training set. ProxelGen's advantages are demonstrated in a standard motif scaffolding benchmark, and we show how 3D density-based generation allows for more flexible shape conditioning.
<div id='section'>Paperid: <span id='pid'>365, <a href='https://arxiv.org/pdf/2506.05768.pdf' target='_blank'>https://arxiv.org/pdf/2506.05768.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenyu Zhu, Jianhui Wang, Bowen Gao, Yinjun Jia, Haichuan Tan, Ya-Qin Zhang, Wei-Ying Ma, Yanyan Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.05768">AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Virtual screening (VS) is a critical component of modern drug discovery, yet most existing methods--whether physics-based or deep learning-based--are developed around holo protein structures with known ligand-bound pockets. Consequently, their performance degrades significantly on apo or predicted structures such as those from AlphaFold2, which are more representative of real-world early-stage drug discovery, where pocket information is often missing. In this paper, we introduce an alignment-and-aggregation framework to enable accurate virtual screening under structural uncertainty. Our method comprises two core components: (1) a tri-modal contrastive learning module that aligns representations of the ligand, the holo pocket, and cavities detected from structures, thereby enhancing robustness to pocket localization error; and (2) a cross-attention based adapter for dynamically aggregating candidate binding sites, enabling the model to learn from activity data even without precise pocket annotations. We evaluated our method on a newly curated benchmark of apo structures, where it significantly outperforms state-of-the-art methods in blind apo setting, improving the early enrichment factor (EF1%) from 11.75 to 37.19. Notably, it also maintains strong performance on holo structures. These results demonstrate the promise of our approach in advancing first-in-class drug discovery, particularly in scenarios lacking experimentally resolved protein-ligand complexes.
<div id='section'>Paperid: <span id='pid'>366, <a href='https://arxiv.org/pdf/2504.10612.pdf' target='_blank'>https://arxiv.org/pdf/2504.10612.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michal Balcerak, Tamaz Amiranashvili, Antonio Terpin, Suprosanna Shit, Lea Bogensperger, Sebastian Kaltenbach, Petros Koumoutsakos, Bjoern Menze
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.10612">Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The most widely used generative models map noise and data distributions by matching flows or scores. However, they struggle to incorporate partial observations and additional priors--something energy-based models (EBMs) handle elegantly by simply adding corresponding scalar energy terms. We address this issue by proposing Energy Matching, a framework that endows flow-based approaches with the flexibility of EBMs. Far from the data manifold, samples move along curl-free, optimal transport paths from noise to data. As they approach the data manifold, an entropic energy term guides the system into a Boltzmann equilibrium distribution, explicitly capturing the underlying likelihood structure of the data. We parameterize this dynamic with a single time-independent scalar field, which serves as both a powerful generator and a flexible prior for effective regularization of inverse problems. Our method substantially outperforms existing EBMs on CIFAR-10 and ImageNet generation in terms of fidelity, while retaining simulation-free training of transport-based approaches away from the data manifold. Furthermore, we leverage the method's flexibility to introduce an interaction energy that supports diverse mode exploration, which we demonstrate in a controlled protein-generation setting. Our approach focuses on learning a scalar potential energy--without time-conditioning, auxiliary generators, or additional networks--which marks a significant departure from recent EBM methods. We believe that this simplified framework significantly advances EBMs capabilities and paves the way for their wider adoption in generative modeling across diverse domains.
<div id='section'>Paperid: <span id='pid'>367, <a href='https://arxiv.org/pdf/2502.16533.pdf' target='_blank'>https://arxiv.org/pdf/2502.16533.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaohao Yuan, Kangfei Zhao, Ercan Engin Kuruoglu, Liang Wang, Tingyang Xu, Wenbing Huang, Deli Zhao, Hong Cheng, Yu Rong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16533">A Survey of Graph Transformers: Architectures, Theories and Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Transformers (GTs) have demonstrated a strong capability in modeling graph structures by addressing the intrinsic limitations of graph neural networks (GNNs), such as over-smoothing and over-squashing. Recent studies have proposed diverse architectures, enhanced explainability, and practical applications for Graph Transformers. In light of these rapid developments, we conduct a comprehensive review of Graph Transformers, covering aspects such as their architectures, theoretical foundations, and applications within this survey. We categorize the architecture of Graph Transformers according to their strategies for processing structural information, including graph tokenization, positional encoding, structure-aware attention and model ensemble. Furthermore, from the theoretical perspective, we examine the expressivity of Graph Transformers in various discussed architectures and contrast them with other advanced graph learning algorithms to discover the connections. Furthermore, we provide a summary of the practical applications where Graph Transformers have been utilized, such as molecule, protein, language, vision, traffic, brain and material data. At the end of this survey, we will discuss the current challenges and prospective directions in Graph Transformers for potential future research.
<div id='section'>Paperid: <span id='pid'>368, <a href='https://arxiv.org/pdf/2410.03769.pdf' target='_blank'>https://arxiv.org/pdf/2410.03769.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianhao Li, Jingyu Lu, Chuangxin Chu, Tianyu Zeng, Yujia Zheng, Mei Li, Haotian Huang, Bin Wu, Zuoxian Liu, Kai Ma, Xuejing Yuan, Xingkai Wang, Keyan Ding, Huajun Chen, Qiang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.03769">SciSafeEval: A Comprehensive Benchmark for Safety Alignment of Large Language Models in Scientific Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have a transformative impact on a variety of scientific tasks across disciplines including biology, chemistry, medicine, and physics. However, ensuring the safety alignment of these models in scientific research remains an underexplored area, with existing benchmarks primarily focusing on textual content and overlooking key scientific representations such as molecular, protein, and genomic languages. Moreover, the safety mechanisms of LLMs in scientific tasks are insufficiently studied. To address these limitations, we introduce SciSafeEval, a comprehensive benchmark designed to evaluate the safety alignment of LLMs across a range of scientific tasks. SciSafeEval spans multiple scientific languages-including textual, molecular, protein, and genomic-and covers a wide range of scientific domains. We evaluate LLMs in zero-shot, few-shot and chain-of-thought settings, and introduce a "jailbreak" enhancement feature that challenges LLMs equipped with safety guardrails, rigorously testing their defenses against malicious intention. Our benchmark surpasses existing safety datasets in both scale and scope, providing a robust platform for assessing the safety and performance of LLMs in scientific contexts. This work aims to facilitate the responsible development and deployment of LLMs, promoting alignment with safety and ethical standards in scientific research.
<div id='section'>Paperid: <span id='pid'>369, <a href='https://arxiv.org/pdf/2409.19688.pdf' target='_blank'>https://arxiv.org/pdf/2409.19688.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yun Zhou, Gang Chen, Bing Xue, Mengjie Zhang, Jeremy S. Rooney, Kirill Lagutin, Andrew MacKenzie, Keith C. Gordon, Daniel P. Killeen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19688">Machine Learning for Raman Spectroscopy-based Cyber-Marine Fish Biochemical Composition Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid and accurate detection of biochemical compositions in fish is a crucial real-world task that facilitates optimal utilization and extraction of high-value products in the seafood industry. Raman spectroscopy provides a promising solution for quickly and non-destructively analyzing the biochemical composition of fish by associating Raman spectra with biochemical reference data using machine learning regression models. This paper investigates different regression models to address this task and proposes a new design of Convolutional Neural Networks (CNNs) for jointly predicting water, protein, and lipids yield. To the best of our knowledge, we are the first to conduct a successful study employing CNNs to analyze the biochemical composition of fish based on a very small Raman spectroscopic dataset. Our approach combines a tailored CNN architecture with the comprehensive data preparation procedure, effectively mitigating the challenges posed by extreme data scarcity. The results demonstrate that our CNN can significantly outperform two state-of-the-art CNN models and multiple traditional machine learning models, paving the way for accurate and automated analysis of fish biochemical composition.
<div id='section'>Paperid: <span id='pid'>370, <a href='https://arxiv.org/pdf/2409.02588.pdf' target='_blank'>https://arxiv.org/pdf/2409.02588.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Quadir, M. Sajid, M. Tanveer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02588">Multiview Random Vector Functional Link Network for Predicting DNA-Binding Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The identification of DNA-binding proteins (DBPs) is a critical task due to their significant impact on various biological activities. Understanding the mechanisms underlying protein-DNA interactions is essential for elucidating various life activities. In recent years, machine learning-based models have been prominently utilized for DBP prediction. In this paper, to predict DBPs, we propose a novel framework termed a multiview random vector functional link (MvRVFL) network, which fuses neural network architecture with multiview learning. The proposed MvRVFL model combines the benefits of late and early fusion, allowing for distinct regularization parameters across different views while leveraging a closed-form solution to determine unknown parameters efficiently. The primal objective function incorporates a coupling term aimed at minimizing a composite of errors stemming from all views. From each of the three protein views of the DBP datasets, we extract five features. These features are then fused together by incorporating a hidden feature during the model training process. The performance of the proposed MvRVFL model on the DBP dataset surpasses that of baseline models, demonstrating its superior effectiveness. Furthermore, we extend our assessment to the UCI, KEEL, AwA, and Corel5k datasets, to establish the practicality of the proposed models. The consistency error bound, the generalization error bound, and empirical findings, coupled with rigorous statistical analyses, confirm the superior generalization capabilities of the MvRVFL model compared to the baseline models.
<div id='section'>Paperid: <span id='pid'>371, <a href='https://arxiv.org/pdf/2406.08980.pdf' target='_blank'>https://arxiv.org/pdf/2406.08980.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Gao, Haichuan Tan, Yanwen Huang, Minsi Ren, Xiao Huang, Wei-Ying Ma, Ya-Qin Zhang, Yanyan Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.08980">From Theory to Therapy: Reframing SBDD Model Evaluation via Practical Metrics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in structure-based drug design (SBDD) have significantly enhanced the efficiency and precision of drug discovery by generating molecules tailored to bind specific protein pockets. Despite these technological strides, their practical application in real-world drug development remains challenging due to the complexities of synthesizing and testing these molecules. The reliability of the Vina docking score, the current standard for assessing binding abilities, is increasingly questioned due to its susceptibility to overfitting. To address these limitations, we propose a comprehensive evaluation framework that includes assessing the similarity of generated molecules to known active compounds, introducing a virtual screening-based metric for practical deployment capabilities, and re-evaluating binding affinity more rigorously. Our experiments reveal that while current SBDD models achieve high Vina scores, they fall short in practical usability metrics, highlighting a significant gap between theoretical predictions and real-world applicability. Our proposed metrics and dataset aim to bridge this gap, enhancing the practical applicability of future SBDD models and aligning them more closely with the needs of pharmaceutical research and development.
<div id='section'>Paperid: <span id='pid'>372, <a href='https://arxiv.org/pdf/2406.08961.pdf' target='_blank'>https://arxiv.org/pdf/2406.08961.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanwen Huang, Bowen Gao, Yinjun Jia, Hongbo Ma, Wei-Ying Ma, Ya-Qin Zhang, Yanyan Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.08961">SIU: A Million-Scale Structural Small Molecule-Protein Interaction Dataset for Unbiased Bioactivity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Small molecules play a pivotal role in modern medicine, and scrutinizing their interactions with protein targets is essential for the discovery and development of novel, life-saving therapeutics. The term "bioactivity" encompasses various biological effects resulting from these interactions, including both binding and functional responses. The magnitude of bioactivity dictates the therapeutic or toxic pharmacological outcomes of small molecules, rendering accurate bioactivity prediction crucial for the development of safe and effective drugs. However, existing structural datasets of small molecule-protein interactions are often limited in scale and lack systematically organized bioactivity labels, thereby impeding our understanding of these interactions and precise bioactivity prediction. In this study, we introduce a comprehensive dataset of small molecule-protein interactions, consisting of over a million binding structures, each annotated with real biological activity labels. This dataset is designed to facilitate unbiased bioactivity prediction. We evaluated several classical models on this dataset, and the results demonstrate that the task of unbiased bioactivity prediction is challenging yet essential.
<div id='section'>Paperid: <span id='pid'>373, <a href='https://arxiv.org/pdf/2403.12987.pdf' target='_blank'>https://arxiv.org/pdf/2403.12987.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Gao, Minsi Ren, Yuyan Ni, Yanwen Huang, Bo Qiang, Zhi-Ming Ma, Wei-Ying Ma, Yanyan Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.12987">Rethinking Specificity in SBDD: Leveraging Delta Score and Energy-Guided Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of Structure-based Drug Design (SBDD), deep learning-based generative models have achieved outstanding performance in terms of docking score. However, further study shows that the existing molecular generative methods and docking scores both have lacked consideration in terms of specificity, which means that generated molecules bind to almost every protein pocket with high affinity. To address this, we introduce the Delta Score, a new metric for evaluating the specificity of molecular binding. To further incorporate this insight for generation, we develop an innovative energy-guided approach using contrastive learning, with active compounds as decoys, to direct generative models toward creating molecules with high specificity. Our empirical results show that this method not only enhances the delta score but also maintains or improves traditional docking scores, successfully bridging the gap between SBDD and real-world needs.
<div id='section'>Paperid: <span id='pid'>374, <a href='https://arxiv.org/pdf/2402.18396.pdf' target='_blank'>https://arxiv.org/pdf/2402.18396.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriele Corso, Arthur Deng, Benjamin Fry, Nicholas Polizzi, Regina Barzilay, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18396">Deep Confident Steps to New Pockets: Strategies for Docking Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate blind docking has the potential to lead to new biological breakthroughs, but for this promise to be realized, docking methods must generalize well across the proteome. Existing benchmarks, however, fail to rigorously assess generalizability. Therefore, we develop DockGen, a new benchmark based on the ligand-binding domains of proteins, and we show that existing machine learning-based docking models have very weak generalization abilities. We carefully analyze the scaling laws of ML-based docking and show that, by scaling data and model size, as well as integrating synthetic data strategies, we are able to significantly increase the generalization capacity and set new state-of-the-art performance across benchmarks. Further, we propose Confidence Bootstrapping, a new training paradigm that solely relies on the interaction between diffusion and confidence models and exploits the multi-resolution generation process of diffusion models. We demonstrate that Confidence Bootstrapping significantly improves the ability of ML-based docking methods to dock to unseen protein classes, edging closer to accurate and generalizable blind docking methods.
<div id='section'>Paperid: <span id='pid'>375, <a href='https://arxiv.org/pdf/2402.04997.pdf' target='_blank'>https://arxiv.org/pdf/2402.04997.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Campbell, Jason Yim, Regina Barzilay, Tom Rainforth, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.04997">Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows with Applications to Protein Co-Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Combining discrete and continuous data is an important capability for generative models. We present Discrete Flow Models (DFMs), a new flow-based model of discrete data that provides the missing link in enabling flow-based generative models to be applied to multimodal continuous and discrete data problems. Our key insight is that the discrete equivalent of continuous space flow matching can be realized using Continuous Time Markov Chains. DFMs benefit from a simple derivation that includes discrete diffusion models as a specific instance while allowing improved performance over existing diffusion-based approaches. We utilize our DFMs method to build a multimodal flow-based modeling framework. We apply this capability to the task of protein co-design, wherein we learn a model for jointly generating protein structure and sequence. Our approach achieves state-of-the-art co-design performance while allowing the same multimodal model to be used for flexible generation of the sequence or structure.
<div id='section'>Paperid: <span id='pid'>376, <a href='https://arxiv.org/pdf/2310.05764.pdf' target='_blank'>https://arxiv.org/pdf/2310.05764.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hannes StÃ¤rk, Bowen Jing, Regina Barzilay, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05764">Harmonic Self-Conditioned Flow Matching for Multi-Ligand Docking and Binding Site Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A significant amount of protein function requires binding small molecules, including enzymatic catalysis. As such, designing binding pockets for small molecules has several impactful applications ranging from drug synthesis to energy storage. Towards this goal, we first develop HarmonicFlow, an improved generative process over 3D protein-ligand binding structures based on our self-conditioned flow matching objective. FlowSite extends this flow model to jointly generate a protein pocket's discrete residue types and the molecule's binding 3D structure. We show that HarmonicFlow improves upon state-of-the-art generative processes for docking in simplicity, generality, and average sample quality in pocket-level docking. Enabled by this structure modeling, FlowSite designs binding sites substantially better than baseline approaches.
<div id='section'>Paperid: <span id='pid'>377, <a href='https://arxiv.org/pdf/2310.03269.pdf' target='_blank'>https://arxiv.org/pdf/2310.03269.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeyuan Wang, Qiang Zhang, Keyan Ding, Ming Qin, Xiang Zhuang, Xiaotong Li, Huajun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03269">InstructProtein: Aligning Human and Protein Language via Knowledge Instruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have revolutionized the field of natural language processing, but they fall short in comprehending biological sequences such as proteins. To address this challenge, we propose InstructProtein, an innovative LLM that possesses bidirectional generation capabilities in both human and protein languages: (i) taking a protein sequence as input to predict its textual function description and (ii) using natural language to prompt protein sequence generation. To achieve this, we first pre-train an LLM on both protein and natural language corpora, enabling it to comprehend individual languages. Then supervised instruction tuning is employed to facilitate the alignment of these two distinct languages. Herein, we introduce a knowledge graph-based instruction generation framework to construct a high-quality instruction dataset, addressing annotation imbalance and instruction deficits in existing protein-text corpus. In particular, the instructions inherit the structural relations between proteins and function annotations in knowledge graphs, which empowers our model to engage in the causal modeling of protein functions, akin to the chain-of-thought processes in natural languages. Extensive experiments on bidirectional protein-text generation tasks show that InstructProtein outperforms state-of-the-art LLMs by large margins. Moreover, InstructProtein serves as a pioneering step towards text-based protein function prediction and sequence design, effectively bridging the gap between protein and human language understanding.
<div id='section'>Paperid: <span id='pid'>378, <a href='https://arxiv.org/pdf/2307.08107.pdf' target='_blank'>https://arxiv.org/pdf/2307.08107.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Zhang, Zongren Zou, Ellen Kuhl, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.08107">Discovering a reaction-diffusion model for Alzheimer's disease by combining PINNs with symbolic regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Misfolded tau proteins play a critical role in the progression and pathology of Alzheimer's disease. Recent studies suggest that the spatio-temporal pattern of misfolded tau follows a reaction-diffusion type equation. However, the precise mathematical model and parameters that characterize the progression of misfolded protein across the brain remain incompletely understood. Here, we use deep learning and artificial intelligence to discover a mathematical model for the progression of Alzheimer's disease using longitudinal tau positron emission tomography from the Alzheimer's Disease Neuroimaging Initiative database. Specifically, we integrate physics informed neural networks (PINNs) and symbolic regression to discover a reaction-diffusion type partial differential equation for tau protein misfolding and spreading. First, we demonstrate the potential of our model and parameter discovery on synthetic data. Then, we apply our method to discover the best model and parameters to explain tau imaging data from 46 individuals who are likely to develop Alzheimer's disease and 30 healthy controls. Our symbolic regression discovers different misfolding models $f(c)$ for two groups, with a faster misfolding for the Alzheimer's group, $f(c) = 0.23c^3 - 1.34c^2 + 1.11c$, than for the healthy control group, $f(c) = -c^3 +0.62c^2 + 0.39c$. Our results suggest that PINNs, supplemented by symbolic regression, can discover a reaction-diffusion type model to explain misfolded tau protein concentrations in Alzheimer's disease. We expect our study to be the starting point for a more holistic analysis to provide image-based technologies for early diagnosis, and ideally early treatment of neurodegeneration in Alzheimer's disease and possibly other misfolding-protein based neurodegenerative disorders.
<div id='section'>Paperid: <span id='pid'>379, <a href='https://arxiv.org/pdf/2302.02277.pdf' target='_blank'>https://arxiv.org/pdf/2302.02277.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jason Yim, Brian L. Trippe, Valentin De Bortoli, Emile Mathieu, Arnaud Doucet, Regina Barzilay, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.02277">SE(3) diffusion model with application to protein backbone generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The design of novel protein structures remains a challenge in protein engineering for applications across biomedicine and chemistry. In this line of work, a diffusion model over rigid bodies in 3D (referred to as frames) has shown success in generating novel, functional protein backbones that have not been observed in nature. However, there exists no principled methodological framework for diffusion on SE(3), the space of orientation preserving rigid motions in R3, that operates on frames and confers the group invariance. We address these shortcomings by developing theoretical foundations of SE(3) invariant diffusion models on multiple frames followed by a novel framework, FrameDiff, for learning the SE(3) equivariant score over multiple frames. We apply FrameDiff on monomer backbone generation and find it can generate designable monomers up to 500 amino acids without relying on a pretrained protein structure prediction network that has been integral to previous methods. We find our samples are capable of generalizing beyond any known protein structure.
<div id='section'>Paperid: <span id='pid'>380, <a href='https://arxiv.org/pdf/2210.01776.pdf' target='_blank'>https://arxiv.org/pdf/2210.01776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriele Corso, Hannes StÃ¤rk, Bowen Jing, Regina Barzilay, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.01776">DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the binding structure of a small molecule ligand to a protein -- a task known as molecular docking -- is critical to drug design. Recent deep learning methods that treat docking as a regression problem have decreased runtime compared to traditional search-based methods but have yet to offer substantial improvements in accuracy. We instead frame molecular docking as a generative modeling problem and develop DiffDock, a diffusion generative model over the non-Euclidean manifold of ligand poses. To do so, we map this manifold to the product space of the degrees of freedom (translational, rotational, and torsional) involved in docking and develop an efficient diffusion process on this space. Empirically, DiffDock obtains a 38% top-1 success rate (RMSD<2A) on PDBBind, significantly outperforming the previous state-of-the-art of traditional docking (23%) and deep learning (20%) methods. Moreover, while previous methods are not able to dock on computationally folded structures (maximum accuracy 10.4%), DiffDock maintains significantly higher precision (21.7%). Finally, DiffDock has fast inference times and provides confidence estimates with high selective accuracy.
<div id='section'>Paperid: <span id='pid'>381, <a href='https://arxiv.org/pdf/2206.04119.pdf' target='_blank'>https://arxiv.org/pdf/2206.04119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Brian L. Trippe, Jason Yim, Doug Tischer, David Baker, Tamara Broderick, Regina Barzilay, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.04119">Diffusion probabilistic modeling of protein backbones in 3D for the motif-scaffolding problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Construction of a scaffold structure that supports a desired motif, conferring protein function, shows promise for the design of vaccines and enzymes. But a general solution to this motif-scaffolding problem remains open. Current machine-learning techniques for scaffold design are either limited to unrealistically small scaffolds (up to length 20) or struggle to produce multiple diverse scaffolds. We propose to learn a distribution over diverse and longer protein backbone structures via an E(3)-equivariant graph neural network. We develop SMCDiff to efficiently sample scaffolds from this distribution conditioned on a given motif; our algorithm is the first to theoretically guarantee conditional samples from a diffusion model in the large-compute limit. We evaluate our designed backbones by how well they align with AlphaFold2-predicted structures. We show that our method can (1) sample scaffolds up to 80 residues and (2) achieve structurally diverse scaffolds for a fixed motif.
<div id='section'>Paperid: <span id='pid'>382, <a href='https://arxiv.org/pdf/2507.18816.pdf' target='_blank'>https://arxiv.org/pdf/2507.18816.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangwen Wang, Gaojie Jin, Xiaowei Huang, Ronghui Mu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18816">ThermoRL:Structure-Aware Reinforcement Learning for Protein Mutation Design to Enhance Thermostability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing mutations to optimize protein thermostability remains challenging due to the complex relationship between sequence variations, structural dynamics, and thermostability, often assessed by Î´Î´G
  (the change in free energy of unfolding). Existing methods rely on experimental random mutagenesis or prediction models tested with pre-defined datasets, using sequence-based heuristics and treating enzyme design as a one-step process without iterative refinement, which limits design space exploration and restricts discoveries beyond known variations. We present ThermoRL, a framework based on reinforcement learning (RL) that leverages graph neural networks (GNN) to design mutations with enhanced thermostability. It combines a pre-trained GNN-based encoder with a hierarchical Q-learning network and employs a surrogate model for reward feedback, guiding the RL agent on where (the position) and which (mutant amino acid) to apply for enhanced thermostability. Experimental results show that ThermoRL achieves higher or comparable rewards than baselines while maintaining computational efficiency. It filters out destabilizing mutations and identifies stabilizing mutations aligned with experimental data. Moreover, ThermoRL accurately detects key mutation sites in unseen proteins, highlighting its strong generalizability. This RL-guided approach powered by GNN embeddings offers a robust alternative to traditional protein mutation design.
<div id='section'>Paperid: <span id='pid'>383, <a href='https://arxiv.org/pdf/2505.24203.pdf' target='_blank'>https://arxiv.org/pdf/2505.24203.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiarui Lu, Xiaoyin Chen, Stephen Zhewen Lu, AurÃ©lie Lozano, Vijil Chenthamarakshan, Payel Das, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.24203">Aligning Protein Conformation Ensemble Generation with Physical Feedback</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein dynamics play a crucial role in protein biological functions and properties, and their traditional study typically relies on time-consuming molecular dynamics (MD) simulations conducted in silico. Recent advances in generative modeling, particularly denoising diffusion models, have enabled efficient accurate protein structure prediction and conformation sampling by learning distributions over crystallographic structures. However, effectively integrating physical supervision into these data-driven approaches remains challenging, as standard energy-based objectives often lead to intractable optimization. In this paper, we introduce Energy-based Alignment (EBA), a method that aligns generative models with feedback from physical models, efficiently calibrating them to appropriately balance conformational states based on their energy differences. Experimental results on the MD ensemble benchmark demonstrate that EBA achieves state-of-the-art performance in generating high-quality protein ensembles. By improving the physical plausibility of generated structures, our approach enhances model predictions and holds promise for applications in structural biology and drug discovery.
<div id='section'>Paperid: <span id='pid'>384, <a href='https://arxiv.org/pdf/2411.17798.pdf' target='_blank'>https://arxiv.org/pdf/2411.17798.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiangbin Zheng, Qianhui Xu, Ruichen Xia, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17798">DapPep: Domain Adaptive Peptide-agnostic Learning for Universal T-cell Receptor-antigen Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying T-cell receptors (TCRs) that interact with antigenic peptides provides the technical basis for developing vaccines and immunotherapies. The emergent deep learning methods excel at learning antigen binding patterns from known TCRs but struggle with novel or sparsely represented antigens. However, binding specificity for unseen antigens or exogenous peptides is critical. We introduce a domain-adaptive peptide-agnostic learning framework DapPep for universal TCR-antigen binding affinity prediction to address this challenge. The lightweight self-attention architecture combines a pre-trained protein language model with an inner-loop self-supervised regime to enable robust TCR-peptide representations. Extensive experiments on various benchmarks demonstrate that DapPep consistently outperforms existing tools, showcasing robust generalization capability, especially for data-scarce settings and unseen peptides. Moreover, DapPep proves effective in challenging clinical tasks such as sorting reactive T cells in tumor neoantigen therapy and identifying key positions in 3D structures.
<div id='section'>Paperid: <span id='pid'>385, <a href='https://arxiv.org/pdf/2411.17795.pdf' target='_blank'>https://arxiv.org/pdf/2411.17795.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiangbin Zheng, Ge Wang, Han Zhang, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17795">Pan-protein Design Learning Enables Task-adaptive Generalization for Low-resource Enzyme Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational protein design (CPD) offers transformative potential for bioengineering, but current deep CPD models, focused on universal domains, struggle with function-specific designs. This work introduces a novel CPD paradigm tailored for functional design tasks, particularly for enzymes-a key protein class often lacking specific application efficiency. To address structural data scarcity, we present CrossDesign, a domain-adaptive framework that leverages pretrained protein language models (PPLMs). By aligning protein structures with sequences, CrossDesign transfers pretrained knowledge to structure models, overcoming the limitations of limited structural data. The framework combines autoregressive (AR) and non-autoregressive (NAR) states in its encoder-decoder architecture, applying it to enzyme datasets and pan-proteins. Experimental results highlight CrossDesign's superior performance and robustness, especially with out-of-domain enzymes. Additionally, the model excels in fitness prediction when tested on large-scale mutation data, showcasing its stability.
<div id='section'>Paperid: <span id='pid'>386, <a href='https://arxiv.org/pdf/2411.05173.pdf' target='_blank'>https://arxiv.org/pdf/2411.05173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prakash Chourasia, Tamkanat E Ali, Sarwan Ali, Murray Pattersn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05173">DWFL: Enhancing Federated Learning through Dynamic Weighted Averaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated Learning (FL) is a distributed learning technique that maintains data privacy by providing a decentralized training method for machine learning models using distributed big data. This promising Federated Learning approach has also gained popularity in bioinformatics, where the privacy of biomedical data holds immense importance, especially when patient data is involved. Despite the successful implementation of Federated learning in biological sequence analysis, rigorous consideration is still required to improve accuracy in a way that data privacy should not be compromised. Additionally, the optimal integration of federated learning, especially in protein sequence analysis, has not been fully explored. We propose a deep feed-forward neural network-based enhanced federated learning method for protein sequence classification to overcome these challenges. Our method introduces novel enhancements to improve classification accuracy. We introduce dynamic weighted federated learning (DWFL) which is a federated learning-based approach, where local model weights are adjusted using weighted averaging based on their performance metrics. By assigning higher weights to well-performing models, we aim to create a more potent initial global model for the federated learning process, leading to improved accuracy. We conduct experiments using real-world protein sequence datasets to assess the effectiveness of DWFL. The results obtained using our proposed approach demonstrate significant improvements in model accuracy, making federated learning a preferred, more robust, and privacy-preserving approach for collaborative machine-learning tasks.
<div id='section'>Paperid: <span id='pid'>387, <a href='https://arxiv.org/pdf/2410.10447.pdf' target='_blank'>https://arxiv.org/pdf/2410.10447.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabin Schieffer, Ivy Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10447">Accelerating Drug Discovery in AutoDock-GPU with Tensor Cores</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In drug discovery, molecular docking aims at characterizing the binding of a drug-like molecule to a macromolecule. AutoDock-GPU, a state-of-the-art docking software, estimates the geometrical conformation of a docked ligand-protein complex by minimizing a scoring function. Our profiling results indicate that the current reduction operation that is heavily used in the scoring function is sub-optimal. Thus, we developed a method to accelerate the sum reduction of four-element vectors using matrix operations on NVIDIA Tensor Cores. We integrated the new reduction operation into AutoDock-GPU and evaluated it on multiple chemical complexes on three GPUs. Our results show that our method for reduction operation is 4-7 times faster than the AutoDock-GPU baseline. We also evaluated the impact of our method on the overall simulation time in the real-world docking simulation and achieved a 27% improvement on the average docking time.
<div id='section'>Paperid: <span id='pid'>388, <a href='https://arxiv.org/pdf/2408.10247.pdf' target='_blank'>https://arxiv.org/pdf/2408.10247.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiangbin Zheng, Han Zhang, Qianqing Xu, An-Ping Zeng, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10247">MetaEnzyme: Meta Pan-Enzyme Learning for Task-Adaptive Redesign</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enzyme design plays a crucial role in both industrial production and biology. However, this field faces challenges due to the lack of comprehensive benchmarks and the complexity of enzyme design tasks, leading to a dearth of systematic research. Consequently, computational enzyme design is relatively overlooked within the broader protein domain and remains in its early stages. In this work, we address these challenges by introducing MetaEnzyme, a staged and unified enzyme design framework. We begin by employing a cross-modal structure-to-sequence transformation architecture, as the feature-driven starting point to obtain initial robust protein representation. Subsequently, we leverage domain adaptive techniques to generalize specific enzyme design tasks under low-resource conditions. MetaEnzyme focuses on three fundamental low-resource enzyme redesign tasks: functional design (FuncDesign), mutation design (MutDesign), and sequence generation design (SeqDesign). Through novel unified paradigm and enhanced representation capabilities, MetaEnzyme demonstrates adaptability to diverse enzyme design tasks, yielding outstanding results. Wet lab experiments further validate these findings, reinforcing the efficacy of the redesign process.
<div id='section'>Paperid: <span id='pid'>389, <a href='https://arxiv.org/pdf/2404.00837.pdf' target='_blank'>https://arxiv.org/pdf/2404.00837.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sahan Yoruc Selcuk, Xilin Yang, Bijie Bai, Yijie Zhang, Yuzhu Li, Musa Aydin, Aras Firat Unal, Aditya Gomatam, Zhen Guo, Darrow Morgan Angus, Goren Kolodney, Karine Atlan, Tal Keidar Haran, Nir Pillar, Aydogan Ozcan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00837">Automated HER2 Scoring in Breast Cancer Images Using Deep Learning and Pyramid Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human epidermal growth factor receptor 2 (HER2) is a critical protein in cancer cell growth that signifies the aggressiveness of breast cancer (BC) and helps predict its prognosis. Accurate assessment of immunohistochemically (IHC) stained tissue slides for HER2 expression levels is essential for both treatment guidance and understanding of cancer mechanisms. Nevertheless, the traditional workflow of manual examination by board-certified pathologists encounters challenges, including inter- and intra-observer inconsistency and extended turnaround times. Here, we introduce a deep learning-based approach utilizing pyramid sampling for the automated classification of HER2 status in IHC-stained BC tissue images. Our approach analyzes morphological features at various spatial scales, efficiently managing the computational load and facilitating a detailed examination of cellular and larger-scale tissue-level details. This method addresses the tissue heterogeneity of HER2 expression by providing a comprehensive view, leading to a blind testing classification accuracy of 84.70%, on a dataset of 523 core images from tissue microarrays. Our automated system, proving reliable as an adjunct pathology tool, has the potential to enhance diagnostic precision and evaluation speed, and might significantly impact cancer treatment planning.
<div id='section'>Paperid: <span id='pid'>390, <a href='https://arxiv.org/pdf/2402.07955.pdf' target='_blank'>https://arxiv.org/pdf/2402.07955.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zuobai Zhang, Jiarui Lu, Vijil Chenthamarakshan, AurÃ©lie Lozano, Payel Das, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07955">ProtIR: Iterative Refinement between Retrievers and Predictors for Protein Function Annotation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein function annotation is an important yet challenging task in biology. Recent deep learning advancements show significant potential for accurate function prediction by learning from protein sequences and structures. Nevertheless, these predictor-based methods often overlook the modeling of protein similarity, an idea commonly employed in traditional approaches using sequence or structure retrieval tools. To fill this gap, we first study the effect of inter-protein similarity modeling by benchmarking retriever-based methods against predictors on protein function annotation tasks. Our results show that retrievers can match or outperform predictors without large-scale pre-training. Building on these insights, we introduce a novel variational pseudo-likelihood framework, ProtIR, designed to improve function predictors by incorporating inter-protein similarity modeling. This framework iteratively refines knowledge between a function predictor and retriever, thereby combining the strengths of both predictors and retrievers. ProtIR showcases around 10% improvement over vanilla predictor-based methods. Besides, it achieves performance on par with protein language model-based methods, yet without the need for massive pre-training, highlighting the efficacy of our framework. Code will be released upon acceptance.
<div id='section'>Paperid: <span id='pid'>391, <a href='https://arxiv.org/pdf/2312.06297.pdf' target='_blank'>https://arxiv.org/pdf/2312.06297.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiangbin Zheng, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.06297">Progressive Multi-Modality Learning for Inverse Protein Folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While deep generative models show promise for learning inverse protein folding directly from data, the lack of publicly available structure-sequence pairings limits their generalization. Previous improvements and data augmentation efforts to overcome this bottleneck have been insufficient. To further address this challenge, we propose a novel protein design paradigm called MMDesign, which leverages multi-modality transfer learning. To our knowledge, MMDesign is the first framework that combines a pretrained structural module with a pretrained contextual module, using an auto-encoder (AE) based language model to incorporate prior protein semantic knowledge. Experimental results, only training with the small dataset, demonstrate that MMDesign consistently outperforms baselines on various public benchmarks. To further assess the biological plausibility, we present systematic quantitative analysis techniques that provide interpretability and reveal more about the laws of protein design.
<div id='section'>Paperid: <span id='pid'>392, <a href='https://arxiv.org/pdf/2310.08061.pdf' target='_blank'>https://arxiv.org/pdf/2310.08061.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiqiang Yi, Xu Wan, Yatao Bian, Le Ou-Yang, Peilin Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08061">ETDock: A Novel Equivariant Transformer for Protein-Ligand Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the docking between proteins and ligands is a crucial and challenging task for drug discovery. However, traditional docking methods mainly rely on scoring functions, and deep learning-based docking approaches usually neglect the 3D spatial information of proteins and ligands, as well as the graph-level features of ligands, which limits their performance. To address these limitations, we propose an equivariant transformer neural network for protein-ligand docking pose prediction. Our approach involves the fusion of ligand graph-level features by feature processing, followed by the learning of ligand and protein representations using our proposed TAMformer module. Additionally, we employ an iterative optimization approach based on the predicted distance matrix to generate refined ligand poses. The experimental results on real datasets show that our model can achieve state-of-the-art performance.
<div id='section'>Paperid: <span id='pid'>393, <a href='https://arxiv.org/pdf/2305.15156.pdf' target='_blank'>https://arxiv.org/pdf/2305.15156.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanfeng Ji, Yatao Bian, Guoji Fu, Peilin Zhao, Ping Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.15156">SyNDock: N Rigid Protein Docking via Learnable Group Synchronization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The regulation of various cellular processes heavily relies on the protein complexes within a living cell, necessitating a comprehensive understanding of their three-dimensional structures to elucidate the underlying mechanisms. While neural docking techniques have exhibited promising outcomes in binary protein docking, the application of advanced neural architectures to multimeric protein docking remains uncertain. This study introduces SyNDock, an automated framework that swiftly assembles precise multimeric complexes within seconds, showcasing performance that can potentially surpass or be on par with recent advanced approaches. SyNDock possesses several appealing advantages not present in previous approaches. Firstly, SyNDock formulates multimeric protein docking as a problem of learning global transformations to holistically depict the placement of chain units of a complex, enabling a learning-centric solution. Secondly, SyNDock proposes a trainable two-step SE(3) algorithm, involving initial pairwise transformation and confidence estimation, followed by global transformation synchronization. This enables effective learning for assembling the complex in a globally consistent manner. Lastly, extensive experiments conducted on our proposed benchmark dataset demonstrate that SyNDock outperforms existing docking software in crucial performance metrics, including accuracy and runtime. For instance, it achieves a 4.5% improvement in performance and a remarkable millionfold acceleration in speed.
<div id='section'>Paperid: <span id='pid'>394, <a href='https://arxiv.org/pdf/2303.11783.pdf' target='_blank'>https://arxiv.org/pdf/2303.11783.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiangbin Zheng, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.11783">CCPL: Cross-modal Contrastive Protein Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective protein representation learning is crucial for predicting protein functions. Traditional methods often pretrain protein language models on large, unlabeled amino acid sequences, followed by finetuning on labeled data. While effective, these methods underutilize the potential of protein structures, which are vital for function determination. Common structural representation techniques rely heavily on annotated data, limiting their generalizability. Moreover, structural pretraining methods, similar to natural language pretraining, can distort actual protein structures. In this work, we introduce a novel unsupervised protein structure representation pretraining method, cross-modal contrastive protein learning (CCPL). CCPL leverages a robust protein language model and uses unsupervised contrastive alignment to enhance structure learning, incorporating self-supervised structural constraints to maintain intrinsic structural information. We evaluated our model across various benchmarks, demonstrating the framework's superiority.
<div id='section'>Paperid: <span id='pid'>395, <a href='https://arxiv.org/pdf/2301.11765.pdf' target='_blank'>https://arxiv.org/pdf/2301.11765.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juntao Tan, Yongfeng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.11765">ExplainableFold: Understanding AlphaFold Prediction with Explainable AI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents ExplainableFold, an explainable AI framework for protein structure prediction. Despite the success of AI-based methods such as AlphaFold in this field, the underlying reasons for their predictions remain unclear due to the black-box nature of deep learning models. To address this, we propose a counterfactual learning framework inspired by biological principles to generate counterfactual explanations for protein structure prediction, enabling a dry-lab experimentation approach. Our experimental results demonstrate the ability of ExplainableFold to generate high-quality explanations for AlphaFold's predictions, providing near-experimental understanding of the effects of amino acids on 3D protein structure. This framework has the potential to facilitate a deeper understanding of protein structures.
<div id='section'>Paperid: <span id='pid'>396, <a href='https://arxiv.org/pdf/2509.02642.pdf' target='_blank'>https://arxiv.org/pdf/2509.02642.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bin Feng, Jiying Zhang, Xinni Zhang, Zijing Liu, Yu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02642">BioMD: All-atom Generative Model for Biomolecular Dynamics Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular dynamics (MD) simulations are essential tools in computational chemistry and drug discovery, offering crucial insights into dynamic molecular behavior. However, their utility is significantly limited by substantial computational costs, which severely restrict accessible timescales for many biologically relevant processes. Despite the encouraging performance of existing machine learning (ML) methods, they struggle to generate extended biomolecular system trajectories, primarily due to the lack of MD datasets and the large computational demands of modeling long historical trajectories. Here, we introduce BioMD, the first all-atom generative model to simulate long-timescale protein-ligand dynamics using a hierarchical framework of forecasting and interpolation. We demonstrate the effectiveness and versatility of BioMD on the DD-13M (ligand unbinding) and MISATO datasets. For both datasets, BioMD generates highly realistic conformations, showing high physical plausibility and low reconstruction errors. Besides, BioMD successfully generates ligand unbinding paths for 97.1% of the protein-ligand systems within ten attempts, demonstrating its ability to explore critical unbinding pathways. Collectively, these results establish BioMD as a tool for simulating complex biomolecular processes, offering broad applicability for computational chemistry and drug discovery.
<div id='section'>Paperid: <span id='pid'>397, <a href='https://arxiv.org/pdf/2507.11839.pdf' target='_blank'>https://arxiv.org/pdf/2507.11839.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chengyue Gong, Xinshi Chen, Yuxuan Zhang, Yuxuan Song, Hao Zhou, Wenzhi Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11839">Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Lightweight inference is critical for biomolecular structure prediction and other downstream tasks, enabling efficient real-world deployment and inference-time scaling for large-scale applications. In this work, we address the challenge of balancing model efficiency and prediction accuracy by making several key modifications, 1) Multi-step AF3 sampler is replaced by a few-step ODE sampler, significantly reducing computational overhead for the diffusion module part during inference; 2) In the open-source Protenix framework, a subset of pairformer or diffusion transformer blocks doesn't make contributions to the final structure prediction, presenting opportunities for architectural pruning and lightweight redesign; 3) A model incorporating an ESM module is trained to substitute the conventional MSA module, reducing MSA preprocessing time. Building on these key insights, we present Protenix-Mini, a compact and optimized model designed for efficient protein structure prediction. This streamlined version incorporates a more efficient architectural design with a two-step Ordinary Differential Equation (ODE) sampling strategy. By eliminating redundant Transformer components and refining the sampling process, Protenix-Mini significantly reduces model complexity with slight accuracy drop. Evaluations on benchmark datasets demonstrate that it achieves high-fidelity predictions, with only a negligible 1 to 5 percent decrease in performance on benchmark datasets compared to its full-scale counterpart. This makes Protenix-Mini an ideal choice for applications where computational resources are limited but accurate structure prediction remains crucial.
<div id='section'>Paperid: <span id='pid'>398, <a href='https://arxiv.org/pdf/2507.09466.pdf' target='_blank'>https://arxiv.org/pdf/2507.09466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomas Geffner, Kieran Didi, Zhonglin Cao, Danny Reidenbach, Zuobai Zhang, Christian Dallago, Emine Kucukbenli, Karsten Kreis, Arash Vahdat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09466">La-Proteina: Atomistic Protein Generation via Partially Latent Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, many generative models for de novo protein structure design have emerged. Yet, only few tackle the difficult task of directly generating fully atomistic structures jointly with the underlying amino acid sequence. This is challenging, for instance, because the model must reason over side chains that change in length during generation. We introduce La-Proteina for atomistic protein design based on a novel partially latent protein representation: coarse backbone structure is modeled explicitly, while sequence and atomistic details are captured via per-residue latent variables of fixed dimensionality, thereby effectively side-stepping challenges of explicit side-chain representations. Flow matching in this partially latent space then models the joint distribution over sequences and full-atom structures. La-Proteina achieves state-of-the-art performance on multiple generation benchmarks, including all-atom co-designability, diversity, and structural validity, as confirmed through detailed structural analyses and evaluations. Notably, La-Proteina also surpasses previous models in atomistic motif scaffolding performance, unlocking critical atomistic structure-conditioned protein design tasks. Moreover, La-Proteina is able to generate co-designable proteins of up to 800 residues, a regime where most baselines collapse and fail to produce valid samples, demonstrating La-Proteina's scalability and robustness.
<div id='section'>Paperid: <span id='pid'>399, <a href='https://arxiv.org/pdf/2506.13196.pdf' target='_blank'>https://arxiv.org/pdf/2506.13196.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Han Liu, Keyan Ding, Peilin Chen, Yinwei Wei, Liqiang Nie, Dapeng Wu, Shiqi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13196">KEPLA: A Knowledge-Enhanced Deep Learning Framework for Accurate Protein-Ligand Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of protein-ligand binding affinity is critical for drug discovery. While recent deep learning approaches have demonstrated promising results, they often rely solely on structural features of proteins and ligands, overlooking their valuable biochemical knowledge associated with binding affinity. To address this limitation, we propose KEPLA, a novel deep learning framework that explicitly integrates prior knowledge from Gene Ontology and ligand properties to enhance prediction performance. KEPLA takes protein sequences and ligand molecular graphs as input and optimizes two complementary objectives: (1) aligning global representations with knowledge graph relations to capture domain-specific biochemical insights, and (2) leveraging cross attention between local representations to construct fine-grained joint embeddings for prediction. Experiments on two benchmark datasets across both in-domain and cross-domain scenarios demonstrate that KEPLA consistently outperforms state-of-the-art baselines. Furthermore, interpretability analyses based on knowledge graph relations and cross attention maps provide valuable insights into the underlying predictive mechanisms.
<div id='section'>Paperid: <span id='pid'>400, <a href='https://arxiv.org/pdf/2504.18367.pdf' target='_blank'>https://arxiv.org/pdf/2504.18367.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maodong Li, Jiying Zhang, Bin Feng, Wenqi Zeng, Dechin Chen, Zhijun Pan, Yu Li, Zijing Liu, Yi Isaac Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.18367">Enhanced Sampling, Public Dataset and Generative Model for Drug-Protein Dissociation Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drug-protein binding and dissociation dynamics are fundamental to understanding molecular interactions in biological systems. While many tools for drug-protein interaction studies have emerged, especially artificial intelligence (AI)-based generative models, predictive tools on binding/dissociation kinetics and dynamics are still limited. We propose a novel research paradigm that combines molecular dynamics (MD) simulations, enhanced sampling, and AI generative models to address this issue. We propose an enhanced sampling strategy to efficiently implement the drug-protein dissociation process in MD simulations and estimate the free energy surface (FES). We constructed a program pipeline of MD simulations based on this sampling strategy, thus generating a dataset including 26,612 drug-protein dissociation trajectories containing about 13 million frames. We named this dissociation dynamics dataset DD-13M and used it to train a deep equivariant generative model UnbindingFlow, which can generate collision-free dissociation trajectories. The DD-13M database and UnbindingFlow model represent a significant advancement in computational structural biology, and we anticipate its broad applicability in machine learning studies of drug-protein interactions. Our ongoing efforts focus on expanding this methodology to encompass a broader spectrum of drug-protein complexes and exploring novel applications in pathway prediction.
<div id='section'>Paperid: <span id='pid'>401, <a href='https://arxiv.org/pdf/2503.17286.pdf' target='_blank'>https://arxiv.org/pdf/2503.17286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minsu Kim, Jiayao Gu, Ye Yuan, Taeyoung Yun, Zixuan Liu, Yoshua Bengio, Can Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17286">Offline Model-Based Optimization: Comprehensive Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline optimization is a fundamental challenge in science and engineering, where the goal is to optimize black-box functions using only offline datasets. This setting is particularly relevant when querying the objective function is prohibitively expensive or infeasible, with applications spanning protein engineering, material discovery, neural architecture search, and beyond. The main difficulty lies in accurately estimating the objective landscape beyond the available data, where extrapolations are fraught with significant epistemic uncertainty. This uncertainty can lead to objective hacking(reward hacking), exploiting model inaccuracies in unseen regions, or other spurious optimizations that yield misleadingly high performance estimates outside the training distribution. Recent advances in model-based optimization(MBO) have harnessed the generalization capabilities of deep neural networks to develop offline-specific surrogate and generative models. Trained with carefully designed strategies, these models are more robust against out-of-distribution issues, facilitating the discovery of improved designs. Despite its growing impact in accelerating scientific discovery, the field lacks a comprehensive review. To bridge this gap, we present the first thorough review of offline MBO. We begin by formalizing the problem for both single-objective and multi-objective settings and by reviewing recent benchmarks and evaluation metrics. We then categorize existing approaches into two key areas: surrogate modeling, which emphasizes accurate function approximation in out-of-distribution regions, and generative modeling, which explores high-dimensional design spaces to identify high-performing designs. Finally, we examine the key challenges and propose promising directions for advancement in this rapidly evolving field including safe control of superintelligent systems.
<div id='section'>Paperid: <span id='pid'>402, <a href='https://arxiv.org/pdf/2503.00710.pdf' target='_blank'>https://arxiv.org/pdf/2503.00710.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomas Geffner, Kieran Didi, Zuobai Zhang, Danny Reidenbach, Zhonglin Cao, Jason Yim, Mario Geiger, Christian Dallago, Emine Kucukbenli, Arash Vahdat, Karsten Kreis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00710">Proteina: Scaling Flow-based Protein Structure Generative Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, diffusion- and flow-based generative models of protein structures have emerged as a powerful tool for de novo protein design. Here, we develop Proteina, a new large-scale flow-based protein backbone generator that utilizes hierarchical fold class labels for conditioning and relies on a tailored scalable transformer architecture with up to 5x as many parameters as previous models. To meaningfully quantify performance, we introduce a new set of metrics that directly measure the distributional similarity of generated proteins with reference sets, complementing existing metrics. We further explore scaling training data to millions of synthetic protein structures and explore improved training and sampling recipes adapted to protein backbone generation. This includes fine-tuning strategies like LoRA for protein backbones, new guidance methods like classifier-free guidance and autoguidance for protein backbones, and new adjusted training objectives. Proteina achieves state-of-the-art performance on de novo protein backbone design and produces diverse and designable proteins at unprecedented length, up to 800 residues. The hierarchical conditioning offers novel control, enabling high-level secondary-structure guidance as well as low-level fold-specific generation.
<div id='section'>Paperid: <span id='pid'>403, <a href='https://arxiv.org/pdf/2502.06173.pdf' target='_blank'>https://arxiv.org/pdf/2502.06173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sanket Jantre, Tianle Wang, Gilchan Park, Kriti Chopra, Nicholas Jeon, Xiaoning Qian, Nathan M. Urban, Byung-Jun Yoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06173">Uncertainty-Aware Adaptation of Large Language Models for Protein-Protein Interaction Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identification of protein-protein interactions (PPIs) helps derive cellular mechanistic understanding, particularly in the context of complex conditions such as neurodegenerative disorders, metabolic syndromes, and cancer. Large Language Models (LLMs) have demonstrated remarkable potential in predicting protein structures and interactions via automated mining of vast biomedical literature; yet their inherent uncertainty remains a key challenge for deriving reproducible findings, critical for biomedical applications. In this study, we present an uncertainty-aware adaptation of LLMs for PPI analysis, leveraging fine-tuned LLaMA-3 and BioMedGPT models. To enhance prediction reliability, we integrate LoRA ensembles and Bayesian LoRA models for uncertainty quantification (UQ), ensuring confidence-calibrated insights into protein behavior. Our approach achieves competitive performance in PPI identification across diverse disease contexts while addressing model uncertainty, thereby enhancing trustworthiness and reproducibility in computational biology. These findings underscore the potential of uncertainty-aware LLM adaptation for advancing precision medicine and biomedical research.
<div id='section'>Paperid: <span id='pid'>404, <a href='https://arxiv.org/pdf/2412.11137.pdf' target='_blank'>https://arxiv.org/pdf/2412.11137.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hezha O. Rasul, Dlzar D. Ghafour, Bakhtyar K. Aziz, Bryar A. Hassan, Tarik A. Rashid, Arif Kivrak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.11137">Decoding Drug Discovery: Exploring A-to-Z In silico Methods for Beginners</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The drug development process is a critical challenge in the pharmaceutical industry due to its time-consuming nature and the need to discover new drug potentials to address various ailments. The initial step in drug development, drug target identification, often consumes considerable time. While valid, traditional methods such as in vivo and in vitro approaches are limited in their ability to analyze vast amounts of data efficiently, leading to wasteful outcomes. To expedite and streamline drug development, an increasing reliance on computer-aided drug design (CADD) approaches has merged. These sophisticated in silico methods offer a promising avenue for efficiently identifying viable drug candidates, thus providing pharmaceutical firms with significant opportunities to uncover new prospective drug targets. The main goal of this work is to review in silico methods used in the drug development process with a focus on identifying therapeutic targets linked to specific diseases at the genetic or protein level. This article thoroughly discusses A-to-Z in silico techniques, which are essential for identifying the targets of bioactive compounds and their potential therapeutic effects. This review intends to improve drug discovery processes by illuminating the state of these cutting-edge approaches, thereby maximizing the effectiveness and duration of clinical trials for novel drug target investigation.
<div id='section'>Paperid: <span id='pid'>405, <a href='https://arxiv.org/pdf/2410.24022.pdf' target='_blank'>https://arxiv.org/pdf/2410.24022.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liang He, Peiran Jin, Yaosen Min, Shufang Xie, Lijun Wu, Tao Qin, Xiaozhuan Liang, Kaiyuan Gao, Yuliang Jiang, Tie-Yan Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.24022">SFM-Protein: Integrative Co-evolutionary Pre-training for Advanced Protein Sequence Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins, essential to biological systems, perform functions intricately linked to their three-dimensional structures. Understanding the relationship between protein structures and their amino acid sequences remains a core challenge in protein modeling. While traditional protein foundation models benefit from pre-training on vast unlabeled datasets, they often struggle to capture critical co-evolutionary information, which evolutionary-based methods excel at. In this study, we introduce a novel pre-training strategy for protein foundation models that emphasizes the interactions among amino acid residues to enhance the extraction of both short-range and long-range co-evolutionary features from sequence data. Trained on a large-scale protein sequence dataset, our model demonstrates superior generalization ability, outperforming established baselines of similar size, including the ESM model, across diverse downstream tasks. Experimental results confirm the model's effectiveness in integrating co-evolutionary information, marking a significant step forward in protein sequence-based modeling.
<div id='section'>Paperid: <span id='pid'>406, <a href='https://arxiv.org/pdf/2410.18403.pdf' target='_blank'>https://arxiv.org/pdf/2410.18403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiarui Lu, Xiaoyin Chen, Stephen Zhewen Lu, Chence Shi, Hongyu Guo, Yoshua Bengio, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.18403">Structure Language Models for Protein Conformation Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins adopt multiple structural conformations to perform their diverse biological functions, and understanding these conformations is crucial for advancing drug discovery. Traditional physics-based simulation methods often struggle with sampling equilibrium conformations and are computationally expensive. Recently, deep generative models have shown promise in generating protein conformations as a more efficient alternative. However, these methods predominantly rely on the diffusion process within a 3D geometric space, which typically centers around the vicinity of metastable states and is often inefficient in terms of runtime. In this paper, we introduce Structure Language Modeling (SLM) as a novel framework for efficient protein conformation generation. Specifically, the protein structures are first encoded into a compact latent space using a discrete variational auto-encoder, followed by conditional language modeling that effectively captures sequence-specific conformation distributions. This enables a more efficient and interpretable exploration of diverse ensemble modes compared to existing methods. Based on this general framework, we instantiate SLM with various popular LM architectures as well as proposing the ESMDiff, a novel BERT-like structure language model fine-tuned from ESM3 with masked diffusion. We verify our approach in various scenarios, including the equilibrium dynamics of BPTI, conformational change pairs, and intrinsically disordered proteins. SLM provides a highly efficient solution, offering a 20-100x speedup than existing methods in generating diverse conformations, shedding light on promising avenues for future research.
<div id='section'>Paperid: <span id='pid'>407, <a href='https://arxiv.org/pdf/2410.08134.pdf' target='_blank'>https://arxiv.org/pdf/2410.08134.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jarrid Rector-Brooks, Mohsin Hasan, Zhangzhi Peng, Zachary Quinn, Chenghao Liu, Sarthak Mittal, Nouha Dziri, Michael Bronstein, Yoshua Bengio, Pranam Chatterjee, Alexander Tong, Avishek Joey Bose
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08134">Steering Masked Discrete Diffusion Models via Discrete Denoising Posterior Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative modeling of discrete data underlies important applications spanning text-based agents like ChatGPT to the design of the very building blocks of life in protein sequences. However, application domains need to exert control over the generated data by steering the generative process - typically via RLHF - to satisfy a specified property, reward, or affinity metric. In this paper, we study the problem of steering Masked Diffusion Models (MDMs), a recent class of discrete diffusion models that offer a compelling alternative to traditional autoregressive models. We introduce Discrete Denoising Posterior Prediction (DDPP), a novel framework that casts the task of steering pre-trained MDMs as a problem of probabilistic inference by learning to sample from a target Bayesian posterior. Our DDPP framework leads to a family of three novel objectives that are all simulation-free, and thus scalable while applying to general non-differentiable reward functions. Empirically, we instantiate DDPP by steering MDMs to perform class-conditional pixel-level image modeling, RLHF-based alignment of MDMs using text-based rewards, and finetuning protein language models to generate more diverse secondary structures and shorter proteins. We substantiate our designs via wet-lab validation, where we observe transient expression of reward-optimized protein sequences.
<div id='section'>Paperid: <span id='pid'>408, <a href='https://arxiv.org/pdf/2409.14617.pdf' target='_blank'>https://arxiv.org/pdf/2409.14617.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bohao Xu, Yingzhou Lu, Yoshitaka Inoue, Namkyeong Lee, Tianfan Fu, Jintai Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.14617">Protein-Mamba: Biological Mamba Models for Protein Function Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein function prediction is a pivotal task in drug discovery, significantly impacting the development of effective and safe therapeutics. Traditional machine learning models often struggle with the complexity and variability inherent in predicting protein functions, necessitating more sophisticated approaches. In this work, we introduce Protein-Mamba, a novel two-stage model that leverages both self-supervised learning and fine-tuning to improve protein function prediction. The pre-training stage allows the model to capture general chemical structures and relationships from large, unlabeled datasets, while the fine-tuning stage refines these insights using specific labeled datasets, resulting in superior prediction performance. Our extensive experiments demonstrate that Protein-Mamba achieves competitive performance, compared with a couple of state-of-the-art methods across a range of protein function datasets. This model's ability to effectively utilize both unlabeled and labeled data highlights the potential of self-supervised learning in advancing protein function prediction and offers a promising direction for future research in drug discovery.
<div id='section'>Paperid: <span id='pid'>409, <a href='https://arxiv.org/pdf/2408.12419.pdf' target='_blank'>https://arxiv.org/pdf/2408.12419.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaihui Cheng, Ce Liu, Qingkun Su, Jun Wang, Liwei Zhang, Yining Tang, Yao Yao, Siyu Zhu, Yuan Qi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12419">AlphaFolding: 4D Diffusion for Dynamic Protein Structure Prediction with Reference and Motion Guidance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structure prediction is pivotal for understanding the structure-function relationship of proteins, advancing biological research, and facilitating pharmaceutical development and experimental design. While deep learning methods and the expanded availability of experimental 3D protein structures have accelerated structure prediction, the dynamic nature of protein structures has received limited attention. This study introduces an innovative 4D diffusion model incorporating molecular dynamics (MD) simulation data to learn dynamic protein structures. Our approach is distinguished by the following components: (1) a unified diffusion model capable of generating dynamic protein structures, including both the backbone and side chains, utilizing atomic grouping and side-chain dihedral angle predictions; (2) a reference network that enhances structural consistency by integrating the latent embeddings of the initial 3D protein structures; and (3) a motion alignment module aimed at improving temporal structural coherence across multiple time steps. To our knowledge, this is the first diffusion-based model aimed at predicting protein trajectories across multiple time steps simultaneously. Validation on benchmark datasets demonstrates that our model exhibits high accuracy in predicting dynamic 3D structures of proteins containing up to 256 amino acids over 32 time steps, effectively capturing both local flexibility in stable states and significant conformational changes. URL: https://fudan-generative-vision.github.io/AlphaFolding/#/
<div id='section'>Paperid: <span id='pid'>410, <a href='https://arxiv.org/pdf/2408.00521.pdf' target='_blank'>https://arxiv.org/pdf/2408.00521.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengdan Fan, Wei Zhang, Haiyan Zhao, Zhi Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00521">A new approach for encoding code and assisting code understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Some companies (e.g., Microsoft Research and Google DeepMind) have discovered some of the limitations of GPTs' autoregressive paradigm next-word prediction, manifested in the model's lack of planning, working memory, backtracking, and reasoning skills. GPTs rely on a local and greedy process of generating the next word, without a global understanding of the task or the output. We have confirmed the above limitations through specialized empirical studies of code comprehension. Although GPT-4 is good at producing fluent and coherent text, it cannot handle complex logic and generate new code that hasn't been seen, and it relies too much on the formatting of the prompt to generate the correct code. We propose a new paradigm for code understanding that goes beyond the next-word prediction paradigm, inspired by the successful application of diffusion techniques to image generation (Dalle-2, Sora) and protein structure generation (AlphaFold-3), which have no autoregressive constraints. Instead of encoding the code in a form that mimics natural language, we encode the code as a heterogeneous image paradigm with a memory of global information that mimics both images and protein structures. We then refer to Sora's CLIP upstream text-to-image encoder model to design a text-to-code encoder model that can be applied to various downstream code understanding tasks. The model learns the global understanding of code under the new paradigm heterogeneous image, connects the encoding space of text and code, and encodes the input of text into the vector of code most similar to it. Using self-supervised comparative learning on 456,360 text-code pairs, the model achieved a zero-shot prediction of new data. This work is the basis for future work on code generation using diffusion techniques under a new paradigm to avoid autoregressive limitations.
<div id='section'>Paperid: <span id='pid'>411, <a href='https://arxiv.org/pdf/2402.12714.pdf' target='_blank'>https://arxiv.org/pdf/2402.12714.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Jiao, Xiangzhe Kong, Li Zhang, Ziyang Yu, Fangyuan Ren, Wenjuan Tan, Wenbing Huang, Yang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12714">An Equivariant Pretrained Transformer for Unified 3D Molecular Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pretraining on a large number of unlabeled 3D molecules has showcased superiority in various scientific applications. However, prior efforts typically focus on pretraining models in a specific domain, either proteins or small molecules, missing the opportunity to leverage cross-domain knowledge. To mitigate this gap, we introduce Equivariant Pretrained Transformer (EPT), an all-atom foundation model that can be pretrained from multiple domain 3D molecules. Built upon an E(3)-equivariant transformer, EPT is able to not only process atom-level information but also incorporate block-level features (e.g. residuals in proteins). Additionally, we employ a block-level denoising task, rather than the conventional atom-level denoising, as the pretraining objective. To pretrain EPT, we construct a large-scale dataset of 5.89M entries, comprising small molecules, proteins, protein-protein complexes, and protein-molecule complexes. Experimental evaluations on downstream tasks including ligand binding affinity prediction, protein property prediction, and molecular property prediction, show that EPT significantly outperforms previous state-of-the-art methods in the first task and achieves competitively superior performance for the remaining two tasks. Furthermore, we demonstrate the potential of EPT in identifying small molecule drug candidates targeting 3CL protease, a critical target in the replication of SARS-CoV-2. Among 1,978 FDA-approved drugs, EPT ranks 7 out of 8 known anti-COVID-19 drugs in the top 200, indicating the high recall of EPT. By using Molecular Dynamics (MD) simulations, EPT further discoveries 7 novel compounds whose binding affinities are higher than that of the top-ranked known anti-COVID-19 drug, showcasing its powerful capabilities in drug discovery.
<div id='section'>Paperid: <span id='pid'>412, <a href='https://arxiv.org/pdf/2402.10433.pdf' target='_blank'>https://arxiv.org/pdf/2402.10433.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiarui Lu, Zuobai Zhang, Bozitao Zhong, Chence Shi, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10433">Fusing Neural and Physical: Augment Protein Conformation Sampling with Tractable Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The protein dynamics are common and important for their biological functions and properties, the study of which usually involves time-consuming molecular dynamics (MD) simulations in silico. Recently, generative models has been leveraged as a surrogate sampler to obtain conformation ensembles with orders of magnitude faster and without requiring any simulation data (a "zero-shot" inference). However, being agnostic of the underlying energy landscape, the accuracy of such generative model may still be limited. In this work, we explore the few-shot setting of such pre-trained generative sampler which incorporates MD simulations in a tractable manner. Specifically, given a target protein of interest, we first acquire some seeding conformations from the pre-trained sampler followed by a number of physical simulations in parallel starting from these seeding samples. Then we fine-tuned the generative model using the simulation trajectories above to become a target-specific sampler. Experimental results demonstrated the superior performance of such few-shot conformation sampler at a tractable computational cost.
<div id='section'>Paperid: <span id='pid'>413, <a href='https://arxiv.org/pdf/2401.08986.pdf' target='_blank'>https://arxiv.org/pdf/2401.08986.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyang Yu, Wenbing Huang, Yang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08986">Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The study of rigid protein-protein docking plays an essential role in a variety of tasks such as drug design and protein engineering. Recently, several learning-based methods have been proposed for the task, exhibiting much faster docking speed than those computational methods. In this paper, we propose a novel learning-based method called ElliDock, which predicts an elliptic paraboloid to represent the protein-protein docking interface. To be specific, our model estimates elliptic paraboloid interfaces for the two input proteins respectively, and obtains the roto-translation transformation for docking by making two interfaces coincide. By its design, ElliDock is independently equivariant with respect to arbitrary rotations/translations of the proteins, which is an indispensable property to ensure the generalization of the docking process. Experimental evaluations show that ElliDock achieves the fastest inference time among all compared methods and is strongly competitive with current state-of-the-art learning-based models such as DiffDock-PP and Multimer particularly for antibody-antigen docking.
<div id='section'>Paperid: <span id='pid'>414, <a href='https://arxiv.org/pdf/2312.06082.pdf' target='_blank'>https://arxiv.org/pdf/2312.06082.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongliang Zhou, Mengxuan Hu, Mariah Salcedo, Nathan Gravel, Wayland Yeung, Aarya Venkat, Dongliang Guo, Jielu Zhang, Natarajan Kannan, Sheng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.06082">XAI meets Biology: A Comprehensive Review of Explainable AI in Bioinformatics Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence (AI), particularly machine learning and deep learning models, has significantly impacted bioinformatics research by offering powerful tools for analyzing complex biological data. However, the lack of interpretability and transparency of these models presents challenges in leveraging these models for deeper biological insights and for generating testable hypotheses. Explainable AI (XAI) has emerged as a promising solution to enhance the transparency and interpretability of AI models in bioinformatics. This review provides a comprehensive analysis of various XAI techniques and their applications across various bioinformatics domains including DNA, RNA, and protein sequence analysis, structural analysis, gene expression and genome analysis, and bioimaging analysis. We introduce the most pertinent machine learning and XAI methods, then discuss their diverse applications and address the current limitations of available XAI tools. By offering insights into XAI's potential and challenges, this review aims to facilitate its practical implementation in bioinformatics research and help researchers navigate the landscape of XAI tools.
<div id='section'>Paperid: <span id='pid'>415, <a href='https://arxiv.org/pdf/2308.01921.pdf' target='_blank'>https://arxiv.org/pdf/2308.01921.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Chen, Yihui Ren, Ai Kagawa, Matthew R. Carbone, Samuel Yen-Chi Chen, Xiaohui Qu, Shinjae Yoo, Austin Clyde, Arvind Ramanathan, Rick L. Stevens, Hubertus J. J. van Dam, Deyu Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.01921">Transferable Graph Neural Fingerprint Models for Quick Response to Future Bio-Threats</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fast screening of drug molecules based on the ligand binding affinity is an important step in the drug discovery pipeline. Graph neural fingerprint is a promising method for developing molecular docking surrogates with high throughput and great fidelity. In this study, we built a COVID-19 drug docking dataset of about 300,000 drug candidates on 23 coronavirus protein targets. With this dataset, we trained graph neural fingerprint docking models for high-throughput virtual COVID-19 drug screening. The graph neural fingerprint models yield high prediction accuracy on docking scores with the mean squared error lower than $0.21$ kcal/mol for most of the docking targets, showing significant improvement over conventional circular fingerprint methods. To make the neural fingerprints transferable for unknown targets, we also propose a transferable graph neural fingerprint method trained on multiple targets. With comparable accuracy to target-specific graph neural fingerprint models, the transferable model exhibits superb training and data efficiency. We highlight that the impact of this study extends beyond COVID-19 dataset, as our approach for fast virtual ligand screening can be easily adapted and integrated into a general machine learning-accelerated pipeline to battle future bio-threats.
<div id='section'>Paperid: <span id='pid'>416, <a href='https://arxiv.org/pdf/2306.13957.pdf' target='_blank'>https://arxiv.org/pdf/2306.13957.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Huang, Zheng Yuan, Huihui Yan, Rong Sheng, Linjing Liu, Fuzhou Wang, Weidun Xie, Nanjun Chen, Fei Huang, Songfang Huang, Ka-Chun Wong, Yaoyun Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13957">DiffDTM: A conditional structure-free framework for bioactive molecules generation targeted for dual proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in deep generative models shed light on de novo molecule generation with desired properties. However, molecule generation targeted for dual protein targets still faces formidable challenges including protein 3D structure data requisition for model training, auto-regressive sampling, and model generalization for unseen targets. Here, we proposed DiffDTM, a novel conditional structure-free deep generative model based on a diffusion model for dual targets based molecule generation to address the above issues. Specifically, DiffDTM receives protein sequences and molecular graphs as inputs instead of protein and molecular conformations and incorporates an information fusion module to achieve conditional generation in a one-shot manner. We have conducted comprehensive multi-view experiments to demonstrate that DiffDTM can generate drug-like, synthesis-accessible, novel, and high-binding affinity molecules targeting specific dual proteins, outperforming the state-of-the-art (SOTA) models in terms of multiple evaluation metrics. Furthermore, we utilized DiffDTM to generate molecules towards dopamine receptor D2 and 5-hydroxytryptamine receptor 1A as new antipsychotics. The experimental results indicate that DiffDTM can be easily plugged into unseen dual targets to generate bioactive molecules, addressing the issues of requiring insufficient active molecule data for training as well as the need to retrain when encountering new targets.
<div id='section'>Paperid: <span id='pid'>417, <a href='https://arxiv.org/pdf/2306.01474.pdf' target='_blank'>https://arxiv.org/pdf/2306.01474.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangzhe Kong, Wenbing Huang, Yang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.01474">Generalist Equivariant Transformer Towards 3D Molecular Interaction Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many processes in biology and drug discovery involve various 3D interactions between molecules, such as protein and protein, protein and small molecule, etc. Given that different molecules are usually represented in different granularity, existing methods usually encode each type of molecules independently with different models, leaving it defective to learn the various underlying interaction physics. In this paper, we first propose to universally represent an arbitrary 3D complex as a geometric graph of sets, shedding light on encoding all types of molecules with one model. We then propose a Generalist Equivariant Transformer (GET) to effectively capture both domain-specific hierarchies and domain-agnostic interaction physics. To be specific, GET consists of a bilevel attention module, a feed-forward module and a layer normalization module, where each module is E(3) equivariant and specialized for handling sets of variable sizes. Notably, in contrast to conventional pooling-based hierarchical models, our GET is able to retain fine-grained information of all levels. Extensive experiments on the interactions between proteins, small molecules and RNA/DNAs verify the effectiveness and generalization capability of our proposed method across different domains.
<div id='section'>Paperid: <span id='pid'>418, <a href='https://arxiv.org/pdf/2302.04611.pdf' target='_blank'>https://arxiv.org/pdf/2302.04611.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengchao Liu, Yanjing Li, Zhuoxinran Li, Anthony Gitter, Yutao Zhu, Jiarui Lu, Zhao Xu, Weili Nie, Arvind Ramanathan, Chaowei Xiao, Jian Tang, Hongyu Guo, Anima Anandkumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.04611">A Text-guided Protein Design Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current AI-assisted protein design mainly utilizes protein sequential and structural information. Meanwhile, there exists tremendous knowledge curated by humans in the text format describing proteins' high-level functionalities. Yet, whether the incorporation of such text data can help protein design tasks has not been explored. To bridge this gap, we propose ProteinDT, a multi-modal framework that leverages textual descriptions for protein design. ProteinDT consists of three subsequent steps: ProteinCLAP which aligns the representation of two modalities, a facilitator that generates the protein representation from the text modality, and a decoder that creates the protein sequences from the representation. To train ProteinDT, we construct a large dataset, SwissProtCLAP, with 441K text and protein pairs. We quantitatively verify the effectiveness of ProteinDT on three challenging tasks: (1) over 90% accuracy for text-guided protein generation; (2) best hit ratio on 12 zero-shot text-guided protein editing tasks; (3) superior performance on four out of six protein property prediction benchmarks.
<div id='section'>Paperid: <span id='pid'>419, <a href='https://arxiv.org/pdf/2302.00203.pdf' target='_blank'>https://arxiv.org/pdf/2302.00203.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangzhe Kong, Wenbing Huang, Yang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.00203">End-to-End Full-Atom Antibody Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibody design is an essential yet challenging task in various domains like therapeutics and biology. There are two major defects in current learning-based methods: 1) tackling only a certain subtask of the whole antibody design pipeline, making them suboptimal or resource-intensive. 2) omitting either the framework regions or side chains, thus incapable of capturing the full-atom geometry. To address these pitfalls, we propose dynamic Multi-channel Equivariant grAph Network (dyMEAN), an end-to-end full-atom model for E(3)-equivariant antibody design given the epitope and the incomplete sequence of the antibody. Specifically, we first explore structural initialization as a knowledgeable guess of the antibody structure and then propose shadow paratope to bridge the epitope-antibody connections. Both 1D sequences and 3D structures are updated via an adaptive multi-channel equivariant encoder that is able to process protein residues of variable sizes when considering full atoms. Finally, the updated antibody is docked to the epitope via the alignment of the shadow paratope. Experiments on epitope-binding CDR-H3 design, complex structure prediction, and affinity optimization demonstrate the superiority of our end-to-end framework and full-atom modeling.
<div id='section'>Paperid: <span id='pid'>420, <a href='https://arxiv.org/pdf/2212.09400.pdf' target='_blank'>https://arxiv.org/pdf/2212.09400.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peng Gao, Feng Gao, Jian-Cheng Ni, Yu Wang, Fei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.09400">Medical Knowledge Graph QA for Drug-Drug Interaction Prediction based on Multi-hop Machine Reading Comprehension</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drug-drug interaction prediction is a crucial issue in molecular biology. Traditional methods of observing drug-drug interactions through medical experiments require significant resources and labor. This paper presents a medical knowledge graph question answering model, dubbed MedKGQA, that predicts drug-drug interaction by employing machine reading comprehension from closed-domain literature and constructing a knowledge graph of drug-protein triplets from open-domain documents. The model vectorizes the drug-protein target attributes in the graph using entity embeddings and establishes directed connections between drug and protein entities based on the metabolic interaction pathways of protein targets in the human body. This aligns multiple external knowledge and applies it to learn the graph neural network. Without bells and whistles, the proposed model achieved a 4.5% improvement in terms of drug-drug interaction prediction accuracy compared to previous state-of-the-art models on the Qangaroo MedHop dataset. Experimental results demonstrate the efficiency and effectiveness of the model and verify the feasibility of integrating external knowledge in machine reading comprehension tasks.
<div id='section'>Paperid: <span id='pid'>421, <a href='https://arxiv.org/pdf/2210.08761.pdf' target='_blank'>https://arxiv.org/pdf/2210.08761.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chence Shi, Chuanrui Wang, Jiarui Lu, Bozitao Zhong, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.08761">Protein Sequence and Structure Co-Design with Equivariant Translation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are macromolecules that perform essential functions in all living organisms. Designing novel proteins with specific structures and desired functions has been a long-standing challenge in the field of bioengineering. Existing approaches generate both protein sequence and structure using either autoregressive models or diffusion models, both of which suffer from high inference costs. In this paper, we propose a new approach capable of protein sequence and structure co-design, which iteratively translates both protein sequence and structure into the desired state from random initialization, based on context features given a priori. Our model consists of a trigonometry-aware encoder that reasons geometrical constraints and interactions from context features, and a roto-translation equivariant decoder that translates protein sequence and structure interdependently. Notably, all protein amino acids are updated in one shot in each translation step, which significantly accelerates the inference process. Experimental results across multiple tasks show that our model outperforms previous state-of-the-art baselines by a large margin, and is able to design proteins of high fidelity as regards both sequence and structure, with running time orders of magnitude less than sampling-based methods.
<div id='section'>Paperid: <span id='pid'>422, <a href='https://arxiv.org/pdf/2203.00854.pdf' target='_blank'>https://arxiv.org/pdf/2203.00854.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shenggan Cheng, Xuanlei Zhao, Guangyang Lu, Jiarui Fang, Zhongming Yu, Tian Zheng, Ruidong Wu, Xiwen Zhang, Jian Peng, Yang You
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.00854">FastFold: Reducing AlphaFold Training Time from 11 Days to 67 Hours</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structure prediction helps to understand gene translation and protein function, which is of growing interest and importance in structural biology. The AlphaFold model, which used transformer architecture to achieve atomic-level accuracy in protein structure prediction, was a significant breakthrough. However, training and inference of the AlphaFold model are challenging due to its high computation and memory cost. In this work, we present FastFold, an efficient implementation of AlphaFold for both training and inference. We propose Dynamic Axial Parallelism and Duality Async Operations to improve the scaling efficiency of model parallelism. Besides, AutoChunk is proposed to reduce memory cost by over 80% during inference by automatically determining the chunk strategy. Experimental results show that FastFold reduces overall training time from 11 days to 67 hours and achieves 7.5X - 9.5X speedup for long-sequence inference. Furthermore, we scale FastFold to 512 GPUs and achieve an aggregate throughput of 6.02 PetaFLOP/s with 90.1% parallel efficiency.
<div id='section'>Paperid: <span id='pid'>423, <a href='https://arxiv.org/pdf/2505.17478.pdf' target='_blank'>https://arxiv.org/pdf/2505.17478.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuning Shen, Lihao Wang, Huizhuo Yuan, Yan Wang, Bangji Yang, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17478">Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding protein dynamics is critical for elucidating their biological functions. The increasing availability of molecular dynamics (MD) data enables the training of deep generative models to efficiently explore the conformational space of proteins. However, existing approaches either fail to explicitly capture the temporal dependencies between conformations or do not support direct generation of time-independent samples. To address these limitations, we introduce ConfRover, an autoregressive model that simultaneously learns protein conformation and dynamics from MD trajectories, supporting both time-dependent and time-independent sampling. At the core of our model is a modular architecture comprising: (i) an encoding layer, adapted from protein folding models, that embeds protein-specific information and conformation at each time frame into a latent space; (ii) a temporal module, a sequence model that captures conformational dynamics across frames; and (iii) an SE(3) diffusion model as the structure decoder, generating conformations in continuous space. Experiments on ATLAS, a large-scale protein MD dataset of diverse structures, demonstrate the effectiveness of our model in learning conformational dynamics and supporting a wide range of downstream tasks. ConfRover is the first model to sample both protein conformations and trajectories within a single framework, offering a novel and flexible approach for learning from protein MD data.
<div id='section'>Paperid: <span id='pid'>424, <a href='https://arxiv.org/pdf/2505.11194.pdf' target='_blank'>https://arxiv.org/pdf/2505.11194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Fei, Michail Chatzianastasis, Sarah Almeida Carneiro, Hadi Abdine, Lawrence P. Petalidis, Michalis Vazirgiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11194">Prot2Text-V2: Protein Function Prediction with Multimodal Contrastive Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting protein function from sequence is a central challenge in computational biology. While existing methods rely heavily on structured ontologies or similarity-based techniques, they often lack the flexibility to express structure-free functional descriptions and novel biological functions. In this work, we introduce Prot2Text-V2, a novel multimodal sequence-to-text model that generates free-form natural language descriptions of protein function directly from amino acid sequences. Our method combines a protein language model as a sequence encoder (ESM-3B) and a decoder-only language model (LLaMA-3.1-8B-Instruct) through a lightweight nonlinear modality projector. A key innovation is our Hybrid Sequence-level Contrastive Alignment Learning (H-SCALE), which improves cross-modal learning by matching mean- and std-pooled protein embeddings with text representations via contrastive loss. After the alignment phase, we apply instruction-based fine-tuning using LoRA on the decoder to teach the model how to generate accurate protein function descriptions conditioned on the protein sequence. We train Prot2Text-V2 on about 250K curated entries from SwissProt and evaluate it under low-homology conditions, where test sequences have low similarity with training samples. Prot2Text-V2 consistently outperforms traditional and LLM-based baselines across various metrics.
<div id='section'>Paperid: <span id='pid'>425, <a href='https://arxiv.org/pdf/2504.05784.pdf' target='_blank'>https://arxiv.org/pdf/2504.05784.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paola F. Antonietti, Mattia Corti, Sergio Gómez, Ilaria Perugia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.05784">A structure-preserving LDG discretization of the Fisher-Kolmogorov equation for modeling neurodegenerative diseases</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents a structure-preserving, high-order, unconditionally stable numerical method for approximating the solution to the Fisher-Kolmogorov equation on polytopic meshes, with a particular focus on its application in simulating misfolded protein spreading in neurodegenerative diseases. The model problem is reformulated using an entropy variable to guarantee solution positivity, boundedness, and satisfaction of a discrete entropy-stability inequality at the numerical level. The scheme combines a local discontinuous Galerkin method on polytopal meshes for the space discretization with a $ν$-step backward differentiation formula for the time integration. Implementation details are discussed, including a detailed derivation of the linear systems arising from Newton's iteration. The accuracy and robustness of the proposed method are demonstrated through extensive numerical tests. Finally, the method's practical performance is demonstrated through simulations of $α$-synuclein propagation in a two-dimensional brain geometry segmented from MRI data, providing a relevant computational framework for modeling synucleopathies (such as Parkinson's disease) and, more generally, neurodegenerative diseases.
<div id='section'>Paperid: <span id='pid'>426, <a href='https://arxiv.org/pdf/2503.20913.pdf' target='_blank'>https://arxiv.org/pdf/2503.20913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiuyuan Hu, Guoqing Liu, Can Chen, Yang Zhao, Hao Zhang, Xue Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.20913">TransDiffSBDD: Causality-Aware Multi-Modal Structure-Based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug design (SBDD) is a critical task in drug discovery, requiring the generation of molecular information across two distinct modalities: discrete molecular graphs and continuous 3D coordinates. However, existing SBDD methods often overlook two key challenges: (1) the multi-modal nature of this task and (2) the causal relationship between these modalities, limiting their plausibility and performance. To address both challenges, we propose TransDiffSBDD, an integrated framework combining autoregressive transformers and diffusion models for SBDD. Specifically, the autoregressive transformer models discrete molecular information, while the diffusion model samples continuous distributions, effectively resolving the first challenge. To address the second challenge, we design a hybrid-modal sequence for protein-ligand complexes that explicitly respects the causality between modalities. Experiments on the CrossDocked2020 benchmark demonstrate that TransDiffSBDD outperforms existing baselines.
<div id='section'>Paperid: <span id='pid'>427, <a href='https://arxiv.org/pdf/2503.06340.pdf' target='_blank'>https://arxiv.org/pdf/2503.06340.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawen Wang, Samin Karim, Yuan Hong, Binghui Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.06340">Backdoor Attacks on Discrete Graph Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models are powerful generative models in continuous data domains such as image and video data. Discrete graph diffusion models (DGDMs) have recently extended them for graph generation, which are crucial in fields like molecule and protein modeling, and obtained the SOTA performance. However, it is risky to deploy DGDMs for safety-critical applications (e.g., drug discovery) without understanding their security vulnerabilities. In this work, we perform the first study on graph diffusion models against backdoor attacks, a severe attack that manipulates both the training and inference/generation phases in graph diffusion models. We first define the threat model, under which we design the attack such that the backdoored graph diffusion model can generate 1) high-quality graphs without backdoor activation, 2) effective, stealthy, and persistent backdoored graphs with backdoor activation, and 3) graphs that are permutation invariant and exchangeable--two core properties in graph generative models. 1) and 2) are validated via empirical evaluations without and with backdoor defenses, while 3) is validated via theoretical results.
<div id='section'>Paperid: <span id='pid'>428, <a href='https://arxiv.org/pdf/2503.03904.pdf' target='_blank'>https://arxiv.org/pdf/2503.03904.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikolaos Nakis, Chrysoula Kosma, Anastasia Brativnyk, Michail Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.03904">The Signed Two-Space Proximity Model for Learning Representations in Protein-Protein Interaction Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting complex protein-protein interactions (PPIs) is crucial for decoding biological processes, from cellular functioning to disease mechanisms. However, experimental methods for determining PPIs are computationally expensive. Thus, attention has been recently drawn to machine learning approaches. Furthermore, insufficient effort has been made toward analyzing signed PPI networks, which capture both activating (positive) and inhibitory (negative) interactions. To accurately represent biological relationships, we present the Signed Two-Space Proximity Model (S2-SPM) for signed PPI networks, which explicitly incorporates both types of interactions, reflecting the complex regulatory mechanisms within biological systems. This is achieved by leveraging two independent latent spaces to differentiate between positive and negative interactions while representing protein similarity through proximity in these spaces. Our approach also enables the identification of archetypes representing extreme protein profiles. S2-SPM's superior performance in predicting the presence and sign of interactions in SPPI networks is demonstrated in link prediction tasks against relevant baseline methods. Additionally, the biological prevalence of the identified archetypes is confirmed by an enrichment analysis of Gene Ontology (GO) terms, which reveals that distinct biological tasks are associated with archetypal groups formed by both interactions. This study is also validated regarding statistical significance and sensitivity analysis, providing insights into the functional roles of different interaction types. Finally, the robustness and consistency of the extracted archetype structures are confirmed using the Bayesian Normalized Mutual Information (BNMI) metric, proving the model's reliability in capturing meaningful SPPI patterns.
<div id='section'>Paperid: <span id='pid'>429, <a href='https://arxiv.org/pdf/2502.15954.pdf' target='_blank'>https://arxiv.org/pdf/2502.15954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zaifu Zhan, Jun Wang, Shuang Zhou, Jiawen Deng, Rui Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15954">MMRAG: Multi-Mode Retrieval-Augmented Generation with Large Language Models for Biomedical In-Context Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Objective: To optimize in-context learning in biomedical natural language processing by improving example selection. Methods: We introduce a novel multi-mode retrieval-augmented generation (MMRAG) framework, which integrates four retrieval strategies: (1) Random Mode, selecting examples arbitrarily; (2) Top Mode, retrieving the most relevant examples based on similarity; (3) Diversity Mode, ensuring variation in selected examples; and (4) Class Mode, selecting category-representative examples. This study evaluates MMRAG on three core biomedical NLP tasks: Named Entity Recognition (NER), Relation Extraction (RE), and Text Classification (TC). The datasets used include BC2GM for gene and protein mention recognition (NER), DDI for drug-drug interaction extraction (RE), GIT for general biomedical information extraction (RE), and HealthAdvice for health-related text classification (TC). The framework is tested with two large language models (Llama2-7B, Llama3-8B) and three retrievers (Contriever, MedCPT, BGE-Large) to assess performance across different retrieval strategies. Results: The results from the Random mode indicate that providing more examples in the prompt improves the model's generation performance. Meanwhile, Top mode and Diversity mode significantly outperform Random mode on the RE (DDI) task, achieving an F1 score of 0.9669, a 26.4% improvement. Among the three retrievers tested, Contriever outperformed the other two in a greater number of experiments. Additionally, Llama 2 and Llama 3 demonstrated varying capabilities across different tasks, with Llama 3 showing a clear advantage in handling NER tasks. Conclusion: MMRAG effectively enhances biomedical in-context learning by refining example selection, mitigating data scarcity issues, and demonstrating superior adaptability for NLP-driven healthcare applications.
<div id='section'>Paperid: <span id='pid'>430, <a href='https://arxiv.org/pdf/2502.06027.pdf' target='_blank'>https://arxiv.org/pdf/2502.06027.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziqi Chen, Bo Peng, Tianhua Zhai, Daniel Adu-Ampratwum, Xia Ning
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06027">Generating 3D Binding Molecules Using Shape-Conditioned Diffusion Models with Guidance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drug development is a critical but notoriously resource- and time-consuming process. In this manuscript, we develop a novel generative artificial intelligence (genAI) method DiffSMol to facilitate drug development. DiffSmol generates 3D binding molecules based on the shapes of known ligands. DiffSMol encapsulates geometric details of ligand shapes within pre-trained, expressive shape embeddings and then generates new binding molecules through a diffusion model. DiffSMol further modifies the generated 3D structures iteratively via shape guidance to better resemble the ligand shapes. It also tailors the generated molecules toward optimal binding affinities under the guidance of protein pockets. Here, we show that DiffSMol outperforms the state-of-the-art methods on benchmark datasets. When generating binding molecules resembling ligand shapes, DiffSMol with shape guidance achieves a success rate 61.4%, substantially outperforming the best baseline (11.2%), meanwhile producing molecules with novel molecular graph structures. DiffSMol with pocket guidance also outperforms the best baseline in binding affinities by 13.2%, and even by 17.7% when combined with shape guidance. Case studies for two critical drug targets demonstrate very favorable physicochemical and pharmacokinetic properties of the generated molecules, thus, the potential of DiffSMol in developing promising drug candidates.
<div id='section'>Paperid: <span id='pid'>431, <a href='https://arxiv.org/pdf/2412.19661.pdf' target='_blank'>https://arxiv.org/pdf/2412.19661.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Valentina Pederzoli, Mattia Corti, Davide Riccobelli, Paola F. Antonietti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.19661">A coupled mathematical and numerical model for protein spreading and tissue atrophy, applied to Alzheimer's disease</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The aim of this paper is to introduce, analyse and test in practice a new mathematical model describing the interplay between biological tissue atrophy driven by pathogen diffusion, with applications to neurodegenerative disorders. This study introduces a novel mathematical and computational model comprising a Fisher-Kolmogorov equation for species diffusion coupled with an elasticity equation governing mass loss. These equations intertwine through a logistic law dictating the reduction of the medium's mass. One potential application of this model lies in understanding the onset and development of Alzheimer's disease. Here, the equations can describe the propagation of misfolded tau-proteins and the ensuing brain atrophy characteristic of the disease. To address numerically the inherited complexities, we propose a Polygonal Discontinuous Galerkin method on polygonal/polyhedral grids for spatial discretization, while time integration relies on the theta-method. We present the mathematical model, delving into its characteristics and propose discretization applied. Furthermore, convergence results are presented to validate the model, accompanied by simulations illustrating the application scenario of the onset of Alzheimer's disease.
<div id='section'>Paperid: <span id='pid'>432, <a href='https://arxiv.org/pdf/2410.03553.pdf' target='_blank'>https://arxiv.org/pdf/2410.03553.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Wu, Chao Wang, Liyi Chen, Mingze Yin, Yiheng Zhu, Kun Fu, Jieping Ye, Hui Xiong, Zheng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.03553">Structure-Enhanced Protein Instruction Tuning: Towards General-Purpose Protein Understanding with LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins, as essential biomolecules, play a central role in biological processes, including metabolic reactions and DNA replication. Accurate prediction of their properties and functions is crucial in biological applications. Recent development of protein language models (pLMs) with supervised fine tuning provides a promising solution to this problem. However, the fine-tuned model is tailored for particular downstream prediction task, and achieving general-purpose protein understanding remains a challenge. In this paper, we introduce Structure-Enhanced Protein Instruction Tuning (SEPIT) framework to bridge this gap. Our approach incorporates a novel structure-aware module into pLMs to enrich their structural knowledge, and subsequently integrates these enhanced pLMs with large language models (LLMs) to advance protein understanding. In this framework, we propose a novel instruction tuning pipeline. First, we warm up the enhanced pLMs using contrastive learning and structure denoising. Then, caption-based instructions are used to establish a basic understanding of proteins. Finally, we refine this understanding by employing a mixture of experts (MoEs) to capture more complex properties and functional information with the same number of activated parameters. Moreover, we construct the largest and most comprehensive protein instruction dataset to date, which allows us to train and evaluate the general-purpose protein understanding model. Extensive experiments on both open-ended generation and closed-set answer tasks demonstrate the superior performance of SEPIT over both closed-source general LLMs and open-source LLMs trained with protein knowledge.
<div id='section'>Paperid: <span id='pid'>433, <a href='https://arxiv.org/pdf/2408.06396.pdf' target='_blank'>https://arxiv.org/pdf/2408.06396.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kamyar Zeinalipour, Neda Jamshidi, Monica Bianchini, Marco Maggini, Marco Gori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.06396">Design Proteins Using Large Language Models: Enhancements and Comparative Analyses</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained LLMs have demonstrated substantial capabilities across a range of conventional natural language processing (NLP) tasks, such as summarization and entity recognition. In this paper, we explore the application of LLMs in the generation of high-quality protein sequences. Specifically, we adopt a suite of pre-trained LLMs, including Mistral-7B1, Llama-2-7B2, Llama-3-8B3, and gemma-7B4, to produce valid protein sequences. All of these models are publicly available.5 Unlike previous work in this field, our approach utilizes a relatively small dataset comprising 42,000 distinct human protein sequences. We retrain these models to process protein-related data, ensuring the generation of biologically feasible protein structures. Our findings demonstrate that even with limited data, the adapted models exhibit efficiency comparable to established protein-focused models such as ProGen varieties, ProtGPT2, and ProLLaMA, which were trained on millions of protein sequences. To validate and quantify the performance of our models, we conduct comparative analyses employing standard metrics such as pLDDT, RMSD, TM-score, and REU. Furthermore, we commit to making the trained versions of all four models publicly available, fostering greater transparency and collaboration in the field of computational biology.
<div id='section'>Paperid: <span id='pid'>434, <a href='https://arxiv.org/pdf/2406.14142.pdf' target='_blank'>https://arxiv.org/pdf/2406.14142.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michail Chatzianastasis, Yang Zhang, George Dasoulas, Michalis Vazirgiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14142">Geometric Self-Supervised Pretraining on 3D Protein Structures using Subgraphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein representation learning aims to learn informative protein embeddings capable of addressing crucial biological questions, such as protein function prediction. Although sequence-based transformer models have shown promising results by leveraging the vast amount of protein sequence data in a self-supervised way, there is still a gap in exploiting the available 3D protein structures. In this work, we propose a pre-training scheme going beyond trivial masking methods leveraging 3D and hierarchical structures of proteins. We propose a novel self-supervised method to pretrain 3D graph neural networks on 3D protein structures, by predicting the distances between local geometric centroids of protein subgraphs and the global geometric centroid of the protein. By considering subgraphs and their relationships to the global protein structure, our model can better learn the geometric properties of the protein structure. We experimentally show that our proposed pertaining strategy leads to significant improvements up to 6\%, in the performance of 3D GNNs in various protein classification tasks. Our work opens new possibilities in unsupervised learning for protein graph models while eliminating the need for multiple views, augmentations, or masking strategies which are currently used so far.
<div id='section'>Paperid: <span id='pid'>435, <a href='https://arxiv.org/pdf/2406.13864.pdf' target='_blank'>https://arxiv.org/pdf/2406.13864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arian R. Jamasb, Alex Morehead, Chaitanya K. Joshi, Zuobai Zhang, Kieran Didi, Simon V. Mathis, Charles Harris, Jian Tang, Jianlin Cheng, Pietro Lio, Tom L. Blundell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.13864">Evaluating representation learning on the protein structure universe</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce ProteinWorkshop, a comprehensive benchmark suite for representation learning on protein structures with Geometric Graph Neural Networks. We consider large-scale pre-training and downstream tasks on both experimental and predicted structures to enable the systematic evaluation of the quality of the learned structural representation and their usefulness in capturing functional relationships for downstream tasks. We find that: (1) large-scale pretraining on AlphaFold structures and auxiliary tasks consistently improve the performance of both rotation-invariant and equivariant GNNs, and (2) more expressive equivariant GNNs benefit from pretraining to a greater extent compared to invariant models. We aim to establish a common ground for the machine learning and computational biology communities to rigorously compare and advance protein structure representation learning. Our open-source codebase reduces the barrier to entry for working with large protein structure datasets by providing: (1) storage-efficient dataloaders for large-scale structural databases including AlphaFoldDB and ESM Atlas, as well as (2) utilities for constructing new tasks from the entire PDB. ProteinWorkshop is available at: github.com/a-r-j/ProteinWorkshop.
<div id='section'>Paperid: <span id='pid'>436, <a href='https://arxiv.org/pdf/2406.05766.pdf' target='_blank'>https://arxiv.org/pdf/2406.05766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zijia Song, Zelin Zang, Yelin Wang, Guozheng Yang, Kaicheng yu, Wanyu Chen, Miaoyu Wang, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.05766">Set-CLIP: Exploring Aligned Semantic From Low-Alignment Multimodal Data Through A Distribution View</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal fusion breaks through the boundaries between diverse modalities and has already achieved notable performances. However, in many specialized fields, it is struggling to obtain sufficient alignment data for training, which seriously limits the use of previously effective models. Therefore, semi-supervised learning approaches are attempted to facilitate multimodal alignment by learning from low-alignment data with fewer matched pairs, but traditional techniques like pseudo-labeling may run into troubles in the label-deficient scenarios. To tackle these challenges, we reframe semi-supervised multimodal alignment as a manifold matching issue and propose a new methodology based on CLIP, termed Set-CLIP. Specifically, by designing a novel semantic density distribution loss, we constrain the latent representation distribution with fine granularity and extract implicit semantic alignment from unpaired multimodal data, thereby reducing the reliance on numerous strictly matched pairs. Furthermore, we apply coarse-grained modality adaptation and unimodal self-supervised guidance to narrow the gaps between modality spaces and improve the stability of representation distributions. Extensive experiments conducted on a range of tasks in various fields, including protein analysis, remote sensing, and the general vision-language field, validate the efficacy of our proposed Set-CLIP method. Especially with no paired data for supervised training, Set-CLIP is still outstanding, which brings an improvement of 144.83% over CLIP.
<div id='section'>Paperid: <span id='pid'>437, <a href='https://arxiv.org/pdf/2405.13964.pdf' target='_blank'>https://arxiv.org/pdf/2405.13964.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ye Yuan, Youyuan Zhang, Can Chen, Haolun Wu, Zixuan Li, Jianmo Li, James J. Clark, Xue Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13964">Design Editing for Offline Model-based Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline model-based optimization (MBO) aims to maximize a black-box objective function using only an offline dataset of designs and scores. These tasks span various domains, such as robotics, material design, and protein and molecular engineering. A common approach involves training a surrogate model using existing designs and their corresponding scores, and then generating new designs through gradient-based updates with respect to the surrogate model. This method suffers from the out-of-distribution issue, where the surrogate model may erroneously predict high scores for unseen designs. To address this challenge, we introduce a novel method, Design Editing for Offline Model-based Optimization (DEMO), which leverages a diffusion prior to calibrate overly optimized designs. DEMO first generates pseudo design candidates by performing gradient ascent with respect to a surrogate model. While these pseudo design candidates contain information beyond the offline dataset, they might be invalid or have erroneously high predicted scores. Therefore, to address this challenge while utilizing the information provided by pseudo design candidates, we propose an editing process to refine these pseudo design candidates. We introduce noise to the pseudo design candidates and subsequently denoise them with a diffusion prior trained on the offline dataset, ensuring they align with the distribution of valid designs. Empirical evaluations on seven offline MBO tasks show that, with properly tuned hyperparameters, DEMOs score is competitive with the best previously reported scores in the literature.
<div id='section'>Paperid: <span id='pid'>438, <a href='https://arxiv.org/pdf/2405.02299.pdf' target='_blank'>https://arxiv.org/pdf/2405.02299.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziqi Gao, Tao Feng, Jiaxuan You, Chenyi Zi, Yan Zhou, Chen Zhang, Jia Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02299">Deep Reinforcement Learning for Modelling Protein Complexes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AlphaFold can be used for both single-chain and multi-chain protein structure prediction, while the latter becomes extremely challenging as the number of chains increases. In this work, by taking each chain as a node and assembly actions as edges, we show that an acyclic undirected connected graph can be used to predict the structure of multi-chain protein complexes (a.k.a., protein complex modelling, PCM). However, there are still two challenges: 1) The huge combinatorial optimization space of $N^{N-2}$ ($N$ is the number of chains) for the PCM problem can easily lead to high computational cost. 2) The scales of protein complexes exhibit distribution shift due to variance in chain numbers, which calls for the generalization in modelling complexes of various scales. To address these challenges, we propose GAPN, a Generative Adversarial Policy Network powered by domain-specific rewards and adversarial loss through policy gradient for automatic PCM prediction. Specifically, GAPN learns to efficiently search through the immense assembly space and optimize the direct docking reward through policy gradient. Importantly, we design an adversarial reward function to enhance the receptive field of our model. In this way, GAPN will simultaneously focus on a specific batch of complexes and the global assembly rules learned from complexes with varied chain numbers. Empirically, we have achieved both significant accuracy (measured by RMSD and TM-Score) and efficiency improvements compared to leading PCM softwares.
<div id='section'>Paperid: <span id='pid'>439, <a href='https://arxiv.org/pdf/2403.14088.pdf' target='_blank'>https://arxiv.org/pdf/2403.14088.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yan Wang, Lihao Wang, Yuning Shen, Yiqun Wang, Huizhuo Yuan, Yue Wu, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14088">Protein Conformation Generation via Force-Guided SE(3) Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The conformational landscape of proteins is crucial to understanding their functionality in complex biological processes. Traditional physics-based computational methods, such as molecular dynamics (MD) simulations, suffer from rare event sampling and long equilibration time problems, hindering their applications in general protein systems. Recently, deep generative modeling techniques, especially diffusion models, have been employed to generate novel protein conformations. However, existing score-based diffusion methods cannot properly incorporate important physical prior knowledge to guide the generation process, causing large deviations in the sampled protein conformations from the equilibrium distribution. In this paper, to overcome these limitations, we propose a force-guided SE(3) diffusion model, ConfDiff, for protein conformation generation. By incorporating a force-guided network with a mixture of data-based score models, ConfDiff can generate protein conformations with rich diversity while preserving high fidelity. Experiments on a variety of protein conformation prediction tasks, including 12 fast-folding proteins and the Bovine Pancreatic Trypsin Inhibitor (BPTI), demonstrate that our method surpasses the state-of-the-art method.
<div id='section'>Paperid: <span id='pid'>440, <a href='https://arxiv.org/pdf/2402.14789.pdf' target='_blank'>https://arxiv.org/pdf/2402.14789.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Johnathan Xie, Yoonho Lee, Annie S. Chen, Chelsea Finn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14789">Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised learning excels in learning representations from large amounts of unlabeled data, demonstrating success across multiple data modalities. Yet, extending self-supervised learning to new modalities is non-trivial because the specifics of existing methods are tailored to each domain, such as domain-specific augmentations which reflect the invariances in the target task. While masked modeling is promising as a domain-agnostic framework for self-supervised learning because it does not rely on input augmentations, its mask sampling procedure remains domain-specific. We present Self-guided Masked Autoencoders (SMA), a fully domain-agnostic masked modeling method. SMA trains an attention based model using a masked modeling objective, by learning masks to sample without any domain-specific assumptions. We evaluate SMA on three self-supervised learning benchmarks in protein biology, chemical property prediction, and particle physics. We find SMA is capable of learning representations without domain-specific knowledge and achieves state-of-the-art performance on these three benchmarks.
<div id='section'>Paperid: <span id='pid'>441, <a href='https://arxiv.org/pdf/2401.15747.pdf' target='_blank'>https://arxiv.org/pdf/2401.15747.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paola F. Antonietti, Mattia Corti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.15747">Numerical modelling of protein misfolding in neurodegenerative diseases: a computational study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The spreading of misfolded proteins is a known hallmark in some neurodegenerative diseases, known as proteinopathies. A significant example is the tau protein, associated with many pathologies, such as Alzheimer's. In this work, we discuss and compare two different models for the mathematical modelling of protein misfolding, namely the heterodimer model and the Fisher-Kolmogorov model, as well as their numerical discretizations. We introduce a discontinuous Galerkin method on polygonal and polyhedral grids for space discretization to accurately simulate the wavefronts typically observed in the prionic spreading. Starting from the semidiscrete formulations, we use a Crank-Nicolson scheme to advance in time. Finally, we simulate the spreading of the misfolded tau protein in a two-dimensional brain slice in the sagittal plane with a polygonal agglomerated grid. The simulation is performed using both the presented models, and we compare the results and the differences deriving from the modelling choices.
<div id='section'>Paperid: <span id='pid'>442, <a href='https://arxiv.org/pdf/2310.15211.pdf' target='_blank'>https://arxiv.org/pdf/2310.15211.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shunian Xiang, Patrick J. Lawrence, Bo Peng, ChienWei Chiang, Dokyoon Kim, Li Shen, Xia Ning
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.15211">Modeling Path Importance for Effective Alzheimer's Disease Drug Repurposing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, drug repurposing has emerged as an effective and resource-efficient paradigm for AD drug discovery. Among various methods for drug repurposing, network-based methods have shown promising results as they are capable of leveraging complex networks that integrate multiple interaction types, such as protein-protein interactions, to more effectively identify candidate drugs. However, existing approaches typically assume paths of the same length in the network have equal importance in identifying the therapeutic effect of drugs. Other domains have found that same length paths do not necessarily have the same importance. Thus, relying on this assumption may be deleterious to drug repurposing attempts. In this work, we propose MPI (Modeling Path Importance), a novel network-based method for AD drug repurposing. MPI is unique in that it prioritizes important paths via learned node embeddings, which can effectively capture a network's rich structural information. Thus, leveraging learned embeddings allows MPI to effectively differentiate the importance among paths. We evaluate MPI against a commonly used baseline method that identifies anti-AD drug candidates primarily based on the shortest paths between drugs and AD in the network. We observe that among the top-50 ranked drugs, MPI prioritizes 20.0% more drugs with anti-AD evidence compared to the baseline. Finally, Cox proportional-hazard models produced from insurance claims data aid us in identifying the use of etodolac, nicotine, and BBB-crossing ACE-INHs as having a reduced risk of AD, suggesting such drugs may be viable candidates for repurposing and should be explored further in future studies.
<div id='section'>Paperid: <span id='pid'>443, <a href='https://arxiv.org/pdf/2310.08342.pdf' target='_blank'>https://arxiv.org/pdf/2310.08342.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paola F. Antonietti, Francesca Bonizzoni, Mattia Corti, Agnese Dall'Olio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08342">Discontinuous Galerkin approximations of the heterodimer model for protein-protein interaction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mathematical models of protein-protein dynamics, such as the heterodimer model, play a crucial role in understanding many physical phenomena. This model is a system of two semilinear parabolic partial differential equations describing the evolution and mutual interaction of biological species. An example is the neurodegenerative disease progression in some significant pathologies, such as Alzheimer's and Parkinson's diseases, characterized by the accumulation and propagation of toxic prionic proteins. This article presents and analyzes a flexible high-order discretization method for the numerical approximation of the heterodimer model. We propose a space discretization based on a Discontinuous Galerkin method on polygonal/polyhedral grids, which provides flexibility in handling complex geometries. Concerning the semi-discrete formulation, we prove stability and a-priori error estimates for the first time. Next, we adopt a $Î¸$-method scheme as a time integration scheme. Convergence tests are carried out to demonstrate the theoretical bounds and the ability of the method to approximate traveling wave solutions, considering also complex geometries such as brain sections reconstructed from medical images. Finally, the proposed scheme is tested in a practical test case stemming from neuroscience applications, namely the simulation of the spread of $Î±$-synuclein in a realistic test case of Parkinson's disease in a two-dimensional sagittal brain section geometry reconstructed from medical images.
<div id='section'>Paperid: <span id='pid'>444, <a href='https://arxiv.org/pdf/2310.06417.pdf' target='_blank'>https://arxiv.org/pdf/2310.06417.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qitian Wu, Chenxiao Yang, Kaipeng Zeng, Michael Bronstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06417">Supercharging Graph Transformers with Advective Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The capability of generalization is a cornerstone for the success of modern learning systems. For non-Euclidean data, e.g., graphs, that particularly involves topological structures, one important aspect neglected by prior studies is how machine learning models generalize under topological shifts. This paper proposes Advective Diffusion Transformer (AdvDIFFormer), a physics-inspired graph Transformer model designed to address this challenge. The model is derived from advective diffusion equations which describe a class of continuous message passing process with observed and latent topological structures. We show that AdvDIFFormer has provable capability for controlling generalization error with topological shifts, which in contrast cannot be guaranteed by graph diffusion models, i.e., the generalized formulation of common graph neural networks in continuous space. Empirically, the model demonstrates superiority in various predictive tasks across information networks, molecular screening and protein interactions.
<div id='section'>Paperid: <span id='pid'>445, <a href='https://arxiv.org/pdf/2309.11600.pdf' target='_blank'>https://arxiv.org/pdf/2309.11600.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ye Yuan, Can Chen, Zixuan Liu, Willie Neiswanger, Xue Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.11600">Importance-aware Co-teaching for Offline Model-based Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline model-based optimization aims to find a design that maximizes a property of interest using only an offline dataset, with applications in robot, protein, and molecule design, among others. A prevalent approach is gradient ascent, where a proxy model is trained on the offline dataset and then used to optimize the design. This method suffers from an out-of-distribution issue, where the proxy is not accurate for unseen designs. To mitigate this issue, we explore using a pseudo-labeler to generate valuable data for fine-tuning the proxy. Specifically, we propose \textit{\textbf{I}mportance-aware \textbf{C}o-\textbf{T}eaching for Offline Model-based Optimization}~(\textbf{ICT}). This method maintains three symmetric proxies with their mean ensemble as the final proxy, and comprises two steps. The first step is \textit{pseudo-label-driven co-teaching}. In this step, one proxy is iteratively selected as the pseudo-labeler for designs near the current optimization point, generating pseudo-labeled data. Subsequently, a co-teaching process identifies small-loss samples as valuable data and exchanges them between the other two proxies for fine-tuning, promoting knowledge transfer. This procedure is repeated three times, with a different proxy chosen as the pseudo-labeler each time, ultimately enhancing the ensemble performance. To further improve accuracy of pseudo-labels, we perform a secondary step of \textit{meta-learning-based sample reweighting}, which assigns importance weights to samples in the pseudo-labeled dataset and updates them via meta-learning. ICT achieves state-of-the-art results across multiple design-bench tasks, achieving the best mean rank of $3.1$ and median rank of $2$, among $15$ methods. Our source code can be found here.
<div id='section'>Paperid: <span id='pid'>446, <a href='https://arxiv.org/pdf/2308.11890.pdf' target='_blank'>https://arxiv.org/pdf/2308.11890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziqi Chen, Bo Peng, Srinivasan Parthasarathy, Xia Ning
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.11890">Shape-conditioned 3D Molecule Generation via Equivariant Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ligand-based drug design aims to identify novel drug candidates of similar shapes with known active molecules. In this paper, we formulated an in silico shape-conditioned molecule generation problem to generate 3D molecule structures conditioned on the shape of a given molecule. To address this problem, we developed a translation- and rotation-equivariant shape-guided generative model ShapeMol. ShapeMol consists of an equivariant shape encoder that maps molecular surface shapes into latent embeddings, and an equivariant diffusion model that generates 3D molecules based on these embeddings. Experimental results show that ShapeMol can generate novel, diverse, drug-like molecules that retain 3D molecular shapes similar to the given shape condition. These results demonstrate the potential of ShapeMol in designing drug candidates of desired 3D shapes binding to protein target pockets.
<div id='section'>Paperid: <span id='pid'>447, <a href='https://arxiv.org/pdf/2307.14367.pdf' target='_blank'>https://arxiv.org/pdf/2307.14367.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hadi Abdine, Michail Chatzianastasis, Costas Bouyioukos, Michalis Vazirgiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.14367">Prot2Text: Multimodal Protein's Function Generation with GNNs and Transformers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, significant progress has been made in the field of protein function prediction with the development of various machine-learning approaches. However, most existing methods formulate the task as a multi-classification problem, i.e. assigning predefined labels to proteins. In this work, we propose a novel approach, Prot2Text, which predicts a protein's function in a free text style, moving beyond the conventional binary or categorical classifications. By combining Graph Neural Networks(GNNs) and Large Language Models(LLMs), in an encoder-decoder framework, our model effectively integrates diverse data types including protein sequence, structure, and textual annotation and description. This multimodal approach allows for a holistic representation of proteins' functions, enabling the generation of detailed and accurate functional descriptions. To evaluate our model, we extracted a multimodal protein dataset from SwissProt, and demonstrate empirically the effectiveness of Prot2Text. These results highlight the transformative impact of multimodal models, specifically the fusion of GNNs and LLMs, empowering researchers with powerful tools for more accurate function prediction of existing as well as first-to-see proteins.
<div id='section'>Paperid: <span id='pid'>448, <a href='https://arxiv.org/pdf/2305.03619.pdf' target='_blank'>https://arxiv.org/pdf/2305.03619.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mattia Corti, Francesca Bonizzoni, Paola F. Antonietti, Alfio M. Quarteroni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.03619">Uncertainty Quantification for Fisher-Kolmogorov Equation on Graphs with Application to Patient-Specific Alzheimer Disease</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Fisher-Kolmogorov equation is a diffusion-reaction PDE that is used to model the accumulation of prionic proteins, which are responsible for many different neurological disorders. Likely, the most important and studied misfolded protein in literature is the Amyloid-$Î²$, responsible for the onset of Alzheimer disease. Starting from medical images we construct a reduced-order model based on a graph brain connectome. The reaction coefficient of the proteins is modelled as a stochastic random field, taking into account all the many different underlying physical processes, which can hardly be measured. Its probability distribution is inferred by means of the Monte Carlo Markov Chain method applied to clinical data. The resulting model is patient-specific and can be employed for predicting the disease's future development. Forward uncertainty quantification techniques (Monte Carlo and sparse grid stochastic collocation) are applied with the aim of quantifying the impact of the variability of the reaction coefficient on the progression of protein accumulation within the next 20 years.
<div id='section'>Paperid: <span id='pid'>449, <a href='https://arxiv.org/pdf/2509.17224.pdf' target='_blank'>https://arxiv.org/pdf/2509.17224.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Jing, Bonnie Berger, Tommi Jaakkola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17224">AI-based Methods for Simulating, Sampling, and Predicting Protein Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in deep learning have opened an era of abundant and accurate predicted protein structures; however, similar progress in protein ensembles has remained elusive. This review highlights several recent research directions towards AI-based predictions of protein ensembles, including coarse-grained force fields, generative models, multiple sequence alignment perturbation methods, and modeling of ensemble descriptors. An emphasis is placed on realistic assessments of the technological maturity of current methods, the strengths and weaknesses of broad families of techniques, and promising machine learning frameworks at an early stage of development. We advocate for "closing the loop" between model training, simulation, and inference to overcome challenges in training data availability and to enable the next generation of models.
<div id='section'>Paperid: <span id='pid'>450, <a href='https://arxiv.org/pdf/2509.15242.pdf' target='_blank'>https://arxiv.org/pdf/2509.15242.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaydeep Rade, Md Hasibul Hasan Hasib, Meric Ozturk, Baboucarr Faal, Sheng Yang, Dipali G. Sashital, Vincenzo Venditti, Baoyu Chen, Soumik Sarkar, Adarsh Krishnamurthy, Anwesha Sarkar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15242">ProFusion: 3D Reconstruction of Protein Complex Structures from Multi-view AFM Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI-based in silico methods have improved protein structure prediction but often struggle with large protein complexes (PCs) involving multiple interacting proteins due to missing 3D spatial cues. Experimental techniques like Cryo-EM are accurate but costly and time-consuming. We present ProFusion, a hybrid framework that integrates a deep learning model with Atomic Force Microscopy (AFM), which provides high-resolution height maps from random orientations, naturally yielding multi-view data for 3D reconstruction. However, generating a large-scale AFM imaging data set sufficient to train deep learning models is impractical. Therefore, we developed a virtual AFM framework that simulates the imaging process and generated a dataset of ~542,000 proteins with multi-view synthetic AFM images. We train a conditional diffusion model to synthesize novel views from unposed inputs and an instance-specific Neural Radiance Field (NeRF) model to reconstruct 3D structures. Our reconstructed 3D protein structures achieve an average Chamfer Distance within the AFM imaging resolution, reflecting high structural fidelity. Our method is extensively validated on experimental AFM images of various PCs, demonstrating strong potential for accurate, cost-effective protein complex structure prediction and rapid iterative validation using AFM experiments.
<div id='section'>Paperid: <span id='pid'>451, <a href='https://arxiv.org/pdf/2506.05864.pdf' target='_blank'>https://arxiv.org/pdf/2506.05864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiakai Zhang, Shouchen Zhou, Haizhao Dai, Xinhang Liu, Peihao Wang, Zhiwen Fan, Yuan Pei, Jingyi Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.05864">CryoFastAR: Fast Cryo-EM Ab Initio Reconstruction Made Easy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pose estimation from unordered images is fundamental for 3D reconstruction, robotics, and scientific imaging. Recent geometric foundation models, such as DUSt3R, enable end-to-end dense 3D reconstruction but remain underexplored in scientific imaging fields like cryo-electron microscopy (cryo-EM) for near-atomic protein reconstruction. In cryo-EM, pose estimation and 3D reconstruction from unordered particle images still depend on time-consuming iterative optimization, primarily due to challenges such as low signal-to-noise ratios (SNR) and distortions from the contrast transfer function (CTF). We introduce CryoFastAR, the first geometric foundation model that can directly predict poses from Cryo-EM noisy images for Fast ab initio Reconstruction. By integrating multi-view features and training on large-scale simulated cryo-EM data with realistic noise and CTF modulations, CryoFastAR enhances pose estimation accuracy and generalization. To enhance training stability, we propose a progressive training strategy that first allows the model to extract essential features under simpler conditions before gradually increasing difficulty to improve robustness. Experiments show that CryoFastAR achieves comparable quality while significantly accelerating inference over traditional iterative approaches on both synthetic and real datasets.
<div id='section'>Paperid: <span id='pid'>452, <a href='https://arxiv.org/pdf/2502.09890.pdf' target='_blank'>https://arxiv.org/pdf/2502.09890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vinh Tong, Trung-Dung Hoang, Anji Liu, Guy Van den Broeck, Mathias Niepert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09890">Rao-Blackwell Gradient Estimators for Equivariant Denoising Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In domains such as molecular and protein generation, physical systems exhibit inherent symmetries that are critical to model. Two main strategies have emerged for learning invariant distributions: designing equivariant network architectures and using data augmentation to approximate equivariance. While equivariant architectures preserve symmetry by design, they often involve greater complexity and pose optimization challenges. Data augmentation, on the other hand, offers flexibility but may fall short in fully capturing symmetries. Our framework enhances both approaches by reducing training variance and providing a provably lower-variance gradient estimator. We achieve this by interpreting data augmentation as a Monte Carlo estimator of the training gradient and applying Rao-Blackwellization. This leads to more stable optimization, faster convergence, and reduced variance, all while requiring only a single forward and backward pass per sample. We also present a practical implementation of this estimator incorporating the loss and sampling procedure through a method we call Orbit Diffusion. Theoretically, we guarantee that our loss admits equivariant minimizers. Empirically, Orbit Diffusion achieves state-of-the-art results on GEOM-QM9 for molecular conformation generation, improves crystal structure prediction, and advances text-guided crystal generation on the Perov-5 and MP-20 benchmarks. Additionally, it enhances protein designability in protein structure generation.
<div id='section'>Paperid: <span id='pid'>453, <a href='https://arxiv.org/pdf/2501.19200.pdf' target='_blank'>https://arxiv.org/pdf/2501.19200.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lea Bogensperger, Dominik Narnhofer, Ahmed Allam, Konrad Schindler, Michael Krauthammer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.19200">A Variational Perspective on Generative Protein Fitness Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of protein fitness optimization is to discover new protein variants with enhanced fitness for a given use. The vast search space and the sparsely populated fitness landscape, along with the discrete nature of protein sequences, pose significant challenges when trying to determine the gradient towards configurations with higher fitness. We introduce Variational Latent Generative Protein Optimization (VLGPO), a variational perspective on fitness optimization. Our method embeds protein sequences in a continuous latent space to enable efficient sampling from the fitness distribution and combines a (learned) flow matching prior over sequence mutations with a fitness predictor to guide optimization towards sequences with high fitness. VLGPO achieves state-of-the-art results on two different protein benchmarks of varying complexity. Moreover, the variational design with explicit prior and likelihood functions offers a flexible plug-and-play framework that can be easily customized to suit various protein design tasks.
<div id='section'>Paperid: <span id='pid'>454, <a href='https://arxiv.org/pdf/2501.06108.pdf' target='_blank'>https://arxiv.org/pdf/2501.06108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>AurÃ©lien Decelle, Alfonso de JesÃºs Navas GÃ³mez, Beatriz Seoane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06108">Inferring Higher-Order Couplings with Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Maximum entropy methods, rooted in the inverse Ising/Potts problem from statistical physics, are widely used to model pairwise interactions in complex systems across disciplines such as bioinformatics and neuroscience. While successful, these approaches often fail to capture higher-order interactions that are critical for understanding collective behavior. In contrast, modern machine learning methods can model such interactions, but their interpretability often comes at a prohibitive computational cost. Restricted Boltzmann Machines (RBMs) provide a computationally efficient alternative by encoding statistical correlations through hidden units in a bipartite architecture. In this work, we introduce a method that maps RBMs onto generalized Potts models, enabling the systematic extraction of interactions up to arbitrary order. Leveraging large-$N$ approximations, made tractable by the RBM's structure, we extract effective many-body couplings with minimal computational effort. We further propose a robust framework for recovering higher-order interactions in more complex generative models, and introduce a simple gauge-fixing scheme for the effective Potts representation. Validation on synthetic data demonstrates accurate recovery of two- and three-body interactions. Applied to protein sequence data, our method reconstructs contact maps with high fidelity and outperforms state-of-the-art inverse Potts models. These results establish RBMs as a powerful and efficient tool for modeling higher-order structure in high-dimensional categorical data.
<div id='section'>Paperid: <span id='pid'>455, <a href='https://arxiv.org/pdf/2412.07778.pdf' target='_blank'>https://arxiv.org/pdf/2412.07778.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuqi Li, Shufang Xie, Hongda Sun, Yuhan Chen, Tao Qin, Tianjun Ke, Rui Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07778">MIN: Multi-channel Interaction Network for Drug-Target Interaction with Protein Distillation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional drug discovery processes are both time-consuming and require extensive professional expertise. With the accumulation of drug-target interaction (DTI) data from experimental studies, leveraging modern machine-learning techniques to discern patterns between drugs and target proteins has become increasingly feasible. In this paper, we introduce the Multi-channel Interaction Network (MIN), a novel framework designed to predict DTIs through two primary components: a representation learning module and a multi-channel interaction module. The representation learning module features a C-Score Predictor-assisted screening mechanism, which selects critical residues to enhance prediction accuracy and reduce noise. The multi-channel interaction module incorporates a structure-agnostic channel, a structure-aware channel, and an extended-mixture channel, facilitating the identification of interaction patterns at various levels for optimal complementarity. Additionally, contrastive learning is utilized to harmonize the representations of diverse data types. Our experimental evaluations on public datasets demonstrate that MIN surpasses other strong DTI prediction methods. Furthermore, the case study reveals a high overlap between the residues selected by the C-Score Predictor and those in actual binding pockets, underscoring MIN's explainability capability. These findings affirm that MIN is not only a potent tool for DTI prediction but also offers fresh insights into the prediction of protein binding sites.
<div id='section'>Paperid: <span id='pid'>456, <a href='https://arxiv.org/pdf/2410.12031.pdf' target='_blank'>https://arxiv.org/pdf/2410.12031.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marko DjukanoviÄ, Jaume Reixach, Ana Nikolikj, Tome Eftimov, Aleksandar Kartelj, Christian Blum
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12031">A Learning Search Algorithm for the Restricted Longest Common Subsequence Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the Restricted Longest Common Subsequence (RLCS) problem, an extension of the well-known Longest Common Subsequence (LCS) problem. This problem has significant applications in bioinformatics, particularly for identifying similarities and discovering mutual patterns and important motifs among DNA, RNA, and protein sequences. Building on recent advancements in solving this problem through a general search framework, this paper introduces two novel heuristic approaches designed to enhance the search process by steering it towards promising regions in the search space. The first heuristic employs a probabilistic model to evaluate partial solutions during the search process. The second heuristic is based on a neural network model trained offline using a genetic algorithm. A key aspect of this approach is extracting problem-specific features of partial solutions and the complete problem instance. An effective hybrid method, referred to as the learning beam search, is developed by combining the trained neural network model with a beam search framework. An important contribution of this paper is found in the generation of real-world instances where scientific abstracts serve as input strings, and a set of frequently occurring academic words from the literature are used as restricted patterns. Comprehensive experimental evaluations demonstrate the effectiveness of the proposed approaches in solving the RLCS problem. Finally, an empirical explainability analysis is applied to the obtained results. In this way, key feature combinations and their respective contributions to the success or failure of the algorithms across different problem types are identified.
<div id='section'>Paperid: <span id='pid'>457, <a href='https://arxiv.org/pdf/2408.06244.pdf' target='_blank'>https://arxiv.org/pdf/2408.06244.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaydeep Rade, Ethan Herron, Soumik Sarkar, Anwesha Sarkar, Adarsh Krishnamurthy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.06244">3D Reconstruction of Protein Structures from Multi-view AFM Images using Neural Radiance Fields (NeRFs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in deep learning for predicting 3D protein structures have shown promise, particularly when leveraging inputs like protein sequences and Cryo-Electron microscopy (Cryo-EM) images. However, these techniques often fall short when predicting the structures of protein complexes (PCs), which involve multiple proteins. In our study, we investigate using atomic force microscopy (AFM) combined with deep learning to predict the 3D structures of PCs. AFM generates height maps that depict the PCs in various random orientations, providing a rich information for training a neural network to predict the 3D structures. We then employ the pre-trained UpFusion model (which utilizes a conditional diffusion model for synthesizing novel views) to train an instance-specific NeRF model for 3D reconstruction. The performance of UpFusion is evaluated through zero-shot predictions of 3D protein structures using AFM images. The challenge, however, lies in the time-intensive and impractical nature of collecting actual AFM images. To address this, we use a virtual AFM imaging process that transforms a `PDB' protein file into multi-view 2D virtual AFM images via volume rendering techniques. We extensively validate the UpFusion architecture using both virtual and actual multi-view AFM images. Our results include a comparison of structures predicted with varying numbers of views and different sets of views. This novel approach holds significant potential for enhancing the accuracy of protein complex structure predictions with further fine-tuning of the UpFusion network.
<div id='section'>Paperid: <span id='pid'>458, <a href='https://arxiv.org/pdf/2311.16126.pdf' target='_blank'>https://arxiv.org/pdf/2311.16126.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fang Wu, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16126">A Hierarchical Training Paradigm for Antibody Structure-sequence Co-design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Therapeutic antibodies are an essential and rapidly expanding drug modality. The binding specificity between antibodies and antigens is decided by complementarity-determining regions (CDRs) at the tips of these Y-shaped proteins. In this paper, we propose a hierarchical training paradigm (HTP) for the antibody sequence-structure co-design. HTP consists of four levels of training stages, each corresponding to a specific protein modality within a particular protein domain. Through carefully crafted tasks in different stages, HTP seamlessly and effectively integrates geometric graph neural networks (GNNs) with large-scale protein language models to excavate evolutionary information from not only geometric structures but also vast antibody and non-antibody sequence databases, which determines ligand binding pose and strength. Empirical experiments show that HTP sets the new state-of-the-art performance in the co-design problem as well as the fix-backbone design. Our research offers a hopeful path to unleash the potential of deep generative architectures and seeks to illuminate the way forward for the antibody sequence and structure co-design challenge.
<div id='section'>Paperid: <span id='pid'>459, <a href='https://arxiv.org/pdf/2310.20447.pdf' target='_blank'>https://arxiv.org/pdf/2310.20447.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steven Adriaensen, Herilalaina Rakotoarison, Samuel MÃ¼ller, Frank Hutter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.20447">Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning curve extrapolation aims to predict model performance in later epochs of training, based on the performance in earlier epochs. In this work, we argue that, while the inherent uncertainty in the extrapolation of learning curves warrants a Bayesian approach, existing methods are (i) overly restrictive, and/or (ii) computationally expensive. We describe the first application of prior-data fitted neural networks (PFNs) in this context. A PFN is a transformer, pre-trained on data generated from a prior, to perform approximate Bayesian inference in a single forward pass. We propose LC-PFN, a PFN trained to extrapolate 10 million artificial right-censored learning curves generated from a parametric prior proposed in prior art using MCMC. We demonstrate that LC-PFN can approximate the posterior predictive distribution more accurately than MCMC, while being over 10 000 times faster. We also show that the same LC-PFN achieves competitive performance extrapolating a total of 20 000 real learning curves from four learning curve benchmarks (LCBench, NAS-Bench-201, Taskset, and PD1) that stem from training a wide range of model architectures (MLPs, CNNs, RNNs, and Transformers) on 53 different datasets with varying input modalities (tabular, image, text, and protein data). Finally, we investigate its potential in the context of model selection and find that a simple LC-PFN based predictive early stopping criterion obtains 2 - 6x speed-ups on 45 of these datasets, at virtually no overhead.
<div id='section'>Paperid: <span id='pid'>460, <a href='https://arxiv.org/pdf/2310.07229.pdf' target='_blank'>https://arxiv.org/pdf/2310.07229.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Gao, Yinjun Jia, Yuanle Mo, Yuyan Ni, Weiying Ma, Zhiming Ma, Yanyan Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.07229">ProFSA: Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pocket representations play a vital role in various biomedical applications, such as druggability estimation, ligand affinity prediction, and de novo drug design. While existing geometric features and pretrained representations have demonstrated promising results, they usually treat pockets independent of ligands, neglecting the fundamental interactions between them. However, the limited pocket-ligand complex structures available in the PDB database (less than 100 thousand non-redundant pairs) hampers large-scale pretraining endeavors for interaction modeling. To address this constraint, we propose a novel pocket pretraining approach that leverages knowledge from high-resolution atomic protein structures, assisted by highly effective pretrained small molecule representations. By segmenting protein structures into drug-like fragments and their corresponding pockets, we obtain a reasonable simulation of ligand-receptor interactions, resulting in the generation of over 5 million complexes. Subsequently, the pocket encoder is trained in a contrastive manner to align with the representation of pseudo-ligand furnished by some pretrained small molecule encoders. Our method, named ProFSA, achieves state-of-the-art performance across various tasks, including pocket druggability prediction, pocket matching, and ligand binding affinity prediction. Notably, ProFSA surpasses other pretraining methods by a substantial margin. Moreover, our work opens up a new avenue for mitigating the scarcity of protein-ligand complex data through the utilization of high-quality and diverse protein structure databases.
<div id='section'>Paperid: <span id='pid'>461, <a href='https://arxiv.org/pdf/2307.08813.pdf' target='_blank'>https://arxiv.org/pdf/2307.08813.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gilchan Park, Byung-Jun Yoon, Xihaier Luo, Vanessa LÃ³pez-Marrero, Shinjae Yoo, Shantenu Jha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.08813">Comparative Performance Evaluation of Large Language Models for Extracting Molecular Interactions and Pathway Knowledge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: Identification of the interactions and regulatory relations between biomolecules play pivotal roles in understanding complex biological systems and the mechanisms underlying diverse biological functions. However, the collection of such molecular interactions has heavily relied on expert curation in the past, making it labor-intensive and time-consuming. To mitigate these challenges, we propose leveraging the capabilities of large language models (LLMs) to automate genome-scale extraction of this crucial knowledge.
  Results: In this study, we investigate the efficacy of various LLMs in addressing biological tasks, such as the recognition of protein interactions, identification of genes linked to pathways affected by low-dose radiation, and the delineation of gene regulatory relationships. Overall, the larger models exhibited superior performance, indicating their potential for specific tasks that involve the extraction of complex interactions among genes and proteins. Although these models possessed detailed information for distinct gene and protein groups, they faced challenges in identifying groups with diverse functions and in recognizing highly correlated gene regulatory relationships.
  Conclusions: By conducting a comprehensive assessment of the state-of-the-art models using well-established molecular interaction and pathway databases, our study reveals that LLMs can identify genes/proteins associated with pathways of interest and predict their interactions to a certain extent. Furthermore, these models can provide important insights, marking a noteworthy stride toward advancing our understanding of biological systems through AI-assisted knowledge discovery.
<div id='section'>Paperid: <span id='pid'>462, <a href='https://arxiv.org/pdf/2307.06797.pdf' target='_blank'>https://arxiv.org/pdf/2307.06797.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alessandra Carbone, AurÃ©lien Decelle, Lorenzo Rosset, Beatriz Seoane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.06797">Fast and Functional Structured Data Generators Rooted in Out-of-Equilibrium Physics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we address the challenge of using energy-based models to produce high-quality, label-specific data in complex structured datasets, such as population genetics, RNA or protein sequences data. Traditional training methods encounter difficulties due to inefficient Markov chain Monte Carlo mixing, which affects the diversity of synthetic data and increases generation times. To address these issues, we use a novel training algorithm that exploits non-equilibrium effects. This approach, applied on the Restricted Boltzmann Machine, improves the model's ability to correctly classify samples and generate high-quality synthetic data in only a few sampling steps. The effectiveness of this method is demonstrated by its successful application to four different types of data: handwritten digits, mutations of human genomes classified by continental origin, functionally characterized sequences of an enzyme protein family, and homologous RNA sequences from specific taxonomies.
<div id='section'>Paperid: <span id='pid'>463, <a href='https://arxiv.org/pdf/2305.18090.pdf' target='_blank'>https://arxiv.org/pdf/2305.18090.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengchao Liu, Jiongxiao Wang, Yijin Yang, Chengpeng Wang, Ling Liu, Hongyu Guo, Chaowei Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.18090">ChatGPT-powered Conversational Drug Editing Using Retrieval and Domain Feedback</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in conversational large language models (LLMs), such as ChatGPT, have demonstrated remarkable promise in various domains, including drug discovery. However, existing works mainly focus on investigating the capabilities of conversational LLMs on chemical reaction and retrosynthesis. While drug editing, a critical task in the drug discovery pipeline, remains largely unexplored. To bridge this gap, we propose ChatDrug, a framework to facilitate the systematic investigation of drug editing using LLMs. ChatDrug jointly leverages a prompt module, a retrieval and domain feedback (ReDF) module, and a conversation module to streamline effective drug editing. We empirically show that ChatDrug reaches the best performance on 33 out of 39 drug editing tasks, encompassing small molecules, peptides, and proteins. We further demonstrate, through 10 case studies, that ChatDrug can successfully identify the key substructures (e.g., the molecule functional groups, peptide motifs, and protein structures) for manipulation, generating diverse and valid suggestions for drug editing. Promisingly, we also show that ChatDrug can offer insightful explanations from a domain-specific perspective, enhancing interpretability and enabling informed decision-making. This research sheds light on the potential of ChatGPT and conversational LLMs for drug editing. It paves the way for a more efficient and collaborative drug discovery pipeline, contributing to the advancement of pharmaceutical research and development.
<div id='section'>Paperid: <span id='pid'>464, <a href='https://arxiv.org/pdf/2302.02609.pdf' target='_blank'>https://arxiv.org/pdf/2302.02609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huaxiu Yao, Xinyu Yang, Xinyi Pan, Shengchao Liu, Pang Wei Koh, Chelsea Finn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.02609">Improving Domain Generalization with Domain Relations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distribution shift presents a significant challenge in machine learning, where models often underperform during the test stage when faced with a different distribution than the one they were trained on. This paper focuses on domain shifts, which occur when the model is applied to new domains that are different from the ones it was trained on, and propose a new approach called D$^3$G. Unlike previous methods that aim to learn a single model that is domain invariant, D$^3$G leverages domain similarities based on domain metadata to learn domain-specific models. Concretely, D$^3$G learns a set of training-domain-specific functions during the training stage and reweights them based on domain relations during the test stage. These domain relations can be directly obtained and learned from domain metadata. Under mild assumptions, we theoretically prove that using domain relations to reweight training-domain-specific functions achieves stronger out-of-domain generalization compared to the conventional averaging approach. Empirically, we evaluate the effectiveness of D$^3$G using real-world datasets for tasks such as temperature regression, land use classification, and molecule-protein binding affinity prediction. Our results show that D$^3$G consistently outperforms state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>465, <a href='https://arxiv.org/pdf/2302.01851.pdf' target='_blank'>https://arxiv.org/pdf/2302.01851.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>AurÃ©lien Decelle, Lorenzo Rosset, Beatriz Seoane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.01851">Unsupervised hierarchical clustering using the learning dynamics of RBMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Datasets in the real world are often complex and to some degree hierarchical, with groups and sub-groups of data sharing common characteristics at different levels of abstraction. Understanding and uncovering the hidden structure of these datasets is an important task that has many practical applications. To address this challenge, we present a new and general method for building relational data trees by exploiting the learning dynamics of the Restricted Boltzmann Machine (RBM). Our method is based on the mean-field approach, derived from the Plefka expansion, and developed in the context of disordered systems. It is designed to be easily interpretable. We tested our method in an artificially created hierarchical dataset and on three different real-world datasets (images of digits, mutations in the human genome, and a homologous family of proteins). The method is able to automatically identify the hierarchical structure of the data. This could be useful in the study of homologous protein sequences, where the relationships between proteins are critical for understanding their function and evolution.
<div id='section'>Paperid: <span id='pid'>466, <a href='https://arxiv.org/pdf/2204.08663.pdf' target='_blank'>https://arxiv.org/pdf/2204.08663.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fang Wu, Shuting Jin, Yinghui Jiang, Xurui Jin, Bowen Tang, Zhangming Niu, Xiangrong Liu, Qiang Zhang, Xiangxiang Zeng, Stan Z. Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.08663">Pre-training of Equivariant Graph Matching Networks with Conformation Flexibility for Drug Binding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The latest biological findings observe that the traditional motionless 'lock-and-key' theory is not generally applicable because the receptor and ligand are constantly moving. Nonetheless, remarkable changes in associated atomic sites and binding pose can provide vital information in understanding the process of drug binding. Based on this mechanism, molecular dynamics (MD) simulations were invented as a useful tool for investigating the dynamic properties of a molecular system. However, the computational expenditure limits the growth and application of protein trajectory-related studies, thus hindering the possibility of supervised learning. To tackle this obstacle, we present a novel spatial-temporal pre-training method based on the modified Equivariant Graph Matching Networks (EGMN), dubbed ProtMD, which has two specially designed self-supervised learning tasks: an atom-level prompt-based denoising generative task and a conformation-level snapshot ordering task to seize the flexibility information inside MD trajectories with very fine temporal resolutions. The ProtMD can grant the encoder network the capacity to capture the time-dependent geometric mobility of conformations along MD trajectories. Two downstream tasks are chosen, i.e., the binding affinity prediction and the ligand efficacy prediction, to verify the effectiveness of ProtMD through linear detection and task-specific fine-tuning. We observe a huge improvement from current state-of-the-art methods, with a decrease of 4.3% in RMSE for the binding affinity problem and an average increase of 13.8% in AUROC and AUPRC for the ligand efficacy problem. The results demonstrate valuable insight into a strong correlation between the magnitude of conformation's motion in the 3D space (i.e., flexibility) and the strength with which the ligand binds with its receptor.
<div id='section'>Paperid: <span id='pid'>467, <a href='https://arxiv.org/pdf/2509.18480.pdf' target='_blank'>https://arxiv.org/pdf/2509.18480.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuyang Wang, Jiarui Lu, Navdeep Jaitly, Josh Susskind, Miguel Angel Bautista
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18480">SimpleFold: Folding Proteins is Simpler than You Think</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein folding models have achieved groundbreaking results typically via a combination of integrating domain knowledge into the architectural blocks and training pipelines. Nonetheless, given the success of generative models across different but related problems, it is natural to question whether these architectural designs are a necessary condition to build performant models. In this paper, we introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer blocks. Protein folding models typically employ computationally expensive modules involving triangular updates, explicit pair representations or multiple training objectives curated for this specific domain. Instead, SimpleFold employs standard transformer blocks with adaptive layers and is trained via a generative flow-matching objective with an additional structural term. We scale SimpleFold to 3B parameters and train it on approximately 9M distilled protein structures together with experimental PDB data. On standard folding benchmarks, SimpleFold-3B achieves competitive performance compared to state-of-the-art baselines, in addition SimpleFold demonstrates strong performance in ensemble prediction which is typically difficult for models trained via deterministic reconstruction objectives. Due to its general-purpose architecture, SimpleFold shows efficiency in deployment and inference on consumer-level hardware. SimpleFold challenges the reliance on complex domain-specific architectures designs in protein folding, opening up an alternative design space for future progress.
<div id='section'>Paperid: <span id='pid'>468, <a href='https://arxiv.org/pdf/2508.14351.pdf' target='_blank'>https://arxiv.org/pdf/2508.14351.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junwei Su, Chuan Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14351">A Non-Asymptotic Convergent Analysis for Scored-Based Graph Generative Model via a System of Stochastic Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Score-based graph generative models (SGGMs) have proven effective in critical applications such as drug discovery and protein synthesis. However, their theoretical behavior, particularly regarding convergence, remains underexplored. Unlike common score-based generative models (SGMs), which are governed by a single stochastic differential equation (SDE), SGGMs involve a system of coupled SDEs. In SGGMs, the graph structure and node features are governed by separate but interdependent SDEs. This distinction makes existing convergence analyses from SGMs inapplicable for SGGMs. In this work, we present the first non-asymptotic convergence analysis for SGGMs, focusing on the convergence bound (the risk of generative error) across three key graph generation paradigms: (1) feature generation with a fixed graph structure, (2) graph structure generation with fixed node features, and (3) joint generation of both graph structure and node features. Our analysis reveals several unique factors specific to SGGMs (e.g., the topological properties of the graph structure) which affect the convergence bound. Additionally, we offer theoretical insights into the selection of hyperparameters (e.g., sampling steps and diffusion length) and advocate for techniques like normalization to improve convergence. To validate our theoretical findings, we conduct a controlled empirical study using synthetic graph models, and the results align with our theoretical predictions. This work deepens the theoretical understanding of SGGMs, demonstrates their applicability in critical domains, and provides practical guidance for designing effective models.
<div id='section'>Paperid: <span id='pid'>469, <a href='https://arxiv.org/pdf/2508.10629.pdf' target='_blank'>https://arxiv.org/pdf/2508.10629.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Patrick Soga, Zhenyu Lei, Yinhan He, Camille Bilodeau, Jundong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10629">Energy-Based Models for Predicting Mutational Effects on Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting changes in binding free energy ($ÎÎG$) is a vital task in protein engineering and protein-protein interaction (PPI) engineering for drug discovery. Previous works have observed a high correlation between $ÎÎG$ and entropy, using probabilities of biologically important objects such as side chain angles and residue identities to estimate $ÎÎG$. However, estimating the full conformational distribution of a protein complex is generally considered intractable. In this work, we propose a new approach to $ÎÎG$ prediction that avoids this issue by instead leveraging energy-based models for estimating the probability of a complex's conformation. Specifically, we novelly decompose $ÎÎG$ into a sequence-based component estimated by an inverse folding model and a structure-based component estimated by an energy model. This decomposition is made tractable by assuming equilibrium between the bound and unbound states, allowing us to simplify the estimation of degeneracies associated with each state. Unlike previous deep learning-based methods, our method incorporates an energy-based physical inductive bias by connecting the often-used sequence log-odds ratio-based approach to $ÎÎG$ prediction with a new $ÎÎE$ term grounded in statistical mechanics. We demonstrate superiority over existing state-of-the-art structure and sequence-based deep learning methods in $ÎÎG$ prediction and antibody optimization against SARS-CoV-2.
<div id='section'>Paperid: <span id='pid'>470, <a href='https://arxiv.org/pdf/2507.10877.pdf' target='_blank'>https://arxiv.org/pdf/2507.10877.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuchen Zhu, Jihong Chen, Yitong Li, Xiaomin Fang, Xianbin Ye, Jingzhou He, Xujun Zhang, Jingxuan Ge, Chao Shen, Xiaonan Zhang, Tingjun Hou, Chang-Yu Hsieh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10877">BioScore: A Foundational Scoring Function For Diverse Biomolecular Complexes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structural assessment of biomolecular complexes is vital for translating molecular models into functional insights, shaping our understanding of biology and aiding drug discovery. However, current structure-based scoring functions often lack generalizability across diverse biomolecular systems. We present BioScore, a foundational scoring function that addresses key challenges -- data sparsity, cross-system representation, and task compatibility -- through a dual-scale geometric graph learning framework with tailored modules for structure assessment and affinity prediction. BioScore supports a wide range of tasks, including affinity prediction, conformation ranking, and structure-based virtual screening. Evaluated on 16 benchmarks spanning proteins, nucleic acids, small molecules, and carbohydrates, BioScore consistently outperforms or matches 70 traditional and deep learning methods. Our newly proposed PPI Benchmark further enables comprehensive evaluation of protein-protein complex scoring. BioScore demonstrates broad applicability: (1) pretraining on mixed-structure data boosts protein-protein affinity prediction by up to 40% and antigen-antibody binding correlation by over 90%; (2) cross-system generalizability enables zero- and few-shot prediction with up to 71% correlation gain; and (3) its unified representation captures chemically challenging systems such as cyclic peptides, improving affinity prediction by over 60%. BioScore establishes a robust and generalizable framework for structural assessment across complex biomolecular landscapes.
<div id='section'>Paperid: <span id='pid'>471, <a href='https://arxiv.org/pdf/2507.02724.pdf' target='_blank'>https://arxiv.org/pdf/2507.02724.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiyi Liu, Buwen Liang, Yuetong Fang, Zixuan Jiang, Renjing Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02724">Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in AI for science have highlighted the power of contrastive learning in bridging heterogeneous biological data modalities. Building on this paradigm, we propose HIPPO (HIerarchical Protein-Protein interaction prediction across Organisms), a hierarchical contrastive framework for protein-protein interaction(PPI) prediction, where protein sequences and their hierarchical attributes are aligned through multi-tiered biological representation matching. The proposed approach incorporates hierarchical contrastive loss functions that emulate the structured relationship among functional classes of proteins. The framework adaptively incorporates domain and family knowledge through a data-driven penalty mechanism, enforcing consistency between the learned embedding space and the intrinsic hierarchy of protein functions. Experiments on benchmark datasets demonstrate that HIPPO achieves state-of-the-art performance, outperforming existing methods and showing robustness in low-data regimes. Notably, the model demonstrates strong zero-shot transferability to other species without retraining, enabling reliable PPI prediction and functional inference even in less characterized or rare organisms where experimental data are limited. Further analysis reveals that hierarchical feature fusion is critical for capturing conserved interaction determinants, such as binding motifs and functional annotations. This work advances cross-species PPI prediction and provides a unified framework for interaction prediction in scenarios with sparse or imbalanced multi-species data.
<div id='section'>Paperid: <span id='pid'>472, <a href='https://arxiv.org/pdf/2506.14853.pdf' target='_blank'>https://arxiv.org/pdf/2506.14853.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Max Ku, Sun Sun, Hongyu Guo, Wenhu Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14853">DisProtEdit: Exploring Disentangled Representations for Multi-Attribute Protein Editing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce DisProtEdit, a controllable protein editing framework that leverages dual-channel natural language supervision to learn disentangled representations of structural and functional properties. Unlike prior approaches that rely on joint holistic embeddings, DisProtEdit explicitly separates semantic factors, enabling modular and interpretable control. To support this, we construct SwissProtDis, a large-scale multimodal dataset where each protein sequence is paired with two textual descriptions, one for structure and one for function, automatically decomposed using a large language model. DisProtEdit aligns protein and text embeddings using alignment and uniformity objectives, while a disentanglement loss promotes independence between structural and functional semantics. At inference time, protein editing is performed by modifying one or both text inputs and decoding from the updated latent representation. Experiments on protein editing and representation learning benchmarks demonstrate that DisProtEdit performs competitively with existing methods while providing improved interpretability and controllability. On a newly constructed multi-attribute editing benchmark, the model achieves a both-hit success rate of up to 61.7%, highlighting its effectiveness in coordinating simultaneous structural and functional edits.
<div id='section'>Paperid: <span id='pid'>473, <a href='https://arxiv.org/pdf/2504.03847.pdf' target='_blank'>https://arxiv.org/pdf/2504.03847.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaokun Liu, Sayedmohammadreza Rastegari, Yijun Huang, Sxe Chang Cheong, Weikang Liu, Wenjie Zhao, Qihao Tian, Hongming Wang, Yingjie Guo, Shuo Zhou, Sina Tabakhi, Xianyuan Liu, Zheqing Zhu, Wei Sang, Haiping Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03847">Interpretable Multimodal Learning for Tumor Protein-Metal Binding: Progress, Challenges, and Perspectives</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In cancer therapeutics, protein-metal binding mechanisms critically govern the pharmacokinetics and targeting efficacy of drugs, thereby fundamentally shaping the rational design of anticancer metallodrugs. While conventional laboratory methods used to study such mechanisms are often costly, low throughput, and limited in capturing dynamic biological processes, machine learning (ML) has emerged as a promising alternative. Despite increasing efforts to develop protein-metal binding datasets and ML algorithms, the application of ML in tumor protein-metal binding remains limited. Key challenges include a shortage of high-quality, tumor-specific datasets, insufficient consideration of multiple data modalities, and the complexity of interpreting results due to the ''black box'' nature of complex ML models. This paper summarizes recent progress and ongoing challenges in using ML to predict tumor protein-metal binding, focusing on data, modeling, and interpretability. We present multimodal protein-metal binding datasets and outline strategies for acquiring, curating, and preprocessing them for training ML models. Moreover, we explore the complementary value provided by different data modalities and examine methods for their integration. We also review approaches for improving model interpretability to support more trustworthy decisions in cancer research. Finally, we offer our perspective on research opportunities and propose strategies to address the scarcity of tumor protein data and the limited number of predictive models for tumor protein-metal binding. We also highlight two promising directions for effective metal-based drug design: integrating protein-protein interaction data to provide structural insights into metal-binding events and predicting structural changes in tumor proteins after metal binding.
<div id='section'>Paperid: <span id='pid'>474, <a href='https://arxiv.org/pdf/2503.06687.pdf' target='_blank'>https://arxiv.org/pdf/2503.06687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gongbo Zhang, Yanting Li, Renqian Luo, Pipi Hu, Yang Yang, Zeru Zhao, Lingbo Li, Guoqing Liu, Zun Wang, Ran Bi, Kaiyuan Gao, Liya Guo, Yu Xie, Chang Liu, Jia Zhang, Tian Xie, Robert Pinsler, Claudio Zeni, Ziheng Lu, Hongxia Hao, Yingce Xia, Marwin Segler, Maik Riechert, Wei Yang, Hao Jiang, Wen-Bin Zhang, Zhijun Zeng, Yi Zhu, Li Dong, Xiuyuan Hu, Li Yuan, Lei Chen, Haiguang Liu, Tao Qin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.06687">UniGenX: a unified generative foundation model that couples sequence, structure and function to accelerate scientific design across proteins, molecules and materials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Function in natural systems arises from one-dimensional sequences forming three-dimensional structures with specific properties. However, current generative models suffer from critical limitations: training objectives seldom target function directly, discrete sequences and continuous coordinates are optimized in isolation, and conformational ensembles are under-modeled. We present UniGenX, a unified generative foundation model that addresses these gaps by co-generating sequences and coordinates under direct functional and property objectives across proteins, molecules, and materials. UniGenX represents heterogeneous inputs as a mixed stream of symbolic and numeric tokens, where a decoder-only autoregressive transformer provides global context and a conditional diffusion head generates numeric fields steered by task-specific tokens. Besides the new high SOTAs on structure prediction tasks, the model demonstrates state-of-the-art or competitive performance for the function-aware generation across domains: in materials, it achieves "conflicted" multi-property conditional generation, yielding 436 crystal candidates meeting triple constraints, including 11 with novel compositions; in chemistry, it sets new benchmarks on five property targets and conformer ensemble generation on GEOM; and in biology, it improves success in modeling protein induced fit (RMSD < 2 Ã) by over 23-fold and enhances EC-conditioned enzyme design. Ablation studies and cross-domain transfer substantiate the benefits of joint discrete-continuous training, establishing UniGenX as a significant advance from prediction to controllable, function-aware generation.
<div id='section'>Paperid: <span id='pid'>475, <a href='https://arxiv.org/pdf/2410.20688.pdf' target='_blank'>https://arxiv.org/pdf/2410.20688.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangxin Zhou, Jiaqi Guan, Yijia Zhang, Xingang Peng, Liang Wang, Jianzhu Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20688">Reprogramming Pretrained Target-Specific Diffusion Models for Dual-Target Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dual-target therapeutic strategies have become a compelling approach and attracted significant attention due to various benefits, such as their potential in overcoming drug resistance in cancer therapy. Considering the tremendous success that deep generative models have achieved in structure-based drug design in recent years, we formulate dual-target drug design as a generative task and curate a novel dataset of potential target pairs based on synergistic drug combinations. We propose to design dual-target drugs with diffusion models that are trained on single-target protein-ligand complex pairs. Specifically, we align two pockets in 3D space with protein-ligand binding priors and build two complex graphs with shared ligand nodes for SE(3)-equivariant composed message passing, based on which we derive a composed drift in both 3D and categorical probability space in the generative process. Our algorithm can well transfer the knowledge gained in single-target pretraining to dual-target scenarios in a zero-shot manner. We also repurpose linker design methods as strong baselines for this task. Extensive experiments demonstrate the effectiveness of our method compared with various baselines.
<div id='section'>Paperid: <span id='pid'>476, <a href='https://arxiv.org/pdf/2410.20317.pdf' target='_blank'>https://arxiv.org/pdf/2410.20317.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddharth Viswanath, Dhananjay Bhaskar, David R. Johnson, Joao Felipe Rocha, Egbert Castro, Jackson D. Grady, Alex T. Grigas, Michael A. Perlmutter, Corey S. O'Hern, Smita Krishnaswamy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20317">ProtSCAPE: Mapping the landscape of protein conformations in molecular dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the dynamic nature of protein structures is essential for comprehending their biological functions. While significant progress has been made in predicting static folded structures, modeling protein motions on microsecond to millisecond scales remains challenging. To address these challenges, we introduce a novel deep learning architecture, Protein Transformer with Scattering, Attention, and Positional Embedding (ProtSCAPE), which leverages the geometric scattering transform alongside transformer-based attention mechanisms to capture protein dynamics from molecular dynamics (MD) simulations. ProtSCAPE utilizes the multi-scale nature of the geometric scattering transform to extract features from protein structures conceptualized as graphs and integrates these features with dual attention structures that focus on residues and amino acid signals, generating latent representations of protein trajectories. Furthermore, ProtSCAPE incorporates a regression head to enforce temporally coherent latent representations.
<div id='section'>Paperid: <span id='pid'>477, <a href='https://arxiv.org/pdf/2410.13643.pdf' target='_blank'>https://arxiv.org/pdf/2410.13643.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenyu Wang, Masatoshi Uehara, Yichun He, Amy Wang, Tommaso Biancalani, Avantika Lal, Tommi Jaakkola, Sergey Levine, Hanchen Wang, Aviv Regev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13643">Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent studies have demonstrated the strong empirical performance of diffusion models on discrete sequences across domains from natural language to biological sequence generation. For example, in the protein inverse folding task, conditional diffusion models have achieved impressive results in generating natural-like sequences that fold back into the original structure. However, practical design tasks often require not only modeling a conditional distribution but also optimizing specific task objectives. For instance, we may prefer protein sequences with high stability. To address this, we consider the scenario where we have pre-trained discrete diffusion models that can generate natural-like sequences, as well as reward models that map sequences to task objectives. We then formulate the reward maximization problem within discrete diffusion models, analogous to reinforcement learning (RL), while minimizing the KL divergence against pretrained diffusion models to preserve naturalness. To solve this RL problem, we propose a novel algorithm, DRAKES, that enables direct backpropagation of rewards through entire trajectories generated by diffusion models, by making the originally non-differentiable trajectories differentiable using the Gumbel-Softmax trick. Our theoretical analysis indicates that our approach can generate sequences that are both natural-like and yield high rewards. While similar tasks have been recently explored in diffusion models for continuous domains, our work addresses unique algorithmic and theoretical challenges specific to discrete diffusion models, which arise from their foundation in continuous-time Markov chains rather than Brownian motion. Finally, we demonstrate the effectiveness of DRAKES in generating DNA and protein sequences that optimize enhancer activity and protein stability, respectively, important tasks for gene therapies and protein-based therapeutics.
<div id='section'>Paperid: <span id='pid'>478, <a href='https://arxiv.org/pdf/2410.07974.pdf' target='_blank'>https://arxiv.org/pdf/2410.07974.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanqi Du, Michael Plainer, Rob Brekelmans, Chenru Duan, Frank NoÃ©, Carla P. Gomes, AlÃ¡n Aspuru-Guzik, Kirill Neklyudov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07974">Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rare event sampling in dynamical systems is a fundamental problem arising in the natural sciences, which poses significant computational challenges due to an exponentially large space of trajectories. For settings where the dynamical system of interest follows a Brownian motion with known drift, the question of conditioning the process to reach a given endpoint or desired rare event is definitively answered by Doob's h-transform. However, the naive estimation of this transform is infeasible, as it requires simulating sufficiently many forward trajectories to estimate rare event probabilities. In this work, we propose a variational formulation of Doob's h-transform as an optimization problem over trajectories between a given initial point and the desired ending point. To solve this optimization, we propose a simulation-free training objective with a model parameterization that imposes the desired boundary conditions by design. Our approach significantly reduces the search space over trajectories and avoids expensive trajectory simulation and inefficient importance sampling estimators which are required in existing methods. We demonstrate the ability of our method to find feasible transition paths on real-world molecular simulation and protein folding tasks.
<div id='section'>Paperid: <span id='pid'>479, <a href='https://arxiv.org/pdf/2405.20313.pdf' target='_blank'>https://arxiv.org/pdf/2405.20313.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guillaume Huguet, James Vuckovic, Kilian Fatras, Eric Thibodeau-Laufer, Pablo Lemos, Riashat Islam, Cheng-Hao Liu, Jarrid Rector-Brooks, Tara Akhound-Sadegh, Michael Bronstein, Alexander Tong, Avishek Joey Bose
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.20313">Sequence-Augmented SE(3)-Flow Matching For Conditional Protein Backbone Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are essential for almost all biological processes and derive their diverse functions from complex 3D structures, which are in turn determined by their amino acid sequences. In this paper, we exploit the rich biological inductive bias of amino acid sequences and introduce FoldFlow-2, a novel sequence-conditioned SE(3)-equivariant flow matching model for protein structure generation. FoldFlow-2 presents substantial new architectural features over the previous FoldFlow family of models including a protein large language model to encode sequence, a new multi-modal fusion trunk that combines structure and sequence representations, and a geometric transformer based decoder. To increase diversity and novelty of generated samples -- crucial for de-novo drug design -- we train FoldFlow-2 at scale on a new dataset that is an order of magnitude larger than PDB datasets of prior works, containing both known proteins in PDB and high-quality synthetic structures achieved through filtering. We further demonstrate the ability to align FoldFlow-2 to arbitrary rewards, e.g. increasing secondary structures diversity, by introducing a Reinforced Finetuning (ReFT) objective. We empirically observe that FoldFlow-2 outperforms previous state-of-the-art protein structure-based generative models, improving over RFDiffusion in terms of unconditional generation across all metrics including designability, diversity, and novelty across all protein lengths, as well as exhibiting generalization on the task of equilibrium conformation sampling. Finally, we demonstrate that a fine-tuned FoldFlow-2 makes progress on challenging conditional design tasks such as designing scaffolds for the VHH nanobody.
<div id='section'>Paperid: <span id='pid'>480, <a href='https://arxiv.org/pdf/2405.17802.pdf' target='_blank'>https://arxiv.org/pdf/2405.17802.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanle Mo, Xin Hong, Bowen Gao, Yinjun Jia, Yanyan Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17802">Multi-level Interaction Modeling for Protein Mutational Effect Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interactions are central mediators in many biological processes. Accurately predicting the effects of mutations on interactions is crucial for guiding the modulation of these interactions, thereby playing a significant role in therapeutic development and drug discovery. Mutations generally affect interactions hierarchically across three levels: mutated residues exhibit different sidechain conformations, which lead to changes in the backbone conformation, eventually affecting the binding affinity between proteins. However, existing methods typically focus only on sidechain-level interaction modeling, resulting in suboptimal predictions. In this work, we propose a self-supervised multi-level pre-training framework, ProMIM, to fully capture all three levels of interactions with well-designed pretraining objectives. Experiments show ProMIM outperforms all the baselines on the standard benchmark, especially on mutations where significant changes in backbone conformations may occur. In addition, leading results from zero-shot evaluations for SARS-CoV-2 mutational effect prediction and antibody optimization underscore the potential of ProMIM as a powerful next-generation tool for developing novel therapeutic approaches and new drugs.
<div id='section'>Paperid: <span id='pid'>481, <a href='https://arxiv.org/pdf/2402.10516.pdf' target='_blank'>https://arxiv.org/pdf/2402.10516.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiheng Zhu, Zitai Kong, Jialu Wu, Weize Liu, Yuqiang Han, Mingze Yin, Hongxia Xu, Chang-Yu Hsieh, Tingjun Hou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10516">Generative AI for Controllable Protein Sequence Design: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The design of novel protein sequences with targeted functionalities underpins a central theme in protein engineering, impacting diverse fields such as drug discovery and enzymatic engineering. However, navigating this vast combinatorial search space remains a severe challenge due to time and financial constraints. This scenario is rapidly evolving as the transformative advancements in AI, particularly in the realm of generative models and optimization algorithms, have been propelling the protein design field towards an unprecedented revolution. In this survey, we systematically review recent advances in generative AI for controllable protein sequence design. To set the stage, we first outline the foundational tasks in protein sequence design in terms of the constraints involved and present key generative models and optimization algorithms. We then offer in-depth reviews of each design task and discuss the pertinent applications. Finally, we identify the unresolved challenges and highlight research opportunities that merit deeper exploration.
<div id='section'>Paperid: <span id='pid'>482, <a href='https://arxiv.org/pdf/2402.07242.pdf' target='_blank'>https://arxiv.org/pdf/2402.07242.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tommaso Boccato, Matteo Ferrante, Nicola Toschi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07242">A Differentiable Model for Optimizing the Genetic Drivers of Synaptogenesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There is growing consensus among neuroscientists that neural circuits critical for survival are the result of genomic decompression processes. We introduce SynaptoGen, a novel computational framework--member of the Connectome Models family--bringing synthetic biological intelligence closer, facilitating neural biological agent development through precise genetic control of synaptogenesis. SynaptoGen is the first model of its kind offering mechanistic explanation of synaptic multiplicity based on genetic expression and protein interaction probabilities. The framework connects genetic factors through a differentiable function, working as a neural network where synaptic weights equal average numbers of synapses between neurons, multiplied by conductance, derived from genetic profiles. Differentiability enables gradient-based optimization, allowing generation of genetic expression patterns producing pre-wired biological agents for specific tasks. Validation in simulated synaptogenesis scenarios shows agents successfully solving four reinforcement learning benchmarks, consistently surpassing control baselines. Despite gaps in biological realism requiring mitigation, this framework has potential to accelerate synthetic biological intelligence research.
<div id='section'>Paperid: <span id='pid'>483, <a href='https://arxiv.org/pdf/2311.16160.pdf' target='_blank'>https://arxiv.org/pdf/2311.16160.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shikun Feng, Minghao Li, Yinjun Jia, Weiying Ma, Yanyan Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16160">Protein-ligand binding representation learning from fine-grained interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The binding between proteins and ligands plays a crucial role in the realm of drug discovery. Previous deep learning approaches have shown promising results over traditional computationally intensive methods, but resulting in poor generalization due to limited supervised data. In this paper, we propose to learn protein-ligand binding representation in a self-supervised learning manner. Different from existing pre-training approaches which treat proteins and ligands individually, we emphasize to discern the intricate binding patterns from fine-grained interactions. Specifically, this self-supervised learning problem is formulated as a prediction of the conclusive binding complex structure given a pocket and ligand with a Transformer based interaction module, which naturally emulates the binding process. To ensure the representation of rich binding information, we introduce two pre-training tasks, i.e.~atomic pairwise distance map prediction and mask ligand reconstruction, which comprehensively model the fine-grained interactions from both structure and feature space. Extensive experiments have demonstrated the superiority of our method across various binding tasks, including protein-ligand affinity prediction, virtual screening and protein-ligand docking.
<div id='section'>Paperid: <span id='pid'>484, <a href='https://arxiv.org/pdf/2310.06367.pdf' target='_blank'>https://arxiv.org/pdf/2310.06367.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Gao, Bo Qiang, Haichuan Tan, Minsi Ren, Yinjun Jia, Minsi Lu, Jingjing Liu, Weiying Ma, Yanyan Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06367">DrugCLIP: Contrastive Protein-Molecule Representation Learning for Virtual Screening</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Virtual screening, which identifies potential drugs from vast compound databases to bind with a particular protein pocket, is a critical step in AI-assisted drug discovery. Traditional docking methods are highly time-consuming, and can only work with a restricted search library in real-life applications. Recent supervised learning approaches using scoring functions for binding-affinity prediction, although promising, have not yet surpassed docking methods due to their strong dependency on limited data with reliable binding-affinity labels. In this paper, we propose a novel contrastive learning framework, DrugCLIP, by reformulating virtual screening as a dense retrieval task and employing contrastive learning to align representations of binding protein pockets and molecules from a large quantity of pairwise data without explicit binding-affinity scores. We also introduce a biological-knowledge inspired data augmentation strategy to learn better protein-molecule representations. Extensive experiments show that DrugCLIP significantly outperforms traditional docking and supervised learning methods on diverse virtual screening benchmarks with highly reduced computation time, especially in zero-shot setting.
<div id='section'>Paperid: <span id='pid'>485, <a href='https://arxiv.org/pdf/2310.02391.pdf' target='_blank'>https://arxiv.org/pdf/2310.02391.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Avishek Joey Bose, Tara Akhound-Sadegh, Guillaume Huguet, Kilian Fatras, Jarrid Rector-Brooks, Cheng-Hao Liu, Andrei Cristian Nica, Maksym Korablyov, Michael Bronstein, Alexander Tong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02391">SE(3)-Stochastic Flow Matching for Protein Backbone Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The computational design of novel protein structures has the potential to impact numerous scientific disciplines greatly. Toward this goal, we introduce FoldFlow, a series of novel generative models of increasing modeling power based on the flow-matching paradigm over $3\mathrm{D}$ rigid motions -- i.e. the group $\text{SE}(3)$ -- enabling accurate modeling of protein backbones. We first introduce FoldFlow-Base, a simulation-free approach to learning deterministic continuous-time dynamics and matching invariant target distributions on $\text{SE}(3)$. We next accelerate training by incorporating Riemannian optimal transport to create FoldFlow-OT, leading to the construction of both more simple and stable flows. Finally, we design FoldFlow-SFM, coupling both Riemannian OT and simulation-free training to learn stochastic continuous-time dynamics over $\text{SE}(3)$. Our family of FoldFlow, generative models offers several key advantages over previous approaches to the generative modeling of proteins: they are more stable and faster to train than diffusion-based approaches, and our models enjoy the ability to map any invariant source distribution to any invariant target distribution over $\text{SE}(3)$. Empirically, we validate FoldFlow, on protein backbone generation of up to $300$ amino acids leading to high-quality designable, diverse, and novel samples.
<div id='section'>Paperid: <span id='pid'>486, <a href='https://arxiv.org/pdf/2307.11694.pdf' target='_blank'>https://arxiv.org/pdf/2307.11694.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carl Edwards, Aakanksha Naik, Tushar Khot, Martin Burke, Heng Ji, Tom Hope
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.11694">SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction and Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting synergistic drug combinations can help accelerate discovery of cancer treatments, particularly therapies personalized to a patient's specific tumor via biopsied cells. In this paper, we propose a novel setting and models for in-context drug synergy learning. We are given a small "personalized dataset" of 10-20 drug synergy relationships in the context of specific cancer cell targets. Our goal is to predict additional drug synergy relationships in that context. Inspired by recent work that pre-trains a GPT language model (LM) to "in-context learn" common function classes, we devise novel pre-training schemes that enable a GPT model to in-context learn "drug synergy functions". Our model -- which does not use any textual corpora, molecular fingerprints, protein interaction or any other domain-specific knowledge -- is able to achieve competitive results. We further integrate our in-context approach with a genetic algorithm to optimize model prompts and select synergy candidates to test after conducting a patient biopsy. Finally, we explore a novel task of inverse drug design which can potentially enable the design of drugs that synergize specifically to target a given patient's "personalized dataset". Our findings can potentially have an important impact on precision cancer medicine, and also raise intriguing questions on non-textual pre-training for LMs.
<div id='section'>Paperid: <span id='pid'>487, <a href='https://arxiv.org/pdf/2307.08452.pdf' target='_blank'>https://arxiv.org/pdf/2307.08452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mayalen Etcheverry, Michael Levin, ClÃ©ment Moulin-Frier, Pierre-Yves Oudeyer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.08452">SBMLtoODEjax: Efficient Simulation and Optimization of Biological Network Models in JAX</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in bioengineering and biomedicine demand a deep understanding of the dynamic behavior of biological systems, ranging from protein pathways to complex cellular processes. Biological networks like gene regulatory networks and protein pathways are key drivers of embryogenesis and physiological processes. Comprehending their diverse behaviors is essential for tackling diseases, including cancer, as well as for engineering novel biological constructs. Despite the availability of extensive mathematical models represented in Systems Biology Markup Language (SBML), researchers face significant challenges in exploring the full spectrum of behaviors and optimizing interventions to efficiently shape those behaviors. Existing tools designed for simulation of biological network models are not tailored to facilitate interventions on network dynamics nor to facilitate automated discovery. Leveraging recent developments in machine learning (ML), this paper introduces SBMLtoODEjax, a lightweight library designed to seamlessly integrate SBML models with ML-supported pipelines, powered by JAX. SBMLtoODEjax facilitates the reuse and customization of SBML-based models, harnessing JAX's capabilities for efficient parallel simulations and optimization, with the aim to accelerate research in biological network analysis.
<div id='section'>Paperid: <span id='pid'>488, <a href='https://arxiv.org/pdf/2306.02508.pdf' target='_blank'>https://arxiv.org/pdf/2306.02508.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel Leone, Aarthi Venkat, Guillaume Huguet, Alexander Tong, Guy Wolf, Smita Krishnaswamy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02508">Graph Fourier MMD for Signals on Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While numerous methods have been proposed for computing distances between probability distributions in Euclidean space, relatively little attention has been given to computing such distances for distributions on graphs. However, there has been a marked increase in data that either lies on graph (such as protein interaction networks) or can be modeled as a graph (single cell data), particularly in the biomedical sciences. Thus, it becomes important to find ways to compare signals defined on such graphs. Here, we propose Graph Fourier MMD (GFMMD), a novel distance between distributions and signals on graphs. GFMMD is defined via an optimal witness function that is both smooth on the graph and maximizes difference in expectation between the pair of distributions on the graph. We find an analytical solution to this optimization problem as well as an embedding of distributions that results from this method. We also prove several properties of this method including scale invariance and applicability to disconnected graphs. We showcase it on graph benchmark datasets as well on single cell RNA-sequencing data analysis. In the latter, we use the GFMMD-based gene embeddings to find meaningful gene clusters. We also propose a novel type of score for gene selection called "gene localization score" which helps select genes for cellular state space characterization.
<div id='section'>Paperid: <span id='pid'>489, <a href='https://arxiv.org/pdf/2305.16151.pdf' target='_blank'>https://arxiv.org/pdf/2305.16151.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vishal Pallagani, Bharath Muppasani, Keerthiram Murugesan, Francesca Rossi, Biplav Srivastava, Lior Horesh, Francesco Fabiano, Andrea Loreggia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.16151">Understanding the Capabilities of Large Language Models for Automated Planning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated planning is concerned with developing efficient algorithms to generate plans or sequences of actions to achieve a specific goal in a given environment. Emerging Large Language Models (LLMs) can answer questions, write high-quality programming code, and predict protein folding, showcasing their versatility in solving various tasks beyond language-based problems. In this paper, we aim to explore how LLMs can also be used for automated planning. To do so, we seek to answer four key questions. Firstly, we want to understand the extent to which LLMs can be used for plan generation. Secondly, we aim to identify which pre-training data is most effective in facilitating plan generation. Thirdly, we investigate whether fine-tuning or prompting is a more effective approach for plan generation. Finally, we explore whether LLMs are capable of plan generalization. By answering these questions, the study seeks to shed light on the capabilities of LLMs in solving complex planning problems and provide insights into the most effective approaches for using LLMs in this context.
<div id='section'>Paperid: <span id='pid'>490, <a href='https://arxiv.org/pdf/2305.13997.pdf' target='_blank'>https://arxiv.org/pdf/2305.13997.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zaixi Zhang, Qi Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.13997">Learning Subpocket Prototypes for Generalizable Structure-based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generating molecules with high binding affinities to target proteins (a.k.a. structure-based drug design) is a fundamental and challenging task in drug discovery. Recently, deep generative models have achieved remarkable success in generating 3D molecules conditioned on the protein pocket. However, most existing methods consider molecular generation for protein pockets independently while neglecting the underlying connections such as subpocket-level similarities. Subpockets are the local protein environments of ligand fragments and pockets with similar subpockets may bind the same molecular fragment (motif) even though their overall structures are different. Therefore, the trained models can hardly generalize to unseen protein pockets in real-world applications. In this paper, we propose a novel method DrugGPS for generalizable structure-based drug design. With the biochemical priors, we propose to learn subpocket prototypes and construct a global interaction graph to model the interactions between subpocket prototypes and molecular motifs. Moreover, a hierarchical graph transformer encoder and motif-based 3D molecule generation scheme are used to improve the model's performance. The experimental results show that our model consistently outperforms baselines in generating realistic drug candidates with high affinities in challenging out-of-distribution settings.
<div id='section'>Paperid: <span id='pid'>491, <a href='https://arxiv.org/pdf/2211.05690.pdf' target='_blank'>https://arxiv.org/pdf/2211.05690.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abrar Zahin, Rajasekhar Anguluri, Lalitha Sankar, Oliver Kosut, Gautam Dasarathy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.05690">Robust Model Selection of Gaussian Graphical Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In Gaussian graphical model selection, noise-corrupted samples present significant challenges. It is known that even minimal amounts of noise can obscure the underlying structure, leading to fundamental identifiability issues. A recent line of work addressing this "robust model selection" problem narrows its focus to tree-structured graphical models. Even within this specific class of models, exact structure recovery is shown to be impossible. However, several algorithms have been developed that are known to provably recover the underlying tree-structure up to an (unavoidable) equivalence class.
  In this paper, we extend these results beyond tree-structured graphs. We first characterize the equivalence class up to which general graphs can be recovered in the presence of noise. Despite the inherent ambiguity (which we prove is unavoidable), the structure that can be recovered reveals local clustering information and global connectivity patterns in the underlying model. Such information is useful in a range of real-world problems, including power grids, social networks, protein-protein interactions, and neural structures. We then propose an algorithm which provably recovers the underlying graph up to the identified ambiguity. We further provide finite sample guarantees in the high-dimensional regime for our algorithm and validate our results through numerical simulations.
<div id='section'>Paperid: <span id='pid'>492, <a href='https://arxiv.org/pdf/2507.11115.pdf' target='_blank'>https://arxiv.org/pdf/2507.11115.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haruya Imamura, Yasuaki Kobayashi, Yota Otachi, Toshiki Saitoh, Keita Sato, Asahi Takaoka, Ryo Yoshinaka, Tom C. van der Zanden
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11115">Finding Order-Preserving Subgraphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>(Induced) Subgraph Isomorphism and Maximum Common (Induced) Subgraph are fundamental problems in graph pattern matching and similarity computation. In graphs derived from time-series data or protein structures, a natural total ordering of vertices often arises from their underlying structure, such as temporal sequences or amino acid sequences. This motivates the study of problem variants that respect this inherent ordering. This paper addresses Ordered (Induced) Subgraph Isomorphism (O(I)SI) and its generalization, Maximum Common Ordered (Induced) Subgraph (MCO(I)S), which seek to find subgraph isomorphisms that preserve the vertex orderings of two given ordered graphs. Our main contributions are threefold: (1) We prove that these problems remain NP-complete even when restricted to small graph classes, such as trees of depth 2 and threshold graphs. (2) We establish a gap in computational complexity between OSI and OISI on certain graph classes. For instance, OSI is polynomial-time solvable for interval graphs with their interval orderings, whereas OISI remains NP-complete under the same setting. (3) We demonstrate that the tractability of these problems can depend on the vertex ordering. For example, while OISI is NP-complete on threshold graphs, its generalization, MCOIS, can be solved in polynomial time if the specific vertex orderings that characterize the threshold graphs are provided.
<div id='section'>Paperid: <span id='pid'>493, <a href='https://arxiv.org/pdf/2507.02925.pdf' target='_blank'>https://arxiv.org/pdf/2507.02925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Janghoon Ock, Radheesh Sharma Meda, Srivathsan Badrinarayanan, Neha S. Aluru, Achuth Chandrasekhar, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02925">Large Language Model Agent for Modular Task Execution in Drug Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a modular framework powered by large language models (LLMs) that automates and streamlines key tasks across the early-stage computational drug discovery pipeline. By combining LLM reasoning with domain-specific tools, the framework performs biomedical data retrieval, domain-specific question answering, molecular generation, property prediction, property-aware molecular refinement, and 3D protein-ligand structure generation. In a case study targeting BCL-2 in lymphocytic leukemia, the agent autonomously retrieved relevant biomolecular information-including FASTA sequences, SMILES representations, and literature-and answered mechanistic questions with improved contextual accuracy over standard LLMs. It then generated chemically diverse seed molecules and predicted 67 ADMET-related properties, which guided iterative molecular refinement. Across two refinement rounds, the number of molecules with QED > 0.6 increased from 34 to 55, and those passing at least four out of five empirical drug-likeness rules rose from 29 to 52, within a pool of 194 molecules. The framework also employed Boltz-2 to generate 3D protein-ligand complexes and provide rapid binding affinity estimates for candidate compounds. These results demonstrate that the approach effectively supports molecular screening, prioritization, and structure evaluation. Its modular design enables flexible integration of evolving tools and models, providing a scalable foundation for AI-assisted therapeutic discovery.
<div id='section'>Paperid: <span id='pid'>494, <a href='https://arxiv.org/pdf/2506.08936.pdf' target='_blank'>https://arxiv.org/pdf/2506.08936.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amina Mollaysa, Artem Moskale, Pushpak Pati, Tommaso Mansi, Mangal Prakash, Rui Liao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08936">BioLangFusion: Multimodal Fusion of DNA, mRNA, and Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present BioLangFusion, a simple approach for integrating pre-trained DNA, mRNA, and protein language models into unified molecular representations. Motivated by the central dogma of molecular biology (information flow from gene to transcript to protein), we align per-modality embeddings at the biologically meaningful codon level (three nucleotides encoding one amino acid) to ensure direct cross-modal correspondence. BioLangFusion studies three standard fusion techniques: (i) codon-level embedding concatenation, (ii) entropy-regularized attention pooling inspired by multiple-instance learning, and (iii) cross-modal multi-head attention -- each technique providing a different inductive bias for combining modality-specific signals. These methods require no additional pre-training or modification of the base models, allowing straightforward integration with existing sequence-based foundation models. Across five molecular property prediction tasks, BioLangFusion outperforms strong unimodal baselines, showing that even simple fusion of pre-trained models can capture complementary multi-omic information with minimal overhead.
<div id='section'>Paperid: <span id='pid'>495, <a href='https://arxiv.org/pdf/2505.22560.pdf' target='_blank'>https://arxiv.org/pdf/2505.22560.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Artem Moskalev, Mangal Prakash, Junjie Xu, Tianyu Cui, Rui Liao, Tommaso Mansi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22560">Geometric Hyena Networks for Large-scale Equivariant Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Processing global geometric context while preserving equivariance is crucial when modeling biological, chemical, and physical systems. Yet, this is challenging due to the computational demands of equivariance and global context at scale. Standard methods such as equivariant self-attention suffer from quadratic complexity, while local methods such as distance-based message passing sacrifice global information. Inspired by the recent success of state-space and long-convolutional models, we introduce Geometric Hyena, the first equivariant long-convolutional model for geometric systems. Geometric Hyena captures global geometric context at sub-quadratic complexity while maintaining equivariance to rotations and translations. Evaluated on all-atom property prediction of large RNA molecules and full protein molecular dynamics, Geometric Hyena outperforms existing equivariant models while requiring significantly less memory and compute that equivariant self-attention. Notably, our model processes the geometric context of 30k tokens 20x faster than the equivariant transformer and allows 72x longer context within the same budget.
<div id='section'>Paperid: <span id='pid'>496, <a href='https://arxiv.org/pdf/2505.21236.pdf' target='_blank'>https://arxiv.org/pdf/2505.21236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felix Chalumeau, Daniel Rajaonarivonivelomanantsoa, Ruan de Kock, Claude Formanek, Sasha Abramowitz, Oumayma Mahjoub, Wiem Khlifi, Simon Du Toit, Louay Ben Nessir, Refiloe Shabe, Arnol Fokam, Siddarth Singh, Ulrich Mbou Sob, Arnu Pretorius
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21236">Breaking the Performance Ceiling in Complex Reinforcement Learning requires Inference Strategies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement learning (RL) systems have countless applications, from energy-grid management to protein design. However, such real-world scenarios are often extremely difficult, combinatorial in nature, and require complex coordination between multiple agents. This level of complexity can cause even state-of-the-art RL systems, trained until convergence, to hit a performance ceiling which they are unable to break out of with zero-shot inference. Meanwhile, many digital or simulation-based applications allow for an inference phase that utilises a specific time and compute budget to explore multiple attempts before outputting a final solution. In this work, we show that such an inference phase employed at execution time, and the choice of a corresponding inference strategy, are key to breaking the performance ceiling observed in complex multi-agent RL problems. Our main result is striking: we can obtain up to a 126% and, on average, a 45% improvement over the previous state-of-the-art across 17 tasks, using only a couple seconds of extra wall-clock time during execution. We also demonstrate promising compute scaling properties, supported by over 60k experiments, making it the largest study on inference strategies for complex RL to date. Our experimental data and code are available at https://sites.google.com/view/inf-marl.
<div id='section'>Paperid: <span id='pid'>497, <a href='https://arxiv.org/pdf/2504.11454.pdf' target='_blank'>https://arxiv.org/pdf/2504.11454.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng-Yen Hsieh, Xinyou Wang, Daiheng Zhang, Dongyu Xue, Fei Ye, Shujian Huang, Zaixiang Zheng, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11454">Elucidating the Design Space of Multimodal Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal protein language models (PLMs) integrate sequence and token-based structural information, serving as a powerful foundation for protein modeling, generation, and design. However, the reliance on tokenizing 3D structures into discrete tokens causes substantial loss of fidelity about fine-grained structural details and correlations. In this paper, we systematically elucidate the design space of multimodal PLMs to overcome their limitations. We identify tokenization loss and inaccurate structure token predictions by the PLMs as major bottlenecks. To address these, our proposed design space covers improved generative modeling, structure-aware architectures and representation learning, and data exploration. Our advancements approach finer-grained supervision, demonstrating that token-based multimodal PLMs can achieve robust structural modeling. The effective design methods dramatically improve the structure generation diversity, and notably, folding abilities of our 650M model by reducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B baselines and on par with the specialized folding models. Project page and code: https://bytedance.github.io/dplm/dplm-2.1/.
<div id='section'>Paperid: <span id='pid'>498, <a href='https://arxiv.org/pdf/2502.03540.pdf' target='_blank'>https://arxiv.org/pdf/2502.03540.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fred Zhangzhi Peng, Zachary Bezemek, Sawan Patel, Jarrid Rector-Brooks, Sherwood Yao, Avishek Joey Bose, Alexander Tong, Pranam Chatterjee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03540">Path Planning for Masked Diffusion Model Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Any order generation of discrete data using masked diffusion models (MDMs) offers a compelling alternative to traditional autoregressive models, especially in domains that lack a natural causal ordering of data. However, current popular MDMs depart from their successful continuous diffusion model counterparts with simplified masked inference wherein unmasked tokens cannot be iteratively refined -- even if there is a mistake. In this paper, we extract the full power of MDMs by introducing a novel inference sampling strategy termed Path Planning (P2) that decomposes each generation step into two sub-stages: planning and denoising. Under P2, the planner at every step selects appropriate tokens that are marked to be updated, which can then be sampled using the denoiser. We demonstrate that P2 generalizes all existing sampling strategies for MDMs and critically enhances generative quality through the new capability of refining and updating existing unmasked tokens. We theoretically prove that P2 establishes a (new) expanded evidence lower bound (ELBO) on the log marginal likelihood of data. We instantiate P2 with a family of planners including: 1.) Self-Planning, 2.) BERT-Planning, and 3.) Trained-Planning with a learned planner leading to SOTA generative performance for MDMs on a suite of domains. Specifically, solely using P2 inference, we observe relative improvements of 22% in protein sequence foldability, 8% in RNA sequence pLDDT, 4% in math reasoning, 68% in story generation (ROUGE score), and 33% in code generation for the challenging pass@1 metric.
<div id='section'>Paperid: <span id='pid'>499, <a href='https://arxiv.org/pdf/2501.15055.pdf' target='_blank'>https://arxiv.org/pdf/2501.15055.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaqi Guan, Jiahan Li, Xiangxin Zhou, Xingang Peng, Sheng Wang, Yunan Luo, Jian Peng, Jianzhu Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15055">Group Ligands Docking to Protein Pockets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking is a key task in computational biology that has attracted increasing interest from the machine learning community. While existing methods have achieved success, they generally treat each protein-ligand pair in isolation. Inspired by the biochemical observation that ligands binding to the same target protein tend to adopt similar poses, we propose \textsc{GroupBind}, a novel molecular docking framework that simultaneously considers multiple ligands docking to a protein. This is achieved by introducing an interaction layer for the group of ligands and a triangle attention module for embedding protein-ligand and group-ligand pairs. By integrating our approach with diffusion-based docking model, we set a new S performance on the PDBBind blind docking benchmark, demonstrating the effectiveness of our proposed molecular docking paradigm.
<div id='section'>Paperid: <span id='pid'>500, <a href='https://arxiv.org/pdf/2501.01930.pdf' target='_blank'>https://arxiv.org/pdf/2501.01930.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuwei Miao, Yuzhi Guo, Hehuan Ma, Jingquan Yan, Feng Jiang, Rui Liao, Junzhou Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01930">GoBERT: Gene Ontology Graph Informed BERT for Universal Gene Function Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Exploring the functions of genes and gene products is crucial to a wide range of fields, including medical research, evolutionary biology, and environmental science. However, discovering new functions largely relies on expensive and exhaustive wet lab experiments. Existing methods of automatic function annotation or prediction mainly focus on protein function prediction with sequence, 3D-structures or protein family information. In this study, we propose to tackle the gene function prediction problem by exploring Gene Ontology graph and annotation with BERT (GoBERT) to decipher the underlying relationships among gene functions. Our proposed novel function prediction task utilizes existing functions as inputs and generalizes the function prediction to gene and gene products. Specifically, two pre-train tasks are designed to jointly train GoBERT to capture both explicit and implicit relations of functions. Neighborhood prediction is a self-supervised multi-label classification task that captures the explicit function relations. Specified masking and recovering task helps GoBERT in finding implicit patterns among functions. The pre-trained GoBERT possess the ability to predict novel functions for various gene and gene products based on known functional annotations. Extensive experiments, biological case studies, and ablation studies are conducted to demonstrate the superiority of our proposed GoBERT.
<div id='section'>Paperid: <span id='pid'>501, <a href='https://arxiv.org/pdf/2412.15790.pdf' target='_blank'>https://arxiv.org/pdf/2412.15790.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Heming Zhang, Di Huang, Yixin Chen, Fuhai Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15790">GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The integration of multi-omic data is pivotal for understanding complex diseases, but its high dimensionality and noise present significant challenges. Graph Neural Networks (GNNs) offer a robust framework for analyzing large-scale signaling pathways and protein-protein interaction networks, yet they face limitations in expressivity when capturing intricate biological relationships. To address this, we propose Graph Sequence Language Model (GraphSeqLM), a framework that enhances GNNs with biological sequence embeddings generated by Large Language Models (LLMs). These embeddings encode structural and biological properties of DNA, RNA, and proteins, augmenting GNNs with enriched features for analyzing sample-specific multi-omic data. By integrating topological, sequence-derived, and biological information, GraphSeqLM demonstrates superior predictive accuracy and outperforms existing methods, paving the way for more effective multi-omic data integration in precision medicine.
<div id='section'>Paperid: <span id='pid'>502, <a href='https://arxiv.org/pdf/2412.12688.pdf' target='_blank'>https://arxiv.org/pdf/2412.12688.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuwei Miao, Yuzhi Guo, Hehuan Ma, Jingquan Yan, Feng Jiang, Weizhi An, Jean Gao, Junzhou Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12688">UniEntrezDB: Large-scale Gene Ontology Annotation Dataset and Evaluation Benchmarks with Unified Entrez Gene Identifiers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gene studies are crucial for fields such as protein structure prediction, drug discovery, and cancer genomics, yet they face challenges in fully utilizing the vast and diverse information available. Gene studies require clean, factual datasets to ensure reliable results. Ontology graphs, neatly organized domain terminology graphs, provide ideal sources for domain facts. However, available gene ontology annotations are currently distributed across various databases without unified identifiers for genes and gene products. To address these challenges, we introduce Unified Entrez Gene Identifier Dataset and Benchmarks (UniEntrezDB), the first systematic effort to unify large-scale public Gene Ontology Annotations (GOA) from various databases using unique gene identifiers. UniEntrezDB includes a pre-training dataset and four downstream tasks designed to comprehensively evaluate gene embedding performance from gene, protein, and cell levels, ultimately enhancing the reliability and applicability of LLMs in gene research and other professional settings.
<div id='section'>Paperid: <span id='pid'>503, <a href='https://arxiv.org/pdf/2411.16686.pdf' target='_blank'>https://arxiv.org/pdf/2411.16686.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiming Ma, Fei Ye, Yi Zhou, Zaixiang Zheng, Dongyu Xue, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16686">ProteinWeaver: A Divide-and-Assembly Approach for Protein Backbone Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nature creates diverse proteins through a 'divide and assembly' strategy. Inspired by this idea, we introduce ProteinWeaver, a two-stage framework for protein backbone design. Our method first generates individual protein domains and then employs an SE(3) diffusion model to flexibly assemble these domains. A key challenge lies in the assembling step, given the complex and rugged nature of the inter-domain interaction landscape. To address this challenge, we employ preference alignment to discern complex relationships between structure and interaction landscapes through comparative analysis of generated samples. Comprehensive experiments demonstrate that ProteinWeaver: (1) generates high-quality, novel protein backbones through versatile domain assembly; (2) outperforms RFdiffusion, the current state-of-the-art in backbone design, by 13\% and 39\% for long-chain proteins; (3) shows the potential for cooperative function design through illustrative case studies. To sum up, by introducing a `divide-and-assembly' paradigm, ProteinWeaver advances protein engineering and opens new avenues for functional protein design.
<div id='section'>Paperid: <span id='pid'>504, <a href='https://arxiv.org/pdf/2411.04165.pdf' target='_blank'>https://arxiv.org/pdf/2411.04165.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Niklas Schmidinger, Lisa Schneckenreiter, Philipp Seidl, Johannes Schimunek, Pieter-Jan Hoedt, Johannes Brandstetter, Andreas Mayr, Sohvi Luukkonen, Sepp Hochreiter, GÃ¼nter Klambauer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04165">Bio-xLSTM: Generative modeling, representation and in-context learning of biological and chemical sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Language models for biological and chemical sequences enable crucial applications such as drug discovery, protein engineering, and precision medicine. Currently, these language models are predominantly based on Transformer architectures. While Transformers have yielded impressive results, their quadratic runtime dependency on the sequence length complicates their use for long genomic sequences and in-context learning on proteins and chemical sequences. Recently, the recurrent xLSTM architecture has been shown to perform favorably compared to Transformers and modern state-space model (SSM) architectures in the natural language domain. Similar to SSMs, xLSTMs have a linear runtime dependency on the sequence length and allow for constant-memory decoding at inference time, which makes them prime candidates for modeling long-range dependencies in biological and chemical sequences. In this work, we tailor xLSTM towards these domains and propose a suite of architectural variants called Bio-xLSTM. Extensive experiments in three large domains, genomics, proteins, and chemistry, were performed to assess xLSTM's ability to model biological and chemical sequences. The results show that models based on Bio-xLSTM a) can serve as proficient generative models for DNA, protein, and chemical sequences, b) learn rich representations for those modalities, and c) can perform in-context learning for proteins and small molecules.
<div id='section'>Paperid: <span id='pid'>505, <a href='https://arxiv.org/pdf/2411.00004.pdf' target='_blank'>https://arxiv.org/pdf/2411.00004.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>RafaÅ Powalski, Bazyli Klockiewicz, Maciej JaÅkowski, Bartosz Topolski, PaweÅ DÄbrowski-TumaÅski, Maciej WiÅniewski, Åukasz KuciÅski, Piotr MiÅoÅ, Dariusz Plewczynski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00004">RapidDock: Unlocking Proteome-scale Molecular Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accelerating molecular docking -- the process of predicting how molecules bind to protein targets -- could boost small-molecule drug discovery and revolutionize medicine. Unfortunately, current molecular docking tools are too slow to screen potential drugs against all relevant proteins, which often results in missed drug candidates or unexpected side effects occurring in clinical trials. To address this gap, we introduce RapidDock, an efficient transformer-based model for blind molecular docking. RapidDock achieves at least a $100 \times$ speed advantage over existing methods without compromising accuracy. On the Posebusters and DockGen benchmarks, our method achieves $52.1\%$ and $44.0\%$ success rates ($\text{RMSD}<2$Ã), respectively. The average inference time is $0.04$ seconds on a single GPU, highlighting RapidDock's potential for large-scale docking studies. We examine the key features of RapidDock that enable leveraging the transformer architecture for molecular docking, including the use of relative distance embeddings of $3$D structures in attention matrices, pre-training on protein folding, and a custom loss function invariant to molecular symmetries.
<div id='section'>Paperid: <span id='pid'>506, <a href='https://arxiv.org/pdf/2410.13782.pdf' target='_blank'>https://arxiv.org/pdf/2410.13782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13782">DPLM-2: A Multimodal Diffusion Protein Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are essential macromolecules defined by their amino acid sequences, which determine their three-dimensional structures and, consequently, their functions in all living organisms. Therefore, generative protein modeling necessitates a multimodal approach to simultaneously model, understand, and generate both sequences and structures. However, existing methods typically use separate models for each modality, limiting their ability to capture the intricate relationships between sequence and structure. This results in suboptimal performance in tasks that requires joint understanding and generation of both modalities. In this paper, we introduce DPLM-2, a multimodal protein foundation model that extends discrete diffusion protein language model (DPLM) to accommodate both sequences and structures. To enable structural learning with the language model, 3D coordinates are converted to discrete tokens using a lookup-free quantization-based tokenizer. By training on both experimental and high-quality synthetic structures, DPLM-2 learns the joint distribution of sequence and structure, as well as their marginals and conditionals. We also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models. Empirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach. Moreover, DPLM-2 demonstrates competitive performance in various conditional generation tasks, including folding, inverse folding, and scaffolding with multimodal motif inputs, as well as providing structure-aware representations for predictive tasks.
<div id='section'>Paperid: <span id='pid'>507, <a href='https://arxiv.org/pdf/2410.12459.pdf' target='_blank'>https://arxiv.org/pdf/2410.12459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehdi Yazdani-Jahromi, Mangal Prakash, Tommaso Mansi, Artem Moskalev, Rui Liao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12459">HELM: Hierarchical Encoding for mRNA Language Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Messenger RNA (mRNA) plays a crucial role in protein synthesis, with its codon structure directly impacting biological properties. While Language Models (LMs) have shown promise in analyzing biological sequences, existing approaches fail to account for the hierarchical nature of mRNA's codon structure. We introduce Hierarchical Encoding for mRNA Language Modeling (HELM), a novel pre-training strategy that incorporates codon-level hierarchical structure into language model training. HELM modulates the loss function based on codon synonymity, aligning the model's learning process with the biological reality of mRNA sequences. We evaluate HELM on diverse mRNA datasets and tasks, demonstrating that HELM outperforms standard language model pre-training as well as existing foundation model baselines on seven diverse downstream property prediction tasks and an antibody region annotation tasks on average by around 8%. Additionally, HELM enhances the generative capabilities of language model, producing diverse mRNA sequences that better align with the underlying true data distribution compared to non-hierarchical baselines.
<div id='section'>Paperid: <span id='pid'>508, <a href='https://arxiv.org/pdf/2409.13361.pdf' target='_blank'>https://arxiv.org/pdf/2409.13361.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sumukh Pinge, Weihong Xu, Wout Bittremieux, Niema Moshiri, Sang-Woo Jun, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13361">RapidOMS: FPGA-based Open Modification Spectral Library Searching with HD Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mass spectrometry (MS) is essential for protein analysis but faces significant challenges with large datasets and complex post-translational modifications, resulting in difficulties in spectral identification. Open Modification Search (OMS) improves the analysis of these modifications. We present RapidOMS, a solution leveraging the Samsung SmartSSD, which integrates SSD and FPGA in a near-storage configuration to minimize data movement and enhance the efficiency of large-scale database searching. RapidOMS employs hyperdimensional computing (HDC), a brain-inspired, high-dimensional data processing approach, exploiting the parallel processing and low-latency capabilities of FPGAs, making it well-suited for MS. Utilizing the parallelism and efficiency of bitwise operations in HDC, RapidOMS delivers up to a 60x speedup over the state-of-the-art (SOTA) CPU tool ANN-Solo and is 2.72x faster than the GPU tool HyperOMS. Furthermore, RapidOMS achieves an 11x improvement in energy efficiency compared to conventional systems, providing scalable, energy-efficient solutions for large-scale proteomics applications and advancing the efficient processing of proteomic data.
<div id='section'>Paperid: <span id='pid'>509, <a href='https://arxiv.org/pdf/2409.06744.pdf' target='_blank'>https://arxiv.org/pdf/2409.06744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fei Ye, Zaixiang Zheng, Dongyu Xue, Yuning Shen, Lihao Wang, Yiming Ma, Yan Wang, Xinyou Wang, Xiangxin Zhou, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06744">ProteinBench: A Holistic Evaluation of Protein Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent years have witnessed a surge in the development of protein foundation models, significantly improving performance in protein prediction and generative tasks ranging from 3D structure prediction and protein design to conformational dynamics. However, the capabilities and limitations associated with these models remain poorly understood due to the absence of a unified evaluation framework. To fill this gap, we introduce ProteinBench, a holistic evaluation framework designed to enhance the transparency of protein foundation models. Our approach consists of three key components: (i) A taxonomic classification of tasks that broadly encompass the main challenges in the protein domain, based on the relationships between different protein modalities; (ii) A multi-metric evaluation approach that assesses performance across four key dimensions: quality, novelty, diversity, and robustness; and (iii) In-depth analyses from various user objectives, providing a holistic view of model performance. Our comprehensive evaluation of protein foundation models reveals several key findings that shed light on their current capabilities and limitations. To promote transparency and facilitate further research, we release the evaluation dataset, code, and a public leaderboard publicly for further analysis and a general modular toolkit. We intend for ProteinBench to be a living benchmark for establishing a standardized, in-depth evaluation framework for protein foundation models, driving their development and application while fostering collaboration within the field.
<div id='section'>Paperid: <span id='pid'>510, <a href='https://arxiv.org/pdf/2407.01649.pdf' target='_blank'>https://arxiv.org/pdf/2407.01649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruidong Wu, Ruihan Guo, Rui Wang, Shitong Luo, Yue Xu, Jiahan Li, Jianzhu Ma, Qiang Liu, Yunan Luo, Jian Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01649">FAFE: Immune Complex Modeling with Geodesic Distance Loss on Noisy Group Frames</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the striking success of general protein folding models such as AlphaFold2(AF2, Jumper et al. (2021)), the accurate computational modeling of antibody-antigen complexes remains a challenging task. In this paper, we first analyze AF2's primary loss function, known as the Frame Aligned Point Error (FAPE), and raise a previously overlooked issue that FAPE tends to face gradient vanishing problem on high-rotational-error targets. To address this fundamental limitation, we propose a novel geodesic loss called Frame Aligned Frame Error (FAFE, denoted as F2E to distinguish from FAPE), which enables the model to better optimize both the rotational and translational errors between two frames. We then prove that F2E can be reformulated as a group-aware geodesic loss, which translates the optimization of the residue-to-residue error to optimizing group-to-group geodesic frame distance. By fine-tuning AF2 with our proposed new loss function, we attain a correct rate of 52.3\% (DockQ $>$ 0.23) on an evaluation set and 43.8\% correct rate on a subset with low homology, with substantial improvement over AF2 by 182\% and 100\% respectively.
<div id='section'>Paperid: <span id='pid'>511, <a href='https://arxiv.org/pdf/2406.00735.pdf' target='_blank'>https://arxiv.org/pdf/2406.00735.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahan Li, Chaoran Cheng, Zuofan Wu, Ruihan Guo, Shitong Luo, Zhizhou Ren, Jian Peng, Jianzhu Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00735">Full-Atom Peptide Design based on Multi-modal Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Peptides, short chains of amino acid residues, play a vital role in numerous biological processes by interacting with other target molecules, offering substantial potential in drug discovery. In this work, we present PepFlow, the first multi-modal deep generative model grounded in the flow-matching framework for the design of full-atom peptides that target specific protein receptors. Drawing inspiration from the crucial roles of residue backbone orientations and side-chain dynamics in protein-peptide interactions, we characterize the peptide structure using rigid backbone frames within the $\mathrm{SE}(3)$ manifold and side-chain angles on high-dimensional tori. Furthermore, we represent discrete residue types in the peptide sequence as categorical distributions on the probability simplex. By learning the joint distributions of each modality using derived flows and vector fields on corresponding manifolds, our method excels in the fine-grained design of full-atom peptides. Harnessing the multi-modal paradigm, our approach adeptly tackles various tasks such as fix-backbone sequence design and side-chain packing through partial sampling. Through meticulously crafted experiments, we demonstrate that PepFlow exhibits superior performance in comprehensive benchmarks, highlighting its significant potential in computational peptide design and analysis.
<div id='section'>Paperid: <span id='pid'>512, <a href='https://arxiv.org/pdf/2405.08226.pdf' target='_blank'>https://arxiv.org/pdf/2405.08226.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Asim Waqas, Aakash Tripathi, Sabeen Ahmed, Ashwin Mukund, Hamza Farooq, Matthew B. Schabath, Paul Stewart, Mia Naeini, Ghulam Rasool
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08226">Self-Normalizing Foundation Model for Enhanced Multi-Omics Data Analysis in Oncology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-omics research has enhanced our understanding of cancer heterogeneity and progression. Investigating molecular data through multi-omics approaches is crucial for unraveling the complex biological mechanisms underlying cancer, thereby enabling more effective diagnosis, treatment, and prevention strategies. However, predicting patient outcomes through the integration of all available multi-omics data is still an under-study research direction. Here, we present SeNMo, a foundation model that has been trained on multi-omics data across 33 cancer types. SeNMo is particularly efficient in handling multi-omics data characterized by high-width and low-length attributes. We trained SeNMo for the task of overall survival of patients using pan-cancer multi-omics data involving 33 cancer sites from the GDC. The training multi-omics data includes gene expression, DNA methylation, miRNA expression, DNA mutations, protein expression modalities, and clinical data. SeNMo was validated on two independent cohorts: Moffitt Cancer Center and CPTAC lung squamous cell carcinoma. We evaluated the model's performance in predicting patient's overall survival using the C-Index. SeNMo performed consistently well in the training regime, reflected by the validation C-Index of 0.76 on GDC's public data. In the testing regime, SeNMo performed with a C-Index of 0.758 on a held-out test set. The model showed an average accuracy of 99.8% on the task of classifying the primary cancer type on the pan-cancer test cohort. SeNMo demonstrated robust performance on the classification task of predicting the primary cancer type of patients. SeNMo further demonstrated significant performance in predicting tertiary lymph structures from multi-omics data, showing generalizability across cancer types, molecular data types, and clinical endpoints.
<div id='section'>Paperid: <span id='pid'>513, <a href='https://arxiv.org/pdf/2404.07194.pdf' target='_blank'>https://arxiv.org/pdf/2404.07194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Florian Sestak, Lisa Schneckenreiter, Johannes Brandstetter, Sepp Hochreiter, Andreas Mayr, GÃ¼nter Klambauer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07194">VN-EGNN: E(3)-Equivariant Graph Neural Networks with Virtual Nodes Enhance Protein Binding Site Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Being able to identify regions within or around proteins, to which ligands can potentially bind, is an essential step to develop new drugs. Binding site identification methods can now profit from the availability of large amounts of 3D structures in protein structure databases or from AlphaFold predictions. Current binding site identification methods heavily rely on graph neural networks (GNNs), usually designed to output E(3)-equivariant predictions. Such methods turned out to be very beneficial for physics-related tasks like binding energy or motion trajectory prediction. However, the performance of GNNs at binding site identification is still limited potentially due to the lack of dedicated nodes that model hidden geometric entities, such as binding pockets. In this work, we extend E(n)-Equivariant Graph Neural Networks (EGNNs) by adding virtual nodes and applying an extended message passing scheme. The virtual nodes in these graphs are dedicated quantities to learn representations of binding sites, which leads to improved predictive performance. In our experiments, we show that our proposed method VN-EGNN sets a new state-of-the-art at locating binding site centers on COACH420, HOLO4K and PDBbind2020.
<div id='section'>Paperid: <span id='pid'>514, <a href='https://arxiv.org/pdf/2403.10358.pdf' target='_blank'>https://arxiv.org/pdf/2403.10358.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Janghoon Ock, Parisa Mollaei, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10358">GradNav: Accelerated Exploration of Potential Energy Surfaces with Gradient-Based Navigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The exploration of molecular systems' potential energy surface is important for comprehending their complex behaviors, particularly through identifying various metastable states. However, the transition between these states is often hindered by substantial energy barriers, demanding prolonged molecular simulations that consume considerable computational efforts. Our study introduces the GradNav algorithm, which enhances the exploration of the energy surface, accelerating the reconstruction of the potential energy surface (PES). This algorithm employs a strategy of initiating short simulation runs from updated starting points, derived from prior observations, to effectively navigate across potential barriers and explore new regions. To evaluate GradNav's performance, we introduce two metrics: the deepest well escape frame (DWEF) and the search success initialization ratio (SSIR). Through applications on Langevin dynamics within Mueller-type potential energy surfaces and molecular dynamics simulations of the Fs-Peptide protein, these metrics demonstrate GradNav's enhanced ability to escape deep energy wells, as shown by reduced DWEF values, and its reduced reliance on initial conditions, highlighted by increased SSIR values. Consequently, this improved exploration capability enables more precise energy estimations from simulation trajectories.
<div id='section'>Paperid: <span id='pid'>515, <a href='https://arxiv.org/pdf/2311.12874.pdf' target='_blank'>https://arxiv.org/pdf/2311.12874.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sumukh Pinge, Weihong Xu, Jaeyoung Kang, Tianqi Zhang, Neima Moshiri, Wout Bittremieux, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12874">SpecHD: Hyperdimensional Computing Framework for FPGA-based Mass Spectrometry Clustering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mass spectrometry-based proteomics is a key enabler for personalized healthcare, providing a deep dive into the complex protein compositions of biological systems. This technology has vast applications in biotechnology and biomedicine but faces significant computational bottlenecks. Current methodologies often require multiple hours or even days to process extensive datasets, particularly in the domain of spectral clustering. To tackle these inefficiencies, we introduce SpecHD, a hyperdimensional computing (HDC) framework supplemented by an FPGA-accelerated architecture with integrated near-storage preprocessing. Utilizing streamlined binary operations in an HDC environment, SpecHD capitalizes on the low-latency and parallel capabilities of FPGAs. This approach markedly improves clustering speed and efficiency, serving as a catalyst for real-time, high-throughput data analysis in future healthcare applications. Our evaluations demonstrate that SpecHD not only maintains but often surpasses existing clustering quality metrics while drastically cutting computational time. Specifically, it can cluster a large-scale human proteome dataset-comprising 25 million MS/MS spectra and 131 GB of MS data-in just 5 minutes. With energy efficiency exceeding 31x and a speedup factor that spans a range of 6x to 54x over existing state of-the-art solutions, SpecHD emerges as a promising solution for the rapid analysis of mass spectrometry data with great implications for personalized healthcare.
<div id='section'>Paperid: <span id='pid'>516, <a href='https://arxiv.org/pdf/2308.15116.pdf' target='_blank'>https://arxiv.org/pdf/2308.15116.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingbang Chen, Yian Wang, Xingwei Qu, Shuangjia Zheng, Yaodong Yang, Hao Dong, Jie Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.15116">Mixup-Augmented Meta-Learning for Sample-Efficient Fine-Tuning of Protein Simulators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular dynamics simulations have emerged as a fundamental instrument for studying biomolecules. At the same time, it is desirable to perform simulations of a collection of particles under various conditions in which the molecules can fluctuate. In this paper, we explore and adapt the soft prompt-based learning method to molecular dynamics tasks. Our model can remarkably generalize to unseen and out-of-distribution scenarios with limited training data. While our work focuses on temperature as a test case, the versatility of our approach allows for efficient simulation through any continuous dynamic conditions, such as pressure and volumes. Our framework has two stages: 1) Pre-trains with data mixing technique, augments molecular structure data and temperature prompts, then applies a curriculum learning method by increasing the ratio of them smoothly. 2) Meta-learning-based fine-tuning framework improves sample-efficiency of fine-tuning process and gives the soft prompt-tuning better initialization points. Comprehensive experiments reveal that our framework excels in accuracy for in-domain data and demonstrates strong generalization capabilities for unseen and out-of-distribution samples.
<div id='section'>Paperid: <span id='pid'>517, <a href='https://arxiv.org/pdf/2304.01565.pdf' target='_blank'>https://arxiv.org/pdf/2304.01565.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengchun Zhang, Maryam Qamar, Taegoo Kang, Yuna Jung, Chenshuang Zhang, Sung-Ho Bae, Chaoning Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.01565">A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have become a new SOTA generative modeling method in various fields, for which there are multiple survey works that provide an overall survey. With the number of articles on diffusion models increasing exponentially in the past few years, there is an increasing need for surveys of diffusion models on specific fields. In this work, we are committed to conducting a survey on the graph diffusion models. Even though our focus is to cover the progress of diffusion models in graphs, we first briefly summarize how other generative modeling methods are used for graphs. After that, we introduce the mechanism of diffusion models in various forms, which facilitates the discussion on the graph diffusion models. The applications of graph diffusion models mainly fall into the category of AI-generated content (AIGC) in science, for which we mainly focus on how graph diffusion models are utilized for generating molecules and proteins but also cover other cases, including materials design. Moreover, we discuss the issue of evaluating diffusion models in the graph domain and the existing challenges.
<div id='section'>Paperid: <span id='pid'>518, <a href='https://arxiv.org/pdf/2303.03543.pdf' target='_blank'>https://arxiv.org/pdf/2303.03543.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaqi Guan, Wesley Wei Qian, Xingang Peng, Yufeng Su, Jian Peng, Jianzhu Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.03543">3D Equivariant Diffusion for Target-Aware Molecule Generation and Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rich data and powerful machine learning models allow us to design drugs for a specific protein target \textit{in silico}. Recently, the inclusion of 3D structures during targeted drug design shows superior performance to other target-free models as the atomic interaction in the 3D space is explicitly modeled. However, current 3D target-aware models either rely on the voxelized atom densities or the autoregressive sampling process, which are not equivariant to rotation or easily violate geometric constraints resulting in unrealistic structures. In this work, we develop a 3D equivariant diffusion model to solve the above challenges. To achieve target-aware molecule design, our method learns a joint generative process of both continuous atom coordinates and categorical atom types with a SE(3)-equivariant network. Moreover, we show that our model can serve as an unsupervised feature extractor to estimate the binding affinity under proper parameterization, which provides an effective way for drug screening. To evaluate our model, we propose a comprehensive framework to evaluate the quality of sampled molecules from different dimensions. Empirical studies show our model could generate molecules with more realistic 3D structures and better affinities towards the protein targets, and improve binding affinity ranking and prediction without retraining.
<div id='section'>Paperid: <span id='pid'>519, <a href='https://arxiv.org/pdf/2303.02162.pdf' target='_blank'>https://arxiv.org/pdf/2303.02162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziqi Chen, Martin Renqiang Min, Hongyu Guo, Chao Cheng, Trevor Clancy, Xia Ning
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02162">T-Cell Receptor Optimization with Reinforcement Learning and Mutation Policies for Precesion Immunotherapy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>T cells monitor the health status of cells by identifying foreign peptides displayed on their surface. T-cell receptors (TCRs), which are protein complexes found on the surface of T cells, are able to bind to these peptides. This process is known as TCR recognition and constitutes a key step for immune response. Optimizing TCR sequences for TCR recognition represents a fundamental step towards the development of personalized treatments to trigger immune responses killing cancerous or virus-infected cells. In this paper, we formulated the search for these optimized TCRs as a reinforcement learning (RL) problem, and presented a framework TCRPPO with a mutation policy using proximal policy optimization. TCRPPO mutates TCRs into effective ones that can recognize given peptides. TCRPPO leverages a reward function that combines the likelihoods of mutated sequences being valid TCRs measured by a new scoring function based on deep autoencoders, with the probabilities of mutated sequences recognizing peptides from a peptide-TCR interaction predictor. We compared TCRPPO with multiple baseline methods and demonstrated that TCRPPO significantly outperforms all the baseline methods to generate positive binding and valid TCRs. These results demonstrate the potential of TCRPPO for both precision immunotherapy and peptide-recognizing TCR motif discovery.
<div id='section'>Paperid: <span id='pid'>520, <a href='https://arxiv.org/pdf/2302.05847.pdf' target='_blank'>https://arxiv.org/pdf/2302.05847.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuqi Lu, Lin Yao, Xi Chen, Hang Zheng, Di He, Guolin Ke
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05847">3D Molecular Generation via Virtual Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug design, i.e., finding molecules with high affinities to the target protein pocket, is one of the most critical tasks in drug discovery. Traditional solutions, like virtual screening, require exhaustively searching on a large molecular database, which are inefficient and cannot return novel molecules beyond the database. The pocket-based 3D molecular generation model, i.e., directly generating a molecule with a 3D structure and binding position in the pocket, is a new promising way to address this issue. Herein, we propose VD-Gen, a novel pocket-based 3D molecular generation pipeline. VD-Gen consists of several carefully designed stages to generate fine-grained 3D molecules with binding positions in the pocket cavity end-to-end. Rather than directly generating or sampling atoms with 3D positions in the pocket like in early attempts, in VD-Gen, we first randomly initialize many virtual particles in the pocket; then iteratively move these virtual particles, making the distribution of virtual particles approximate the distribution of molecular atoms. After virtual particles are stabilized in 3D space, we extract a 3D molecule from them. Finally, we further refine atoms in the extracted molecule by iterative movement again, to get a high-quality 3D molecule, and predict a confidence score for it. Extensive experiment results on pocket-based molecular generation demonstrate that VD-Gen can generate novel 3D molecules to fill the target pocket cavity with high binding affinities, significantly outperforming previous baselines.
<div id='section'>Paperid: <span id='pid'>521, <a href='https://arxiv.org/pdf/2302.01649.pdf' target='_blank'>https://arxiv.org/pdf/2302.01649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zaixiang Zheng, Yifan Deng, Dongyu Xue, Yi Zhou, Fei YE, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.01649">Structure-informed Language Models Are Protein Designers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper demonstrates that language models are strong structure-based protein designers. We present LM-Design, a generic approach to reprogramming sequence-based protein language models (pLMs), that have learned massive sequential evolutionary knowledge from the universe of natural protein sequences, to acquire an immediate capability to design preferable protein sequences for given folds. We conduct a structural surgery on pLMs, where a lightweight structural adapter is implanted into pLMs and endows it with structural awareness. During inference, iterative refinement is performed to effectively optimize the generated protein sequences. Experiments show that LM-Design improves the state-of-the-art results by a large margin, leading to up to 4% to 12% accuracy gains in sequence recovery (e.g., 55.65%/56.63% on CATH 4.2/4.3 single-chain benchmarks, and >60% when designing protein complexes). We provide extensive and in-depth analyses, which verify that LM-Design can (1) indeed leverage both structural and sequential knowledge to accurately handle structurally non-deterministic regions, (2) benefit from scaling data and model size, and (3) generalize to other proteins (e.g., antibodies and de novo proteins)
<div id='section'>Paperid: <span id='pid'>522, <a href='https://arxiv.org/pdf/2301.02120.pdf' target='_blank'>https://arxiv.org/pdf/2301.02120.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ria Vinod, Pin-Yu Chen, Payel Das
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.02120">Reprogramming Pretrained Language Models for Protein Sequence Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine Learning-guided solutions for protein learning tasks have made significant headway in recent years. However, success in scientific discovery tasks is limited by the accessibility of well-defined and labeled in-domain data. To tackle the low-data constraint, recent adaptions of deep learning models pretrained on millions of protein sequences have shown promise; however, the construction of such domain-specific large-scale model is computationally expensive. Here, we propose Representation Learning via Dictionary Learning (R2DL), an end-to-end representation learning framework in which we reprogram deep models for alternate-domain tasks that can perform well on protein property prediction with significantly fewer training samples. R2DL reprograms a pretrained English language model to learn the embeddings of protein sequences, by learning a sparse linear mapping between English and protein sequence vocabulary embeddings. Our model can attain better accuracy and significantly improve the data efficiency by up to $10^5$ times over the baselines set by pretrained and standard supervised methods. To this end, we reprogram an off-the-shelf pre-trained English language transformer and benchmark it on a set of protein physicochemical prediction tasks (secondary structure, stability, homology, stability) as well as on a biomedically relevant set of protein function prediction tasks (antimicrobial, toxicity, antibody affinity).
<div id='section'>Paperid: <span id='pid'>523, <a href='https://arxiv.org/pdf/2211.16422.pdf' target='_blank'>https://arxiv.org/pdf/2211.16422.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaeyoung Kang, Weihong Xu, Wout Bittremieux, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.16422">Massively Parallel Open Modification Spectral Library Searching with Hyperdimensional Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mass spectrometry, commonly used for protein identification, generates a massive number of spectra that need to be matched against a large database. In reality, most of them remain unidentified or mismatched due to unexpected post-translational modifications. Open modification search (OMS) has been proposed as a strategy to improve the identification rate by considering every possible change in spectra, but it expands the search space exponentially. In this work, we propose HyperOMS, which redesigns OMS based on hyperdimensional computing to cope with such challenges. Unlike existing algorithms that represent spectral data with floating point numbers, HyperOMS encodes them with high dimensional binary vectors and performs the efficient OMS in high-dimensional space. With the massive parallelism and simple boolean operations, HyperOMS can be efficiently handled on parallel computing platforms. Experimental results show that HyperOMS on GPU is up to $17\times$ faster and $6.4\times$ more energy efficient than the state-of-the-art GPU-based OMS tool while providing comparable search quality to competing search tools.
<div id='section'>Paperid: <span id='pid'>524, <a href='https://arxiv.org/pdf/2211.14207.pdf' target='_blank'>https://arxiv.org/pdf/2211.14207.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan Schuchardt, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.14207">Invariance-Aware Randomized Smoothing Certificates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Building models that comply with the invariances inherent to different domains, such as invariance under translation or rotation, is a key aspect of applying machine learning to real world problems like molecular property prediction, medical imaging, protein folding or LiDAR classification. For the first time, we study how the invariances of a model can be leveraged to provably guarantee the robustness of its predictions. We propose a gray-box approach, enhancing the powerful black-box randomized smoothing technique with white-box knowledge about invariances. First, we develop gray-box certificates based on group orbits, which can be applied to arbitrary models with invariance under permutation and Euclidean isometries. Then, we derive provably tight gray-box certificates. We experimentally demonstrate that the provably tight certificates can offer much stronger guarantees, but that in practical scenarios the orbit-based method is a good approximation.
<div id='section'>Paperid: <span id='pid'>525, <a href='https://arxiv.org/pdf/2205.07249.pdf' target='_blank'>https://arxiv.org/pdf/2205.07249.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingang Peng, Shitong Luo, Jiaqi Guan, Qi Xie, Jian Peng, Jianzhu Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.07249">Pocket2Mol: Efficient Molecular Sampling Based on 3D Protein Pockets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep generative models have achieved tremendous success in designing novel drug molecules in recent years. A new thread of works have shown the great potential in advancing the specificity and success rate of in silico drug design by considering the structure of protein pockets. This setting posts fundamental computational challenges in sampling new chemical compounds that could satisfy multiple geometrical constraints imposed by pockets. Previous sampling algorithms either sample in the graph space or only consider the 3D coordinates of atoms while ignoring other detailed chemical structures such as bond types and functional groups. To address the challenge, we develop Pocket2Mol, an E(3)-equivariant generative network composed of two modules: 1) a new graph neural network capturing both spatial and bonding relationships between atoms of the binding pockets and 2) a new efficient algorithm which samples new drug candidates conditioned on the pocket representations from a tractable distribution without relying on MCMC. Experimental results demonstrate that molecules sampled from Pocket2Mol achieve significantly better binding affinity and other drug properties such as druglikeness and synthetic accessibility.
<div id='section'>Paperid: <span id='pid'>526, <a href='https://arxiv.org/pdf/2509.14029.pdf' target='_blank'>https://arxiv.org/pdf/2509.14029.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel Tovey, Julian Hoßbach, Sandro Kuppel, Tobias Ensslen, Jan C. Behrends, Christian Holm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14029">Deep Learning-Driven Peptide Classification in Biological Nanopores</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A device capable of performing real time classification of proteins in a clinical setting would allow for inexpensive and rapid disease diagnosis. One such candidate for this technology are nanopore devices. These devices work by measuring a current signal that arises when a protein or peptide enters a nanometer-length-scale pore. Should this current be uniquely related to the structure of the peptide and its interactions with the pore, the signals can be used to perform identification. While such a method would allow for real time identification of peptides and proteins in a clinical setting, to date, the complexities of these signals limit their accuracy. In this work, we tackle the issue of classification by converting the current signals into scaleogram images via wavelet transforms, capturing amplitude, frequency, and time information in a modality well-suited to machine learning algorithms. When tested on 42 peptides, our method achieved a classification accuracy of ~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward practical peptide/protein diagnostics at the point of care. In addition, we demonstrate model transfer techniques that will be critical when deploying these models into real hardware, paving the way to a new method for real-time disease diagnosis.
<div id='section'>Paperid: <span id='pid'>527, <a href='https://arxiv.org/pdf/2507.07426.pdf' target='_blank'>https://arxiv.org/pdf/2507.07426.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zerui Yang, Yuwei Wan, Siyu Yan, Yudai Matsuda, Tong Xie, Bram Hoex, Linqi Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07426">DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in large language models have demonstrated considerable potential in scientific domains such as drug repositioning. However, their effectiveness remains constrained when reasoning extends beyond the knowledge acquired during pretraining. Conventional approaches, such as fine-tuning or retrieval-augmented generation, face limitations in either imposing high computational overhead or failing to fully exploit structured scientific data. To overcome these challenges, we propose DrugMCTS, a novel framework that synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree Search for drug repositioning. The framework employs five specialized agents tasked with retrieving and analyzing molecular and protein information, thereby enabling structured and iterative reasoning. Extensive experiments on the DrugBank and KIBA datasets demonstrate that DrugMCTS achieves substantially higher recall and robustness compared to both general-purpose LLMs and deep learning baselines. Our results highlight the importance of structured reasoning, agent-based collaboration, and feedback-driven search mechanisms in advancing LLM applications for drug repositioning.
<div id='section'>Paperid: <span id='pid'>528, <a href='https://arxiv.org/pdf/2506.23184.pdf' target='_blank'>https://arxiv.org/pdf/2506.23184.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anran Liu, Xiaofei Wang, Jing Cai, Chao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23184">Score-based Diffusion Model for Unpaired Virtual Histology Staining</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hematoxylin and eosin (H&E) staining visualizes histology but lacks specificity for diagnostic markers. Immunohistochemistry (IHC) staining provides protein-targeted staining but is restricted by tissue availability and antibody specificity. Virtual staining, i.e., computationally translating the H&E image to its IHC counterpart while preserving the tissue structure, is promising for efficient IHC generation. Existing virtual staining methods still face key challenges: 1) effective decomposition of staining style and tissue structure, 2) controllable staining process adaptable to diverse tissue and proteins, and 3) rigorous structural consistency modelling to handle the non-pixel-aligned nature of paired H&E and IHC images. This study proposes a mutual-information (MI)-guided score-based diffusion model for unpaired virtual staining. Specifically, we design 1) a global MI-guided energy function that disentangles the tissue structure and staining characteristics across modalities, 2) a novel timestep-customized reverse diffusion process for precise control of the staining intensity and structural reconstruction, and 3) a local MI-driven contrastive learning strategy to ensure the cellular level structural consistency between H&E-IHC images. Extensive experiments demonstrate the our superiority over state-of-the-art approaches, highlighting its biomedical potential. Codes will be open-sourced upon acceptance.
<div id='section'>Paperid: <span id='pid'>529, <a href='https://arxiv.org/pdf/2506.11420.pdf' target='_blank'>https://arxiv.org/pdf/2506.11420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenqiao Song, Tiaoxiao Li, Lei Li, Martin Renqiang Min
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.11420">PPDiff: Diffusing in Hybrid Sequence-Structure Space for Protein-Protein Complex Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing protein-binding proteins with high affinity is critical in biomedical research and biotechnology. Despite recent advancements targeting specific proteins, the ability to create high-affinity binders for arbitrary protein targets on demand, without extensive rounds of wet-lab testing, remains a significant challenge. Here, we introduce PPDiff, a diffusion model to jointly design the sequence and structure of binders for arbitrary protein targets in a non-autoregressive manner. PPDiffbuilds upon our developed Sequence Structure Interleaving Network with Causal attention layers (SSINC), which integrates interleaved self-attention layers to capture global amino acid correlations, k-nearest neighbor (kNN) equivariant graph layers to model local interactions in three-dimensional (3D) space, and causal attention layers to simplify the intricate interdependencies within the protein sequence. To assess PPDiff, we curate PPBench, a general protein-protein complex dataset comprising 706,360 complexes from the Protein Data Bank (PDB). The model is pretrained on PPBenchand finetuned on two real-world applications: target-protein mini-binder complex design and antigen-antibody complex design. PPDiffconsistently surpasses baseline methods, achieving success rates of 50.00%, 23.16%, and 16.89% for the pretraining task and the two downstream applications, respectively.
<div id='section'>Paperid: <span id='pid'>530, <a href='https://arxiv.org/pdf/2506.09332.pdf' target='_blank'>https://arxiv.org/pdf/2506.09332.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenqiao Song, Ramith Hettiarachchi, Chuan Li, Jianwen Xie, Lei Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09332">Natural Language Guided Ligand-Binding Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Can AI protein models follow human language instructions and design proteins with desired functions (e.g. binding to a ligand)? Designing proteins that bind to a given ligand is crucial in a wide range of applications in biology and chemistry. Most prior AI models are trained on protein-ligand complex data, which is scarce due to the high cost and time requirements of laboratory experiments. In contrast, there is a substantial body of human-curated text descriptions about protein-ligand interactions and ligand formula. In this paper, we propose InstructPro, a family of protein generative models that follow natural language instructions to design ligand-binding proteins. Given a textual description of the desired function and a ligand formula in SMILES, InstructPro generates protein sequences that are functionally consistent with the specified instructions. We develop the model architecture, training strategy, and a large-scale dataset, InstructProBench, to support both training and evaluation. InstructProBench consists of 9,592,829 triples of (function description, ligand formula, protein sequence). We train two model variants: InstructPro-1B (with 1 billion parameters) and InstructPro-3B~(with 3 billion parameters). Both variants consistently outperform strong baselines, including ProGen2, ESM3, and Pinal. Notably, InstructPro-1B achieves the highest docking success rate (81.52% at moderate confidence) and the lowest average root mean square deviation (RMSD) compared to ground truth structures (4.026Ã). InstructPro-3B further descreases the average RMSD to 2.527Ã, demonstrating InstructPro's ability to generate ligand-binding proteins that align with the functional specifications.
<div id='section'>Paperid: <span id='pid'>531, <a href='https://arxiv.org/pdf/2505.21873.pdf' target='_blank'>https://arxiv.org/pdf/2505.21873.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jie Gao, Jun Li, Jing Hu, Shanzhuo Zhang, Kunrui Zhu, Yueyang Huang, Xiaonan Zhang, Xiaomin Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21873">HelixDesign-Binder: A Scalable Production-Grade Platform for Binder Design Built on HelixFold3</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein binder design is central to therapeutics, diagnostics, and synthetic biology, yet practical deployment remains challenging due to fragmented workflows, high computational costs, and complex tool integration. We present HelixDesign-Binder, a production-grade, high-throughput platform built on HelixFold3 that automates the full binder design pipeline, from backbone generation and sequence design to structural evaluation and multi-dimensional scoring. By unifying these stages into a scalable and user-friendly system, HelixDesign-Binder enables efficient exploration of binder candidates with favorable structural, energetic, and physicochemical properties. The platform leverages Baidu Cloud's high-performance infrastructure to support large-scale design and incorporates advanced scoring metrics, including ipTM, predicted binding free energy, and interface hydrophobicity. Benchmarking across six protein targets demonstrates that HelixDesign-Binder reliably produces diverse and high-quality binders, some of which match or exceed validated designs in predicted binding affinity. HelixDesign-Binder is accessible via an interactive web interface in PaddleHelix platform, supporting both academic research and industrial applications in antibody and protein binder development.
<div id='section'>Paperid: <span id='pid'>532, <a href='https://arxiv.org/pdf/2505.20346.pdf' target='_blank'>https://arxiv.org/pdf/2505.20346.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahao Kuang, Nuowei Liu, Changzhi Sun, Tao Ji, Yuanbin Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20346">PDFBench: A Benchmark for De novo Protein Design from Function</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, while natural language processing and multimodal learning have seen rapid advancements, the field of de novo protein design has also experienced significant growth. However, most current methods rely on proprietary datasets and evaluation rubrics, making fair comparisons between different approaches challenging. Moreover, these methods often employ evaluation metrics that capture only a subset of the desired properties of designed proteins, lacking a comprehensive assessment framework. To address these, we introduce PDFBench, the first comprehensive benchmark for evaluating de novo protein design from function. PDFBench supports two tasks: description-guided design and keyword-guided design. To ensure fair and multifaceted evaluation, we compile 22 metrics covering sequence plausibility, structural fidelity, and language-protein alignment, along with measures of novelty and diversity. We evaluate five state-of-the-art baselines, revealing their respective strengths and weaknesses across tasks. Finally, we analyze inter-metric correlations, exploring the relationships between four categories of metrics, and offering guidelines for metric selection. PDFBench establishes a unified framework to drive future advances in function-driven de novo protein design.
<div id='section'>Paperid: <span id='pid'>533, <a href='https://arxiv.org/pdf/2505.20301.pdf' target='_blank'>https://arxiv.org/pdf/2505.20301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Liu, Mingchen Li, Yang Tan, Wenrui Gou, Guisheng Fan, Bingxin Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20301">Sequence-Only Prediction of Binding Affinity Changes: A Robust and Interpretable Model for Antibody Engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A pivotal area of research in antibody engineering is to find effective modifications that enhance antibody-antigen binding affinity. Traditional wet-lab experiments assess mutants in a costly and time-consuming manner. Emerging deep learning solutions offer an alternative by modeling antibody structures to predict binding affinity changes. However, they heavily depend on high-quality complex structures, which are frequently unavailable in practice. Therefore, we propose ProtAttBA, a deep learning model that predicts binding affinity changes based solely on the sequence information of antibody-antigen complexes. ProtAttBA employs a pre-training phase to learn protein sequence patterns, following a supervised training phase using labeled antibody-antigen complex data to train a cross-attention-based regressor for predicting binding affinity changes. We evaluated ProtAttBA on three open benchmarks under different conditions. Compared to both sequence- and structure-based prediction methods, our approach achieves competitive performance, demonstrating notable robustness, especially with uncertain complex structures. Notably, our method possesses interpretability from the attention mechanism. We show that the learned attention scores can identify critical residues with impacts on binding affinity. This work introduces a rapid and cost-effective computational tool for antibody engineering, with the potential to accelerate the development of novel therapeutic antibodies.
<div id='section'>Paperid: <span id='pid'>534, <a href='https://arxiv.org/pdf/2505.18966.pdf' target='_blank'>https://arxiv.org/pdf/2505.18966.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nuowei Liu, Jiahao Kuang, Yanting Liu, Changzhi Sun, Tao Ji, Yuanbin Wu, Man Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18966">Protein Design with Dynamic Protein Vocabulary</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein design is a fundamental challenge in biotechnology, aiming to design novel sequences with specific functions within the vast space of possible proteins. Recent advances in deep generative models have enabled function-based protein design from textual descriptions, yet struggle with structural plausibility. Inspired by classical protein design methods that leverage natural protein structures, we explore whether incorporating fragments from natural proteins can enhance foldability in generative models. Our empirical results show that even random incorporation of fragments improves foldability. Building on this insight, we introduce ProDVa, a novel protein design approach that integrates a text encoder for functional descriptions, a protein language model for designing proteins, and a fragment encoder to dynamically retrieve protein fragments based on textual functional descriptions. Experimental results demonstrate that our approach effectively designs protein sequences that are both functionally aligned and structurally plausible. Compared to state-of-the-art models, ProDVa achieves comparable function alignment using less than 0.04% of the training data, while designing significantly more well-folded proteins, with the proportion of proteins having pLDDT above 70 increasing by 7.38% and those with PAE below 10 increasing by 9.6%.
<div id='section'>Paperid: <span id='pid'>535, <a href='https://arxiv.org/pdf/2503.15853.pdf' target='_blank'>https://arxiv.org/pdf/2503.15853.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashkan Dehghan, PaweÅ PraÅat, FranÃ§ois ThÃ©berge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15853">Network Embedding Exploration Tool (NEExT)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many real-world and artificial systems and processes can be represented as graphs. Some examples of such systems include social networks, financial transactions, supply chains, and molecular structures. In many of these cases, one needs to consider a collection of graphs, rather than a single network. This could be a collection of distinct but related graphs, such as different protein structures or graphs resulting from dynamic processes on the same network. Examples of the latter include the evolution of social networks, community-induced graphs, or ego-nets around various nodes. A significant challenge commonly encountered is the absence of ground-truth labels for graphs or nodes, necessitating the use of unsupervised techniques to analyze such systems. Moreover, even when ground-truth labels are available, many existing graph machine learning methods depend on complex deep learning models, complicating model explainability and interpretability. To address some of these challenges, we have introduced NEExT (Network Embedding Exploration Tool) for embedding collections of graphs via user-defined node features. The advantages of the framework are twofold: (i) the ability to easily define your own interpretable node-based features in view of the task at hand, and (ii) fast embedding of graphs provided by the Vectorizers library. In this paper, we demonstrate the usefulness of NEExT on collections of synthetic and real-world graphs. For supervised tasks, we demonstrate that performance in graph classification tasks could be achieved similarly to other state-of-the-art techniques while maintaining model interpretability. Furthermore, our framework can also be used to generate high-quality embeddings in an unsupervised way, where target variables are not available.
<div id='section'>Paperid: <span id='pid'>536, <a href='https://arxiv.org/pdf/2503.04362.pdf' target='_blank'>https://arxiv.org/pdf/2503.04362.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiheng Zhu, Mingyang Li, Junlong Liu, Kun Fu, Jiansheng Wu, Qiuyi Li, Mingze Yin, Jieping Ye, Jian Wu, Zheng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04362">A Generalist Cross-Domain Molecular Learning Framework for Structure-Based Drug Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug discovery (SBDD) is a systematic scientific process that develops new drugs by leveraging the detailed physical structure of the target protein. Recent advancements in pre-trained models for biomolecules have demonstrated remarkable success across various biochemical applications, including drug discovery and protein engineering. However, in most approaches, the pre-trained models primarily focus on the characteristics of either small molecules or proteins, without delving into their binding interactions which are essential cross-domain relationships pivotal to SBDD. To fill this gap, we propose a general-purpose foundation model named BIT (an abbreviation for Biomolecular Interaction Transformer), which is capable of encoding a range of biochemical entities, including small molecules, proteins, and protein-ligand complexes, as well as various data formats, encompassing both 2D and 3D structures. Specifically, we introduce Mixture-of-Domain-Experts (MoDE) to handle the biomolecules from diverse biochemical domains and Mixture-of-Structure-Experts (MoSE) to capture positional dependencies in the molecular structures. The proposed mixture-of-experts approach enables BIT to achieve both deep fusion and domain-specific encoding, effectively capturing fine-grained molecular interactions within protein-ligand complexes. Then, we perform cross-domain pre-training on the shared Transformer backbone via several unified self-supervised denoising tasks. Experimental results on various benchmarks demonstrate that BIT achieves exceptional performance in downstream tasks, including binding affinity prediction, structure-based virtual screening, and molecular property prediction.
<div id='section'>Paperid: <span id='pid'>537, <a href='https://arxiv.org/pdf/2503.01203.pdf' target='_blank'>https://arxiv.org/pdf/2503.01203.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Feng, Shiquan Liu, Xiangmin Han, Shaoyi Du, Zongze Wu, Han Hu, Yue Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.01203">Hypergraph Foundation Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hypergraph neural networks (HGNNs) effectively model complex high-order relationships in domains like protein interactions and social networks by connecting multiple vertices through hyperedges, enhancing modeling capabilities, and reducing information loss. Developing foundation models for hypergraphs is challenging due to their distinct data, which includes both vertex features and intricate structural information. We present Hyper-FM, a Hypergraph Foundation Model for multi-domain knowledge extraction, featuring Hierarchical High-Order Neighbor Guided Vertex Knowledge Embedding for vertex feature representation and Hierarchical Multi-Hypergraph Guided Structural Knowledge Extraction for structural information. Additionally, we curate 10 text-attributed hypergraph datasets to advance research between HGNNs and LLMs. Experiments on these datasets show that Hyper-FM outperforms baseline methods by approximately 13.3\%, validating our approach. Furthermore, we propose the first scaling law for hypergraph foundation models, demonstrating that increasing domain diversity significantly enhances performance, unlike merely augmenting vertex and hyperedge counts. This underscores the critical role of domain diversity in scaling hypergraph models.
<div id='section'>Paperid: <span id='pid'>538, <a href='https://arxiv.org/pdf/2503.00975.pdf' target='_blank'>https://arxiv.org/pdf/2503.00975.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guanlue Li, Chenran Jiang, Ziqi Gao, Yu Liu, Chenyang Liu, Jiean Chen, Yong Huang, Jia Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00975">Molecule Generation for Target Protein Binding with Hierarchical Consistency Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective generation of molecular structures, or new chemical entities, that bind to target proteins is crucial for lead identification and optimization in drug discovery. Despite advancements in atom- and motif-wise deep learning models for 3D molecular generation, current methods often struggle with validity and reliability. To address these issues, we develop the Atom-Motif Consistency Diffusion Model (AMDiff), utilizing a joint-training paradigm for multi-view learning. This model features a hierarchical diffusion architecture that integrates both atom- and motif-level views of molecules, allowing for comprehensive exploration of complementary information. By leveraging classifier-free guidance and incorporating binding site features as conditional inputs, AMDiff ensures robust molecule generation across diverse targets. Compared to existing approaches, AMDiff exhibits superior validity and novelty in generating molecules tailored to fit various protein pockets. Case studies targeting protein kinases, including Anaplastic Lymphoma Kinase (ALK) and Cyclin-dependent kinase 4 (CDK4), demonstrate the model's capability in structure-based de novo drug design. Overall, AMDiff bridges the gap between atom-view and motif-view drug discovery and speeds up the process of target-aware molecular generation.
<div id='section'>Paperid: <span id='pid'>539, <a href='https://arxiv.org/pdf/2502.19395.pdf' target='_blank'>https://arxiv.org/pdf/2502.19395.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyi Zhang, Kun Xie, Ningqiao Huang, Wei Liu, Peilin Zhao, Sibo Wang, Kangfei Zhao, Biaobin Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19395">Fast and Accurate Antibody Sequence Design via Structure Retrieval</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in protein design have leveraged diffusion models to generate structural scaffolds, followed by a process known as protein inverse folding, which involves sequence inference on these scaffolds. However, these methodologies face significant challenges when applied to hyper-variable structures such as antibody Complementarity-Determining Regions (CDRs), where sequence inference frequently results in non-functional sequences due to hallucinations. Distinguished from prevailing protein inverse folding approaches, this paper introduces Igseek, a novel structure-retrieval framework that infers CDR sequences by retrieving similar structures from a natural antibody database. Specifically, Igseek employs a simple yet effective multi-channel equivariant graph neural network to generate high-quality geometric representations of CDR backbone structures. Subsequently, it aligns sequences of structurally similar CDRs and utilizes structurally conserved sequence motifs to enhance inference accuracy. Our experiments demonstrate that Igseek not only proves to be highly efficient in structural retrieval but also outperforms state-of-the-art approaches in sequence recovery for both antibodies and T-Cell Receptors, offering a new retrieval-based perspective for therapeutic protein design.
<div id='section'>Paperid: <span id='pid'>540, <a href='https://arxiv.org/pdf/2502.15867.pdf' target='_blank'>https://arxiv.org/pdf/2502.15867.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingying Sun, Jun A, Zhiwei Liu, Rui Sun, Liujia Qian, Samuel H. Payne, Wout Bittremieux, Markus Ralser, Chen Li, Yi Chen, Zhen Dong, Yasset Perez-Riverol, Asif Khan, Chris Sander, Ruedi Aebersold, Juan Antonio VizcaÃ­no, Jonathan R Krieger, Jianhua Yao, Han Wen, Linfeng Zhang, Yunping Zhu, Yue Xuan, Benjamin Boyang Sun, Liang Qiao, Henning Hermjakob, Haixu Tang, Huanhuan Gao, Yamin Deng, Qing Zhong, Cheng Chang, Nuno Bandeira, Ming Li, Weinan E, Siqi Sun, Yuedong Yang, Gilbert S. Omenn, Yue Zhang, Ping Xu, Yan Fu, Xiaowen Liu, Christopher M. Overall, Yu Wang, Eric W. Deutsch, Luonan Chen, JÃ¼rgen Cox, Vadim Demichev, Fuchu He, Jiaxing Huang, Huilin Jin, Chao Liu, Nan Li, Zhongzhi Luan, Jiangning Song, Kaicheng Yu, Wanggen Wan, Tai Wang, Kang Zhang, Le Zhang, Peter A. Bell, Matthias Mann, Bing Zhang, Tiannan Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15867">Strategic priorities for transformative progress in advancing biology with proteomics and artificial intelligence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence (AI) is transforming scientific research, including proteomics. Advances in mass spectrometry (MS)-based proteomics data quality, diversity, and scale, combined with groundbreaking AI techniques, are unlocking new challenges and opportunities in biological discovery. Here, we highlight key areas where AI is driving innovation, from data analysis to new biological insights. These include developing an AI-friendly ecosystem for proteomics data generation, sharing, and analysis; improving peptide and protein identification and quantification; characterizing protein-protein interactions and protein complexes; advancing spatial and perturbation proteomics; integrating multi-omics data; and ultimately enabling AI-empowered virtual cells.
<div id='section'>Paperid: <span id='pid'>541, <a href='https://arxiv.org/pdf/2502.12280.pdf' target='_blank'>https://arxiv.org/pdf/2502.12280.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Heng Ma, Alexander Brace, Carlo Siebenschuh, Greg Pauloski, Ian Foster, Arvind Ramanathan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12280">Connecting Large Language Model Agent to High Performance Computing Resource</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Large Language Model agent workflow enables the LLM to invoke tool functions to increase the performance on specific scientific domain questions. To tackle large scale of scientific research, it requires access to computing resource and parallel computing setup. In this work, we implemented Parsl to the LangChain/LangGraph tool call setup, to bridge the gap between the LLM agent to the computing resource. Two tool call implementations were set up and tested on both local workstation and HPC environment on Polaris/ALCF. The first implementation with Parsl-enabled LangChain tool node queues the tool functions concurrently to the Parsl workers for parallel execution. The second configuration is implemented by converting the tool functions into Parsl ensemble functions, and is more suitable for large task on super computer environment. The LLM agent workflow was prompted to run molecular dynamics simulations, with different protein structure and simulation conditions. These results showed the LLM agent tools were managed and executed concurrently by Parsl on the available computing resource.
<div id='section'>Paperid: <span id='pid'>542, <a href='https://arxiv.org/pdf/2412.11618.pdf' target='_blank'>https://arxiv.org/pdf/2412.11618.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nuowei Liu, Changzhi Sun, Tao Ji, Junfeng Tian, Jianxin Tang, Yuanbin Wu, Man Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.11618">EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current Large Language Models (LLMs) for understanding proteins primarily treats amino acid sequences as a text modality. Meanwhile, Protein Language Models (PLMs), such as ESM-2, have learned massive sequential evolutionary knowledge from the universe of natural protein sequences. Furthermore, structure-based encoders like ProteinMPNN learn the structural information of proteins through Graph Neural Networks. However, whether the incorporation of protein encoders can enhance the protein understanding of LLMs has not been explored. To bridge this gap, we propose EvoLlama, a multimodal framework that connects a structure-based encoder, a sequence-based protein encoder and an LLM for protein understanding. EvoLlama consists of a ProteinMPNN structure encoder, an ESM-2 protein sequence encoder, a multimodal projector to align protein and text representations and a Llama-3 text decoder. To train EvoLlama, we fine-tune it on protein-oriented instructions and protein property prediction datasets verbalized via natural language instruction templates. Our experiments show that EvoLlama's protein understanding capabilities have been significantly enhanced, outperforming other fine-tuned protein-oriented LLMs in zero-shot settings by an average of 1%-8% and surpassing the state-of-the-art baseline with supervised fine-tuning by an average of 6%. On protein property prediction datasets, our approach achieves promising results that are competitive with state-of-the-art task-specific baselines. We will release our code in a future version.
<div id='section'>Paperid: <span id='pid'>543, <a href='https://arxiv.org/pdf/2412.09380.pdf' target='_blank'>https://arxiv.org/pdf/2412.09380.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenglin Wang, Yucheng Zhou, Zijie Zhai, Jianbing Shen, Kai Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09380">Diffusion Model with Representation Alignment for Protein Inverse Folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein inverse folding is a fundamental problem in bioinformatics, aiming to recover the amino acid sequences from a given protein backbone structure. Despite the success of existing methods, they struggle to fully capture the intricate inter-residue relationships critical for accurate sequence prediction. We propose a novel method that leverages diffusion models with representation alignment (DMRA), which enhances diffusion-based inverse folding by (1) proposing a shared center that aggregates contextual information from the entire protein structure and selectively distributes it to each residue; and (2) aligning noisy hidden representations with clean semantic representations during the denoising process. This is achieved by predefined semantic representations for amino acid types and a representation alignment method that utilizes type embeddings as semantic feedback to normalize each residue. In experiments, we conduct extensive evaluations on the CATH4.2 dataset to demonstrate that DMRA outperforms leading methods, achieving state-of-the-art performance and exhibiting strong generalization capabilities on the TS50 and TS500 datasets.
<div id='section'>Paperid: <span id='pid'>544, <a href='https://arxiv.org/pdf/2410.11499.pdf' target='_blank'>https://arxiv.org/pdf/2410.11499.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weixi Xiang, Xueting Han, Xiujuan Chai, Jing Bai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.11499">BSM: Small but Powerful Biological Sequence Model for Genes and Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling biological sequences such as DNA, RNA, and proteins is crucial for understanding complex processes like gene regulation and protein synthesis. However, most current models either focus on a single type or treat multiple types of data separately, limiting their ability to capture cross-modal relationships. We propose that by learning the relationships between these modalities, the model can enhance its understanding of each type. To address this, we introduce BSM, a small but powerful mixed-modal biological sequence foundation model, trained on three types of data: RefSeq, Gene Related Sequences, and interleaved biological sequences from the web. These datasets capture the genetic flow, gene-protein relationships, and the natural co-occurrence of diverse biological data, respectively. By training on mixed-modal data, BSM significantly enhances learning efficiency and cross-modal representation, outperforming models trained solely on unimodal data. With only 110M parameters, BSM achieves performance comparable to much larger models across both single-modal and mixed-modal tasks, and uniquely demonstrates in-context learning capability for mixed-modal tasks, which is absent in existing models. Further scaling to 270M parameters demonstrates even greater performance gains, highlighting the potential of BSM as a significant advancement in multimodal biological sequence modeling.
<div id='section'>Paperid: <span id='pid'>545, <a href='https://arxiv.org/pdf/2410.04060.pdf' target='_blank'>https://arxiv.org/pdf/2410.04060.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ignacio Hounie, Charilaos Kanatsoulis, Arnuv Tandon, Alejandro Ribeiro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04060">LoRTA: Low Rank Tensor Adaptation of Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Low Rank Adaptation (LoRA) is a popular Parameter Efficient Fine Tuning (PEFT) method that effectively adapts large pre-trained models for downstream tasks. LoRA parameterizes model updates using low-rank matrices at each layer, significantly reducing the number of trainable parameters and, consequently, resource requirements during fine-tuning. However, the lower bound on the number of trainable parameters remains high due to the use of the low-rank matrix model. Recent works have addressed this limitation by proposing low rank tensor parameterizations for model updates. However, they only exploit redundancy across layers, or tensorize individual matrices using ad-hoc schemes that introduce additional hyperparameters. In this work, we propose a higher-order Candecomp/Parafac (CP) decomposition, enabling a more compact and flexible representation compared to existing matrix and tensor based PEFT methods. Our experiments on Natural Language Understanding, Instruction Tuning, Preference Optimization and Protein Folding benchmarks demonstrate that our method can achieve a reduction in the number of parameters while maintaining comparable performance.
<div id='section'>Paperid: <span id='pid'>546, <a href='https://arxiv.org/pdf/2408.16975.pdf' target='_blank'>https://arxiv.org/pdf/2408.16975.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lihang Liu, Shanzhuo Zhang, Yang Xue, Xianbin Ye, Kunrui Zhu, Yuxin Li, Yang Liu, Jie Gao, Wenlai Zhao, Hongkun Yu, Zhihua Wu, Xiaonan Zhang, Xiaomin Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16975">Technical Report of HelixFold3 for Biomolecular Structure Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The AlphaFold series has transformed protein structure prediction with remarkable accuracy, often matching experimental methods. AlphaFold2, AlphaFold-Multimer, and the latest AlphaFold3 represent significant strides in predicting single protein chains, protein complexes, and biomolecular structures. While AlphaFold2 and AlphaFold-Multimer are open-sourced, facilitating rapid and reliable predictions, AlphaFold3 remains partially accessible through a limited online server and has not been open-sourced, restricting further development. To address these challenges, the PaddleHelix team is developing HelixFold3, aiming to replicate AlphaFold3's capabilities. Leveraging insights from previous models and extensive datasets, HelixFold3 achieves accuracy comparable to AlphaFold3 in predicting the structures of the conventional ligands, nucleic acids, and proteins. The initial release of HelixFold3 is available as open source on GitHub for academic research, promising to advance biomolecular research and accelerate discoveries. The latest version will be continuously updated on the HelixFold3 web server, providing both interactive visualization and API access.
<div id='section'>Paperid: <span id='pid'>547, <a href='https://arxiv.org/pdf/2408.00892.pdf' target='_blank'>https://arxiv.org/pdf/2408.00892.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thuong Le Hoai Pham, Jillur Rahman Saurav, Aisosa A. Omere, Calvin J. Heyl, Mohammad Sadegh Nasr, Cody Tyler Reynolds, Jai Prakash Yadav Veerla, Helen H Shang, Justyn Jaworski, Alison Ravenscraft, Joseph Anthony Buonomo, Jacob M. Luber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00892">Peptide Sequencing Via Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a protein language model for determining the complete sequence of a peptide based on measurement of a limited set of amino acids. To date, protein sequencing relies on mass spectrometry, with some novel edman degregation based platforms able to sequence non-native peptides. Current protein sequencing techniques face limitations in accurately identifying all amino acids, hindering comprehensive proteome analysis. Our method simulates partial sequencing data by selectively masking amino acids that are experimentally difficult to identify in protein sequences from the UniRef database. This targeted masking mimics real-world sequencing limitations. We then modify and finetune a ProtBert derived transformer-based model, for a new downstream task predicting these masked residues, providing an approximation of the complete sequence. Evaluating on three bacterial Escherichia species, we achieve per-amino-acid accuracy up to 90.5% when only four amino acids ([KCYM]) are known. Structural assessment using AlphaFold and TM-score validates the biological relevance of our predictions. The model also demonstrates potential for evolutionary analysis through cross-species performance. This integration of simulated experimental constraints with computational predictions offers a promising avenue for enhancing protein sequence analysis, potentially accelerating advancements in proteomics and structural biology by providing a probabilistic reconstruction of the complete protein sequence from limited experimental data.
<div id='section'>Paperid: <span id='pid'>548, <a href='https://arxiv.org/pdf/2407.09274.pdf' target='_blank'>https://arxiv.org/pdf/2407.09274.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyuan Chen, Tianhao Chen, Chenggang Xie, Yang Xue, Xiaonan Zhang, Jingbo Zhou, Xiaomin Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.09274">Unifying Sequences, Structures, and Descriptions for Any-to-Any Protein Generation with the Large Multimodal Model HelixProtX</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are fundamental components of biological systems and can be represented through various modalities, including sequences, structures, and textual descriptions. Despite the advances in deep learning and scientific large language models (LLMs) for protein research, current methodologies predominantly focus on limited specialized tasks -- often predicting one protein modality from another. These approaches restrict the understanding and generation of multimodal protein data. In contrast, large multimodal models have demonstrated potential capabilities in generating any-to-any content like text, images, and videos, thus enriching user interactions across various domains. Integrating these multimodal model technologies into protein research offers significant promise by potentially transforming how proteins are studied. To this end, we introduce HelixProtX, a system built upon the large multimodal model, aiming to offer a comprehensive solution to protein research by supporting any-to-any protein modality generation. Unlike existing methods, it allows for the transformation of any input protein modality into any desired protein modality. The experimental results affirm the advanced capabilities of HelixProtX, not only in generating functional descriptions from amino acid sequences but also in executing critical tasks such as designing protein sequences and structures from textual descriptions. Preliminary findings indicate that HelixProtX consistently achieves superior accuracy across a range of protein-related tasks, outperforming existing state-of-the-art models. By integrating multimodal large models into protein research, HelixProtX opens new avenues for understanding protein biology, thereby promising to accelerate scientific discovery.
<div id='section'>Paperid: <span id='pid'>549, <a href='https://arxiv.org/pdf/2406.19755.pdf' target='_blank'>https://arxiv.org/pdf/2406.19755.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Tan, Lirong Zheng, Bozitao Zhong, Liang Hong, Bingxin Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.19755">Protein Representation Learning with Sequence Information Embedding: Does it Always Lead to a Better Performance?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has become a crucial tool in studying proteins. While the significance of modeling protein structure has been discussed extensively in the literature, amino acid types are typically included in the input as a default operation for many inference tasks. This study demonstrates with structure alignment task that embedding amino acid types in some cases may not help a deep learning model learn better representation. To this end, we propose ProtLOCA, a local geometry alignment method based solely on amino acid structure representation. The effectiveness of ProtLOCA is examined by a global structure-matching task on protein pairs with an independent test dataset based on CATH labels. Our method outperforms existing sequence- and structure-based representation learning methods by more quickly and accurately matching structurally consistent protein domains. Furthermore, in local structure pairing tasks, ProtLOCA for the first time provides a valid solution to highlight common local structures among proteins with different overall structures but the same function. This suggests a new possibility for using deep learning methods to analyze protein structure to infer function.
<div id='section'>Paperid: <span id='pid'>550, <a href='https://arxiv.org/pdf/2405.12868.pdf' target='_blank'>https://arxiv.org/pdf/2405.12868.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liming Wu, Zhichao Hou, Jirui Yuan, Yu Rong, Wenbing Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12868">Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning to represent and simulate the dynamics of physical systems is a crucial yet challenging task. Existing equivariant Graph Neural Network (GNN) based methods have encapsulated the symmetry of physics, \emph{e.g.}, translations, rotations, etc, leading to better generalization ability. Nevertheless, their frame-to-frame formulation of the task overlooks the non-Markov property mainly incurred by unobserved dynamics in the environment. In this paper, we reformulate dynamics simulation as a spatio-temporal prediction task, by employing the trajectory in the past period to recover the Non-Markovian interactions. We propose Equivariant Spatio-Temporal Attentive Graph Networks (ESTAG), an equivariant version of spatio-temporal GNNs, to fulfill our purpose. At its core, we design a novel Equivariant Discrete Fourier Transform (EDFT) to extract periodic patterns from the history frames, and then construct an Equivariant Spatial Module (ESM) to accomplish spatial message passing, and an Equivariant Temporal Module (ETM) with the forward attention and equivariant pooling mechanisms to aggregate temporal message. We evaluate our model on three real datasets corresponding to the molecular-, protein- and macro-level. Experimental results verify the effectiveness of ESTAG compared to typical spatio-temporal GNNs and equivariant GNNs.
<div id='section'>Paperid: <span id='pid'>551, <a href='https://arxiv.org/pdf/2405.08205.pdf' target='_blank'>https://arxiv.org/pdf/2405.08205.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenqiao Song, Yunlong Zhao, Wenxian Shi, Wengong Jin, Yang Yang, Lei Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08205">Generative Enzyme Design Guided by Functionally Important Sites and Small-Molecule Substrates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enzymes are genetically encoded biocatalysts capable of accelerating chemical reactions. How can we automatically design functional enzymes? In this paper, we propose EnzyGen, an approach to learn a unified model to design enzymes across all functional families. Our key idea is to generate an enzyme's amino acid sequence and their three-dimensional (3D) coordinates based on functionally important sites and substrates corresponding to a desired catalytic function. These sites are automatically mined from enzyme databases. EnzyGen consists of a novel interleaving network of attention and neighborhood equivariant layers, which captures both long-range correlation in an entire protein sequence and local influence from nearest amino acids in 3D space. To learn the generative model, we devise a joint training objective, including a sequence generation loss, a position prediction loss and an enzyme-substrate interaction loss. We further construct EnzyBench, a dataset with 3157 enzyme families, covering all available enzymes within the protein data bank (PDB). Experimental results show that our EnzyGen consistently achieves the best performance across all 323 testing families, surpassing the best baseline by 10.79% in terms of substrate binding affinity. These findings demonstrate EnzyGen's superior capability in designing well-folded and effective enzymes binding to specific substrates with high affinities.
<div id='section'>Paperid: <span id='pid'>552, <a href='https://arxiv.org/pdf/2405.06693.pdf' target='_blank'>https://arxiv.org/pdf/2405.06693.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenqiao Song, Tinglin Huang, Lei Li, Wengong Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06693">SurfPro: Functional Protein Design Based on Continuous Surface</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>How can we design proteins with desired functions? We are motivated by a chemical intuition that both geometric structure and biochemical properties are critical to a protein's function. In this paper, we propose SurfPro, a new method to generate functional proteins given a desired surface and its associated biochemical properties. SurfPro comprises a hierarchical encoder that progressively models the geometric shape and biochemical features of a protein surface, and an autoregressive decoder to produce an amino acid sequence. We evaluate SurfPro on a standard inverse folding benchmark CATH 4.2 and two functional protein design tasks: protein binder design and enzyme design. Our SurfPro consistently surpasses previous state-of-the-art inverse folding methods, achieving a recovery rate of 57.78% on CATH 4.2 and higher success rates in terms of protein-protein binding and enzyme-substrate interaction scores.
<div id='section'>Paperid: <span id='pid'>553, <a href='https://arxiv.org/pdf/2404.16866.pdf' target='_blank'>https://arxiv.org/pdf/2404.16866.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaohao Yuan, Songyou Li, Geyan Ye, Yikun Zhang, Long-Kai Huang, Wenbing Huang, Wei Liu, Jianhua Yao, Yu Rong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.16866">Annotation-guided Protein Design with Multi-Level Domain Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The core challenge of de novo protein design lies in creating proteins with specific functions or properties, guided by certain conditions. Current models explore to generate protein using structural and evolutionary guidance, which only provide indirect conditions concerning functions and properties. However, textual annotations of proteins, especially the annotations for protein domains, which directly describe the protein's high-level functionalities, properties, and their correlation with target amino acid sequences, remain unexplored in the context of protein design tasks. In this paper, we propose Protein-Annotation Alignment Generation, PAAG, a multi-modality protein design framework that integrates the textual annotations extracted from protein database for controllable generation in sequence space. Specifically, within a multi-level alignment module, PAAG can explicitly generate proteins containing specific domains conditioned on the corresponding domain annotations, and can even design novel proteins with flexible combinations of different kinds of annotations. Our experimental results underscore the superiority of the aligned protein representations from PAAG over 7 prediction tasks. Furthermore, PAAG demonstrates a significant increase in generation success rate (24.7% vs 4.7% in zinc finger, and 54.3% vs 22.0% in the immunoglobulin domain) in comparison to the existing model. We anticipate that PAAG will broaden the horizons of protein design by leveraging the knowledge from between textual annotation and proteins.
<div id='section'>Paperid: <span id='pid'>554, <a href='https://arxiv.org/pdf/2404.10260.pdf' target='_blank'>https://arxiv.org/pdf/2404.10260.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaomin Fang, Jie Gao, Jing Hu, Lihang Liu, Yang Xue, Xiaonan Zhang, Kunrui Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10260">HelixFold-Multimer: Elevating Protein Complex Structure Prediction to New Heights</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While monomer protein structure prediction tools boast impressive accuracy, the prediction of protein complex structures remains a daunting challenge in the field. This challenge is particularly pronounced in scenarios involving complexes with protein chains from different species, such as antigen-antibody interactions, where accuracy often falls short. Limited by the accuracy of complex prediction, tasks based on precise protein-protein interaction analysis also face obstacles. In this report, we highlight the ongoing advancements of our protein complex structure prediction model, HelixFold-Multimer, underscoring its enhanced performance. HelixFold-Multimer provides precise predictions for diverse protein complex structures, especially in therapeutic protein interactions. Notably, HelixFold-Multimer achieves remarkable success in antigen-antibody and peptide-protein structure prediction, greatly surpassing AlphaFold 3. HelixFold-Multimer is now available for public use on the PaddleHelix platform, offering both a general version and an antigen-antibody version. Researchers can conveniently access and utilize this service for their development needs.
<div id='section'>Paperid: <span id='pid'>555, <a href='https://arxiv.org/pdf/2310.13913.pdf' target='_blank'>https://arxiv.org/pdf/2310.13913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lihang Liu, Shanzhuo Zhang, Donglong He, Xianbin Ye, Jingbo Zhou, Xiaonan Zhang, Yaoyao Jiang, Weiming Diao, Hang Yin, Hua Chai, Fan Wang, Jingzhou He, Liang Zheng, Yonghui Li, Xiaomin Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.13913">Pre-Training on Large-Scale Generated Docking Conformations with HelixDock to Unlock the Potential of Protein-ligand Structure Prediction Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-ligand structure prediction is an essential task in drug discovery, predicting the binding interactions between small molecules (ligands) and target proteins (receptors). Recent advances have incorporated deep learning techniques to improve the accuracy of protein-ligand structure prediction. Nevertheless, the experimental validation of docking conformations remains costly, it raises concerns regarding the generalizability of these deep learning-based methods due to the limited training data. In this work, we show that by pre-training on a large-scale docking conformation generated by traditional physics-based docking tools and then fine-tuning with a limited set of experimentally validated receptor-ligand complexes, we can obtain a protein-ligand structure prediction model with outstanding performance. Specifically, this process involved the generation of 100 million docking conformations for protein-ligand pairings, an endeavor consuming roughly 1 million CPU core days. The proposed model, HelixDock, aims to acquire the physical knowledge encapsulated by the physics-based docking tools during the pre-training phase. HelixDock has been rigorously benchmarked against both physics-based and deep learning-based baselines, demonstrating its exceptional precision and robust transferability in predicting binding confirmation. In addition, our investigation reveals the scaling laws governing pre-trained protein-ligand structure prediction models, indicating a consistent enhancement in performance with increases in model parameters and the volume of pre-training data. Moreover, we applied HelixDock to several drug discovery-related tasks to validate its practical utility. HelixDock demonstrates outstanding capabilities on both cross-docking and structure-based virtual screening benchmarks.
<div id='section'>Paperid: <span id='pid'>556, <a href='https://arxiv.org/pdf/2310.04343.pdf' target='_blank'>https://arxiv.org/pdf/2310.04343.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenqiao Song, Yunlong Zhao, Wenxian Shi, Yang Yang, Lei Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.04343">Functional Geometry Guided Protein Sequence and Backbone Structure Co-Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are macromolecules responsible for essential functions in almost all living organisms. Designing reasonable proteins with desired functions is crucial. A protein's sequence and structure are strongly correlated and they together determine its function. In this paper, we propose NAEPro, a model to jointly design Protein sequence and structure based on automatically detected functional sites. NAEPro is powered by an interleaving network of attention and equivariant layers, which can capture global correlation in a whole sequence and local influence from nearest amino acids in three dimensional (3D) space. Such an architecture facilitates effective yet economic message passing at two levels. We evaluate our model and several strong baselines on two protein datasets, $Î²$-lactamase and myoglobin. Experimental results show that our model consistently achieves the highest amino acid recovery rate, TM-score, and the lowest RMSD among all competitors. These findings prove the capability of our model to design protein sequences and structures that closely resemble their natural counterparts. Furthermore, in-depth analysis further confirms our model's ability to generate highly effective proteins capable of binding to their target metallocofactors. We provide code, data and models in Github.
<div id='section'>Paperid: <span id='pid'>557, <a href='https://arxiv.org/pdf/2310.02546.pdf' target='_blank'>https://arxiv.org/pdf/2310.02546.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenqiao Song, Yunlong Zhao, Yufei Song, Wenxian Shi, Yang Yang, Lei Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02546">Joint Design of Protein Sequence and Structure based on Motifs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing novel proteins with desired functions is crucial in biology and chemistry. However, most existing work focus on protein sequence design, leaving protein sequence and structure co-design underexplored. In this paper, we propose GeoPro, a method to design protein backbone structure and sequence jointly. Our motivation is that protein sequence and its backbone structure constrain each other, and thus joint design of both can not only avoid nonfolding and misfolding but also produce more diverse candidates with desired functions. To this end, GeoPro is powered by an equivariant encoder for three-dimensional (3D) backbone structure and a protein sequence decoder guided by 3D geometry. Experimental results on two biologically significant metalloprotein datasets, including $Î²$-lactamases and myoglobins, show that our proposed GeoPro outperforms several strong baselines on most metrics. Remarkably, our method discovers novel $Î²$-lactamases and myoglobins which are not present in protein data bank (PDB) and UniProt. These proteins exhibit stable folding and active site environments reminiscent of those of natural proteins, demonstrating their excellent potential to be biologically functional.
<div id='section'>Paperid: <span id='pid'>558, <a href='https://arxiv.org/pdf/2306.09391.pdf' target='_blank'>https://arxiv.org/pdf/2306.09391.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahil Mehrizi, Arash Mehrjou, Maryana Alegro, Yi Zhao, Benedetta Carbone, Carl Fishwick, Johanna Vappiani, Jing Bi, Siobhan Sanford, Hakan Keles, Marcus Bantscheff, Cuong Nguyen, Patrick Schwab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09391">Multi-omics Prediction from High-content Cellular Imaging with Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-content cellular imaging, transcriptomics, and proteomics data provide rich and complementary views on the molecular layers of biology that influence cellular states and function. However, the biological determinants through which changes in multi-omics measurements influence cellular morphology have not yet been systematically explored, and the degree to which cell imaging could potentially enable the prediction of multi-omics directly from cell imaging data is therefore currently unclear. Here, we address the question of whether it is possible to predict bulk multi-omics measurements directly from cell images using Image2Omics - a deep learning approach that predicts multi-omics in a cell population directly from high-content images of cells stained with multiplexed fluorescent dyes. We perform an experimental evaluation in gene-edited macrophages derived from human induced pluripotent stem cells (hiPSC) under multiple stimulation conditions and demonstrate that Image2Omics achieves significantly better performance in predicting transcriptomics and proteomics measurements directly from cell images than predictions based on the mean observed training set abundance. We observed significant predictability of abundances for 4927 (18.72%; 95% CI: 6.52%, 35.52%) and 3521 (13.38%; 95% CI: 4.10%, 32.21%) transcripts out of 26137 in M1 and M2-stimulated macrophages respectively and for 422 (8.46%; 95% CI: 0.58%, 25.83%) and 697 (13.98%; 95% CI: 2.41%, 32.83%) proteins out of 4986 in M1 and M2-stimulated macrophages respectively. Our results show that some transcript and protein abundances are predictable from cell imaging and that cell imaging may potentially, in some settings and depending on the mechanisms of interest and desired performance threshold, even be a scalable and resource-efficient substitute for multi-omics measurements.
<div id='section'>Paperid: <span id='pid'>559, <a href='https://arxiv.org/pdf/2306.04899.pdf' target='_blank'>https://arxiv.org/pdf/2306.04899.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Tan, Bingxin Zhou, Yuanhong Jiang, Yu Guang Wang, Liang Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.04899">Multi-level Protein Representation Learning for Blind Mutational Effect Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Directed evolution plays an indispensable role in protein engineering that revises existing protein sequences to attain new or enhanced functions. Accurately predicting the effects of protein variants necessitates an in-depth understanding of protein structure and function. Although large self-supervised language models have demonstrated remarkable performance in zero-shot inference using only protein sequences, these models inherently do not interpret the spatial characteristics of protein structures, which are crucial for comprehending protein folding stability and internal molecular interactions. This paper introduces a novel pre-training framework that cascades sequential and geometric analyzers for protein primary and tertiary structures. It guides mutational directions toward desired traits by simulating natural selection on wild-type proteins and evaluates the effects of variants based on their fitness to perform the function. We assess the proposed approach using a public database and two new databases for a variety of variant effect prediction tasks, which encompass a diverse set of proteins and assays from different taxa. The prediction results achieve state-of-the-art performance over other zero-shot learning methods for both single-site mutations and deep mutations.
<div id='section'>Paperid: <span id='pid'>560, <a href='https://arxiv.org/pdf/2305.20009.pdf' target='_blank'>https://arxiv.org/pdf/2305.20009.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nate Gruver, Samuel Stanton, Nathan C. Frey, Tim G. J. Rudner, Isidro Hotzel, Julien Lafrance-Vanasse, Arvind Rajpal, Kyunghyun Cho, Andrew Gordon Wilson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.20009">Protein Design with Guided Discrete Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A popular approach to protein design is to combine a generative model with a discriminative model for conditional sampling. The generative model samples plausible sequences while the discriminative model guides a search for sequences with high fitness. Given its broad success in conditional sampling, classifier-guided diffusion modeling is a promising foundation for protein design, leading many to develop guided diffusion models for structure with inverse folding to recover sequences. In this work, we propose diffusioN Optimized Sampling (NOS), a guidance method for discrete diffusion models that follows gradients in the hidden states of the denoising network. NOS makes it possible to perform design directly in sequence space, circumventing significant limitations of structure-based methods, including scarce data and challenging inverse design. Moreover, we use NOS to generalize LaMBO, a Bayesian optimization procedure for sequence design that facilitates multiple objectives and edit-based constraints. The resulting method, LaMBO-2, enables discrete diffusions and stronger performance with limited edits through a novel application of saliency maps. We apply LaMBO-2 to a real-world protein design task, optimizing antibodies for higher expression yield and binding affinity to several therapeutic targets under locality and developability constraints, attaining a 99% expression rate and 40% binding rate in exploratory in vitro experiments.
<div id='section'>Paperid: <span id='pid'>561, <a href='https://arxiv.org/pdf/2305.17598.pdf' target='_blank'>https://arxiv.org/pdf/2305.17598.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Crane, Brian Lavallee, Blair D. Sullivan, Nate Veldt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.17598">Overlapping and Robust Edge-Colored Clustering in Hypergraphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A recent trend in data mining has explored (hyper)graph clustering algorithms for data with categorical relationship types. Such algorithms have applications in the analysis of social, co-authorship, and protein interaction networks, to name a few. Many such applications naturally have some overlap between clusters, a nuance which is missing from current combinatorial models. Additionally, existing models lack a mechanism for handling noise in datasets. We address these concerns by generalizing Edge-Colored Clustering, a recent framework for categorical clustering of hypergraphs. Our generalizations allow for a budgeted number of either (a) overlapping cluster assignments or (b) node deletions. For each new model we present a greedy algorithm which approximately minimizes an edge mistake objective, as well as bicriteria approximations where the second approximation factor is on the budget. Additionally, we address the parameterized complexity of each problem, providing FPT algorithms and hardness results.
<div id='section'>Paperid: <span id='pid'>562, <a href='https://arxiv.org/pdf/2305.01523.pdf' target='_blank'>https://arxiv.org/pdf/2305.01523.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizhen Luo, Xing Yi Liu, Kai Yang, Kui Huang, Massimo Hong, Jiahuan Zhang, Yushuai Wu, Zaiqing Nie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.01523">Towards Unified AI Drug Discovery with Multiple Knowledge Modalities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, AI models that mine intrinsic patterns from molecular structures and protein sequences have shown promise in accelerating drug discovery. However, these methods partly lag behind real-world pharmaceutical approaches of human experts that additionally grasp structured knowledge from knowledge bases and unstructured knowledge from biomedical literature. To bridge this gap, we propose KEDD, a unified, end-to-end, and multimodal deep learning framework that optimally incorporates both structured and unstructured knowledge for vast AI drug discovery tasks. The framework first extracts underlying characteristics from heterogeneous inputs, and then applies multimodal fusion for accurate prediction. To mitigate the problem of missing modalities, we leverage multi-head sparse attention and a modality masking mechanism to extract relevant information robustly. Benefiting from integrated knowledge, our framework achieves a deeper understanding of molecule entities, brings significant improvements over state-of-the-art methods on a wide range of tasks and benchmarks, and reveals its promising potential in assisting real-world drug discovery.
<div id='section'>Paperid: <span id='pid'>563, <a href='https://arxiv.org/pdf/2305.00386.pdf' target='_blank'>https://arxiv.org/pdf/2305.00386.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenqiao Song, Lei Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.00386">Importance Weighted Expectation-Maximization for Protein Sequence Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing protein sequences with desired biological function is crucial in biology and chemistry. Recent machine learning methods use a surrogate sequence-function model to replace the expensive wet-lab validation. How can we efficiently generate diverse and novel protein sequences with high fitness? In this paper, we propose IsEM-Pro, an approach to generate protein sequences towards a given fitness criterion. At its core, IsEM-Pro is a latent generative model, augmented by combinatorial structure features from a separately learned Markov random fields (MRFs). We develop an Monte Carlo Expectation-Maximization method (MCEM) to learn the model. During inference, sampling from its latent space enhances diversity while its MRFs features guide the exploration in high fitness regions. Experiments on eight protein sequence design tasks show that our IsEM-Pro outperforms the previous best methods by at least 55% on average fitness score and generates more diverse and novel protein sequences.
<div id='section'>Paperid: <span id='pid'>564, <a href='https://arxiv.org/pdf/2304.10031.pdf' target='_blank'>https://arxiv.org/pdf/2304.10031.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mathilde Papillon, Sophia Sanborn, Mustafa Hajij, Nina Miolane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10031">Architectures of Topological Deep Learning: A Survey of Message-Passing Topological Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The natural world is full of complex systems characterized by intricate relations between their components: from social interactions between individuals in a social network to electrostatic interactions between atoms in a protein. Topological Deep Learning (TDL) provides a comprehensive framework to process and extract knowledge from data associated with these systems, such as predicting the social community to which an individual belongs or predicting whether a protein can be a reasonable target for drug development. TDL has demonstrated theoretical and practical advantages that hold the promise of breaking ground in the applied sciences and beyond. However, the rapid growth of the TDL literature for relational systems has also led to a lack of unification in notation and language across message-passing Topological Neural Network (TNN) architectures. This presents a real obstacle for building upon existing works and for deploying message-passing TNNs to new real-world problems. To address this issue, we provide an accessible introduction to TDL for relational systems, and compare the recently published message-passing TNNs using a unified mathematical and graphical notation. Through an intuitive and critical review of the emerging field of TDL, we extract valuable insights into current challenges and exciting opportunities for future development.
<div id='section'>Paperid: <span id='pid'>565, <a href='https://arxiv.org/pdf/2304.08299.pdf' target='_blank'>https://arxiv.org/pdf/2304.08299.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bingxin Zhou, Outongyi Lv, Kai Yi, Xinye Xiong, Pan Tan, Liang Hong, Yu Guang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.08299">Accurate and Definite Mutational Effect Prediction with Lightweight Equivariant Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Directed evolution as a widely-used engineering strategy faces obstacles in finding desired mutants from the massive size of candidate modifications. While deep learning methods learn protein contexts to establish feasible searching space, many existing models are computationally demanding and fail to predict how specific mutational tests will affect a protein's sequence or function. This research introduces a lightweight graph representation learning scheme that efficiently analyzes the microenvironment of wild-type proteins and recommends practical higher-order mutations exclusive to the user-specified protein and function of interest. Our method enables continuous improvement of the inference model by limited computational resources and a few hundred mutational training samples, resulting in accurate prediction of variant effects that exhibit near-perfect correlation with the ground truth across deep mutational scanning assays of 19 proteins. With its affordability and applicability to both computer scientists and biochemical laboratories, our solution offers a wide range of benefits that make it an ideal choice for the community.
<div id='section'>Paperid: <span id='pid'>566, <a href='https://arxiv.org/pdf/2304.04982.pdf' target='_blank'>https://arxiv.org/pdf/2304.04982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinnan Dai, Caihua Shan, Jie Zheng, Xiaoxiao Li, Dongsheng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04982">Biological Factor Regulatory Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Genes are fundamental for analyzing biological systems and many recent works proposed to utilize gene expression for various biological tasks by deep learning models. Despite their promising performance, it is hard for deep neural networks to provide biological insights for humans due to their black-box nature. Recently, some works integrated biological knowledge with neural networks to improve the transparency and performance of their models. However, these methods can only incorporate partial biological knowledge, leading to suboptimal performance. In this paper, we propose the Biological Factor Regulatory Neural Network (BFReg-NN), a generic framework to model relations among biological factors in cell systems. BFReg-NN starts from gene expression data and is capable of merging most existing biological knowledge into the model, including the regulatory relations among genes or proteins (e.g., gene regulatory networks (GRN), protein-protein interaction networks (PPI)) and the hierarchical relations among genes, proteins and pathways (e.g., several genes/proteins are contained in a pathway). Moreover, BFReg-NN also has the ability to provide new biologically meaningful insights because of its white-box characteristics. Experimental results on different gene expression-based tasks verify the superiority of BFReg-NN compared with baselines. Our case studies also show that the key insights found by BFReg-NN are consistent with the biological literature.
<div id='section'>Paperid: <span id='pid'>567, <a href='https://arxiv.org/pdf/2205.10373.pdf' target='_blank'>https://arxiv.org/pdf/2205.10373.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jillur Rahman Saurav, Mohammad Sadegh Nasr, Paul Koomey, Michael Robben, Manfred Huber, Jon Weidanz, BrÃ­d Ryan, Eytan Ruppin, Peng Jiang, Jacob M. Luber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.10373">A SSIM Guided cGAN Architecture For Clinically Driven Generative Image Synthesis of Multiplexed Spatial Proteomics Channels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Here we present a structural similarity index measure (SSIM) guided conditional Generative Adversarial Network (cGAN) that generatively performs image-to-image (i2i) synthesis to generate photo-accurate protein channels in multiplexed spatial proteomics images. This approach can be utilized to accurately generate missing spatial proteomics channels that were not included during experimental data collection either at the bench or the clinic. Experimental spatial proteomic data from the Human BioMolecular Atlas Program (HuBMAP) was used to generate spatial representations of missing proteins through a U-Net based image synthesis pipeline. HuBMAP channels were hierarchically clustered by the (SSIM) as a heuristic to obtain the minimal set needed to recapitulate the underlying biology represented by the spatial landscape of proteins. We subsequently prove that our SSIM based architecture allows for scaling of generative image synthesis to slides with up to 100 channels, which is better than current state of the art algorithms which are limited to data with 11 channels. We validate these claims by generating a new experimental spatial proteomics data set from human lung adenocarcinoma tissue sections and show that a model trained on HuBMAP can accurately synthesize channels from our new data set. The ability to recapitulate experimental data from sparsely stained multiplexed histological slides containing spatial proteomic will have tremendous impact on medical diagnostics and drug development, and also raises important questions on the medical ethics of utilizing data produced by generative image synthesis in the clinical setting. The algorithm that we present in this paper will allow researchers and clinicians to save time and costs in proteomics based histological staining while also increasing the amount of data that they can generate through their experiments.
<div id='section'>Paperid: <span id='pid'>568, <a href='https://arxiv.org/pdf/2110.05006.pdf' target='_blank'>https://arxiv.org/pdf/2110.05006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Benyou Wang, Qianqian Xie, Jiahuan Pei, Zhihong Chen, Prayag Tiwari, Zhao Li, Jie fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.05006">Pre-trained Language Models in Biomedical Domain: A Systematic Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained language models (PLMs) have been the de facto paradigm for most natural language processing (NLP) tasks. This also benefits biomedical domain: researchers from informatics, medicine, and computer science (CS) communities propose various PLMs trained on biomedical datasets, e.g., biomedical text, electronic health records, protein, and DNA sequences for various biomedical tasks. However, the cross-discipline characteristics of biomedical PLMs hinder their spreading among communities; some existing works are isolated from each other without comprehensive comparison and discussions. It expects a survey that not only systematically reviews recent advances of biomedical PLMs and their applications but also standardizes terminology and benchmarks. In this paper, we summarize the recent progress of pre-trained language models in the biomedical domain and their applications in biomedical downstream tasks. Particularly, we discuss the motivations and propose a taxonomy of existing biomedical PLMs. Their applications in biomedical downstream tasks are exhaustively discussed. At last, we illustrate various limitations and future trends, which we hope can provide inspiration for the future research of the research community.
<div id='section'>Paperid: <span id='pid'>569, <a href='https://arxiv.org/pdf/2509.15796.pdf' target='_blank'>https://arxiv.org/pdf/2509.15796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuefeng Liu, Mingxuan Cao, Songhao Jiang, Xiao Luo, Xiaotian Duan, Mengdi Wang, Tobin R. Sosnick, Jinbo Xu, Rick Stevens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15796">Monte Carlo Tree Diffusion with Multiple Experts for Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of protein design is to generate amino acid sequences that fold into functional structures with desired properties. Prior methods combining autoregressive language models with Monte Carlo Tree Search (MCTS) struggle with long-range dependencies and suffer from an impractically large search space. We propose MCTD-ME, Monte Carlo Tree Diffusion with Multiple Experts, which integrates masked diffusion models with tree search to enable multi-token planning and efficient exploration. Unlike autoregressive planners, MCTD-ME uses biophysical-fidelity-enhanced diffusion denoising as the rollout engine, jointly revising multiple positions and scaling to large sequence spaces. It further leverages experts of varying capacities to enrich exploration, guided by a pLDDT-based masking schedule that targets low-confidence regions while preserving reliable residues. We propose a novel multi-expert selection rule (PH-UCT-ME) extends predictive-entropy UCT to expert ensembles. On the inverse folding task (CAMEO and PDB benchmarks), MCTD-ME outperforms single-expert and unguided baselines in both sequence recovery (AAR) and structural similarity (scTM), with gains increasing for longer proteins and benefiting from multi-expert guidance. More generally, the framework is model-agnostic and applicable beyond inverse folding, including de novo protein engineering and multi-objective molecular generation.
<div id='section'>Paperid: <span id='pid'>570, <a href='https://arxiv.org/pdf/2505.11037.pdf' target='_blank'>https://arxiv.org/pdf/2505.11037.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiqing Sun, Dawei Feng, Sen Yang, Yijie Wang, Huaimin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11037">Evolutionary training-free guidance in diffusion model for 3D multi-objective molecular generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discovering novel 3D molecular structures that simultaneously satisfy multiple property targets remains a central challenge in materials and drug design. Although recent diffusion-based models can generate 3D conformations, they require expensive retraining for each new property or property-combination and lack flexibility in enforcing structural constraints. We introduce EGD (Evolutionary Guidance in Diffusion), a training-free framework that embeds evolutionary operators directly into the diffusion sampling process. By performing crossover on noise-perturbed samples and then denoising them with a pretrained Unconditional diffusion model, EGD seamlessly blends structural fragments and steers generation toward user-specified objectives without any additional model updates. On both single- and multi-target 3D conditional generation tasks-and on multi-objective optimization of quantum properties EGD outperforms state-of-the-art conditional diffusion methods in accuracy and runs up to five times faster per generation. In the single-objective optimization of protein ligands, EGD enables customized ligand generation. Moreover, EGD can embed arbitrary 3D fragments into the generated molecules while optimizing multiple conflicting properties in one unified process. This combination of efficiency, flexibility, and controllable structure makes EGD a powerful tool for rapid, guided exploration of chemical space.
<div id='section'>Paperid: <span id='pid'>571, <a href='https://arxiv.org/pdf/2504.04770.pdf' target='_blank'>https://arxiv.org/pdf/2504.04770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuefeng Liu, Songhao Jiang, Chih-chan Tien, Jinbo Xu, Rick Stevens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04770">Bidirectional Hierarchical Protein Multi-Modal Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein representation learning is critical for numerous biological tasks. Recently, large transformer-based protein language models (pLMs) pretrained on large scale protein sequences have demonstrated significant success in sequence-based tasks. However, pLMs lack structural context. Conversely, graph neural networks (GNNs) designed to leverage 3D structural information have shown promising generalization in protein-related prediction tasks, but their effectiveness is often constrained by the scarcity of labeled structural data. Recognizing that sequence and structural representations are complementary perspectives of the same protein entity, we propose a multimodal bidirectional hierarchical fusion framework to effectively merge these modalities. Our framework employs attention and gating mechanisms to enable effective interaction between pLMs-generated sequential representations and GNN-extracted structural features, improving information exchange and enhancement across layers of the neural network. This bidirectional and hierarchical (Bi-Hierarchical) fusion approach leverages the strengths of both modalities to capture richer and more comprehensive protein representations. Based on the framework, we further introduce local Bi-Hierarchical Fusion with gating and global Bi-Hierarchical Fusion with multihead self-attention approaches. Our method demonstrates consistent improvements over strong baselines and existing fusion techniques in a variety of protein representation learning benchmarks, including enzyme EC classification, model quality assessment, protein-ligand binding affinity prediction, protein-protein binding site prediction, and B cell epitopes prediction. Our method establishes a new state-of-the-art for multimodal protein representation learning, emphasizing the efficacy of Bi-Hierarchical Fusion in bridging sequence and structural modalities.
<div id='section'>Paperid: <span id='pid'>572, <a href='https://arxiv.org/pdf/2504.03715.pdf' target='_blank'>https://arxiv.org/pdf/2504.03715.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hannah Janmohamed, Antoine Cully
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03715">Multi-Objective Quality-Diversity in Unstructured and Unbounded Spaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quality-Diversity algorithms are powerful tools for discovering diverse, high-performing solutions. Recently, Multi-Objective Quality-Diversity (MOQD) extends QD to problems with several objectives while preserving solution diversity. MOQD has shown promise in fields such as robotics and materials science, where finding trade-offs between competing objectives like energy efficiency and speed, or material properties is essential. However, existing methods in MOQD rely on tessellating the feature space into a grid structure, which prevents their application in domains where feature spaces are unknown or must be learned, such as complex biological systems or latent exploration tasks. In this work, we introduce Multi-Objective Unstructured Repertoire for Quality-Diversity (MOUR-QD), a MOQD algorithm designed for unstructured and unbounded feature spaces. We evaluate MOUR-QD on five robotic tasks. Importantly, we show that our method excels in tasks where features must be learned, paving the way for applying MOQD to unsupervised domains. We also demonstrate that MOUR-QD is advantageous in domains with unbounded feature spaces, outperforming existing grid-based methods. Finally, we demonstrate that MOUR-QD is competitive with established MOQD methods on existing MOQD tasks and achieves double the MOQD-score in some environments. MOUR-QD opens up new opportunities for MOQD in domains like protein design and image generation.
<div id='section'>Paperid: <span id='pid'>573, <a href='https://arxiv.org/pdf/2501.15492.pdf' target='_blank'>https://arxiv.org/pdf/2501.15492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michaela Cohrs, Shiwoo Koak, Yejin Lee, Yu Jin Sung, Wesley De Neve, Hristo L. Svilenov, Utku Ozbulak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15492">Color Flow Imaging Microscopy Improves Identification of Stress Sources of Protein Aggregates in Biopharmaceuticals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-based therapeutics play a pivotal role in modern medicine targeting various diseases. Despite their therapeutic importance, these products can aggregate and form subvisible particles (SvPs), which can compromise their efficacy and trigger immunological responses, emphasizing the critical need for robust monitoring techniques. Flow Imaging Microscopy (FIM) has been a significant advancement in detecting SvPs, evolving from monochrome to more recently incorporating color imaging. Complementing SvP images obtained via FIM, deep learning techniques have recently been employed successfully for stress source identification of monochrome SvPs. In this study, we explore the potential of color FIM to enhance the characterization of stress sources in SvPs. To achieve this, we curate a new dataset comprising 16,000 SvPs from eight commercial monoclonal antibodies subjected to heat and mechanical stress. Using both supervised and self-supervised convolutional neural networks, as well as vision transformers in large-scale experiments, we demonstrate that deep learning with color FIM images consistently outperforms monochrome images, thus highlighting the potential of color FIM in stress source classification compared to its monochrome counterparts.
<div id='section'>Paperid: <span id='pid'>574, <a href='https://arxiv.org/pdf/2501.09274.pdf' target='_blank'>https://arxiv.org/pdf/2501.09274.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinkai Wang, Jiaxing He, Yuanqi Du, Xiaohui Chen, Jianan Canal Li, Li-Ping Liu, Xiaolin Xu, Soha Hassoun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.09274">Large Language Model is Secretly a Protein Sequence Optimizer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the protein sequence engineering problem, which aims to find protein sequences with high fitness levels, starting from a given wild-type sequence. Directed evolution has been a dominating paradigm in this field which has an iterative process to generate variants and select via experimental feedback. We demonstrate large language models (LLMs), despite being trained on massive texts, are secretly protein sequence optimizers. With a directed evolutionary method, LLM can perform protein engineering through Pareto and experiment-budget constrained optimization, demonstrating success on both synthetic and experimental fitness landscapes.
<div id='section'>Paperid: <span id='pid'>575, <a href='https://arxiv.org/pdf/2412.07815.pdf' target='_blank'>https://arxiv.org/pdf/2412.07815.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peizhen Bai, Filip MiljkoviÄ, Xianyuan Liu, Leonardo De Maria, Rebecca Croasdale-Wood, Owen Rackham, Haiping Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07815">Mask prior-guided denoising diffusion improves inverse protein folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse protein folding generates valid amino acid sequences that can fold into a desired protein structure, with recent deep-learning advances showing strong potential and competitive performance. However, challenges remain, such as predicting elements with high structural uncertainty, including disordered regions. To tackle such low-confidence residue prediction, we propose a Mask-prior-guided denoising Diffusion (MapDiff) framework that accurately captures both structural information and residue interactions for inverse protein folding. MapDiff is a discrete diffusion probabilistic model that iteratively generates amino acid sequences with reduced noise, conditioned on a given protein backbone. To incorporate structural information and residue interactions, we develop a graph-based denoising network with a mask-prior pre-training strategy. Moreover, in the generative process, we combine the denoising diffusion implicit model with Monte-Carlo dropout to reduce uncertainty. Evaluation on four challenging sequence design benchmarks shows that MapDiff substantially outperforms state-of-the-art methods. Furthermore, the in silico sequences generated by MapDiff closely resemble the physico-chemical and structural characteristics of native proteins across different protein families and architectures.
<div id='section'>Paperid: <span id='pid'>576, <a href='https://arxiv.org/pdf/2411.15624.pdf' target='_blank'>https://arxiv.org/pdf/2411.15624.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Boxin Zhao, Cong Ma, Mladen Kolar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15624">Trans-Glasso: A Transfer Learning Approach to Precision Matrix Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Precision matrix estimation is essential in various fields, yet it is challenging when samples for the target study are limited. Transfer learning can enhance estimation accuracy by leveraging data from related source studies. We propose Trans-Glasso, a two-step transfer learning method for precision matrix estimation. First, we obtain initial estimators using a multi-task learning objective that captures shared and unique features across studies. Then, we refine these estimators through differential network estimation to adjust for structural differences between the target and source precision matrices. Under the assumption that most entries of the target precision matrix are shared with source matrices, we derive non-asymptotic error bounds and show that Trans-Glasso achieves minimax optimality under certain conditions. Extensive simulations demonstrate Trans Glasso's superior performance compared to baseline methods, particularly in small-sample settings. We further validate Trans-Glasso in applications to gene networks across brain tissues and protein networks for various cancer subtypes, showcasing its effectiveness in biological contexts. Additionally, we derive the minimax optimal rate for differential network estimation, representing the first such guarantee in this area.
<div id='section'>Paperid: <span id='pid'>577, <a href='https://arxiv.org/pdf/2410.20354.pdf' target='_blank'>https://arxiv.org/pdf/2410.20354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zaixi Zhang, Ruofan Jin, Kaidi Fu, Le Cong, Marinka Zitnik, Mengdi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20354">FoldMark: Protecting Protein Generative Models with Watermarking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structure is key to understanding protein function and is essential for progress in bioengineering, drug discovery, and molecular biology. Recently, with the incorporation of generative AI, the power and accuracy of computational protein structure prediction/design have been improved significantly. However, ethical concerns such as copyright protection and harmful content generation (biosecurity) pose challenges to the wide implementation of protein generative models. Here, we investigate whether it is possible to embed watermarks into protein generative models and their outputs for copyright authentication and the tracking of generated structures. As a proof of concept, we propose a two-stage method FoldMark as a generalized watermarking strategy for protein generative models. FoldMark first pretrain watermark encoder and decoder, which can minorly adjust protein structures to embed user-specific information and faithfully recover the information from the encoded structure. In the second step, protein generative models are fine-tuned with watermark-conditioned Low-Rank Adaptation (LoRA) modules to preserve generation quality while learning to generate watermarked structures with high recovery rates. Extensive experiments are conducted on open-source protein structure prediction models (e.g., ESMFold and MultiFlow) and de novo structure design models (e.g., FrameDiff and FoldFlow) and we demonstrate that our method is effective across all these generative models. Meanwhile, our watermarking framework only exerts a negligible impact on the original protein structure quality and is robust under potential post-processing and adaptive attacks.
<div id='section'>Paperid: <span id='pid'>578, <a href='https://arxiv.org/pdf/2410.13487.pdf' target='_blank'>https://arxiv.org/pdf/2410.13487.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro Zuidberg Dos Martires, Vincent Derkinderen, Luc De Raedt, Marcus Krantz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13487">Automated Reasoning in Systems Biology: a Necessity for Precision Medicine</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent developments in AI have reinvigorated pursuits to advance the (life) sciences using AI techniques, thereby creating a renewed opportunity to bridge different fields and find synergies. Headlines for AI and the life sciences have been dominated by data-driven techniques, for instance, to solve protein folding with next to no expert knowledge. In contrast to this, we argue for the necessity of a formal representation of expert knowledge - either to develop explicit scientific theories or to compensate for the lack of data. Specifically, we argue that the fields of knowledge representation (KR) and systems biology (SysBio) exhibit important overlaps that have been largely ignored so far. This, in turn, means that relevant scientific questions are ready to be answered using the right domain knowledge (SysBio), encoded in the right way (SysBio/KR), and by combining it with modern automated reasoning tools (KR). Hence, the formal representation of domain knowledge is a natural meeting place for SysBio and KR. On the one hand, we argue that such an interdisciplinary approach will advance the field SysBio by exposing it to industrial-grade reasoning tools and thereby allowing novel scientific questions to be tackled. On the other hand, we see ample opportunities to move the state-of-the-art in KR by tailoring KR methods to the field of SysBio, which comes with challenging problem characteristics, e.g. scale, partial knowledge, noise, or sub-symbolic data. We stipulate that this proposed interdisciplinary research is necessary to attain a prominent long-term goal in the health sciences: precision medicine.
<div id='section'>Paperid: <span id='pid'>579, <a href='https://arxiv.org/pdf/2410.02847.pdf' target='_blank'>https://arxiv.org/pdf/2410.02847.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tiexin Qin, Mengxu Zhu, Chunyang Li, Terry Lyons, Hong Yan, Haoliang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.02847">Deep Signature: Characterization of Large-Scale Molecular Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding protein dynamics are essential for deciphering protein functional mechanisms and developing molecular therapies. However, the complex high-dimensional dynamics and interatomic interactions of biological processes pose significant challenge for existing computational techniques. In this paper, we approach this problem for the first time by introducing Deep Signature, a novel computationally tractable framework that characterizes complex dynamics and interatomic interactions based on their evolving trajectories. Specifically, our approach incorporates soft spectral clustering that locally aggregates cooperative dynamics to reduce the size of the system, as well as signature transform that collects iterated integrals to provide a global characterization of the non-smooth interactive dynamics. Theoretical analysis demonstrates that Deep Signature exhibits several desirable properties, including invariance to translation, near invariance to rotation, equivariance to permutation of atomic coordinates, and invariance under time reparameterization. Furthermore, experimental results on three benchmarks of biological processes verify that our approach can achieve superior performance compared to baseline methods.
<div id='section'>Paperid: <span id='pid'>580, <a href='https://arxiv.org/pdf/2410.02143.pdf' target='_blank'>https://arxiv.org/pdf/2410.02143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Guo, Yuchen Zhu, Molei Tao, Yongxin Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.02143">Plug-and-Play Controllable Generation for Discrete Masked Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This article makes discrete masked models for the generative modeling of discrete data controllable. The goal is to generate samples of a discrete random variable that adheres to a posterior distribution, satisfies specific constraints, or optimizes a reward function. This methodological development enables broad applications across downstream tasks such as class-specific image generation and protein design. Existing approaches for controllable generation of masked models typically rely on task-specific fine-tuning or additional modifications, which can be inefficient and resource-intensive. To overcome these limitations, we propose a novel plug-and-play framework based on importance sampling that bypasses the need for training a conditional score. Our framework is agnostic to the choice of control criteria, requires no gradient information, and is well-suited for tasks such as posterior sampling, Bayesian inverse problems, and constrained generation. We demonstrate the effectiveness of our approach through extensive experiments, showcasing its versatility across multiple domains, including protein design.
<div id='section'>Paperid: <span id='pid'>581, <a href='https://arxiv.org/pdf/2410.00709.pdf' target='_blank'>https://arxiv.org/pdf/2410.00709.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuefeng Liu, Songhao Jiang, Xiaotian Duan, Archit Vasan, Chong Liu, Chih-chan Tien, Heng Ma, Thomas Brettin, Fangfang Xia, Ian T. Foster, Rick L. Stevens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00709">Binding Affinity Prediction: From Conventional to Machine Learning-Based Approaches</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-ligand binding is the process by which a small molecule (drug or inhibitor) attaches to a target protein. The binding affinity, which refers to the strength of this interaction, is central to many important problems in bioinformatics such as drug design. An extensive amount of work has been devoted to predicting binding affinity over the past decades due to its significance. In this paper, we review all significant recent works, focusing on the methods, features, and benchmark datasets. We have observed a rising trend in the use of traditional machine learning and deep learning models for predicting binding affinity, accompanied by an increasing amount of data on proteins and small drug-like molecules. While prediction results are constantly improving, we also identify several open questions and potential directions that remain unexplored in the field. This paper could serve as an excellent starting point for machine learning researchers who wish to engage in the study of binding affinity, or for anyone with general interests in machine learning, drug discovery, and bioinformatics.
<div id='section'>Paperid: <span id='pid'>582, <a href='https://arxiv.org/pdf/2409.03773.pdf' target='_blank'>https://arxiv.org/pdf/2409.03773.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rong Han, Xiaohong Liu, Tong Pan, Jing Xu, Xiaoyu Wang, Wuyang Lan, Zhenyu Li, Zixuan Wang, Jiangning Song, Guangyu Wang, Ting Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03773">CoPRA: Bridging Cross-domain Pretrained Sequence Models with Complex Structures for Protein-RNA Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately measuring protein-RNA binding affinity is crucial in many biological processes and drug design. Previous computational methods for protein-RNA binding affinity prediction rely on either sequence or structure features, unable to capture the binding mechanisms comprehensively. The recent emerging pre-trained language models trained on massive unsupervised sequences of protein and RNA have shown strong representation ability for various in-domain downstream tasks, including binding site prediction. However, applying different-domain language models collaboratively for complex-level tasks remains unexplored. In this paper, we propose CoPRA to bridge pre-trained language models from different biological domains via Complex structure for Protein-RNA binding Affinity prediction. We demonstrate for the first time that cross-biological modal language models can collaborate to improve binding affinity prediction. We propose a Co-Former to combine the cross-modal sequence and structure information and a bi-scope pre-training strategy for improving Co-Former's interaction understanding. Meanwhile, we build the largest protein-RNA binding affinity dataset PRA310 for performance evaluation. We also test our model on a public dataset for mutation effect prediction. CoPRA reaches state-of-the-art performance on all the datasets. We provide extensive analyses and verify that CoPRA can (1) accurately predict the protein-RNA binding affinity; (2) understand the binding affinity change caused by mutations; and (3) benefit from scaling data and model size.
<div id='section'>Paperid: <span id='pid'>583, <a href='https://arxiv.org/pdf/2406.09003.pdf' target='_blank'>https://arxiv.org/pdf/2406.09003.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lincan Cai, Shuang Li, Wenxuan Ma, Jingxuan Kang, Binhui Xie, Zixun Sun, Chengwei Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09003">Enhancing Cross-Modal Fine-Tuning with Gradually Intermediate Modality Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large-scale pretrained models have proven immensely valuable in handling data-intensive modalities like text and image. However, fine-tuning these models for certain specialized modalities, such as protein sequence and cosmic ray, poses challenges due to the significant modality discrepancy and scarcity of labeled data. In this paper, we propose an end-to-end method, PaRe, to enhance cross-modal fine-tuning, aiming to transfer a large-scale pretrained model to various target modalities. PaRe employs a gating mechanism to select key patches from both source and target data. Through a modality-agnostic Patch Replacement scheme, these patches are preserved and combined to construct data-rich intermediate modalities ranging from easy to hard. By gradually intermediate modality generation, we can not only effectively bridge the modality gap to enhance stability and transferability of cross-modal fine-tuning, but also address the challenge of limited data in the target modality by leveraging enriched intermediate modality data. Compared with hand-designed, general-purpose, task-specific, and state-of-the-art cross-modal fine-tuning approaches, PaRe demonstrates superior performance across three challenging benchmarks, encompassing more than ten modalities.
<div id='section'>Paperid: <span id='pid'>584, <a href='https://arxiv.org/pdf/2403.14915.pdf' target='_blank'>https://arxiv.org/pdf/2403.14915.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anqi Dong, Can Chen, Tryphon T. Georgiou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14915">Network Learning with Directional Sign Patterns</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Complex systems can be effectively modeled via graphs that encode networked interactions, where relations between entities or nodes are often quantified by signed edge weights, e.g., promotion/inhibition in gene regulatory networks, or encoding political of friendship differences in social networks. However, it is often the case that only an aggregate consequence of such edge weights that characterize relations may be directly observable, as in protein expression of in gene regulatory networks. Thus, learning edge weights poses a significant challenge that is further exacerbated for intricate and large-scale networks. In this article, we address a model problem to determine the strength of sign-indefinite relations that explain marginal distributions that constitute our data. To this end, we develop a paradigm akin to that of the SchrÃ¶dinger bridge problem and an efficient Sinkhorn type algorithm (more properly, SchrÃ¶dinger-Fortet-Sinkhorn algorithm) that allows fast convergence to parameters that minimize a relative entropy/likelihood criterion between the sought signed adjacency matrix and a prior. The formalism that we present represents a novel generalization of the earlier SchrÃ¶dinger formalism in that marginal computations may incorporate weights that model directionality in underlying relations, and further, that it can be extended to high-order networks -- the SchrÃ¶dinger-Fortet-Sinkhorn algorithm that we derive is applicable all the same and allows geometric convergence to a sought sign-indefinite adjacency matrix or tensor, for high-order networks. We demonstrate our framework with synthetic and real-world examples.
<div id='section'>Paperid: <span id='pid'>585, <a href='https://arxiv.org/pdf/2403.08167.pdf' target='_blank'>https://arxiv.org/pdf/2403.08167.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Teng Xiao, Chao Cui, Huaisheng Zhu, Vasant G. Honavar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.08167">MolBind: Multimodal Alignment of Language, Molecules, and Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in biology and chemistry have leveraged multi-modal learning, integrating molecules and their natural language descriptions to enhance drug discovery. However, current pre-training frameworks are limited to two modalities, and designing a unified network to process different modalities (e.g., natural language, 2D molecular graphs, 3D molecular conformations, and 3D proteins) remains challenging due to inherent gaps among them. In this work, we propose MolBind, a framework that trains encoders for multiple modalities through contrastive learning, mapping all modalities to a shared feature space for multi-modal semantic alignment. To facilitate effective pre-training of MolBind on multiple modalities, we also build and collect a high-quality dataset with four modalities, MolBind-M4, including graph-language, conformation-language, graph-conformation, and conformation-protein paired data. MolBind shows superior zero-shot learning performance across a wide range of tasks, demonstrating its strong capability of capturing the underlying semantics of multiple modalities.
<div id='section'>Paperid: <span id='pid'>586, <a href='https://arxiv.org/pdf/2402.06079.pdf' target='_blank'>https://arxiv.org/pdf/2402.06079.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zehui Li, Yuhao Ni, William A V Beardall, Guoxuan Xia, Akashaditya Das, Guy-Bart Stan, Yiren Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06079">DiscDiff: Latent Diffusion Model for DNA Sequence Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel framework for DNA sequence generation, comprising two key components: DiscDiff, a Latent Diffusion Model (LDM) tailored for generating discrete DNA sequences, and Absorb-Escape, a post-training algorithm designed to refine these sequences. Absorb-Escape enhances the realism of the generated sequences by correcting `round errors' inherent in the conversion process between latent and input spaces. Our approach not only sets new standards in DNA sequence generation but also demonstrates superior performance over existing diffusion models, in generating both short and long DNA sequences. Additionally, we introduce EPD-GenDNA, the first comprehensive, multi-species dataset for DNA generation, encompassing 160,000 unique sequences from 15 species. We hope this study will advance the generative modelling of DNA, with potential implications for gene therapy and protein production.
<div id='section'>Paperid: <span id='pid'>587, <a href='https://arxiv.org/pdf/2402.03675.pdf' target='_blank'>https://arxiv.org/pdf/2402.03675.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenqing Hua, Connor Coley, Guy Wolf, Doina Precup, Shuangjia Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03675">Effective Protein-Protein Interaction Exploration with PPIretrieval</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interactions (PPIs) are crucial in regulating numerous cellular functions, including signal transduction, transportation, and immune defense. As the accuracy of multi-chain protein complex structure prediction improves, the challenge has shifted towards effectively navigating the vast complex universe to identify potential PPIs. Herein, we propose PPIretrieval, the first deep learning-based model for protein-protein interaction exploration, which leverages existing PPI data to effectively search for potential PPIs in an embedding space, capturing rich geometric and chemical information of protein surfaces. When provided with an unseen query protein with its associated binding site, PPIretrieval effectively identifies a potential binding partner along with its corresponding binding site in an embedding space, facilitating the formation of protein-protein complexes.
<div id='section'>Paperid: <span id='pid'>588, <a href='https://arxiv.org/pdf/2311.15056.pdf' target='_blank'>https://arxiv.org/pdf/2311.15056.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaqing Wang, Zaifei Yang, Quanming Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.15056">Accurate and interpretable drug-drug interaction prediction enabled by knowledge subgraph learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: Discovering potential drug-drug interactions (DDIs) is a long-standing challenge in clinical treatments and drug developments. Recently, deep learning techniques have been developed for DDI prediction. However, they generally require a huge number of samples, while known DDIs are rare.
  Methods: In this work, we present KnowDDI, a graph neural network-based method that addresses the above challenge. KnowDDI enhances drug representations by adaptively leveraging rich neighborhood information from large biomedical knowledge graphs. Then, it learns a knowledge subgraph for each drug-pair to interpret the predicted DDI, where each of the edges is associated with a connection strength indicating the importance of a known DDI or resembling strength between a drug-pair whose connection is unknown. Thus, the lack of DDIs is implicitly compensated by the enriched drug representations and propagated drug similarities.
  Results: We evaluate KnowDDI on two benchmark DDI datasets. Results show that KnowDDI obtains the state-of-the-art prediction performance with better interpretability. We also find that KnowDDI suffers less than existing works given a sparser knowledge graph. This indicates that the propagated drug similarities play a more important role in compensating for the lack of DDIs when the drug representations are less enriched.
  Conclusions: KnowDDI nicely combines the efficiency of deep learning techniques and the rich prior knowledge in biomedical knowledge graphs. As an original open-source tool, KnowDDI can help detect possible interactions in a broad range of relevant interaction prediction tasks, such as protein-protein interactions, drug-target interactions and disease-gene interactions, eventually promoting the development of biomedicine and healthcare.
<div id='section'>Paperid: <span id='pid'>589, <a href='https://arxiv.org/pdf/2309.16519.pdf' target='_blank'>https://arxiv.org/pdf/2309.16519.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vincent Mallet, Souhaib Attaiki, Yangyang Miao, Bruno Correia, Maks Ovsjanikov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16519">AtomSurf : Surface Representation for Learning on Protein Structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While there has been significant progress in evaluating and comparing different representations for learning on protein data, the role of surface-based learning approaches remains not well-understood. In particular, there is a lack of direct and fair benchmark comparison between the best available surface-based learning methods against alternative representations such as graphs. Moreover, the few existing surface-based approaches either use surface information in isolation or, at best, perform global pooling between surface and graph-based architectures.
  In this work, we fill this gap by first adapting a state-of-the-art surface encoder for protein learning tasks. We then perform a direct and fair comparison of the resulting method against alternative approaches within the Atom3D benchmark, highlighting the limitations of pure surface-based learning. Finally, we propose an integrated approach, which allows learned feature sharing between graphs and surface representations on the level of nodes and vertices $\textit{across all layers}$.
  We demonstrate that the resulting architecture achieves state-of-the-art results on all tasks in the Atom3D benchmark, while adhering to the strict benchmark protocol, as well as more broadly on binding site identification and binding pocket classification. Furthermore, we use coarsened surfaces and optimize our approach for efficiency, making our tool competitive in training and inference time with existing techniques. Our code and data can be found online: $\texttt{github.com/Vincentx15/atomsurf}$
<div id='section'>Paperid: <span id='pid'>590, <a href='https://arxiv.org/pdf/2306.12205.pdf' target='_blank'>https://arxiv.org/pdf/2306.12205.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamad Ballout, Ulf Krumnack, Gunther Heidemann, Kai-Uwe KÃ¼hnberger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.12205">Investigating Pre-trained Language Models on Cross-Domain Datasets, a Step Closer to General AI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained language models have recently emerged as a powerful tool for fine-tuning a variety of language tasks. Ideally, when models are pre-trained on large amount of data, they are expected to gain implicit knowledge. In this paper, we investigate the ability of pre-trained language models to generalize to different non-language tasks. In particular, we test them on tasks from different domains such as computer vision, reasoning on hierarchical data, and protein fold prediction. The four pre-trained models that we used, T5, BART, BERT, and GPT-2 achieve outstanding results. They all have similar performance and they outperform transformers that are trained from scratch by a large margin. For instance, pre-trained language models perform better on the Listops dataset, with an average accuracy of 58.7\%, compared to transformers trained from scratch, which have an average accuracy of 29.0\%. The significant improvement demonstrated across three types of datasets suggests that pre-training on language helps the models to acquire general knowledge, bringing us a step closer to general AI. We also showed that reducing the number of parameters in pre-trained language models does not have a great impact as the performance drops slightly when using T5-Small instead of T5-Base. In fact, when using only 2\% of the parameters, we achieved a great improvement compared to training from scratch. Finally, in contrast to prior work, we find out that using pre-trained embeddings for the input layer is necessary to achieve the desired results.
<div id='section'>Paperid: <span id='pid'>591, <a href='https://arxiv.org/pdf/2306.05445.pdf' target='_blank'>https://arxiv.org/pdf/2306.05445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuxin Zheng, Jiyan He, Chang Liu, Yu Shi, Ziheng Lu, Weitao Feng, Fusong Ju, Jiaxi Wang, Jianwei Zhu, Yaosen Min, He Zhang, Shidi Tang, Hongxia Hao, Peiran Jin, Chi Chen, Frank NoÃ©, Haiguang Liu, Tie-Yan Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.05445">Towards Predicting Equilibrium Distributions for Molecular Systems with Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in deep learning have greatly improved structure prediction of molecules. However, many macroscopic observations that are important for real-world applications are not functions of a single molecular structure, but rather determined from the equilibrium distribution of structures. Traditional methods for obtaining these distributions, such as molecular dynamics simulation, are computationally expensive and often intractable. In this paper, we introduce a novel deep learning framework, called Distributional Graphormer (DiG), in an attempt to predict the equilibrium distribution of molecular systems. Inspired by the annealing process in thermodynamics, DiG employs deep neural networks to transform a simple distribution towards the equilibrium distribution, conditioned on a descriptor of a molecular system, such as a chemical graph or a protein sequence. This framework enables efficient generation of diverse conformations and provides estimations of state densities. We demonstrate the performance of DiG on several molecular tasks, including protein conformation sampling, ligand structure sampling, catalyst-adsorbate sampling, and property-guided structure generation. DiG presents a significant advancement in methodology for statistically understanding molecular systems, opening up new research opportunities in molecular science.
<div id='section'>Paperid: <span id='pid'>592, <a href='https://arxiv.org/pdf/2306.01005.pdf' target='_blank'>https://arxiv.org/pdf/2306.01005.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yogesh Verma, Markus Heinonen, Vikas Garg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.01005">AbODE: Ab Initio Antibody Design using Conjoined ODEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibodies are Y-shaped proteins that neutralize pathogens and constitute the core of our adaptive immune system. De novo generation of new antibodies that target specific antigens holds the key to accelerating vaccine discovery. However, this co-design of the amino acid sequence and the 3D structure subsumes and accentuates some central challenges from multiple tasks, including protein folding (sequence to structure), inverse folding (structure to sequence), and docking (binding). We strive to surmount these challenges with a new generative model AbODE that extends graph PDEs to accommodate both contextual information and external interactions. Unlike existing approaches, AbODE uses a single round of full-shot decoding and elicits continuous differential attention that encapsulates and evolves with latent interactions within the antibody as well as those involving the antigen. We unravel fundamental connections between AbODE and temporal networks as well as graph-matching networks. The proposed model significantly outperforms existing methods on standard metrics across benchmarks.
<div id='section'>Paperid: <span id='pid'>593, <a href='https://arxiv.org/pdf/2302.08261.pdf' target='_blank'>https://arxiv.org/pdf/2302.08261.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiqiang Zhong, Anastasia Barkova, Davide Mottin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08261">Knowledge-augmented Graph Machine Learning for Drug Discovery: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The integration of Artificial Intelligence (AI) into the field of drug discovery has been a growing area of interdisciplinary scientific research. However, conventional AI models are heavily limited in handling complex biomedical structures (such as 2D or 3D protein and molecule structures) and providing interpretations for outputs, which hinders their practical application. As of late, Graph Machine Learning (GML) has gained considerable attention for its exceptional ability to model graph-structured biomedical data and investigate their properties and functional relationships. Despite extensive efforts, GML methods still suffer from several deficiencies, such as the limited ability to handle supervision sparsity and provide interpretability in learning and inference processes, and their ineffectiveness in utilising relevant domain knowledge. In response, recent studies have proposed integrating external biomedical knowledge into the GML pipeline to realise more precise and interpretable drug discovery with limited training instances. However, a systematic definition for this burgeoning research direction is yet to be established. This survey presents a comprehensive overview of long-standing drug discovery principles, provides the foundational concepts and cutting-edge techniques for graph-structured data and knowledge databases, and formally summarises Knowledge-augmented Graph Machine Learning (KaGML) for drug discovery. we propose a thorough review of related KaGML works, collected following a carefully designed search methodology, and organise them into four categories following a novel-defined taxonomy. To facilitate research in this promptly emerging field, we also share collected practical resources that are valuable for intelligent drug discovery and provide an in-depth discussion of the potential avenues for future advancements.
<div id='section'>Paperid: <span id='pid'>594, <a href='https://arxiv.org/pdf/2210.10404.pdf' target='_blank'>https://arxiv.org/pdf/2210.10404.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ron Ofir, Thomas Kriecherbauer, Lars GrÃ¼ne, Michael Margaliot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.10404">On the gain of entrainment in the $n$-dimensional ribosome flow model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ribosome flow model (RFM) is a phenomenological model for the flow of particles along a 1D chain of $n$ sites. It has been extensively used to study ribosome flow along the mRNA molecule during translation. When the transition rates along the chain are time-varying and jointly $T$-periodic the RFM entrains, i.e., every trajectory of the RFM converges to a unique $T$-periodic solution that depends on the transition rates, but not on the initial condition. In general, entrainment to periodic excitations like the 24h solar day or the 50Hz frequency of the electric grid is important in numerous natural and artificial systems. An interesting question, called the gain of entrainment (GOE) in the RFM, is whether proper coordination of the periodic translation rates along the mRNA can lead to a larger average protein production rate. Analyzing the GOE in the RFM is non-trivial and partial results exist only for the RFM with dimensions $n=1,2$. We use a new approach to derive several results on the GOE in the general $n$-dimensional RFM. Perhaps surprisingly, we rigorously characterize several cases where there is no GOE, so to maximize the average production rate in these cases, the best choice is to use constant transition rates all along the chain.
<div id='section'>Paperid: <span id='pid'>595, <a href='https://arxiv.org/pdf/2208.10715.pdf' target='_blank'>https://arxiv.org/pdf/2208.10715.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ellis R. Crabtree, Juan M. Bello-Rivas, Andrew L. Ferguson, Ioannis G. Kevrekidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.10715">GANs and Closures: Micro-Macro Consistency in Multiscale Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sampling the phase space of molecular systems -- and, more generally, of complex systems effectively modeled by stochastic differential equations -- is a crucial modeling step in many fields, from protein folding to materials discovery. These problems are often multiscale in nature: they can be described in terms of low-dimensional effective free energy surfaces parametrized by a small number of "slow" reaction coordinates; the remaining "fast" degrees of freedom populate an equilibrium measure on the reaction coordinate values. Sampling procedures for such problems are used to estimate effective free energy differences as well as ensemble averages with respect to the conditional equilibrium distributions; these latter averages lead to closures for effective reduced dynamic models. Over the years, enhanced sampling techniques coupled with molecular simulation have been developed. An intriguing analogy arises with the field of Machine Learning (ML), where Generative Adversarial Networks can produce high dimensional samples from low dimensional probability distributions. This sample generation returns plausible high dimensional space realizations of a model state, from information about its low-dimensional representation. In this work, we present an approach that couples physics-based simulations and biasing methods for sampling conditional distributions with ML-based conditional generative adversarial networks for the same task. The "coarse descriptors" on which we condition the fine scale realizations can either be known a priori, or learned through nonlinear dimensionality reduction. We suggest that this may bring out the best features of both approaches: we demonstrate that a framework that couples cGANs with physics-based enhanced sampling techniques can improve multiscale SDE dynamical systems sampling, and even shows promise for systems of increasing complexity.
<div id='section'>Paperid: <span id='pid'>596, <a href='https://arxiv.org/pdf/2509.01038.pdf' target='_blank'>https://arxiv.org/pdf/2509.01038.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mihir Bafna, Bowen Jing, Bonnie Berger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01038">Learning residue level protein dynamics with multiscale Gaussians</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many methods have been developed to predict static protein structures, however understanding the dynamics of protein structure is essential for elucidating biological function. While molecular dynamics (MD) simulations remain the in silico gold standard, its high computational cost limits scalability. We present DynaProt, a lightweight, SE(3)-invariant framework that predicts rich descriptors of protein dynamics directly from static structures. By casting the problem through the lens of multivariate Gaussians, DynaProt estimates dynamics at two complementary scales: (1) per-residue marginal anisotropy as $3 \times 3$ covariance matrices capturing local flexibility, and (2) joint scalar covariances encoding pairwise dynamic coupling across residues. From these dynamics outputs, DynaProt achieves high accuracy in predicting residue-level flexibility (RMSF) and, remarkably, enables reasonable reconstruction of the full covariance matrix for fast ensemble generation. Notably, it does so using orders of magnitude fewer parameters than prior methods. Our results highlight the potential of direct protein dynamics prediction as a scalable alternative to existing methods.
<div id='section'>Paperid: <span id='pid'>597, <a href='https://arxiv.org/pdf/2508.15103.pdf' target='_blank'>https://arxiv.org/pdf/2508.15103.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehdi Yazdani-Jahromi, Ali Khodabandeh Yalabadi, Ozlem Ozmen Garibay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15103">Equi-mRNA: Protein Translation Equivariant Encoding for mRNA Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing importance of mRNA therapeutics and synthetic biology highlights the need for models that capture the latent structure of synonymous codon (different triplets encoding the same amino acid) usage, which subtly modulates translation efficiency and gene expression. While recent efforts incorporate codon-level inductive biases through auxiliary objectives, they often fall short of explicitly modeling the structured relationships that arise from the genetic code's inherent symmetries. We introduce Equi-mRNA, the first codon-level equivariant mRNA language model that explicitly encodes synonymous codon symmetries as cyclic subgroups of 2D Special Orthogonal matrix (SO(2)). By combining group-theoretic priors with an auxiliary equivariance loss and symmetry-aware pooling, Equi-mRNA learns biologically grounded representations that outperform vanilla baselines across multiple axes. On downstream property-prediction tasks including expression, stability, and riboswitch switching Equi-mRNA delivers up to approximately 10% improvements in accuracy. In sequence generation, it produces mRNA constructs that are up to approximately 4x more realistic under Frechet BioDistance metrics and approximately 28% better preserve functional properties compared to vanilla baseline. Interpretability analyses further reveal that learned codon-rotation distributions recapitulate known GC-content biases and tRNA abundance patterns, offering novel insights into codon usage. Equi-mRNA establishes a new biologically principled paradigm for mRNA modeling, with significant implications for the design of next-generation therapeutics.
<div id='section'>Paperid: <span id='pid'>598, <a href='https://arxiv.org/pdf/2508.12212.pdf' target='_blank'>https://arxiv.org/pdf/2508.12212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuanliu Fan, Zicheng Ma, Jun Gao, Nan Yu, Jun Zhang, Ziqiang Cao, Yi Qin Gao, Guohong Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12212">ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in protein large language models, such as ProtTeX, represent both side-chain amino acids and backbone structure as discrete token sequences of residue length. While this design enables unified modeling of multimodal protein information, it suffers from two major limitations: (1) The concatenation of sequence and structure tokens approximately doubles the protein length and breaks the intrinsic residue-level alignment between modalities. (2) Constrained by the training corpus and limited context window, ProtTeX is typically trained on single-protein inputs, rendering it incompatible with in-context learning (ICL) and thus limiting its generalization capability. To address these issues, we propose ProtTeX-CC, a lightweight two-stage compression framework designed to enhance ProtTeX under few-shot settings. We first design a joint embedding compression mechanism that fuses sequence and structure representations at the residue level, effectively reducing the protein input length by half without sacrificing performance. Then we propose a self-compression module that aggregates each full demonstration into the latent space of the last few linguistic tokens, reducing the average demonstration length from 751 tokens to less than 16 tokens. Compared to the original ProtTeX, our self-compression approach achieves a compression ratio of approximately 93.68% in the total prompt length under the 16-shot setting. Without modifying the backbone model, ProtTeX-CC introduces only a small number of additional parameters through PEFT-based tuning in the joint embedding compression stage and a single trainable projection layer in the self-compression stage. Extensive experiments on protein function prediction show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and generalizes well to the out-of-domain dataset with a performance gain of 11%.
<div id='section'>Paperid: <span id='pid'>599, <a href='https://arxiv.org/pdf/2508.10841.pdf' target='_blank'>https://arxiv.org/pdf/2508.10841.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Viktor Zaverkin, Matheus Ferraz, Francesco Alesiani, Mathias Niepert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10841">Performance of universal machine-learned potentials with explicit long-range interactions in biomolecular simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Universal machine-learned potentials promise transferable accuracy across compositional and vibrational degrees of freedom, yet their application to biomolecular simulations remains underexplored. This work systematically evaluates equivariant message-passing architectures trained on the SPICE-v2 dataset with and without explicit long-range dispersion and electrostatics. We assess the impact of model size, training data composition, and electrostatic treatment across in- and out-of-distribution benchmark datasets, as well as molecular simulations of bulk liquid water, aqueous NaCl solutions, and biomolecules, including alanine tripeptide, the mini-protein Trp-cage, and Crambin. While larger models improve accuracy on benchmark datasets, this trend does not consistently extend to properties obtained from simulations. Predicted properties also depend on the composition of the training dataset. Long-range electrostatics show no systematic impact across systems. However, for Trp-cage, their inclusion yields increased conformational variability. Our results suggest that imbalanced datasets and immature evaluation practices currently challenge the applicability of universal machine-learned potentials to biomolecular simulations.
<div id='section'>Paperid: <span id='pid'>600, <a href='https://arxiv.org/pdf/2508.02229.pdf' target='_blank'>https://arxiv.org/pdf/2508.02229.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jessica Bariffi, Antonia Wachter-Zeh, Eitan Yaakobi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02229">Sequence Reconstruction over Coloring Channels for Protein Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper studies the sequence reconstruction problem for a channel inspired by protein identification. We introduce a coloring channel, where a sequence is transmitted through a channel that deletes all symbols not belonging to a fixed subset (the coloring) of the alphabet. By extending this to a coloring profile, a tuple of distinct colorings, we analyze the channel's information rate and capacity. We prove that optimal (i.e., achieving maximum information rate) coloring profiles correspond to 2-covering designs and identify the minimal covering number required for maximum information rate, as well as the minimum number for which any coloring profile is optimal.
<div id='section'>Paperid: <span id='pid'>601, <a href='https://arxiv.org/pdf/2507.19755.pdf' target='_blank'>https://arxiv.org/pdf/2507.19755.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziqi Zhang, Shiheng Chen, Runze Yang, Zhisheng Wei, Wei Zhang, Lei Wang, Zhanzhi Liu, Fengshan Zhang, Jing Wu, Xiaoyong Pan, Hongbin Shen, Longbing Cao, Zhaohong Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19755">Modeling enzyme temperature stability from sequence segment perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing enzymes with desired thermal properties is crucial for a wide range of industrial and research applications, and determining temperature stability is an essential step in this process. Experimental determination of thermal parameters is labor-intensive, time-consuming, and costly. Moreover, existing computational approaches are often hindered by limited data availability and imbalanced distributions. To address these challenges, we introduce a curated temperature stability dataset designed for model development and benchmarking in enzyme thermal modeling. Leveraging this dataset, we present the \textit{Segment Transformer}, a novel deep learning framework that enables efficient and accurate prediction of enzyme temperature stability. The model achieves state-of-the-art performance with an RMSE of 24.03, MAE of 18.09, and Pearson and Spearman correlations of 0.33, respectively. These results highlight the effectiveness of incorporating segment-level representations, grounded in the biological observation that different regions of a protein sequence contribute unequally to thermal behavior. As a proof of concept, we applied the Segment Transformer to guide the engineering of a cutinase enzyme. Experimental validation demonstrated a 1.64-fold improvement in relative activity following heat treatment, achieved through only 17 mutations and without compromising catalytic function.
<div id='section'>Paperid: <span id='pid'>602, <a href='https://arxiv.org/pdf/2507.06366.pdf' target='_blank'>https://arxiv.org/pdf/2507.06366.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yupu Zhang, Zelin Xu, Tingsong Xiao, Gustavo Seabra, Yanjun Li, Chenglong Li, Zhe Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06366">DecoyDB: A Dataset for Graph Contrastive Learning in Protein-Ligand Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the binding affinity of protein-ligand complexes plays a vital role in drug discovery. Unfortunately, progress has been hindered by the lack of large-scale and high-quality binding affinity labels. The widely used PDBbind dataset has fewer than 20K labeled complexes. Self-supervised learning, especially graph contrastive learning (GCL), provides a unique opportunity to break the barrier by pre-training graph neural network models based on vast unlabeled complexes and fine-tuning the models on much fewer labeled complexes. However, the problem faces unique challenges, including a lack of a comprehensive unlabeled dataset with well-defined positive/negative complex pairs and the need to design GCL algorithms that incorporate the unique characteristics of such data. To fill the gap, we propose DecoyDB, a large-scale, structure-aware dataset specifically designed for self-supervised GCL on protein-ligand complexes. DecoyDB consists of high-resolution ground truth complexes (less than 2.5 Angstrom) and diverse decoy structures with computationally generated binding poses that range from realistic to suboptimal (negative pairs). Each decoy is annotated with a Root Mean Squared Deviation (RMSD) from the native pose. We further design a customized GCL framework to pre-train graph neural networks based on DecoyDB and fine-tune the models with labels from PDBbind. Extensive experiments confirm that models pre-trained with DecoyDB achieve superior accuracy, label efficiency, and generalizability.
<div id='section'>Paperid: <span id='pid'>603, <a href='https://arxiv.org/pdf/2506.13485.pdf' target='_blank'>https://arxiv.org/pdf/2506.13485.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Zhang, Jiaqi Wei, Zijie Qiu, Sheng Xu, Nanqing Dong, Zhiqiang Gao, Siqi Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13485">Curriculum Learning for Biological Sequence Prediction: The Case of De Novo Peptide Sequencing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Peptide sequencing-the process of identifying amino acid sequences from mass spectrometry data-is a fundamental task in proteomics. Non-Autoregressive Transformers (NATs) have proven highly effective for this task, outperforming traditional methods. Unlike autoregressive models, which generate tokens sequentially, NATs predict all positions simultaneously, leveraging bidirectional context through unmasked self-attention. However, existing NAT approaches often rely on Connectionist Temporal Classification (CTC) loss, which presents significant optimization challenges due to CTC's complexity and increases the risk of training failures. To address these issues, we propose an improved non-autoregressive peptide sequencing model that incorporates a structured protein sequence curriculum learning strategy. This approach adjusts protein's learning difficulty based on the model's estimated protein generational capabilities through a sampling process, progressively learning peptide generation from simple to complex sequences. Additionally, we introduce a self-refining inference-time module that iteratively enhances predictions using learned NAT token embeddings, improving sequence accuracy at a fine-grained level. Our curriculum learning strategy reduces NAT training failures frequency by more than 90% based on sampled training over various data distributions. Evaluations on nine benchmark species demonstrate that our approach outperforms all previous methods across multiple metrics and species.
<div id='section'>Paperid: <span id='pid'>604, <a href='https://arxiv.org/pdf/2506.04490.pdf' target='_blank'>https://arxiv.org/pdf/2506.04490.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rishwanth Raghu, Axel Levy, Gordon Wetzstein, Ellen D. Zhong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.04490">Multiscale guidance of AlphaFold3 with heterogeneous cryo-EM data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structure prediction models are now capable of generating accurate 3D structural hypotheses from sequence alone. However, they routinely fail to capture the conformational diversity of dynamic biomolecular complexes, often requiring heuristic MSA subsampling approaches for generating alternative states. In parallel, cryo-electron microscopy (cryo-EM) has emerged as a powerful tool for imaging near-native structural heterogeneity, but is challenged by arduous pipelines to go from raw experimental data to atomic models. Here, we bridge the gap between these modalities, combining cryo-EM density maps with the rich sequence and biophysical priors learned by protein structure prediction models. Our method, CryoBoltz, guides the sampling trajectory of a pretrained protein structure prediction model using both global and local structural constraints derived from density maps, driving predictions towards conformational states consistent with the experimental data. We demonstrate that this flexible yet powerful inference-time approach allows us to build atomic models into heterogeneous cryo-EM maps across a variety of dynamic biomolecular systems including transporters and antibodies.
<div id='section'>Paperid: <span id='pid'>605, <a href='https://arxiv.org/pdf/2505.15118.pdf' target='_blank'>https://arxiv.org/pdf/2505.15118.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongbo Xia, Kaiqiang Yu, Shengxin Liu, Cheng Long, Xun Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15118">Maximum Degree-Based Quasi-Clique Search via an Iterative Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cohesive subgraph mining is a fundamental problem in graph theory with numerous real-world applications, such as social network analysis and protein-protein interaction modeling. Among various cohesive subgraphs, the $Î³$-quasi-clique is widely studied for its flexibility in requiring each vertex to connect to at least a $Î³$ proportion of other vertices in the subgraph. However, solving the maximum $Î³$-quasi-clique problem is NP-hard and further complicated by the lack of the hereditary property, which makes designing efficient pruning strategies challenging. Existing algorithms, such as DDA and FastQC, either struggle with scalability or exhibit significant performance declines for small values of $Î³$. In this paper, we propose a novel algorithm, IterQC, which reformulates the maximum $Î³$-quasi-clique problem as a series of $k$-plex problems that possess the hereditary property. IterQC introduces a non-trivial iterative framework and incorporates two key optimization techniques: (1) the pseudo lower bound (pseudo LB) technique, which leverages information across iterations to improve the efficiency of branch-and-bound searches, and (2) the preprocessing technique that reduces problem size and unnecessary iterations. Extensive experiments demonstrate that IterQC achieves up to four orders of magnitude speedup and solves significantly more graph instances compared to state-of-the-art algorithms DDA and FastQC.
<div id='section'>Paperid: <span id='pid'>606, <a href='https://arxiv.org/pdf/2505.12511.pdf' target='_blank'>https://arxiv.org/pdf/2505.12511.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanting Li, Jiyue Jiang, Zikang Wang, Ziqian Lin, Dongchen He, Yuheng Shan, Yanruisheng Shao, Jiayi Li, Xiangyu Shi, Jiuming Wang, Yanyu Chen, Yimin Fan, Han Li, Yu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12511">DS-ProGen: A Dual-Structure Deep Language Model for Functional Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse Protein Folding (IPF) is a critical subtask in the field of protein design, aiming to engineer amino acid sequences capable of folding correctly into a specified three-dimensional (3D) conformation. Although substantial progress has been achieved in recent years, existing methods generally rely on either backbone coordinates or molecular surface features alone, which restricts their ability to fully capture the complex chemical and geometric constraints necessary for precise sequence prediction. To address this limitation, we present DS-ProGen, a dual-structure deep language model for functional protein design, which integrates both backbone geometry and surface-level representations. By incorporating backbone coordinates as well as surface chemical and geometric descriptors into a next-amino-acid prediction paradigm, DS-ProGen is able to generate functionally relevant and structurally stable sequences while satisfying both global and local conformational constraints. On the PRIDE dataset, DS-ProGen attains the current state-of-the-art recovery rate of 61.47%, demonstrating the synergistic advantage of multi-modal structural encoding in protein design. Furthermore, DS-ProGen excels in predicting interactions with a variety of biological partners, including ligands, ions, and RNA, confirming its robust functional retention capabilities.
<div id='section'>Paperid: <span id='pid'>607, <a href='https://arxiv.org/pdf/2505.04967.pdf' target='_blank'>https://arxiv.org/pdf/2505.04967.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Li Ni, Ziqi Deng, Lin Mu, Lei Zhang, Wenjian Luo, Yiwen Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04967">Community and hyperedge inference in multiple hypergraphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hypergraphs, capable of representing high-order interactions via hyperedges, have become a powerful tool for modeling real-world biological and social systems. Inherent relationships within these real-world systems, such as the encoding relationship between genes and their protein products, drive the establishment of interconnections between multiple hypergraphs. Here, we demonstrate how to utilize those interconnections between multiple hypergraphs to synthesize integrated information from multiple higher-order systems, thereby enhancing understanding of underlying structures. We propose a model based on the stochastic block model, which integrates information from multiple hypergraphs to reveal latent high-order structures. Real-world hyperedges exhibit preferential attachment, where certain nodes dominate hyperedge formation. To characterize this phenomenon, our model introduces hyperedge internal degree to quantify nodes' contributions to hyperedge formation. This model is capable of mining communities, predicting missing hyperedges of arbitrary sizes within hypergraphs, and inferring inter-hypergraph edges between hypergraphs. We apply our model to high-order datasets to evaluate its performance. Experimental results demonstrate strong performance of our model in community detection, hyperedge prediction, and inter-hypergraph edge prediction tasks. Moreover, we show that our model enables analysis of multiple hypergraphs of different types and supports the analysis of a single hypergraph in the absence of inter-hypergraph edges. Our work provides a practical and flexible tool for analyzing multiple hypergraphs, greatly advancing the understanding of the organization in real-world high-order systems.
<div id='section'>Paperid: <span id='pid'>608, <a href='https://arxiv.org/pdf/2504.10283.pdf' target='_blank'>https://arxiv.org/pdf/2504.10283.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaoran Cheng, Jiahan Li, Jiajun Fan, Ge Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.10283">$Î±$-Flow: A Unified Framework for Continuous-State Discrete Flow Matching Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent efforts have extended the flow-matching framework to discrete generative modeling. One strand of models directly works with the continuous probabilities instead of discrete tokens, which we colloquially refer to as Continuous-State Discrete Flow Matching (CS-DFM). Existing CS-DFM models differ significantly in their representations and geometric assumptions. This work presents a unified framework for CS-DFM models, under which the existing variants can be understood as operating on different $Î±$-representations of probabilities. Building upon the theory of information geometry, we introduce $Î±$-Flow, a family of CS-DFM models that adheres to the canonical $Î±$-geometry of the statistical manifold, and demonstrate its optimality in minimizing the generalized kinetic energy. Theoretically, we show that the flow matching loss for $Î±$-flow establishes a unified variational bound for the discrete negative log-likelihood. We comprehensively evaluate different instantiations of $Î±$-flow on various discrete generation domains to demonstrate their effectiveness in discrete generative modeling, including intermediate values whose geometries have never been explored before. $Î±$-flow significantly outperforms its discrete-state counterpart in image and protein sequence generation and better captures the entropy in language modeling.
<div id='section'>Paperid: <span id='pid'>609, <a href='https://arxiv.org/pdf/2503.08179.pdf' target='_blank'>https://arxiv.org/pdf/2503.08179.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zicheng Ma, Chuanliu Fan, Zhicong Wang, Zhenyu Chen, Xiaohan Lin, Yanheng Li, Shihao Feng, Jun Zhang, Ziqiang Cao, Yi Qin Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08179">ProtTeX: Structure-In-Context Reasoning and Editing of Proteins with Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models have made remarkable progress in the field of molecular science, particularly in understanding and generating functional small molecules. This success is largely attributed to the effectiveness of molecular tokenization strategies. In protein science, the amino acid sequence serves as the sole tokenizer for LLMs. However, many fundamental challenges in protein science are inherently structure-dependent. The absence of structure-aware tokens significantly limits the capabilities of LLMs for comprehensive biomolecular comprehension and multimodal generation. To address these challenges, we introduce a novel framework, ProtTeX, which tokenizes the protein sequences, structures, and textual information into a unified discrete space. This innovative approach enables joint training of the LLM exclusively through the Next-Token Prediction paradigm, facilitating multimodal protein reasoning and generation. ProtTeX enables general LLMs to perceive and process protein structures through sequential text input, leverage structural information as intermediate reasoning components, and generate or manipulate structures via sequential text output. Experiments demonstrate that our model achieves significant improvements in protein function prediction, outperforming the state-of-the-art domain expert model with a twofold increase in accuracy. Our framework enables high-quality conformational generation and customizable protein design. For the first time, we demonstrate that by adopting the standard training and inference pipelines from the LLM domain, ProtTeX empowers decoder-only LLMs to effectively address diverse spectrum of protein-related tasks.
<div id='section'>Paperid: <span id='pid'>610, <a href='https://arxiv.org/pdf/2503.04490.pdf' target='_blank'>https://arxiv.org/pdf/2503.04490.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenyu Wang, Zikang Wang, Jiyue Jiang, Pengan Chen, Xiangyu Shi, Yu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04490">Large Language Models in Bioinformatics: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are revolutionizing bioinformatics, enabling advanced analysis of DNA, RNA, proteins, and single-cell data. This survey provides a systematic review of recent advancements, focusing on genomic sequence modeling, RNA structure prediction, protein function inference, and single-cell transcriptomics. Meanwhile, we also discuss several key challenges, including data scarcity, computational complexity, and cross-omics integration, and explore future directions such as multimodal learning, hybrid AI models, and clinical applications. By offering a comprehensive perspective, this paper underscores the transformative potential of LLMs in driving innovations in bioinformatics and precision medicine.
<div id='section'>Paperid: <span id='pid'>611, <a href='https://arxiv.org/pdf/2503.04135.pdf' target='_blank'>https://arxiv.org/pdf/2503.04135.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiyue Jiang, Zikang Wang, Yuheng Shan, Heyan Chai, Jiayi Li, Zixian Ma, Xinrui Zhang, Yu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04135">Biological Sequence with Language Model Prompting: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language models (LLMs) have emerged as powerful tools for addressing challenges across diverse domains. Notably, recent studies have demonstrated that large language models significantly enhance the efficiency of biomolecular analysis and synthesis, attracting widespread attention from academics and medicine. In this paper, we systematically investigate the application of prompt-based methods with LLMs to biological sequences, including DNA, RNA, proteins, and drug discovery tasks. Specifically, we focus on how prompt engineering enables LLMs to tackle domain-specific problems, such as promoter sequence prediction, protein structure modeling, and drug-target binding affinity prediction, often with limited labeled data. Furthermore, our discussion highlights the transformative potential of prompting in bioinformatics while addressing key challenges such as data scarcity, multimodal fusion, and computational resource limitations. Our aim is for this paper to function both as a foundational primer for newcomers and a catalyst for continued innovation within this dynamic field of study.
<div id='section'>Paperid: <span id='pid'>612, <a href='https://arxiv.org/pdf/2501.15007.pdf' target='_blank'>https://arxiv.org/pdf/2501.15007.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangyu Liu, Yi Liu, Silei Chen, Wei Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15007">Controllable Protein Sequence Generation with LLM Preference Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing proteins with specific attributes offers an important solution to address biomedical challenges. Pre-trained protein large language models (LLMs) have shown promising results on protein sequence generation. However, to control sequence generation for specific attributes, existing work still exhibits poor functionality and structural stability. In this paper, we propose a novel controllable protein design method called CtrlProt. We finetune a protein LLM with a new multi-listwise preference optimization strategy to improve generation quality and support multi-attribute controllable generation. Experiments demonstrate that CtrlProt can meet functionality and structural stability requirements effectively, achieving state-of-the-art performance in both single-attribute and multi-attribute protein sequence generation.
<div id='section'>Paperid: <span id='pid'>613, <a href='https://arxiv.org/pdf/2412.21154.pdf' target='_blank'>https://arxiv.org/pdf/2412.21154.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddharth Narayanan, James D. Braza, Ryan-Rhys Griffiths, Manu Ponnapati, Albert Bou, Jon Laurent, Ori Kabeli, Geemi Wellawatte, Sam Cox, Samuel G. Rodriques, Andrew D. White
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.21154">Aviary: training language agents on challenging scientific tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving complex real-world tasks requires cycles of actions and observations. This is particularly true in science, where tasks require many cycles of analysis, tool use, and experimentation. Language agents are promising for automating intellectual tasks in science because they can interact with tools via natural language or code. Yet their flexibility creates conceptual and practical challenges for software implementations, since agents may comprise non-standard components such as internal reasoning, planning, tool usage, as well as the inherent stochasticity of temperature-sampled language models. Here, we introduce Aviary, an extensible gymnasium for language agents. We formalize agents as policies solving language-grounded partially observable Markov decision processes, which we term language decision processes. We then implement five environments, including three challenging scientific environments: (1) manipulating DNA constructs for molecular cloning, (2) answering research questions by accessing scientific literature, and (3) engineering protein stability. These environments were selected for their focus on multi-step reasoning and their relevance to contemporary biology research. Finally, with online training and scaling inference-time compute, we show that language agents backed by open-source, non-frontier LLMs can match and exceed both frontier LLM agents and human experts on multiple tasks at up to 100x lower inference cost.
<div id='section'>Paperid: <span id='pid'>614, <a href='https://arxiv.org/pdf/2412.15086.pdf' target='_blank'>https://arxiv.org/pdf/2412.15086.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoran Liu, Youzhi Luo, Tianxiao Li, James Caverlee, Martin Renqiang Min
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15086">Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the conditional generation of 3D drug-like molecules with \textit{explicit control} over molecular properties such as drug-like properties (e.g., Quantitative Estimate of Druglikeness or Synthetic Accessibility score) and effectively binding to specific protein sites. To tackle this problem, we propose an E(3)-equivariant Wasserstein autoencoder and factorize the latent space of our generative model into two disentangled aspects: molecular properties and the remaining structural context of 3D molecules. Our model ensures explicit control over these molecular attributes while maintaining equivariance of coordinate representation and invariance of data likelihood. Furthermore, we introduce a novel alignment-based coordinate loss to adapt equivariant networks for auto-regressive de-novo 3D molecule generation from scratch. Extensive experiments validate our model's effectiveness on property-guided and context-guided molecule generation, both for de-novo 3D molecule design and structure-based drug discovery against protein targets.
<div id='section'>Paperid: <span id='pid'>615, <a href='https://arxiv.org/pdf/2412.09420.pdf' target='_blank'>https://arxiv.org/pdf/2412.09420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Axel Levy, Rishwanth Raghu, David Shustin, Adele Rui-Yang Peng, Huan Li, Oliver Biggs Clarke, Gordon Wetzstein, Ellen D. Zhong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09420">Mixture of neural fields for heterogeneous reconstruction in cryo-EM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryo-electron microscopy (cryo-EM) is an experimental technique for protein structure determination that images an ensemble of macromolecules in near-physiological contexts. While recent advances enable the reconstruction of dynamic conformations of a single biomolecular complex, current methods do not adequately model samples with mixed conformational and compositional heterogeneity. In particular, datasets containing mixtures of multiple proteins require the joint inference of structure, pose, compositional class, and conformational states for 3D reconstruction. Here, we present Hydra, an approach that models both conformational and compositional heterogeneity fully ab initio by parameterizing structures as arising from one of K neural fields. We employ a new likelihood-based loss function and demonstrate the effectiveness of our approach on synthetic datasets composed of mixtures of proteins with large degrees of conformational variability. We additionally demonstrate Hydra on an experimental dataset of a cellular lysate containing a mixture of different protein complexes. Hydra expands the expressivity of heterogeneous reconstruction methods and thus broadens the scope of cryo-EM to increasingly complex samples.
<div id='section'>Paperid: <span id='pid'>616, <a href='https://arxiv.org/pdf/2412.03791.pdf' target='_blank'>https://arxiv.org/pdf/2412.03791.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuyang Wang, Anurag Ranjan, Josh Susskind, Miguel Angel Bautista
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03791">INRFlow: Flow Matching for INRs in Ambient Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Flow matching models have emerged as a powerful method for generative modeling on domains like images or videos, and even on irregular or unstructured data like 3D point clouds or even protein structures. These models are commonly trained in two stages: first, a data compressor is trained, and in a subsequent training stage a flow matching generative model is trained in the latent space of the data compressor. This two-stage paradigm sets obstacles for unifying models across data domains, as hand-crafted compressors architectures are used for different data modalities. To this end, we introduce INRFlow, a domain-agnostic approach to learn flow matching transformers directly in ambient space. Drawing inspiration from INRs, we introduce a conditionally independent point-wise training objective that enables INRFlow to make predictions continuously in coordinate space. Our empirical results demonstrate that INRFlow effectively handles different data modalities such as images, 3D point clouds and protein structure data, achieving strong performance in different domains and outperforming comparable approaches. INRFlow is a promising step towards domain-agnostic flow matching generative models that can be trivially adopted in different data domains.
<div id='section'>Paperid: <span id='pid'>617, <a href='https://arxiv.org/pdf/2410.18070.pdf' target='_blank'>https://arxiv.org/pdf/2410.18070.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luran Wang, Chaoran Cheng, Yizhen Liao, Yanru Qu, Ge Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.18070">Training Free Guided Flow Matching with Optimal Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Controlled generation with pre-trained Diffusion and Flow Matching models has vast applications. One strategy for guiding ODE-based generative models is through optimizing a target loss $R(x_1)$ while staying close to the prior distribution. Along this line, some recent work showed the effectiveness of guiding flow model by differentiating through its ODE sampling process. Despite the superior performance, the theoretical understanding of this line of methods is still preliminary, leaving space for algorithm improvement. Moreover, existing methods predominately focus on Euclidean data manifold, and there is a compelling need for guided flow methods on complex geometries such as SO(3), which prevails in high-stake scientific applications like protein design. We present OC-Flow, a general and theoretically grounded training-free framework for guided flow matching using optimal control. Building upon advances in optimal control theory, we develop effective and practical algorithms for solving optimal control in guided ODE-based generation and provide a systematic theoretical analysis of the convergence guarantee in both Euclidean and SO(3). We show that existing backprop-through-ODE methods can be interpreted as special cases of Euclidean OC-Flow. OC-Flow achieved superior performance in extensive experiments on text-guided image manipulation, conditional molecule generation, and all-atom peptide design.
<div id='section'>Paperid: <span id='pid'>618, <a href='https://arxiv.org/pdf/2408.16978.pdf' target='_blank'>https://arxiv.org/pdf/2408.16978.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinghan Yao, Sam Ade Jacobs, Masahiro Tanaka, Olatunji Ruwase, Hari Subramoni, Dhabaleswar K. Panda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16978">Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) with long context capabilities are integral to complex tasks in natural language processing and computational biology, such as text generation and protein sequence analysis. However, training LLMs directly on extremely long contexts demands considerable GPU resources and increased memory, leading to higher costs and greater complexity. Alternative approaches that introduce long context capabilities via downstream finetuning or adaptations impose significant design limitations. In this paper, we propose Fully Pipelined Distributed Transformer (FPDT) for efficiently training long-context LLMs with extreme hardware efficiency. For GPT and Llama models, we achieve a 16x increase in sequence length that can be trained on the same hardware compared to current state-of-the-art solutions. With our dedicated sequence chunk pipeline design, we can now train 8B LLM with 2 million sequence length on only 4 GPUs, while also maintaining over 55% of MFU. Our proposed FPDT is agnostic to existing training techniques and is proven to work efficiently across different LLM models.
<div id='section'>Paperid: <span id='pid'>619, <a href='https://arxiv.org/pdf/2407.13981.pdf' target='_blank'>https://arxiv.org/pdf/2407.13981.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiwei Cheng, Xiangxin Zhou, Yuwei Yang, Yu Bao, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13981">Decomposed Direct Preference Optimization for Structure-Based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have achieved promising results for Structure-Based Drug Design (SBDD). Nevertheless, high-quality protein subpocket and ligand data are relatively scarce, which hinders the models' generation capabilities. Recently, Direct Preference Optimization (DPO) has emerged as a pivotal tool for aligning generative models with human preferences. In this paper, we propose DecompDPO, a structure-based optimization method aligns diffusion models with pharmaceutical needs using multi-granularity preference pairs. DecompDPO introduces decomposition into the optimization objectives and obtains preference pairs at the molecule or decomposed substructure level based on each objective's decomposability. Additionally, DecompDPO introduces a physics-informed energy term to ensure reasonable molecular conformations in the optimization results. Notably, DecompDPO can be effectively used for two main purposes: (1) fine-tuning pretrained diffusion models for molecule generation across various protein families, and (2) molecular optimization given a specific protein subpocket after generation. Extensive experiments on the CrossDocked2020 benchmark show that DecompDPO significantly improves model performance, achieving up to 95.2% Med. High Affinity and a 36.2% success rate for molecule generation, and 100% Med. High Affinity and a 52.1% success rate for molecular optimization.
<div id='section'>Paperid: <span id='pid'>620, <a href='https://arxiv.org/pdf/2407.11548.pdf' target='_blank'>https://arxiv.org/pdf/2407.11548.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxuan Wu, Xiao Yi, Yang Tan, Huiqun Yu, Guisheng Fan, Gaowei Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11548">A PLMs based protein retrieval framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein retrieval, which targets the deconstruction of the relationship between sequences, structures and functions, empowers the advancing of biology. Basic Local Alignment Search Tool (BLAST), a sequence-similarity-based algorithm, has proved the efficiency of this field. Despite the existing tools for protein retrieval, they prioritize sequence similarity and probably overlook proteins that are dissimilar but share homology or functionality. In order to tackle this problem, we propose a novel protein retrieval framework that mitigates the bias towards sequence similarity. Our framework initiatively harnesses protein language models (PLMs) to embed protein sequences within a high-dimensional feature space, thereby enhancing the representation capacity for subsequent analysis. Subsequently, an accelerated indexed vector database is constructed to facilitate expedited access and retrieval of dense vectors. Extensive experiments demonstrate that our framework can equally retrieve both similar and dissimilar proteins. Moreover, this approach enables the identification of proteins that conventional methods fail to uncover. This framework will effectively assist in protein mining and empower the development of biology.
<div id='section'>Paperid: <span id='pid'>621, <a href='https://arxiv.org/pdf/2407.10362.pdf' target='_blank'>https://arxiv.org/pdf/2407.10362.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jon M. Laurent, Joseph D. Janizek, Michael Ruzo, Michaela M. Hinks, Michael J. Hammerling, Siddharth Narayanan, Manvitha Ponnapati, Andrew D. White, Samuel G. Rodriques
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.10362">LAB-Bench: Measuring Capabilities of Language Models for Biology Research</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There is widespread optimism that frontier Large Language Models (LLMs) and LLM-augmented systems have the potential to rapidly accelerate scientific discovery across disciplines. Today, many benchmarks exist to measure LLM knowledge and reasoning on textbook-style science questions, but few if any benchmarks are designed to evaluate language model performance on practical tasks required for scientific research, such as literature search, protocol planning, and data analysis. As a step toward building such benchmarks, we introduce the Language Agent Biology Benchmark (LAB-Bench), a broad dataset of over 2,400 multiple choice questions for evaluating AI systems on a range of practical biology research capabilities, including recall and reasoning over literature, interpretation of figures, access and navigation of databases, and comprehension and manipulation of DNA and protein sequences. Importantly, in contrast to previous scientific benchmarks, we expect that an AI system that can achieve consistently high scores on the more difficult LAB-Bench tasks would serve as a useful assistant for researchers in areas such as literature search and molecular cloning. As an initial assessment of the emergent scientific task capabilities of frontier language models, we measure performance of several against our benchmark and report results compared to human expert biology researchers. We will continue to update and expand LAB-Bench over time, and expect it to serve as a useful tool in the development of automated research systems going forward. A public subset of LAB-Bench is available for use at the following URL: https://huggingface.co/datasets/futurehouse/lab-bench
<div id='section'>Paperid: <span id='pid'>622, <a href='https://arxiv.org/pdf/2406.18330.pdf' target='_blank'>https://arxiv.org/pdf/2406.18330.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matan Halfon, Eyal Rozenberg, Ehud Rivlin, Daniel Freedman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.18330">Molecular Diffusion Models with Virtual Receptors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning approaches to Structure-Based Drug Design (SBDD) have proven quite fertile over the last few years. In particular, diffusion-based approaches to SBDD have shown great promise. We present a technique which expands on this diffusion approach in two crucial ways. First, we address the size disparity between the drug molecule and the target/receptor, which makes learning more challenging and inference slower. We do so through the notion of a Virtual Receptor, which is a compressed version of the receptor; it is learned so as to preserve key aspects of the structural information of the original receptor, while respecting the relevant group equivariance. Second, we incorporate a protein language embedding used originally in the context of protein folding. We experimentally demonstrate the contributions of both the virtual receptors and the protein embeddings: in practice, they lead to both better performance, as well as significantly faster computations.
<div id='section'>Paperid: <span id='pid'>623, <a href='https://arxiv.org/pdf/2406.05347.pdf' target='_blank'>https://arxiv.org/pdf/2406.05347.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Chen, Zhilei Bei, Xingyi Cheng, Pan Li, Jie Tang, Le Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.05347">MSAGPT: Neural Prompting Protein Structure Prediction via MSA Generative Pre-Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiple Sequence Alignment (MSA) plays a pivotal role in unveiling the evolutionary trajectories of protein families. The accuracy of protein structure predictions is often compromised for protein sequences that lack sufficient homologous information to construct high quality MSA. Although various methods have been proposed to generate virtual MSA under these conditions, they fall short in comprehensively capturing the intricate coevolutionary patterns within MSA or require guidance from external oracle models. Here we introduce MSAGPT, a novel approach to prompt protein structure predictions via MSA generative pretraining in the low MSA regime. MSAGPT employs a simple yet effective 2D evolutionary positional encoding scheme to model complex evolutionary patterns. Endowed by this, its flexible 1D MSA decoding framework facilitates zero or few shot learning. Moreover, we demonstrate that leveraging the feedback from AlphaFold2 can further enhance the model capacity via Rejective Fine tuning (RFT) and Reinforcement Learning from AF2 Feedback (RLAF). Extensive experiments confirm the efficacy of MSAGPT in generating faithful virtual MSA to enhance the structure prediction accuracy. The transfer learning capabilities also highlight its great potential for facilitating other protein tasks.
<div id='section'>Paperid: <span id='pid'>624, <a href='https://arxiv.org/pdf/2406.04239.pdf' target='_blank'>https://arxiv.org/pdf/2406.04239.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Axel Levy, Eric R. Chan, Sara Fridovich-Keil, FrÃ©dÃ©ric Poitevin, Ellen D. Zhong, Gordon Wetzstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04239">Solving Inverse Problems in Protein Space Using Diffusion-Based Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The interaction of a protein with its environment can be understood and controlled via its 3D structure. Experimental methods for protein structure determination, such as X-ray crystallography or cryogenic electron microscopy, shed light on biological processes but introduce challenging inverse problems. Learning-based approaches have emerged as accurate and efficient methods to solve these inverse problems for 3D structure determination, but are specialized for a predefined type of measurement. Here, we introduce a versatile framework to turn biophysical measurements, such as cryo-EM density maps, into 3D atomic models. Our method combines a physics-based forward model of the measurement process with a pretrained generative model providing a task-agnostic, data-driven prior. Our method outperforms posterior sampling baselines on linear and non-linear inverse problems. In particular, it is the first diffusion-based method for refining atomic models from cryo-EM maps and building atomic models from sparse distance matrices.
<div id='section'>Paperid: <span id='pid'>625, <a href='https://arxiv.org/pdf/2406.04052.pdf' target='_blank'>https://arxiv.org/pdf/2406.04052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cong Liu, David Ruhe, Patrick ForrÃ©
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04052">Multivector Neurons: Better and Faster O(n)-Equivariant Clifford Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most current deep learning models equivariant to $O(n)$ or $SO(n)$ either consider mostly scalar information such as distances and angles or have a very high computational complexity. In this work, we test a few novel message passing graph neural networks (GNNs) based on Clifford multivectors, structured similarly to other prevalent equivariant models in geometric deep learning. Our approach leverages efficient invariant scalar features while simultaneously performing expressive learning on multivector representations, particularly through the use of the equivariant geometric product operator. By integrating these elements, our methods outperform established efficient baseline models on an N-Body simulation task and protein denoising task while maintaining a high efficiency. In particular, we push the state-of-the-art error on the N-body dataset to 0.0035 (averaged over 3 runs); an 8% improvement over recent methods. Our implementation is available on Github.
<div id='section'>Paperid: <span id='pid'>626, <a href='https://arxiv.org/pdf/2405.17902.pdf' target='_blank'>https://arxiv.org/pdf/2405.17902.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaoyao Xu, Xinjian Zhao, Xiaozhuang Song, Benyou Wang, Tianshu Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17902">Boosting Protein Language Models with Negative Sample Mining</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a pioneering methodology for boosting large language models in the domain of protein representation learning. Our primary contribution lies in the refinement process for correlating the over-reliance on co-evolution knowledge, in a way that networks are trained to distill invaluable insights from negative samples, constituted by protein pairs sourced from disparate categories. By capitalizing on this novel approach, our technique steers the training of transformer-based models within the attention score space. This advanced strategy not only amplifies performance but also reflects the nuanced biological behaviors exhibited by proteins, offering aligned evidence with traditional biological mechanisms such as protein-protein interaction. We experimentally observed improved performance on various tasks over datasets, on top of several well-established large protein models. This innovative paradigm opens up promising horizons for further progress in the realms of protein research and computational biology.
<div id='section'>Paperid: <span id='pid'>627, <a href='https://arxiv.org/pdf/2404.00551.pdf' target='_blank'>https://arxiv.org/pdf/2404.00551.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuan Gao, Jian Huang, Yuling Jiao, Shurong Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00551">Convergence of Continuous Normalizing Flows for Learning Probability Distributions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continuous normalizing flows (CNFs) are a generative method for learning probability distributions, which is based on ordinary differential equations. This method has shown remarkable empirical success across various applications, including large-scale image synthesis, protein structure prediction, and molecule generation. In this work, we study the theoretical properties of CNFs with linear interpolation in learning probability distributions from a finite random sample, using a flow matching objective function. We establish non-asymptotic error bounds for the distribution estimator based on CNFs, in terms of the Wasserstein-2 distance. The key assumption in our analysis is that the target distribution satisfies one of the following three conditions: it either has a bounded support, is strongly log-concave, or is a finite or infinite mixture of Gaussian distributions. We present a convergence analysis framework that encompasses the error due to velocity estimation, the discretization error, and the early stopping error. A key step in our analysis involves establishing the regularity properties of the velocity field and its estimator for CNFs constructed with linear interpolation. This necessitates the development of uniform error bounds with Lipschitz regularity control of deep ReLU networks that approximate the Lipschitz function class, which could be of independent interest. Our nonparametric convergence analysis offers theoretical guarantees for using CNFs to learn probability distributions from a finite random sample.
<div id='section'>Paperid: <span id='pid'>628, <a href='https://arxiv.org/pdf/2403.06890.pdf' target='_blank'>https://arxiv.org/pdf/2403.06890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Debarshi Kundu, Archisman Ghosh, Srinivasan Ekambaram, Jian Wang, Nikolay Dokholyan, Swaroop Ghosh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.06890">Application of Quantum Tensor Networks for Protein Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We show that protein sequences can be thought of as sentences in natural language processing and can be parsed using the existing Quantum Natural Language framework into parameterized quantum circuits of reasonable qubits, which can be trained to solve various protein-related machine-learning problems. We classify proteins based on their subcellular locations, a pivotal task in bioinformatics that is key to understanding biological processes and disease mechanisms. Leveraging the quantum-enhanced processing capabilities, we demonstrate that Quantum Tensor Networks (QTN) can effectively handle the complexity and diversity of protein sequences. We present a detailed methodology that adapts QTN architectures to the nuanced requirements of protein data, supported by comprehensive experimental results. We demonstrate two distinct QTNs, inspired by classical recurrent neural networks (RNN) and convolutional neural networks (CNN), to solve the binary classification task mentioned above. Our top-performing quantum model has achieved a 94% accuracy rate, which is comparable to the performance of a classical model that uses the ESM2 protein language model embeddings. It's noteworthy that the ESM2 model is extremely large, containing 8 million parameters in its smallest configuration, whereas our best quantum model requires only around 800 parameters. We demonstrate that these hybrid models exhibit promising performance, showcasing their potential to compete with classical models of similar complexity.
<div id='section'>Paperid: <span id='pid'>629, <a href='https://arxiv.org/pdf/2402.13297.pdf' target='_blank'>https://arxiv.org/pdf/2402.13297.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhanglu Yan, Weiran Chu, Yuhua Sheng, Kaiwen Tang, Shida Wang, Yanfeng Liu, Weng-Fai Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.13297">Integrating Deep Learning and Synthetic Biology: A Co-Design Approach for Enhancing Gene Expression via N-terminal Coding Sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>N-terminal coding sequence (NCS) influences gene expression by impacting the translation initiation rate. The NCS optimization problem is to find an NCS that maximizes gene expression. The problem is important in genetic engineering. However, current methods for NCS optimization such as rational design and statistics-guided approaches are labor-intensive yield only relatively small improvements. This paper introduces a deep learning/synthetic biology co-designed few-shot training workflow for NCS optimization. Our method utilizes k-nearest encoding followed by word2vec to encode the NCS, then performs feature extraction using attention mechanisms, before constructing a time-series network for predicting gene expression intensity, and finally a direct search algorithm identifies the optimal NCS with limited training data. We took green fluorescent protein (GFP) expressed by Bacillus subtilis as a reporting protein of NCSs, and employed the fluorescence enhancement factor as the metric of NCS optimization. Within just six iterative experiments, our model generated an NCS (MLD62) that increased average GFP expression by 5.41-fold, outperforming the state-of-the-art NCS designs. Extending our findings beyond GFP, we showed that our engineered NCS (MLD62) can effectively boost the production of N-acetylneuraminic acid by enhancing the expression of the crucial rate-limiting GNA1 gene, demonstrating its practical utility. We have open-sourced our NCS expression database and experimental procedures for public use.
<div id='section'>Paperid: <span id='pid'>630, <a href='https://arxiv.org/pdf/2402.11729.pdf' target='_blank'>https://arxiv.org/pdf/2402.11729.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gautam Machiraju, Alexander Derry, Arjun Desai, Neel Guha, Amir-Hossein Karimi, James Zou, Russ Altman, Christopher RÃ©, Parag Mallick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11729">Prospector Heads: Generalized Feature Attribution for Large Models & Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Feature attribution, the ability to localize regions of the input data that are relevant for classification, is an important capability for ML models in scientific and biomedical domains. Current methods for feature attribution, which rely on "explaining" the predictions of end-to-end classifiers, suffer from imprecise feature localization and are inadequate for use with small sample sizes and high-dimensional datasets due to computational challenges. We introduce prospector heads, an efficient and interpretable alternative to explanation-based attribution methods that can be applied to any encoder and any data modality. Prospector heads generalize across modalities through experiments on sequences (text), images (pathology), and graphs (protein structures), outperforming baseline attribution methods by up to 26.3 points in mean localization AUPRC. We also demonstrate how prospector heads enable improved interpretation and discovery of class-specific patterns in input data. Through their high performance, flexibility, and generalizability, prospectors provide a framework for improving trust and transparency for ML models in complex domains.
<div id='section'>Paperid: <span id='pid'>631, <a href='https://arxiv.org/pdf/2402.04384.pdf' target='_blank'>https://arxiv.org/pdf/2402.04384.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Richard E. Turner, Cristiana-Diana Diaconu, Stratis Markou, Aliaksandra Shysheya, Andrew Y. K. Foong, Bruno Mlodozeniec
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.04384">Denoising Diffusion Probabilistic Models in Six Simple Steps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Denoising Diffusion Probabilistic Models (DDPMs) are a very popular class of deep generative model that have been successfully applied to a diverse range of problems including image and video generation, protein and material synthesis, weather forecasting, and neural surrogates of partial differential equations. Despite their ubiquity it is hard to find an introduction to DDPMs which is simple, comprehensive, clean and clear. The compact explanations necessary in research papers are not able to elucidate all of the different design steps taken to formulate the DDPM and the rationale of the steps that are presented is often omitted to save space. Moreover, the expositions are typically presented from the variational lower bound perspective which is unnecessary and arguably harmful as it obfuscates why the method is working and suggests generalisations that do not perform well in practice. On the other hand, perspectives that take the continuous time-limit are beautiful and general, but they have a high barrier-to-entry as they require background knowledge of stochastic differential equations and probability flow. In this note, we distill down the formulation of the DDPM into six simple steps each of which comes with a clear rationale. We assume that the reader is familiar with fundamental topics in machine learning including basic probabilistic modelling, Gaussian distributions, maximum likelihood estimation, and deep learning.
<div id='section'>Paperid: <span id='pid'>632, <a href='https://arxiv.org/pdf/2401.15122.pdf' target='_blank'>https://arxiv.org/pdf/2401.15122.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengchao Liu, Weitao Du, Hannan Xu, Yanjing Li, Zhuoxinran Li, Vignesh Bhethanabotla, Divin Yan, Christian Borgs, Anima Anandkumar, Hongyu Guo, Jennifer Chayes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.15122">A Multi-Grained Symmetric Differential Equation Model for Learning Protein-Ligand Binding Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In drug discovery, molecular dynamics (MD) simulation for protein-ligand binding provides a powerful tool for predicting binding affinities, estimating transport properties, and exploring pocket sites. There has been a long history of improving the efficiency of MD simulations through better numerical methods and, more recently, by utilizing machine learning (ML) methods. Yet, challenges remain, such as accurate modeling of extended-timescale simulations. To address this issue, we propose NeuralMD, the first ML surrogate that can facilitate numerical MD and provide accurate simulations in protein-ligand binding dynamics. We propose a principled approach that incorporates a novel physics-informed multi-grained group symmetric framework. Specifically, we propose (1) the BindingNet model that satisfies group symmetry using vector frames and captures the multi-level protein-ligand interactions, and (2) an augmented neural differential equation solver that learns the trajectory under Newtonian mechanics. For the experiment, we design ten single-trajectory and three multi-trajectory binding simulation tasks. We demonstrate the efficiency and effectiveness of NeuralMD, achieving over 1K$\times$ speedup compared to standard numerical MD simulations. NeuralMD also outperforms all other ML approaches, achieving up to 15$\times$ reduction in reconstruction error and 70% increase in validity. Additionally, we qualitatively illustrate that the oscillations in the predicted trajectories align more closely with ground-truth dynamics than those of other machine-learning methods. We believe NeuralMD paves the foundation for a new research paradigm in simulating protein-ligand dynamics.
<div id='section'>Paperid: <span id='pid'>633, <a href='https://arxiv.org/pdf/2401.02882.pdf' target='_blank'>https://arxiv.org/pdf/2401.02882.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jai Prakash Veerla, Partha Sai Guttikonda, Amir Hajighasemi, Jillur Rahman Saurav, Aarti Darji, Cody T. Reynolds, Mohamed Mohamed, Mohammad S. Nasr, Helen H. Shang, Jacob M. Luber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02882">SpatialVisVR: An Immersive, Multiplexed Medical Image Viewer With Contextual Similar-Patient Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In contemporary pathology, multiplexed immunofluorescence (mIF) and multiplex immunohistochemistry (mIHC) present both significant opportunities and challenges. These methodologies shed light on intricate tumor microenvironment interactions, emphasizing the need for intuitive visualization tools to analyze vast biological datasets effectively. As electronic health records (EHR) proliferate and physicians face increasing information overload, the integration of advanced technologies becomes imperative. SpatialVisVR emerges as a versatile VR platform tailored for comparing medical images, with adaptability for data privacy on embedded hardware. Clinicians can capture pathology slides in real-time via mobile devices, leveraging SpatialVisVR's deep learning algorithm to match and display similar mIF images. This interface supports the manipulation of up to 100 multiplexed protein channels, thereby assisting in immuno-oncology decision-making. Ultimately, SpatialVisVR aims to streamline diagnostic processes, advocating for a comprehensive and efficient approach to immuno-oncology research and treatment.
<div id='section'>Paperid: <span id='pid'>634, <a href='https://arxiv.org/pdf/2312.07511.pdf' target='_blank'>https://arxiv.org/pdf/2312.07511.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexandre Duval, Simon V. Mathis, Chaitanya K. Joshi, Victor Schmidt, Santiago Miret, Fragkiskos D. Malliaros, Taco Cohen, Pietro LiÃ², Yoshua Bengio, Michael Bronstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.07511">A Hitchhiker's Guide to Geometric GNNs for 3D Atomic Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in computational modelling of atomic systems, spanning molecules, proteins, and materials, represent them as geometric graphs with atoms embedded as nodes in 3D Euclidean space. In these graphs, the geometric attributes transform according to the inherent physical symmetries of 3D atomic systems, including rotations and translations in Euclidean space, as well as node permutations. In recent years, Geometric Graph Neural Networks have emerged as the preferred machine learning architecture powering applications ranging from protein structure prediction to molecular simulations and material generation. Their specificity lies in the inductive biases they leverage - such as physical symmetries and chemical properties - to learn informative representations of these geometric graphs.
  In this opinionated paper, we provide a comprehensive and self-contained overview of the field of Geometric GNNs for 3D atomic systems. We cover fundamental background material and introduce a pedagogical taxonomy of Geometric GNN architectures: (1) invariant networks, (2) equivariant networks in Cartesian basis, (3) equivariant networks in spherical basis, and (4) unconstrained networks. Additionally, we outline key datasets and application areas and suggest future research directions. The objective of this work is to present a structured perspective on the field, making it accessible to newcomers and aiding practitioners in gaining an intuition for its mathematical abstractions.
<div id='section'>Paperid: <span id='pid'>635, <a href='https://arxiv.org/pdf/2312.00189.pdf' target='_blank'>https://arxiv.org/pdf/2312.00189.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Farhan Tanvir, Khaled Mohammed Saifuddin, Tanvir Hossain, Arunkumar Bagavathi, Esra Akbas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00189">HeTriNet: Heterogeneous Graph Triplet Attention Network for Drug-Target-Disease Interaction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling the interactions between drugs, targets, and diseases is paramount in drug discovery and has significant implications for precision medicine and personalized treatments. Current approaches frequently consider drug-target or drug-disease interactions individually, ignoring the interdependencies among all three entities. Within human metabolic systems, drugs interact with protein targets in cells, influencing target activities and subsequently impacting biological pathways to promote healthy functions and treat diseases. Moving beyond binary relationships and exploring tighter triple relationships is essential to understanding drugs' mechanism of action (MoAs). Moreover, identifying the heterogeneity of drugs, targets, and diseases, along with their distinct characteristics, is critical to model these complex interactions appropriately. To address these challenges, we effectively model the interconnectedness of all entities in a heterogeneous graph and develop a novel Heterogeneous Graph Triplet Attention Network (\texttt{HeTriNet}). \texttt{HeTriNet} introduces a novel triplet attention mechanism within this heterogeneous graph structure. Beyond pairwise attention as the importance of an entity for the other one, we define triplet attention to model the importance of pairs for entities in the drug-target-disease triplet prediction problem. Experimental results on real-world datasets show that \texttt{HeTriNet} outperforms several baselines, demonstrating its remarkable proficiency in uncovering novel drug-target-disease relationships.
<div id='section'>Paperid: <span id='pid'>636, <a href='https://arxiv.org/pdf/2311.02326.pdf' target='_blank'>https://arxiv.org/pdf/2311.02326.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Khodabandeh Yalabadi, Mehdi Yazdani-Jahromi, Niloofar Yousefi, Aida Tayebi, Sina Abdidizaji, Ozlem Ozmen Garibay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.02326">FragXsiteDTI: Revealing Responsible Segments in Drug-Target Interaction with Transformer-Driven Interpretation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drug-Target Interaction (DTI) prediction is vital for drug discovery, yet challenges persist in achieving model interpretability and optimizing performance. We propose a novel transformer-based model, FragXsiteDTI, that aims to address these challenges in DTI prediction. Notably, FragXsiteDTI is the first DTI model to simultaneously leverage drug molecule fragments and protein pockets. Our information-rich representations for both proteins and drugs offer a detailed perspective on their interaction. Inspired by the Perceiver IO framework, our model features a learnable latent array, initially interacting with protein binding site embeddings using cross-attention and later refined through self-attention and used as a query to the drug fragments in the drug's cross-attention transformer block. This learnable query array serves as a mediator and enables seamless information translation, preserving critical nuances in drug-protein interactions. Our computational results on three benchmarking datasets demonstrate the superior predictive power of our model over several state-of-the-art models. We also show the interpretability of our model in terms of the critical components of both target proteins and drug molecules within drug-target pairs.
<div id='section'>Paperid: <span id='pid'>637, <a href='https://arxiv.org/pdf/2309.14954.pdf' target='_blank'>https://arxiv.org/pdf/2309.14954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hui Zhang, Dihan Zheng, Qiurong Wu, Nieng Yan, Zuoqiang Shi, Mingxu Hu, Chenglong Bao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.14954">Addressing preferred orientation in single-particle cryo-EM through AI-generated auxiliary particles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The single-particle cryo-EM field faces the persistent challenge of preferred orientation, lacking general computational solutions. We introduce cryoPROS, an AI-based approach designed to address the above issue. By generating the auxiliary particles with a conditional deep generative model, cryoPROS addresses the intrinsic bias in orientation estimation for the observed particles. We effectively employed cryoPROS in the cryo-EM single particle analysis of the hemagglutinin trimer, showing the ability to restore the near-atomic resolution structure on non-tilt data. Moreover, the enhanced version named cryoPROS-MP significantly improves the resolution of the membrane protein NaX using the no-tilted data that contains the effects of micelles. Compared to the classical approaches, cryoPROS does not need special experimental or image acquisition techniques, providing a purely computational yet effective solution for the preferred orientation problem. Finally, we conduct extensive experiments that establish the low risk of model bias and the high robustness of cryoPROS.
<div id='section'>Paperid: <span id='pid'>638, <a href='https://arxiv.org/pdf/2309.13593.pdf' target='_blank'>https://arxiv.org/pdf/2309.13593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Henrik Christiansen, Federico Errica, Francesco Alesiani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.13593">Self-Tuning Hamiltonian Monte Carlo for Accelerated Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The performance of Hamiltonian Monte Carlo simulations crucially depends on both the integration timestep and the number of integration steps. We present an adaptive general-purpose framework to automatically tune such parameters, based on a local loss function which promotes the fast exploration of phase-space. We show that a good correspondence between loss and autocorrelation time can be established, allowing for gradient-based optimization using a fully-differentiable set-up. The loss is constructed in such a way that it also allows for gradient-driven learning of a distribution over the number of integration steps. Our approach is demonstrated for the one-dimensional harmonic oscillator and alanine dipeptide, a small protein common as a test case for simulation methods. Through the application to the harmonic oscillator, we highlight the importance of not using a fixed timestep to avoid a rugged loss surface with many local minima, otherwise trapping the optimization. In the case of alanine dipeptide, by tuning the only free parameter of our loss definition, we find a good correspondence between it and the autocorrelation times, resulting in a $>100$ fold speed up in optimization of simulation parameters compared to a grid-search. For this system, we also extend the integrator to allow for atom-dependent timesteps, providing a further reduction of $25\%$ in autocorrelation times.
<div id='section'>Paperid: <span id='pid'>639, <a href='https://arxiv.org/pdf/2307.14394.pdf' target='_blank'>https://arxiv.org/pdf/2307.14394.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Feng, Jiashu Han, Shihui Ying, Yue Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.14394">Hypergraph Isomorphism Computation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The isomorphism problem is a fundamental problem in network analysis, which involves capturing both low-order and high-order structural information. In terms of extracting low-order structural information, graph isomorphism algorithms analyze the structural equivalence to reduce the solver space dimension, which demonstrates its power in many applications, such as protein design, chemical pathways, and community detection. For the more commonly occurring high-order relationships in real-life scenarios, the problem of hypergraph isomorphism, which effectively captures these high-order structural relationships, cannot be straightforwardly addressed using graph isomorphism methods. Besides, the existing hypergraph kernel methods may suffer from high memory consumption or inaccurate sub-structure identification, thus yielding sub-optimal performance. In this paper, to address the abovementioned problems, we first propose the hypergraph Weisfiler-Lehman test algorithm for the hypergraph isomorphism test problem by generalizing the Weisfiler-Lehman test algorithm from graphs to hypergraphs. Secondly, based on the presented algorithm, we propose a general hypergraph Weisfieler-Lehman kernel framework and implement two instances, which are Hypergraph Weisfeiler-Lehamn Subtree Kernel and Hypergraph Weisfeiler-Lehamn Hyperedge Kernel. In order to fulfill our research objectives, a comprehensive set of experiments was meticulously designed, including seven graph classification datasets and 12 hypergraph classification datasets. Results on hypergraph classification datasets show significant improvements compared to other typical kernel-based methods, which demonstrates the effectiveness of the proposed methods. In our evaluation, we found that our proposed methods outperform the second-best method in terms of runtime, running over 80 times faster when handling complex hypergraph structures.
<div id='section'>Paperid: <span id='pid'>640, <a href='https://arxiv.org/pdf/2306.05138.pdf' target='_blank'>https://arxiv.org/pdf/2306.05138.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Raphael Boige, Guillaume Richard, JÃ©rÃ©mie Dona, Thomas Pierrot, Antoine Cully
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.05138">Gradient-Informed Quality Diversity for the Illumination of Discrete Spaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quality Diversity (QD) algorithms have been proposed to search for a large collection of both diverse and high-performing solutions instead of a single set of local optima. While early QD algorithms view the objective and descriptor functions as black-box functions, novel tools have been introduced to use gradient information to accelerate the search and improve overall performance of those algorithms over continuous input spaces. However a broad range of applications involve discrete spaces, such as drug discovery or image generation. Exploring those spaces is challenging as they are combinatorially large and gradients cannot be used in the same manner as in continuous spaces. We introduce map-elites with a Gradient-Informed Discrete Emitter (ME-GIDE), which extends QD optimisation with differentiable functions over discrete search spaces. ME-GIDE leverages the gradient information of the objective and descriptor functions with respect to its discrete inputs to propose gradient-informed updates that guide the search towards a diverse set of high quality solutions. We evaluate our method on challenging benchmarks including protein design and discrete latent space illumination and find that our method outperforms state-of-the-art QD algorithms in all benchmarks.
<div id='section'>Paperid: <span id='pid'>641, <a href='https://arxiv.org/pdf/2305.18089.pdf' target='_blank'>https://arxiv.org/pdf/2305.18089.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Natalie Maus, Yimeng Zeng, Daniel Allen Anderson, Phillip Maffettone, Aaron Solomon, Peyton Greenside, Osbert Bastani, Jacob R. Gardner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.18089">Inverse Protein Folding Using Deep Bayesian Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse protein folding -- the task of predicting a protein sequence from its backbone atom coordinates -- has surfaced as an important problem in the "top down", de novo design of proteins. Contemporary approaches have cast this problem as a conditional generative modelling problem, where a large generative model over protein sequences is conditioned on the backbone. While these generative models very rapidly produce promising sequences, independent draws from generative models may fail to produce sequences that reliably fold to the correct backbone. Furthermore, it is challenging to adapt pure generative approaches to other settings, e.g., when constraints exist. In this paper, we cast the problem of improving generated inverse folds as an optimization problem that we solve using recent advances in "deep" or "latent space" Bayesian optimization. Our approach consistently produces protein sequences with greatly reduced structural error to the target backbone structure as measured by TM score and RMSD while using fewer computational resources. Additionally, we demonstrate other advantages of an optimization-based approach to the problem, such as the ability to handle constraints.
<div id='section'>Paperid: <span id='pid'>642, <a href='https://arxiv.org/pdf/2304.10061.pdf' target='_blank'>https://arxiv.org/pdf/2304.10061.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Albert Musaelian, Anders Johansson, Simon Batzner, Boris Kozinsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10061">Scaling the leading accuracy of deep equivariant models to biomolecular simulations of realistic size</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work brings the leading accuracy, sample efficiency, and robustness of deep equivariant neural networks to the extreme computational scale. This is achieved through a combination of innovative model architecture, massive parallelization, and models and implementations optimized for efficient GPU utilization. The resulting Allegro architecture bridges the accuracy-speed tradeoff of atomistic simulations and enables description of dynamics in structures of unprecedented complexity at quantum fidelity. To illustrate the scalability of Allegro, we perform nanoseconds-long stable simulations of protein dynamics and scale up to a 44-million atom structure of a complete, all-atom, explicitly solvated HIV capsid on the Perlmutter supercomputer. We demonstrate excellent strong scaling up to 100 million atoms and 70% weak scaling to 5120 A100 GPUs.
<div id='section'>Paperid: <span id='pid'>643, <a href='https://arxiv.org/pdf/2303.09916.pdf' target='_blank'>https://arxiv.org/pdf/2303.09916.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>YuPeng Huang, Hong Zhang, Siyuan Jiang, Dajiong Yue, Xiaohan Lin, Jun Zhang, Yi Qin Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.09916">DSDP: A Blind Docking Strategy Accelerated by GPUs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Virtual screening, including molecular docking, plays an essential role in drug discovery. Many traditional and machine-learning based methods are available to fulfil the docking task. The traditional docking methods are normally extensively time-consuming, and their performance in blind docking remains to be improved. Although the runtime of docking based on machine learning is significantly decreased, their accuracy is still limited. In this study, we take the advantage of both traditional and machine-learning based methods, and present a method Deep Site and Docking Pose (DSDP) to improve the performance of blind docking. For the traditional blind docking, the entire protein is covered by a cube, and the initial positions of ligands are randomly generated in the cube. In contract, DSDP can predict the binding site of proteins and provide an accurate searching space and initial positions for the further conformational sampling. The docking task of DSDP makes use of the score function and a similar but modified searching strategy of AutoDock Vina, accelerated by implementation in GPUs. We systematically compare its performance with the state-of-the-art methods, including Autodock Vina, GNINA, QuickVina, SMINA, and DiffDock. DSDP reaches a 29.8% top-1 success rate (RMSD < 2 Ã) on an unbiased and challenging test dataset with 1.2 s wall-clock computational time per system. Its performances on DUD-E dataset and the time-split PDBBind dataset used in EquiBind, TankBind, and DiffDock are also effective, presenting a 57.2% and 41.8% top-1 success rate with 0.8 s and 1.0 s per system, respectively.
<div id='section'>Paperid: <span id='pid'>644, <a href='https://arxiv.org/pdf/2301.00004.pdf' target='_blank'>https://arxiv.org/pdf/2301.00004.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingchen Li, Liqi Kang, Yi Xiong, Yu Guang Wang, Guisheng Fan, Pan Tan, Liang Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.00004">SESNet: sequence-structure feature-integrated deep learning method for data-efficient protein engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has been widely used for protein engineering. However, it is limited by the lack of sufficient experimental data to train an accurate model for predicting the functional fitness of high-order mutants. Here, we develop SESNet, a supervised deep-learning model to predict the fitness for protein mutants by leveraging both sequence and structure information, and exploiting attention mechanism. Our model integrates local evolutionary context from homologous sequences, the global evolutionary context encoding rich semantic from the universal protein sequence space and the structure information accounting for the microenvironment around each residue in a protein. We show that SESNet outperforms state-of-the-art models for predicting the sequence-function relationship on 26 deep mutational scanning datasets. More importantly, we propose a data augmentation strategy by leveraging the data from unsupervised models to pre-train our model. After that, our model can achieve strikingly high accuracy in prediction of the fitness of protein mutants, especially for the higher order variants (> 4 mutation sites), when finetuned by using only a small number of experimental mutation data (<50). The strategy proposed is of great practical value as the required experimental effort, i.e., producing a few tens of experimental mutation data on a given protein, is generally affordable by an ordinary biochemical group and can be applied on almost any protein.
<div id='section'>Paperid: <span id='pid'>645, <a href='https://arxiv.org/pdf/2208.09652.pdf' target='_blank'>https://arxiv.org/pdf/2208.09652.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Zhang, Sirui Liu, Mengyun Chen, Haotian Chu, Min Wang, Zidong Wang, Jialiang Yu, Ningxi Ni, Fan Yu, Diqing Chen, Yi Isaac Yang, Boxin Xue, Lijiang Yang, Yuan Liu, Yi Qin Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.09652">Unsupervisedly Prompting AlphaFold2 for Few-Shot Learning of Accurate Folding Landscape and Protein Structure Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven predictive methods which can efficiently and accurately transform protein sequences into biologically active structures are highly valuable for scientific research and medical development. Determining accurate folding landscape using co-evolutionary information is fundamental to the success of modern protein structure prediction methods. As the state of the art, AlphaFold2 has dramatically raised the accuracy without performing explicit co-evolutionary analysis. Nevertheless, its performance still shows strong dependence on available sequence homologs. Based on the interrogation on the cause of such dependence, we presented EvoGen, a meta generative model, to remedy the underperformance of AlphaFold2 for poor MSA targets. By prompting the model with calibrated or virtually generated homologue sequences, EvoGen helps AlphaFold2 fold accurately in low-data regime and even achieve encouraging performance with single-sequence predictions. Being able to make accurate predictions with few-shot MSA not only generalizes AlphaFold2 better for orphan sequences, but also democratizes its use for high-throughput applications. Besides, EvoGen combined with AlphaFold2 yields a probabilistic structure generation method which could explore alternative conformations of protein sequences, and the task-aware differentiable algorithm for sequence generation will benefit other related tasks including protein design.
<div id='section'>Paperid: <span id='pid'>646, <a href='https://arxiv.org/pdf/2508.15321.pdf' target='_blank'>https://arxiv.org/pdf/2508.15321.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan Spirandelli, Arnur Nigmetov, Dmitriy Morozov, Myfanwy E. Evans
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15321">Topological potentials guiding protein self-assembly</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The simulated self-assembly of molecular building blocks into functional complexes is a key area of study in computational biology and materials science. Self-assembly simulations of proteins using physically-motivated potentials for non-polar interactions, can identify the biologically correct assembly as the energy-minimizing state. Short-range potentials, however, produce rugged energy landscapes, which lead to simulations becoming trapped in non-functional local minimizers. Successful self-assembly simulations depend on the physical realism of the driving potentials as well as their ability to efficiently explore the configuration space. We introduce a long-range topological potential, quantified via weighted total persistence, and combine it with the morphometric approach to solvation-free energy. This combination improves the assembly success rate in simulations of the tobacco mosaic virus dimer and other protein complexes by up to sixteen-fold compared with the morphometric model alone. It further enables successful simulation in systems that don't otherwise assemble during the examined timescales. Compared to previous topology-based work, which has been primarily descriptive, our approach uses topological measures as an active energetic bias that is independent of electrostatics or chemical specificity and depends only on atomic coordinates. Therefore, the method can, in principle, be applied to arbitrary systems where such coordinates are optimized. Integrating topological descriptions into an energy function offers a general strategy for overcoming kinetic barriers in molecular simulations, with potential applications in drug design, materials development, and the study of complex self-assembly processes.
<div id='section'>Paperid: <span id='pid'>647, <a href='https://arxiv.org/pdf/2508.05006.pdf' target='_blank'>https://arxiv.org/pdf/2508.05006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youzhi Zhang, Yufei Li, Gaofeng Meng, Hongbin Liu, Jiebo Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05006">The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein-Ligand Binding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking is a crucial aspect of drug discovery, as it predicts the binding interactions between small-molecule ligands and protein pockets. However, current multi-task learning models for docking often show inferior performance in ligand docking compared to protein pocket docking. This disparity arises largely due to the distinct structural complexities of ligands and proteins. To address this issue, we propose a novel game-theoretic framework that models the protein-ligand interaction as a two-player game called the Docking Game, with the ligand docking module acting as the ligand player and the protein pocket docking module as the protein player. To solve this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which alternately trains these players through a two-level loop. In the outer loop, the players exchange predicted poses, allowing each to incorporate the other's structural predictions, which fosters mutual adaptation over multiple iterations. In the inner loop, each player dynamically refines its predictions by incorporating its own predicted ligand or pocket poses back into its model. We theoretically show the convergence of LoopPlay, ensuring stable optimization. Extensive experiments conducted on public benchmark datasets demonstrate that LoopPlay achieves approximately a 10\% improvement in predicting accurate binding modes compared to previous state-of-the-art methods. This highlights its potential to enhance the accuracy of molecular docking in drug discovery.
<div id='section'>Paperid: <span id='pid'>648, <a href='https://arxiv.org/pdf/2508.04415.pdf' target='_blank'>https://arxiv.org/pdf/2508.04415.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuan Chen, Yu Huang, Miaowen Wen, Shahid Mumtaz, Fatih Gulec, Anwer Al-Dulaimi, Andrew W. Eckford
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.04415">Empowering Nanoscale Connectivity through Molecular Communication: A Case Study of Virus Infection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Internet of Bio-Nano Things (IoBNT), envisioned as a revolutionary healthcare paradigm, shows promise for epidemic control. This paper explores the potential of using molecular communication (MC) to address the challenges in constructing IoBNT for epidemic prevention, specifically focusing on modeling viral transmission, detecting the virus/infected individuals, and identifying virus mutations. First, the MC channels in macroscale and microscale scenarios are discussed to match viral transmission in both scales separately. Besides, the detection methods for these two scales are also studied, along with the localization mechanism designed for the virus/infected individuals. Moreover, an identification strategy is proposed to determine potential virus mutations, which is validated through simulation using the ORF3a protein as a benchmark. Finally, open research issues are discussed. In summary, this paper aims to analyze viral transmission through MC and combat viral spread using signal processing techniques within MC.
<div id='section'>Paperid: <span id='pid'>649, <a href='https://arxiv.org/pdf/2508.02674.pdf' target='_blank'>https://arxiv.org/pdf/2508.02674.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tamir Bendory, Dan Edidin, Josh Katz, Shay Kreymer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02674">Orbit recovery for spherical functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Orbit recovery is a central problem in both mathematics and applied sciences, with important applications to structural biology. This paper focuses on recovering generic orbits of functions on ${\mathbb R}^{n}$ and the sphere $S^{n-1}$ under the rotation action of $SO(n)$. Specifically, we demonstrate that invariants of degree three (called the bispectrum) suffice to recover generic orbits of functions in finite-dimensional approximations of $L^2({\mathbb R}^n)$ obtained by band-limiting the spherical component and discretizing the radial direction. In particular, our main result explicitly bounds the number of samples in the radial direction required for recovery from the degree three invariants. From an application perspective, the most important case is $SO(3)$, which arises in many scientific fields, and in particular, plays a central role in leading structural biology applications such as cryo-electron tomography and cryo-electron microscopy. Our result for $SO(3)$ states that considering three spherical shells (i.e., samples in the radial direction) is sufficient to recover generic orbits, which verifies an implicit conjecture made in a paper of Bandeira et al. Our proof technique provides an explicit, computationally efficient algorithm to recover the signal by successively solving systems of linear equations. We implemented this algorithm and demonstrated its effectiveness on two protein structures.
<div id='section'>Paperid: <span id='pid'>650, <a href='https://arxiv.org/pdf/2507.10737.pdf' target='_blank'>https://arxiv.org/pdf/2507.10737.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiayuan Chen, Thai-Hoang Pham, Yuanlong Wang, Ping Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10737">Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-throughput screening techniques, such as microscopy imaging of cellular responses to genetic and chemical perturbations, play a crucial role in drug discovery and biomedical research. However, robust perturbation screening for \textit{de novo} cell lines remains challenging due to the significant morphological and biological heterogeneity across cell lines. To address this, we propose a novel framework that integrates external biological knowledge into existing pretraining strategies to enhance microscopy image profiling models. Our approach explicitly disentangles perturbation-specific and cell line-specific representations using external biological information. Specifically, we construct a knowledge graph leveraging protein interaction data from STRING and Hetionet databases to guide models toward perturbation-specific features during pretraining. Additionally, we incorporate transcriptomic features from single-cell foundation models to capture cell line-specific representations. By learning these disentangled features, our method improves the generalization of imaging models to \textit{de novo} cell lines. We evaluate our framework on the RxRx database through one-shot fine-tuning on an RxRx1 cell line and few-shot fine-tuning on cell lines from the RxRx19a dataset. Experimental results demonstrate that our method enhances microscopy image profiling for \textit{de novo} cell lines, highlighting its effectiveness in real-world phenotype-based drug discovery applications.
<div id='section'>Paperid: <span id='pid'>651, <a href='https://arxiv.org/pdf/2507.02883.pdf' target='_blank'>https://arxiv.org/pdf/2507.02883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyue Zeng, Tuo Wang, Adithya Kulkarni, Alexander Lu, Alexandra Ni, Phoebe Xing, Junhan Zhao, Siwei Chen, Dawei Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02883">DISPROTBENCH: A Disorder-Aware, Task-Rich Benchmark for Evaluating Protein Structure Prediction in Realistic Biological Contexts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in protein structure prediction have achieved near-atomic accuracy for well-folded proteins. However, current benchmarks inadequately assess model performance in biologically challenging contexts, especially those involving intrinsically disordered regions (IDRs), limiting their utility in applications such as drug discovery, disease variant interpretation, and protein interface design. We introduce DisProtBench, a comprehensive benchmark for evaluating protein structure prediction models (PSPMs) under structural disorder and complex biological conditions. DisProtBench spans three key axes: (1) Data complexity, covering disordered regions, G protein-coupled receptor (GPCR) ligand pairs, and multimeric complexes; (2) Task diversity, benchmarking twelve leading PSPMs across structure-based tasks with unified classification, regression, and interface metrics; and (3) Interpretability, via the DisProtBench Portal, which provides precomputed 3D structures and visual error analyses. Our results reveal significant variability in model robustness under disorder, with low-confidence regions linked to functional prediction failures. Notably, global accuracy metrics often fail to predict task performance in disordered settings, emphasizing the need for function-aware evaluation. DisProtBench establishes a reproducible, extensible, and biologically grounded framework for assessing next-generation PSPMs in realistic biomedical scenarios.
<div id='section'>Paperid: <span id='pid'>652, <a href='https://arxiv.org/pdf/2507.02006.pdf' target='_blank'>https://arxiv.org/pdf/2507.02006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shakya Jayakody, Youpeng Zhao, Jun Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02006">AIRES: Accelerating Out-of-Core GCNs via Algorithm-System Co-Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph convolutional networks (GCNs) are fundamental in various scientific applications, ranging from biomedical protein-protein interactions (PPI) to large-scale recommendation systems. An essential component for modeling graph structures in GCNs is sparse general matrix-matrix multiplication (SpGEMM). As the size of graph data continues to scale up, SpGEMMs are often conducted in an out-of-core fashion due to limited GPU memory space in resource-constrained systems. Albeit recent efforts that aim to alleviate the memory constraints of out-of-core SpGEMM through either GPU feature caching, hybrid CPU-GPU memory layout, or performing the computation in sparse format, current systems suffer from both high I/O latency and GPU under-utilization issues.
  In this paper, we first identify the problems of existing systems, where sparse format data alignment and memory allocation are the main performance bottlenecks, and propose AIRES, a novel algorithm-system co-design solution to accelerate out-of-core SpGEMM computation for GCNs. Specifically, from the algorithm angle, AIRES proposes to alleviate the data alignment issues on the block level for matrices in sparse formats and develops a tiling algorithm to facilitate row block-wise alignment. On the system level, AIRES employs a three-phase dynamic scheduling that features a dual-way data transfer strategy utilizing a tiered memory system: integrating GPU memory, GPU Direct Storage (GDS), and host memory to reduce I/O latency and improve throughput. Evaluations show that AIRES significantly outperforms the state-of-the-art methods, achieving up to 1.8x lower latency in real-world graph processing benchmarks.
<div id='section'>Paperid: <span id='pid'>653, <a href='https://arxiv.org/pdf/2506.14793.pdf' target='_blank'>https://arxiv.org/pdf/2506.14793.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aditya Ravuri, Neil D. Lawrence
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14793">Protein Language Model Zero-Shot Fitness Predictions are Improved by Inference-only Dropout</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein Language Models (PLMs) such as ESM2 have been shown to be capable of zero-shot prediction of critical scalar properties of proteins (fitness). In this work, we show that injecting a dropout layer at inference time between a PLM's featurizer/embedding layer and its transformer, and averaging its output akin to Monte-Carlo dropout increases zero-shot performance on a subset of the ProteinGym dataset. This is the case even when the model was not trained with dropouts to begin with, and does not require retraining or finetuning of the PLM. A dropout of 0.1 seems performant across all models.
<div id='section'>Paperid: <span id='pid'>654, <a href='https://arxiv.org/pdf/2506.08023.pdf' target='_blank'>https://arxiv.org/pdf/2506.08023.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qifeng Wu, Zhengzhe Liu, Han Zhu, Yizhou Zhao, Daisuke Kihara, Min Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08023">Aligning Proteins and Language: A Foundation Model for Protein Retrieval</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper aims to retrieve proteins with similar structures and semantics from large-scale protein dataset, facilitating the functional interpretation of protein structures derived by structural determination methods like cryo-Electron Microscopy (cryo-EM). Motivated by the recent progress of vision-language models (VLMs), we propose a CLIP-style framework for aligning 3D protein structures with functional annotations using contrastive learning. For model training, we propose a large-scale dataset of approximately 200,000 protein-caption pairs with rich functional descriptors. We evaluate our model in both in-domain and more challenging cross-database retrieval on Protein Data Bank (PDB) and Electron Microscopy Data Bank (EMDB) dataset, respectively. In both cases, our approach demonstrates promising zero-shot retrieval performance, highlighting the potential of multimodal foundation models for structure-function understanding in protein biology.
<div id='section'>Paperid: <span id='pid'>655, <a href='https://arxiv.org/pdf/2505.20251.pdf' target='_blank'>https://arxiv.org/pdf/2505.20251.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sophia Hager, Aleem Khan, Andrew Wang, Nicholas Andrews
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20251">Learning Extrapolative Sequence Transformations from Markov Chains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most successful applications of deep learning involve similar training and test conditions. However, tasks such as biological sequence design involve searching for sequences that improve desirable properties beyond previously known values, which requires novel hypotheses that \emph{extrapolate} beyond training data. In these settings, extrapolation may be achieved by using random search methods such as Markov chain Monte Carlo (MCMC), which, given an initial state, sample local transformations to approximate a target density that rewards states with the desired properties. However, even with a well-designed proposal, MCMC may struggle to explore large structured state spaces efficiently. Rather than relying on stochastic search, it would be desirable to have a model that greedily optimizes the properties of interest, successfully extrapolating in as few steps as possible. We propose to learn such a model from the Markov chains resulting from MCMC search. Specifically, our approach uses selected states from Markov chains as a source of training data for an autoregressive model, which is then able to efficiently generate novel sequences that extrapolate along the sequence-level properties of interest. The proposed approach is validated on three problems: protein sequence design, text sentiment control, and text anonymization. We find that the autoregressive model can extrapolate as well or better than MCMC, but with the additional benefits of scalability and significantly higher sample efficiency.
<div id='section'>Paperid: <span id='pid'>656, <a href='https://arxiv.org/pdf/2505.02639.pdf' target='_blank'>https://arxiv.org/pdf/2505.02639.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuan Lin, Qingrui Liu, Hongxin Xiang, Daojian Zeng, Xiangxiang Zeng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02639">Enhancing Chemical Reaction and Retrosynthesis Prediction with Large Language Model and Dual-task Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Chemical reaction and retrosynthesis prediction are fundamental tasks in drug discovery. Recently, large language models (LLMs) have shown potential in many domains. However, directly applying LLMs to these tasks faces two major challenges: (i) lacking a large-scale chemical synthesis-related instruction dataset; (ii) ignoring the close correlation between reaction and retrosynthesis prediction for the existing fine-tuning strategies. To address these challenges, we propose ChemDual, a novel LLM framework for accurate chemical synthesis. Specifically, considering the high cost of data acquisition for reaction and retrosynthesis, ChemDual regards the reaction-and-retrosynthesis of molecules as a related recombination-and-fragmentation process and constructs a large-scale of 4.4 million instruction dataset. Furthermore, ChemDual introduces an enhanced LLaMA, equipped with a multi-scale tokenizer and dual-task learning strategy, to jointly optimize the process of recombination and fragmentation as well as the tasks between reaction and retrosynthesis prediction. Extensive experiments on Mol-Instruction and USPTO-50K datasets demonstrate that ChemDual achieves state-of-the-art performance in both predictions of reaction and retrosynthesis, outperforming the existing conventional single-task approaches and the general open-source LLMs. Through molecular docking analysis, ChemDual generates compounds with diverse and strong protein binding affinity, further highlighting its strong potential in drug design.
<div id='section'>Paperid: <span id='pid'>657, <a href='https://arxiv.org/pdf/2504.15508.pdf' target='_blank'>https://arxiv.org/pdf/2504.15508.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianxiong Li, Beining Zhang, Mingzhen Li, Siyu Hu, Jinzhe Zeng, Lijun Liu, Guojun Yuan, Zhan Wang, Guangming Tan, Weile Jia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15508">Scaling Neural-Network-Based Molecular Dynamics with Long-Range Electrostatic Interactions to 51 Nanoseconds per Day</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural network-based molecular dynamics (NNMD) simulations incorporating long-range electrostatic interactions have significantly extended the applicability to heterogeneous and ionic systems, enabling effective modeling critical physical phenomena such as protein folding and dipolar surface and maintaining ab initio accuracy. However, neural network inference and long-range force computation remain the major bottlenecks, severely limiting simulation speed. In this paper, we target DPLR, a state-of-the-art NNMD package that supports long-range electrostatics, and propose a set of comprehensive optimizations to enhance computational efficiency. We introduce (1) a hardware-offloaded FFT method to reduce the communication overhead; (2) an overlapping strategy that hides long-range force computations using a single core per node, and (3) a ring-based load balancing method that enables atom-level task evenly redistribution with minimal communication overhead. Experimental results on the Fugaku supercomputer show that our work achieves a 37x performance improvement, reaching a maximum simulation speed of 51 ns/day.
<div id='section'>Paperid: <span id='pid'>658, <a href='https://arxiv.org/pdf/2503.04680.pdf' target='_blank'>https://arxiv.org/pdf/2503.04680.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ryan Barron, Maksim E. Eren, Duc P. Truong, Cynthia Matuszek, James Wendelberger, Mary F. Dorn, Boian Alexandrov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04680">Matrix Factorization for Inferring Associations and Missing Links</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Missing link prediction is a method for network analysis, with applications in recommender systems, biology, social sciences, cybersecurity, information retrieval, and Artificial Intelligence (AI) reasoning in Knowledge Graphs. Missing link prediction identifies unseen but potentially existing connections in a network by analyzing the observed patterns and relationships. In proliferation detection, this supports efforts to identify and characterize attempts by state and non-state actors to acquire nuclear weapons or associated technology - a notoriously challenging but vital mission for global security. Dimensionality reduction techniques like Non-Negative Matrix Factorization (NMF) and Logistic Matrix Factorization (LMF) are effective but require selection of the matrix rank parameter, that is, of the number of hidden features, k, to avoid over/under-fitting. We introduce novel Weighted (WNMFk), Boolean (BNMFk), and Recommender (RNMFk) matrix factorization methods, along with ensemble variants incorporating logistic factorization, for link prediction. Our methods integrate automatic model determination for rank estimation by evaluating stability and accuracy using a modified bootstrap methodology and uncertainty quantification (UQ), assessing prediction reliability under random perturbations. We incorporate Otsu threshold selection and k-means clustering for Boolean matrix factorization, comparing them to coordinate descent-based Boolean thresholding. Our experiments highlight the impact of rank k selection, evaluate model performance under varying test-set sizes, and demonstrate the benefits of UQ for reliable predictions using abstention. We validate our methods on three synthetic datasets (Boolean and uniformly distributed) and benchmark them against LMF and symmetric LMF (symLMF) on five real-world protein-protein interaction networks, showcasing an improved prediction performance.
<div id='section'>Paperid: <span id='pid'>659, <a href='https://arxiv.org/pdf/2411.18648.pdf' target='_blank'>https://arxiv.org/pdf/2411.18648.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Lin, Mingjie Li, Yisen Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.18648">MADE: Graph Backdoor Defense with Masked Unlearning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) have garnered significant attention from researchers due to their outstanding performance in handling graph-related tasks, such as social network analysis, protein design, and so on. Despite their widespread application, recent research has demonstrated that GNNs are vulnerable to backdoor attacks, implemented by injecting triggers into the training datasets. Trained on the poisoned data, GNNs will predict target labels when attaching trigger patterns to inputs. This vulnerability poses significant security risks for applications of GNNs in sensitive domains, such as drug discovery. While there has been extensive research into backdoor defenses for images, strategies to safeguard GNNs against such attacks remain underdeveloped. Furthermore, we point out that conventional backdoor defense methods designed for images cannot work well when directly implemented on graph data. In this paper, we first analyze the key difference between image backdoor and graph backdoor attacks. Then we tackle the graph defense problem by presenting a novel approach called MADE, which devises an adversarial mask generation mechanism that selectively preserves clean sub-graphs and further leverages masks on edge weights to eliminate the influence of triggers effectively. Extensive experiments across various graph classification tasks demonstrate the effectiveness of MADE in significantly reducing the attack success rate (ASR) while maintaining a high classification accuracy.
<div id='section'>Paperid: <span id='pid'>660, <a href='https://arxiv.org/pdf/2411.11265.pdf' target='_blank'>https://arxiv.org/pdf/2411.11265.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thanh V. T. Tran, Nhat Khang Ngo, Viet Anh Nguyen, Truong Son Hy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11265">GROOT: Effective Design of Biological Sequences with Limited Experimental Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Latent space optimization (LSO) is a powerful method for designing discrete, high-dimensional biological sequences that maximize expensive black-box functions, such as wet lab experiments. This is accomplished by learning a latent space from available data and using a surrogate model to guide optimization algorithms toward optimal outputs. However, existing methods struggle when labeled data is limited, as training the surrogate model with few labeled data points can lead to subpar outputs, offering no advantage over the training data itself. We address this challenge by introducing GROOT, a Graph-based Latent Smoothing for Biological Sequence Optimization. In particular, GROOT generates pseudo-labels for neighbors sampled around the training latent embeddings. These pseudo-labels are then refined and smoothed by Label Propagation. Additionally, we theoretically and empirically justify our approach, demonstrate GROOT's ability to extrapolate to regions beyond the training set while maintaining reliability within an upper bound of their expected distances from the training regions. We evaluate GROOT on various biological sequence design tasks, including protein optimization (GFP and AAV) and three tasks with exact oracles from Design-Bench. The results demonstrate that GROOT equalizes and surpasses existing methods without requiring access to black-box oracles or vast amounts of labeled data, highlighting its practicality and effectiveness. We release our code at https://anonymous.4open.science/r/GROOT-D554
<div id='section'>Paperid: <span id='pid'>661, <a href='https://arxiv.org/pdf/2411.10548.pdf' target='_blank'>https://arxiv.org/pdf/2411.10548.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peter St. John, Dejun Lin, Polina Binder, Malcolm Greaves, Vega Shah, John St. John, Adrian Lange, Patrick Hsu, Rajesh Illango, Arvind Ramanathan, Anima Anandkumar, David H Brookes, Akosua Busia, Abhishaike Mahajan, Stephen Malina, Neha Prasad, Sam Sinai, Lindsay Edwards, Thomas Gaudelet, Cristian Regep, Martin Steinegger, Burkhard Rost, Alexander Brace, Kyle Hippe, Luca Naef, Keisuke Kamata, George Armstrong, Kevin Boyd, Zhonglin Cao, Han-Yi Chou, Simon Chu, Allan dos Santos Costa, Sajad Darabi, Eric Dawson, Kieran Didi, Cong Fu, Mario Geiger, Michelle Gill, Darren J Hsu, Gagan Kaushik, Maria Korshunova, Steven Kothen-Hill, Youhan Lee, Meng Liu, Micha Livne, Zachary McClure, Jonathan Mitchell, Alireza Moradzadeh, Ohad Mosafi, Youssef Nashed, Saee Paliwal, Yuxing Peng, Sara Rabhi, Farhad Ramezanghorbani, Danny Reidenbach, Camir Ricketts, Brian C Roland, Kushal Shah, Tyler Shimko, Hassan Sirelkhatim, Savitha Srinivasan, Abraham C Stern, Dorota Toczydlowska, Srimukh Prasad Veccham, Niccolò Alberto Elia Venanzi, Anton Vorontsov, Jared Wilber, Isabel Wilkinson, Wei Jing Wong, Eva Xue, Cory Ye, Xin Yu, Yang Zhang, Guoqing Zhou, Becca Zandstein, Alejandro Chacon, Prashant Sohani, Maximilian Stadler, Christian Hundt, Feiwen Zhu, Christian Dallago, Bruno Trentini, Emine Kucukbenli, Saee Paliwal, Timur Rvachov, Eddie Calleja, Johnny Israeli, Harry Clifford, Risto Haukioja, Nicholas Haemel, Kyle Tretina, Neha Tadimeti, Anthony B Costa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.10548">BioNeMo Framework: a modular, high-performance library for AI model development in drug discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial Intelligence models encoding biology and chemistry are opening new routes to high-throughput and high-quality in-silico drug development. However, their training increasingly relies on computational scale, with recent protein language models (pLM) training on hundreds of graphical processing units (GPUs). We introduce the BioNeMo Framework to facilitate the training of computational biology and chemistry AI models across hundreds of GPUs. Its modular design allows the integration of individual components, such as data loaders, into existing workflows and is open to community contributions. We detail technical features of the BioNeMo Framework through use cases such as pLM pre-training and fine-tuning. On 256 NVIDIA A100s, BioNeMo Framework trains a three billion parameter BERT-based pLM on over one trillion tokens in 4.2 days. The BioNeMo Framework is open-source and free for everyone to use.
<div id='section'>Paperid: <span id='pid'>662, <a href='https://arxiv.org/pdf/2409.13746.pdf' target='_blank'>https://arxiv.org/pdf/2409.13746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thanh Son Do, Daniel B. Hier, Tayo Obafemi-Ajayi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13746">Mapping Biomedical Ontology Terms to IDs: Effect of Domain Prevalence on Prediction Accuracy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study evaluates the ability of large language models (LLMs) to map biomedical ontology terms to their corresponding ontology IDs across the Human Phenotype Ontology (HPO), Gene Ontology (GO), and UniProtKB terminologies. Using counts of ontology IDs in the PubMed Central (PMC) dataset as a surrogate for their prevalence in the biomedical literature, we examined the relationship between ontology ID prevalence and mapping accuracy. Results indicate that ontology ID prevalence strongly predicts accurate mapping of HPO terms to HPO IDs, GO terms to GO IDs, and protein names to UniProtKB accession numbers. Higher prevalence of ontology IDs in the biomedical literature correlated with higher mapping accuracy. Predictive models based on receiver operating characteristic (ROC) curves confirmed this relationship.
  In contrast, this pattern did not apply to mapping protein names to Human Genome Organisation's (HUGO) gene symbols. GPT-4 achieved a high baseline performance (95%) in mapping protein names to HUGO gene symbols, with mapping accuracy unaffected by prevalence. We propose that the high prevalence of HUGO gene symbols in the literature has caused these symbols to become lexicalized, enabling GPT-4 to map protein names to HUGO gene symbols with high accuracy. These findings highlight the limitations of LLMs in mapping ontology terms to low-prevalence ontology IDs and underscore the importance of incorporating ontology ID prevalence into the training and evaluation of LLMs for biomedical applications.
<div id='section'>Paperid: <span id='pid'>663, <a href='https://arxiv.org/pdf/2408.12413.pdf' target='_blank'>https://arxiv.org/pdf/2408.12413.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ce Liu, Jun Wang, Zhiqiang Cai, Yingxu Wang, Huizhen Kuang, Kaihui Cheng, Liwei Zhang, Qingkun Su, Yining Tang, Fenglei Cao, Limei Han, Siyu Zhu, Yuan Qi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12413">Dynamic PDB: A New Dataset and a SE(3) Model Extension by Integrating Dynamic Behaviors and Physical Properties in Protein Structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite significant progress in static protein structure collection and prediction, the dynamic behavior of proteins, one of their most vital characteristics, has been largely overlooked in prior research. This oversight can be attributed to the limited availability, diversity, and heterogeneity of dynamic protein datasets. To address this gap, we propose to enhance existing prestigious static 3D protein structural databases, such as the Protein Data Bank (PDB), by integrating dynamic data and additional physical properties. Specifically, we introduce a large-scale dataset, Dynamic PDB, encompassing approximately 12.6K proteins, each subjected to all-atom molecular dynamics (MD) simulations lasting 1 microsecond to capture conformational changes. Furthermore, we provide a comprehensive suite of physical properties, including atomic velocities and forces, potential and kinetic energies of proteins, and the temperature of the simulation environment, recorded at 1 picosecond intervals throughout the simulations. For benchmarking purposes, we evaluate state-of-the-art methods on the proposed dataset for the task of trajectory prediction. To demonstrate the value of integrating richer physical properties in the study of protein dynamics and related model design, we base our approach on the SE(3) diffusion model and incorporate these physical properties into the trajectory prediction process. Preliminary results indicate that this straightforward extension of the SE(3) model yields improved accuracy, as measured by MAE and RMSD, when the proposed physical properties are taken into consideration. https://fudan-generative-vision.github.io/dynamicPDB/ .
<div id='section'>Paperid: <span id='pid'>664, <a href='https://arxiv.org/pdf/2407.19073.pdf' target='_blank'>https://arxiv.org/pdf/2407.19073.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikolai Schapin, Carles Navarro, Albert Bou, Gianni De Fabritiis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.19073">On Machine Learning Approaches for Protein-Ligand Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Binding affinity optimization is crucial in early-stage drug discovery. While numerous machine learning methods exist for predicting ligand potency, their comparative efficacy remains unclear. This study evaluates the performance of classical tree-based models and advanced neural networks in protein-ligand binding affinity prediction. Our comprehensive benchmarking encompasses 2D models utilizing ligand-only RDKit embeddings and Large Language Model (LLM) ligand representations, as well as 3D neural networks incorporating bound protein-ligand conformations. We assess these models across multiple standard datasets, examining various predictive scenarios including classification, ranking, regression, and active learning. Results indicate that simpler models can surpass more complex ones in specific tasks, while 3D models leveraging structural information become increasingly competitive with larger training datasets containing compounds with labelled affinity data against multiple targets. Pre-trained 3D models, by incorporating protein pocket environments, demonstrate significant advantages in data-scarce scenarios for specific binding pockets. Additionally, LLM pretraining on 2D ligand data enhances complex model performance, providing versatile embeddings that outperform traditional RDKit features in computational efficiency. Finally, we show that combining 2D and 3D model strengths improves active learning outcomes beyond current state-of-the-art approaches. These findings offer valuable insights for optimizing machine learning strategies in drug discovery pipelines.
<div id='section'>Paperid: <span id='pid'>665, <a href='https://arxiv.org/pdf/2407.11942.pdf' target='_blank'>https://arxiv.org/pdf/2407.11942.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leo Klarner, Tim G. J. Rudner, Garrett M. Morris, Charlotte M. Deane, Yee Whye Teh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11942">Context-Guided Diffusion for Out-of-Distribution Molecular and Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative models have the potential to accelerate key steps in the discovery of novel molecular therapeutics and materials. Diffusion models have recently emerged as a powerful approach, excelling at unconditional sample generation and, with data-driven guidance, conditional generation within their training domain. Reliably sampling from high-value regions beyond the training data, however, remains an open challenge -- with current methods predominantly focusing on modifying the diffusion process itself. In this paper, we develop context-guided diffusion (CGD), a simple plug-and-play method that leverages unlabeled data and smoothness constraints to improve the out-of-distribution generalization of guided diffusion models. We demonstrate that this approach leads to substantial performance gains across various settings, including continuous, discrete, and graph-structured diffusion processes with applications across drug discovery, materials science, and protein design.
<div id='section'>Paperid: <span id='pid'>666, <a href='https://arxiv.org/pdf/2407.04493.pdf' target='_blank'>https://arxiv.org/pdf/2407.04493.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinghua Yao, Yuangang Pan, Jing Li, Ivor Tsang, Xin Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04493">PROUD: PaRetO-gUided Diffusion Model for Multi-objective Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in the realm of deep generative models focus on generating samples that satisfy multiple desired properties. However, prevalent approaches optimize these property functions independently, thus omitting the trade-offs among them. In addition, the property optimization is often improperly integrated into the generative models, resulting in an unnecessary compromise on generation quality (i.e., the quality of generated samples). To address these issues, we formulate a constrained optimization problem. It seeks to optimize generation quality while ensuring that generated samples reside at the Pareto front of multiple property objectives. Such a formulation enables the generation of samples that cannot be further improved simultaneously on the conflicting property functions and preserves good quality of generated samples. Building upon this formulation, we introduce the PaRetO-gUided Diffusion model (PROUD), wherein the gradients in the denoising process are dynamically adjusted to enhance generation quality while the generated samples adhere to Pareto optimality. Experimental evaluations on image generation and protein generation tasks demonstrate that our PROUD consistently maintains superior generation quality while approaching Pareto optimality across multiple property functions compared to various baselines.
<div id='section'>Paperid: <span id='pid'>667, <a href='https://arxiv.org/pdf/2406.00812.pdf' target='_blank'>https://arxiv.org/pdf/2406.00812.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yueming Lyu, Kim Yong Tan, Yew Soon Ong, Ivor W. Tsang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00812">Covariance-Adaptive Sequential Black-box Optimization for Diffusion Targeted Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have demonstrated great potential in generating high-quality content for images, natural language, protein domains, etc. However, how to perform user-preferred targeted generation via diffusion models with only black-box target scores of users remains challenging. To address this issue, we first formulate the fine-tuning of the targeted reserve-time stochastic differential equation (SDE) associated with a pre-trained diffusion model as a sequential black-box optimization problem. Furthermore, we propose a novel covariance-adaptive sequential optimization algorithm to optimize cumulative black-box scores under unknown transition dynamics. Theoretically, we prove a $O(\frac{d^2}{\sqrt{T}})$ convergence rate for cumulative convex functions without smooth and strongly convex assumptions. Empirically, experiments on both numerical test problems and target-guided 3D-molecule generation tasks show the superior performance of our method in achieving better target scores.
<div id='section'>Paperid: <span id='pid'>668, <a href='https://arxiv.org/pdf/2403.12636.pdf' target='_blank'>https://arxiv.org/pdf/2403.12636.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Bischoff, Alana Darcher, Michael Deistler, Richard Gao, Franziska Gerken, Manuel Gloeckler, Lisa Haxel, Jaivardhan Kapoor, Janne K Lappalainen, Jakob H Macke, Guy Moss, Matthijs Pals, Felix Pei, Rachel Rapp, A Erdem SaÄtekin, Cornelius SchrÃ¶der, Auguste Schulz, Zinovia Stefanidi, Shoji Toyota, Linda Ulmer, Julius Vetter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.12636">A Practical Guide to Sample-based Statistical Distances for Evaluating Generative Models in Science</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative models are invaluable in many fields of science because of their ability to capture high-dimensional and complicated distributions, such as photo-realistic images, protein structures, and connectomes. How do we evaluate the samples these models generate? This work aims to provide an accessible entry point to understanding popular sample-based statistical distances, requiring only foundational knowledge in mathematics and statistics. We focus on four commonly used notions of statistical distances representing different methodologies: Using low-dimensional projections (Sliced-Wasserstein; SW), obtaining a distance using classifiers (Classifier Two-Sample Tests; C2ST), using embeddings through kernels (Maximum Mean Discrepancy; MMD), or neural networks (FrÃ©chet Inception Distance; FID). We highlight the intuition behind each distance and explain their merits, scalability, complexity, and pitfalls. To demonstrate how these distances are used in practice, we evaluate generative models from different scientific domains, namely a model of decision-making and a model generating medical images. We showcase that distinct distances can give different results on similar data. Through this guide, we aim to help researchers to use, interpret, and evaluate statistical distances for generative models in science.
<div id='section'>Paperid: <span id='pid'>669, <a href='https://arxiv.org/pdf/2402.01542.pdf' target='_blank'>https://arxiv.org/pdf/2402.01542.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soojung Yang, Juno Nam, Johannes C. B. Dietschreit, Rafael GÃ³mez-Bombarelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01542">Learning Collective Variables with Synthetic Data Augmentation through Physics-Inspired Geodesic Interpolation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In molecular dynamics simulations, rare events, such as protein folding, are typically studied using enhanced sampling techniques, most of which are based on the definition of a collective variable (CV) along which acceleration occurs. Obtaining an expressive CV is crucial, but often hindered by the lack of information about the particular event, e.g., the transition from unfolded to folded conformation. We propose a simulation-free data augmentation strategy using physics-inspired metrics to generate geodesic interpolations resembling protein folding transitions, thereby improving sampling efficiency without true transition state samples. This new data can be used to improve the accuracy of classifier-based methods. Alternatively, a regression-based learning scheme for CV models can be adopted by leveraging the interpolation progress parameter.
<div id='section'>Paperid: <span id='pid'>670, <a href='https://arxiv.org/pdf/2309.16684.pdf' target='_blank'>https://arxiv.org/pdf/2309.16684.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiamin Wu, He Cao, Yuan Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16684">Leveraging Side Information for Ligand Conformation Generation using Diffusion-Based Approaches</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ligand molecule conformation generation is a critical challenge in drug discovery. Deep learning models have been developed to tackle this problem, particularly through the use of generative models in recent years. However, these models often generate conformations that lack meaningful structure and randomness due to the absence of essential side information. Examples of such side information include the chemical and geometric features of the target protein, ligand-target compound interactions, and ligand chemical properties. Without these constraints, the generated conformations may not be suitable for further selection and design of new drugs. To address this limitation, we propose a novel method for generating ligand conformations that leverage side information and incorporate flexible constraints into standard diffusion models. Drawing inspiration from the concept of message passing, we introduce ligand-target massage passing block, a mechanism that facilitates the exchange of information between target nodes and ligand nodes, thereby incorporating target node features. To capture non-covalent interactions, we introduce ligand-target compound inter and intra edges. To further improve the biological relevance of the generated conformations, we train energy models using scalar chemical features. These models guide the progress of the standard Denoising Diffusion Probabilistic Models, resulting in more biologically meaningful conformations. We evaluate the performance of SIDEGEN using the PDBBind-2020 dataset, comparing it against other methods. The results demonstrate improvements in both Aligned RMSD and Ligand RMSD evaluations. Specifically, our model outperforms GeoDiff (trained on PDBBind-2020) by 20% in terms of the median aligned RMSD metric.
<div id='section'>Paperid: <span id='pid'>671, <a href='https://arxiv.org/pdf/2308.13487.pdf' target='_blank'>https://arxiv.org/pdf/2308.13487.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gunnar Reiske, Sungwon In, Yalong Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.13487">Multi-Focus Querying of the Human Genome Information on Desktop and in Virtual Reality: an Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The human genome is incredibly information-rich, consisting of approximately 25,000 protein-coding genes spread out over 3.2 billion nucleotide base pairs contained within 24 unique chromosomes. The genome is important in maintaining spatial context, which assists in understanding gene interactions and relationships. However, existing methods of genome visualization that utilize spatial awareness are inefficient and prone to limitations in presenting gene information and spatial context. This study proposed an innovative approach to genome visualization and exploration utilizing virtual reality. To determine the optimal placement of gene information and evaluate its essentiality in a VR environment, we implemented and conducted a user study with three different interaction methods. Two interaction methods were developed in virtual reality to determine if gene information is better suited to be embedded within the chromosome ideogram or separate from the ideogram. The final ideogram interaction method was performed on a desktop and served as a benchmark to evaluate the potential benefits associated with the use of VR. Our study findings reveal a preference for VR, despite longer task completion times. In addition, the placement of gene information within the visualization had a notable impact on the ability of a user to complete tasks. Specifically, gene information embedded within the chromosome ideogram was better suited for single target identification and summarization tasks, while separating gene information from the ideogram better supported region comparison tasks.
<div id='section'>Paperid: <span id='pid'>672, <a href='https://arxiv.org/pdf/2307.12790.pdf' target='_blank'>https://arxiv.org/pdf/2307.12790.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aryan Singh, Pepijn Van de Ven, CiarÃ¡n Eising, Patrick Denny
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.12790">Compact & Capable: Harnessing Graph Neural Networks and Edge Convolution for Medical Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph-based neural network models are gaining traction in the field of representation learning due to their ability to uncover latent topological relationships between entities that are otherwise challenging to identify. These models have been employed across a diverse range of domains, encompassing drug discovery, protein interactions, semantic segmentation, and fluid dynamics research. In this study, we investigate the potential of Graph Neural Networks (GNNs) for medical image classification. We introduce a novel model that combines GNNs and edge convolution, leveraging the interconnectedness of RGB channel feature values to strongly represent connections between crucial graph nodes. Our proposed model not only performs on par with state-of-the-art Deep Neural Networks (DNNs) but does so with 1000 times fewer parameters, resulting in reduced training time and data requirements. We compare our Graph Convolutional Neural Network (GCNN) to pre-trained DNNs for classifying MedMNIST dataset classes, revealing promising prospects for GNNs in medical image analysis. Our results also encourage further exploration of advanced graph-based models such as Graph Attention Networks (GAT) and Graph Auto-Encoders in the medical imaging domain. The proposed model yields more reliable, interpretable, and accurate outcomes for tasks like semantic segmentation and image classification compared to simpler GCNNs
<div id='section'>Paperid: <span id='pid'>673, <a href='https://arxiv.org/pdf/2306.16819.pdf' target='_blank'>https://arxiv.org/pdf/2306.16819.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai Yi, Bingxin Zhou, Yiqing Shen, Pietro LiÃ², Yu Guang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.16819">Graph Denoising Diffusion for Inverse Protein Folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse protein folding is challenging due to its inherent one-to-many mapping characteristic, where numerous possible amino acid sequences can fold into a single, identical protein backbone. This task involves not only identifying viable sequences but also representing the sheer diversity of potential solutions. However, existing discriminative models, such as transformer-based auto-regressive models, struggle to encapsulate the diverse range of plausible solutions. In contrast, diffusion probabilistic models, as an emerging genre of generative approaches, offer the potential to generate a diverse set of sequence candidates for determined protein backbones. We propose a novel graph denoising diffusion model for inverse protein folding, where a given protein backbone guides the diffusion process on the corresponding amino acid residue types. The model infers the joint distribution of amino acids conditioned on the nodes' physiochemical properties and local environment. Moreover, we utilize amino acid replacement matrices for the diffusion forward process, encoding the biologically-meaningful prior knowledge of amino acids from their spatial and sequential neighbors as well as themselves, which reduces the sampling space of the generative process. Our model achieves state-of-the-art performance over a set of popular baseline methods in sequence recovery and exhibits great potential in generating diverse protein sequences for a determined protein backbone structure.
<div id='section'>Paperid: <span id='pid'>674, <a href='https://arxiv.org/pdf/2305.08929.pdf' target='_blank'>https://arxiv.org/pdf/2305.08929.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongju Yuan, Tao Shen, Sheng Xu, Leiye Yu, Ruobing Ren, Siqi Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.08929">AF2-Mutation: Adversarial Sequence Mutations against AlphaFold2 on Protein Tertiary Structure Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based approaches, such as AlphaFold2 (AF2), have significantly advanced protein tertiary structure prediction, achieving results comparable to real biological experimental methods. While AF2 has shown limitations in predicting the effects of mutations, its robustness against sequence mutations remains to be determined. Starting with the wild-type (WT) sequence, we investigate adversarial sequences generated via an evolutionary approach, which AF2 predicts to be substantially different from WT. Our experiments on CASP14 reveal that by modifying merely three residues in the protein sequence using a combination of replacement, deletion, and insertion strategies, the alteration in AF2's predictions, as measured by the Local Distance Difference Test (lDDT), reaches 46.61. Moreover, when applied to a specific protein, SPNS2, our proposed algorithm successfully identifies biologically meaningful residues critical to protein structure determination and potentially indicates alternative conformations, thus significantly expediting the experimental process.
<div id='section'>Paperid: <span id='pid'>675, <a href='https://arxiv.org/pdf/2304.02656.pdf' target='_blank'>https://arxiv.org/pdf/2304.02656.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinye Xiong, Bingxin Zhou, Yu Guang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.02656">Graph Representation Learning for Interactive Biomolecule Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in deep learning models have revolutionized the study of biomolecule systems and their mechanisms. Graph representation learning, in particular, is important for accurately capturing the geometric information of biomolecules at different levels. This paper presents a comprehensive review of the methodologies used to represent biological molecules and systems as computer-recognizable objects, such as sequences, graphs, and surfaces. Moreover, it examines how geometric deep learning models, with an emphasis on graph-based techniques, can analyze biomolecule data to enable drug discovery, protein characterization, and biological system analysis. The study concludes with an overview of the current state of the field, highlighting the challenges that exist and the potential future research directions.
<div id='section'>Paperid: <span id='pid'>676, <a href='https://arxiv.org/pdf/2302.13053.pdf' target='_blank'>https://arxiv.org/pdf/2302.13053.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aashish Kolluri, Sarthak Choudhary, Bryan Hooi, Prateek Saxena
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.13053">Scalable Neural Network Training over Distributed Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph neural networks (GNNs) fuel diverse machine learning tasks involving graph-structured data, ranging from predicting protein structures to serving personalized recommendations. Real-world graph data must often be stored distributed across many machines not just because of capacity constraints, but because of compliance with data residency or privacy laws. In such setups, network communication is costly and becomes the main bottleneck to train GNNs. Optimizations for distributed GNN training have targeted data-level improvements so far -- via caching, network-aware partitioning, and sub-sampling -- that work for data center-like setups where graph data is accessible to a single entity and data transfer costs are ignored.
  We present RETEXO, the first framework which eliminates the severe communication bottleneck in distributed GNN training while respecting any given data partitioning configuration. The key is a new training procedure, lazy message passing, that reorders the sequence of training GNN elements. RETEXO achieves 1-2 orders of magnitude reduction in network data costs compared to standard GNN training, while retaining accuracy. RETEXO scales gracefully with increasing decentralization and decreasing bandwidth. It is the first framework that can be used to train GNNs at all network decentralization levels -- including centralized data-center networks, wide area networks, proximity networks, and edge networks.
<div id='section'>Paperid: <span id='pid'>677, <a href='https://arxiv.org/pdf/2302.03907.pdf' target='_blank'>https://arxiv.org/pdf/2302.03907.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan Kralj, BlaÅ¾ Å krlj, Å½iva RamÅ¡ak, Nada LavraÄ, Kristina Gruden
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.03907">DDeMON: Ontology-based function prediction by Deep Learning from Dynamic Multiplex Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biological systems can be studied at multiple levels of information, including gene, protein, RNA and different interaction networks levels. The goal of this work is to explore how the fusion of systems' level information with temporal dynamics of gene expression can be used in combination with non-linear approximation power of deep neural networks to predict novel gene functions in a non-model organism potato \emph{Solanum tuberosum}. We propose DDeMON (Dynamic Deep learning from temporal Multiplex Ontology-annotated Networks), an approach for scalable, systems-level inference of function annotation using time-dependent multiscale biological information. The proposed method, which is capable of considering billions of potential links between the genes of interest, was applied on experimental gene expression data and the background knowledge network to reliably classify genes with unknown function into five different functional ontology categories, linked to the experimental data set. Predicted novel functions of genes were validated using extensive protein domain search approach.
<div id='section'>Paperid: <span id='pid'>678, <a href='https://arxiv.org/pdf/2301.08553.pdf' target='_blank'>https://arxiv.org/pdf/2301.08553.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kim G. Larsen, Daniele Toller, Mirco Tribastone, Max Tschaikowski, Andrea Vandin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.08553">Optimality-preserving Reduction of Chemical Reaction Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Across many disciplines, chemical reaction networks (CRNs) are an established population model defined as a system of coupled nonlinear ordinary differential equations. In many applications, for example, in systems biology and epidemiology, CRN parameters such as the kinetic reaction rates can be used as control inputs to steer the system toward a given target. Unfortunately, the resulting optimal control problem is nonlinear, therefore, computationally very challenging. We address this issue by introducing an optimality-preserving reduction algorithm for CRNs. The algorithm partitions the original state variables into a reduced set of macro-variables for which one can define a reduced optimal control problem from which one can exactly recover the solution of the original control problem. Notably, the reduction algorithm runs with polynomial time complexity in the size of the CRN. We use this result to reduce reachability and control problems of large-scale protein-interaction networks and vaccination models with hundreds of thousands of state variables.
<div id='section'>Paperid: <span id='pid'>679, <a href='https://arxiv.org/pdf/2210.06069.pdf' target='_blank'>https://arxiv.org/pdf/2210.06069.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangtian Zhang, Huiyu Cai, Chence Shi, Bozitao Zhong, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.06069">E3Bind: An End-to-End Equivariant Network for Protein-Ligand Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In silico prediction of the ligand binding pose to a given protein target is a crucial but challenging task in drug discovery. This work focuses on blind flexible selfdocking, where we aim to predict the positions, orientations and conformations of docked molecules. Traditional physics-based methods usually suffer from inaccurate scoring functions and high inference cost. Recently, data-driven methods based on deep learning techniques are attracting growing interest thanks to their efficiency during inference and promising performance. These methods usually either adopt a two-stage approach by first predicting the distances between proteins and ligands and then generating the final coordinates based on the predicted distances, or directly predicting the global roto-translation of ligands. In this paper, we take a different route. Inspired by the resounding success of AlphaFold2 for protein structure prediction, we propose E3Bind, an end-to-end equivariant network that iteratively updates the ligand pose. E3Bind models the protein-ligand interaction through careful consideration of the geometric constraints in docking and the local context of the binding site. Experiments on standard benchmark datasets demonstrate the superior performance of our end-to-end trainable model compared to traditional and recently-proposed deep learning methods.
<div id='section'>Paperid: <span id='pid'>680, <a href='https://arxiv.org/pdf/2509.13216.pdf' target='_blank'>https://arxiv.org/pdf/2509.13216.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rebecca Manuela Neeser, Ilia Igashov, Arne Schneuing, Michael Bronstein, Philippe Schwaller, Bruno Correia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13216">Flow-Based Fragment Identification via Binding Site-Specific Latent Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fragment-based drug design is a promising strategy leveraging the binding of small chemical moieties that can efficiently guide drug discovery. The initial step of fragment identification remains challenging, as fragments often bind weakly and non-specifically. We developed a protein-fragment encoder that relies on a contrastive learning approach to map both molecular fragments and protein surfaces in a shared latent space. The encoder captures interaction-relevant features and allows to perform virtual screening as well as generative design with our new method LatentFrag. In LatentFrag, fragment embeddings and positions are generated conditioned on the protein surface while being chemically realistic by construction. Our expressive fragment and protein representations allow location of protein-fragment interaction sites with high sensitivity and we observe state-of-the-art fragment recovery rates when sampling from the learned distribution of latent fragment embeddings. Our generative method outperforms common methods such as virtual screening at a fraction of its computational cost providing a valuable starting point for fragment hit discovery. We further show the practical utility of LatentFrag and extend the workflow to full ligand design tasks. Together, these approaches contribute to advancing fragment identification and provide valuable tools for fragment-based drug discovery.
<div id='section'>Paperid: <span id='pid'>681, <a href='https://arxiv.org/pdf/2509.01486.pdf' target='_blank'>https://arxiv.org/pdf/2509.01486.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyuan Zhou, Hao Qian, Shikui Tu, Lei Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01486">Prior-Guided Flow Matching for Target-Aware Molecule Design with Learnable Atom Number</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug design (SBDD), aiming to generate 3D molecules with high binding affinity toward target proteins, is a vital approach in novel drug discovery. Although recent generative models have shown great potential, they suffer from unstable probability dynamics and mismatch between generated molecule size and the protein pockets geometry, resulting in inconsistent quality and off-target effects. We propose PAFlow, a novel target-aware molecular generation model featuring prior interaction guidance and a learnable atom number predictor. PAFlow adopts the efficient flow matching framework to model the generation process and constructs a new form of conditional flow matching for discrete atom types. A protein-ligand interaction predictor is incorporated to guide the vector field toward higher-affinity regions during generation, while an atom number predictor based on protein pocket information is designed to better align generated molecule size with target geometry. Extensive experiments on the CrossDocked2020 benchmark show that PAFlow achieves a new state-of-the-art in binding affinity (up to -8.31 Avg. Vina Score), simultaneously maintains favorable molecular properties.
<div id='section'>Paperid: <span id='pid'>682, <a href='https://arxiv.org/pdf/2508.17815.pdf' target='_blank'>https://arxiv.org/pdf/2508.17815.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arne Schneuing, Ilia Igashov, Adrian W. Dobbelstein, Thomas Castiglione, Michael Bronstein, Bruno Correia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17815">Multi-domain Distribution Learning for De Novo Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce DrugFlow, a generative model for structure-based drug design that integrates continuous flow matching with discrete Markov bridges, demonstrating state-of-the-art performance in learning chemical, geometric, and physical aspects of three-dimensional protein-ligand data. We endow DrugFlow with an uncertainty estimate that is able to detect out-of-distribution samples. To further enhance the sampling process towards distribution regions with desirable metric values, we propose a joint preference alignment scheme applicable to both flow matching and Markov bridge frameworks. Furthermore, we extend our model to also explore the conformational landscape of the protein by jointly sampling side chain angles and molecules.
<div id='section'>Paperid: <span id='pid'>683, <a href='https://arxiv.org/pdf/2508.10775.pdf' target='_blank'>https://arxiv.org/pdf/2508.10775.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dong Xu, Zhangfan Yang, Jenna Xinyi Yao, Shuangbao Song, Zexuan Zhu, Junkai Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10775">IBEX: Information-Bottleneck-EXplored Coarse-to-Fine Molecular Generation under Limited Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Three-dimensional generative models increasingly drive structure-based drug discovery, yet it remains constrained by the scarce publicly available protein-ligand complexes. Under such data scarcity, almost all existing pipelines struggle to learn transferable geometric priors and consequently overfit to training-set biases. As such, we present IBEX, an Information-Bottleneck-EXplored coarse-to-fine pipeline to tackle the chronic shortage of protein-ligand complex data in structure-based drug design. Specifically, we use PAC-Bayesian information-bottleneck theory to quantify the information density of each sample. This analysis reveals how different masking strategies affect generalization and indicates that, compared with conventional de novo generation, the constrained Scaffold Hopping task endows the model with greater effective capacity and improved transfer performance. IBEX retains the original TargetDiff architecture and hyperparameters for training to generate molecules compatible with the binding pocket; it then applies an L-BFGS optimization step to finely refine each conformation by optimizing five physics-based terms and adjusting six translational and rotational degrees of freedom in under one second. With only these modifications, IBEX raises the zero-shot docking success rate on CBGBench CrossDocked2020-based from 53% to 64%, improves the mean Vina score from $-7.41 kcal mol^{-1}$ to $-8.07 kcal mol^{-1}$, and achieves the best median Vina energy in 57 of 100 pockets versus 3 for the original TargetDiff. IBEX also increases the QED by 25%, achieves state-of-the-art validity and diversity, and markedly reduces extrapolation error.
<div id='section'>Paperid: <span id='pid'>684, <a href='https://arxiv.org/pdf/2507.15226.pdf' target='_blank'>https://arxiv.org/pdf/2507.15226.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Changguo Jia, Yi Zhan, Tianqi Zhao, Hengzhi Ye, Minghui Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.15226">Code Clone Detection via an AlphaFold-Inspired Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Code clone detection, which aims to identify functionally equivalent code fragments, plays a critical role in software maintenance and vulnerability analysis. Substantial methods have been proposed to detect code clones, but they fall short in capturing code semantics or relying on language-specific analyzers. Inspired by the remarkable success of AlphaFold in predicting three-dimensional protein structures from protein sequences, in this paper, we leverage AlphaFold for code clone detection based on the insight that protein sequences and token sequences share a common linear sequential structure. In particular, we propose AlphaCC, which represents code fragments as token sequences to ensure multi-language applicability and adapts AlphaFold's sequence-to-structure modeling capability to infer code semantics. The pipeline of AlphaCC goes through three steps. First, AlphaCC transforms each input code fragment into a token sequence and, motivated by AlphaFold's use of multiple sequence alignment (MSA) to enhance contextual understanding, constructs an MSA from lexically similar token sequences. Second, AlphaCC adopts a modified attention-based encoder based on AlphaFold to model dependencies within and across token sequences. Finally, unlike AlphaFold's protein structure prediction task, AlphaCC computes similarity scores between token sequences through a late interaction strategy and performs binary classification to determine code clone pairs. Comprehensive evaluations on three language-diverse datasets demonstrate AlphaCC's applicability across multiple programming languages. On two semantic clone detection datasets, it consistently outperforms all baselines, showing strong semantic understanding. Moreover, AlphaCC maintains competitive efficiency, enabling practical usage in large-scale clone detection tasks.
<div id='section'>Paperid: <span id='pid'>685, <a href='https://arxiv.org/pdf/2507.07201.pdf' target='_blank'>https://arxiv.org/pdf/2507.07201.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dong Xu, Zhangfan Yang, Sisi Yuan, Jenna Xinyi Yao, Jiangqiang Li, Junkai Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07201">MODA: A Unified 3D Diffusion Framework for Multi-Task Target-Aware Molecular Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Three-dimensional molecular generators based on diffusion models can now reach near-crystallographic accuracy, yet they remain fragmented across tasks. SMILES-only inputs, two-stage pretrain-finetune pipelines, and one-task-one-model practices hinder stereochemical fidelity, task alignment, and zero-shot transfer. We introduce MODA, a diffusion framework that unifies fragment growing, linker design, scaffold hopping, and side-chain decoration with a Bayesian mask scheduler. During training, a contiguous spatial fragment is masked and then denoised in one pass, enabling the model to learn shared geometric and chemical priors across tasks. Multi-task training yields a universal backbone that surpasses six diffusion baselines and three training paradigms on substructure, chemical property, interaction, and geometry. Model-C reduces ligand-protein clashes and substructure divergences while maintaining Lipinski compliance, whereas Model-B preserves similarity but trails in novelty and binding affinity. Zero-shot de novo design and lead-optimisation tests confirm stable negative Vina scores and high improvement rates without force-field refinement. These results demonstrate that a single-stage multi-task diffusion routine can replace two-stage workflows for structure-based molecular design.
<div id='section'>Paperid: <span id='pid'>686, <a href='https://arxiv.org/pdf/2507.07032.pdf' target='_blank'>https://arxiv.org/pdf/2507.07032.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanqun Cao, Xinyi Zhou, Zijun Gao, Chenyu Wang, Xin Gao, Zhi Zhang, Chunbin Gu, Ge Liu, Pheng-Ann Heng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07032">PLAME: Lightweight MSA Design Advances Protein Folding From Evolutionary Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structure prediction often hinges on multiple sequence alignments (MSAs), which underperform on low-homology and orphan proteins. We introduce PLAME, a lightweight MSA design framework that leverages evolutionary embeddings from pretrained protein language models to generate MSAs that better support downstream folding. PLAME couples these embeddings with a conservation-diversity loss that balances agreement on conserved positions with coverage of plausible sequence variation. Beyond generation, we develop (i) an MSA selection strategy to filter high-quality candidates and (ii) a sequence-quality metric that is complementary to depth-based measures and predictive of folding gains. On AlphaFold2 low-homology/orphan benchmarks, PLAME delivers state-of-the-art improvements in structure accuracy (e.g., lDDT/TM-score), with consistent gains when paired with AlphaFold3. Ablations isolate the benefits of the selection strategy, and case studies elucidate how MSA characteristics shape AlphaFold confidence and error modes. Finally, we show PLAME functions as a lightweight adapter, enabling ESMFold to approach AlphaFold2-level accuracy while retaining ESMFold-like inference speed. PLAME thus provides a practical path to high-quality folding for proteins lacking strong evolutionary neighbors.
<div id='section'>Paperid: <span id='pid'>687, <a href='https://arxiv.org/pdf/2506.14488.pdf' target='_blank'>https://arxiv.org/pdf/2506.14488.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dong Xu, Zhangfan Yang, Ka-chun Wong, Zexuan Zhu, Jiangqiang Li, Junkai Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14488">Reimagining Target-Aware Molecular Generation through Retrieval-Enhanced Aligned Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Breakthroughs in high-accuracy protein structure prediction, such as AlphaFold, have established receptor-based molecule design as a critical driver for rapid early-phase drug discovery. However, most approaches still struggle to balance pocket-specific geometric fit with strict valence and synthetic constraints. To resolve this trade-off, a Retrieval-Enhanced Aligned Diffusion termed READ is introduced, which is the first to merge molecular Retrieval-Augmented Generation with an SE(3)-equivariant diffusion model. Specifically, a contrastively pre-trained encoder aligns atom-level representations during training, then retrieves graph embeddings of pocket-matched scaffolds to guide each reverse-diffusion step at inference. This single mechanism can inject real-world chemical priors exactly where needed, producing valid, diverse, and shape-complementary ligands. Experimental results demonstrate that READ can achieve very competitive performance in CBGBench, surpassing state-of-the-art generative models and even native ligands. That suggests retrieval and diffusion can be co-optimized for faster, more reliable structure-based drug design.
<div id='section'>Paperid: <span id='pid'>688, <a href='https://arxiv.org/pdf/2506.07459.pdf' target='_blank'>https://arxiv.org/pdf/2506.07459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziwen Wang, Jiajun Fan, Ruihan Guo, Thao Nguyen, Heng Ji, Ge Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.07459">ProteinZero: Self-Improving Protein Generation via Online Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein generative models have shown remarkable promise in protein design but still face limitations in success rate, due to the scarcity of high-quality protein datasets for supervised pretraining. We present ProteinZero, a novel framework that enables scalable, automated, and continuous self-improvement of the inverse folding model through online reinforcement learning. To achieve computationally tractable online feedback, we introduce efficient proxy reward models based on ESM-fold and a novel rapid ddG predictor that significantly accelerates evaluation speed. ProteinZero employs a general RL framework balancing multi-reward maximization, KL-divergence from a reference model, and a novel protein-embedding level diversity regularization that prevents mode collapse while promoting higher sequence diversity. Through extensive experiments, we demonstrate that ProteinZero substantially outperforms existing methods across every key metric in protein design, achieving significant improvements in structural accuracy, designability, thermodynamic stability, and sequence diversity. Most impressively, ProteinZero reduces design failure rates by approximately 36% - 48% compared to widely-used methods like ProteinMPNN, ESM-IF and InstructPLM, consistently achieving success rates exceeding 90% across diverse and complex protein folds. Notably, the entire RL run on CATH-4.3 can be done with a single 8 X GPU node in under 3 days, including reward computation. Our work establishes a new paradigm for protein design where models evolve continuously from their own generated outputs, opening new possibilities for exploring the vast protein design space.
<div id='section'>Paperid: <span id='pid'>689, <a href='https://arxiv.org/pdf/2506.05596.pdf' target='_blank'>https://arxiv.org/pdf/2506.05596.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jes Frellsen, Maher M. Kassem, Tone Bengtsen, Lars Olsen, Kresten Lindorff-Larsen, Jesper Ferkinghoff-Borg, Wouter Boomsma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.05596">Zero-shot protein stability prediction by inverse folding models: a free energy interpretation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse folding models have proven to be highly effective zero-shot predictors of protein stability. Despite this success, the link between the amino acid preferences of an inverse folding model and the free-energy considerations underlying thermodynamic stability remains incompletely understood. A better understanding would be of interest not only from a theoretical perspective, but also potentially provide the basis for stronger zero-shot stability prediction. In this paper, we take steps to clarify the free-energy foundations of inverse folding models. Our derivation reveals the standard practice of likelihood ratios as a simplistic approximation and suggests several paths towards better estimates of the relative stability. We empirically assess these approaches and demonstrate that considerable gains in zero-shot performance can be achieved with fairly simple means.
<div id='section'>Paperid: <span id='pid'>690, <a href='https://arxiv.org/pdf/2505.15093.pdf' target='_blank'>https://arxiv.org/pdf/2505.15093.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jason Yang, Wenda Chu, Daniel Khalil, Raul Astudillo, Bruce J. Wittmann, Frances H. Arnold, Yisong Yue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15093">Steering Generative Models with Experimental Data for Protein Fitness Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein fitness optimization involves finding a protein sequence that maximizes desired quantitative properties in a combinatorially large design space of possible sequences. Recent developments in steering protein generative models (e.g diffusion models, language models) offer a promising approach. However, by and large, past studies have optimized surrogate rewards and/or utilized large amounts of labeled data for steering, making it unclear how well existing methods perform and compare to each other in real-world optimization campaigns where fitness is measured by low-throughput wet-lab assays. In this study, we explore fitness optimization using small amounts (hundreds) of labeled sequence-fitness pairs and comprehensively evaluate strategies such as classifier guidance and posterior sampling for guiding generation from different discrete diffusion models of protein sequences. We also demonstrate how guidance can be integrated into adaptive sequence selection akin to Thompson sampling in Bayesian optimization, showing that plug-and-play guidance strategies offer advantages compared to alternatives such as reinforcement learning with protein language models.
<div id='section'>Paperid: <span id='pid'>691, <a href='https://arxiv.org/pdf/2504.19017.pdf' target='_blank'>https://arxiv.org/pdf/2504.19017.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Ghafarollahi, Markus J. Buehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.19017">Sparks: Multi-Agent Artificial Intelligence Model Discovers Protein Design Principles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in artificial intelligence (AI) promise autonomous discovery, yet most systems still resurface knowledge latent in their training data. We present Sparks, a multi-modal multi-agent AI model that executes the entire discovery cycle that includes hypothesis generation, experiment design and iterative refinement to develop generalizable principles and a report without human intervention. Applied to protein science, Sparks uncovered two previously unknown phenomena: (i) a length-dependent mechanical crossover whereby beta-sheet-biased peptides surpass alpha-helical ones in unfolding force beyond ~80 residues, establishing a new design principle for peptide mechanics; and (ii) a chain-length/secondary-structure stability map revealing unexpectedly robust beta-sheet-rich architectures and a "frustration zone" of high variance in mixed alpha/beta folds. These findings emerged from fully self-directed reasoning cycles that combined generative sequence design, high-accuracy structure prediction and physics-aware property models, with paired generation-and-reflection agents enforcing self-correction and reproducibility. The key result is that Sparks can independently conduct rigorous scientific inquiry and identify previously unknown scientific principles.
<div id='section'>Paperid: <span id='pid'>692, <a href='https://arxiv.org/pdf/2504.06806.pdf' target='_blank'>https://arxiv.org/pdf/2504.06806.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan Rossi, Guido Barducci, Tiziana Sanavia, Paola Turina, Emidio Capriotti, Piero Fariselli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.06806">Mass Balance Approximation of Unfolding Improves Potential-Like Methods for Protein Stability Predictions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The prediction of protein stability changes following single-point mutations plays a pivotal role in computational biology, particularly in areas like drug discovery, enzyme reengineering, and genetic disease analysis. Although deep-learning strategies have pushed the field forward, their use in standard workflows remains limited due to resource demands. Conversely, potential-like methods are fast, intuitive, and efficient. Yet, these typically estimate Gibbs free energy shifts without considering the free-energy variations in the unfolded protein state, an omission that may breach mass balance and diminish accuracy. This study shows that incorporating a mass-balance correction (MBC) to account for the unfolded state significantly enhances these methods. While many machine learning models partially model this balance, our analysis suggests that a refined representation of the unfolded state may improve the predictive performance.
<div id='section'>Paperid: <span id='pid'>693, <a href='https://arxiv.org/pdf/2503.19186.pdf' target='_blank'>https://arxiv.org/pdf/2503.19186.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Parisa Mollaei, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.19186">Protein Structure-Function Relationship: A Kernel-PCA Approach for Reaction Coordinate Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we propose a Kernel-PCA model designed to capture structure-function relationships in a protein. This model also enables ranking of reaction coordinates according to their impact on protein properties. By leveraging machine learning techniques, including Kernel and principal component analysis (PCA), our model uncovers meaningful patterns in high-dimensional protein data obtained from molecular dynamics (MD) simulations. The effectiveness of our model in accurately identifying reaction coordinates has been demonstrated through its application to a G protein-coupled receptor. Furthermore, this model utilizes a network-based approach to uncover correlations in the dynamic behavior of residues associated with a specific protein property. These findings underscore the potential of our model as a powerful tool for protein structure-function analysis and visualization.
<div id='section'>Paperid: <span id='pid'>694, <a href='https://arxiv.org/pdf/2503.00648.pdf' target='_blank'>https://arxiv.org/pdf/2503.00648.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gian Marco Visani, Michael N. Pun, Anastasia A. Minervina, Philip Bradley, Paul Thomas, Armita Nourmohammad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00648">T-cell receptor specificity landscape revealed through de novo peptide design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>T-cells play a key role in adaptive immunity by mounting specific responses against diverse pathogens. An effective binding between T-cell receptors (TCRs) and pathogen-derived peptides presented on Major Histocompatibility Complexes (MHCs) mediate an immune response. However, predicting these interactions remains challenging due to limited functional data on T-cell reactivities. Here, we introduce a computational approach to predict TCR interactions with peptides presented on MHC class I alleles, and to design novel immunogenic peptides for specified TCR-MHC complexes. Our method leverages HERMES, a structure-based, physics-guided machine learning model trained on the protein universe to predict amino acid preferences based on local structural environments. Despite no direct training on TCR-pMHC data, the implicit physical reasoning in HERMES enables us to make accurate predictions of both TCR-pMHC binding affinities and T-cell activities across diverse viral epitopes and cancer neoantigens, achieving up to 0.72 correlation with experimental data. Leveraging our TCR recognition model, we develop a computational protocol for de novo design of immunogenic peptides. Through experimental validation in three TCR-MHC systems targeting viral and cancer peptides, we demonstrate that our designs -- with up to five substitutions from the native sequence -- activate T-cells at success rates of up to 50%. Lastly, we use our generative framework to quantify the diversity of the peptide recognition landscape for various TCR-MHC complexes, offering key insights into T-cell specificity in both humans and mice. Our approach provides a platform for immunogenic peptide and neoantigen design, as well as for evaluating TCR specificity, offering a computational framework to inform design of engineered T-cell therapies and vaccines.
<div id='section'>Paperid: <span id='pid'>695, <a href='https://arxiv.org/pdf/2502.19794.pdf' target='_blank'>https://arxiv.org/pdf/2502.19794.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuanliu Fan, Ziqiang Cao, Zicheng Ma, Nan Yu, Yimin Peng, Jun Zhang, Yiqin Gao, Guohong Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19794">ChatMol: A Versatile Molecule Designer Based on the Numerically Enhanced Large Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Goal-oriented de novo molecule design, namely generating molecules with specific property or substructure constraints, is a crucial yet challenging task in drug discovery. Existing methods, such as Bayesian optimization and reinforcement learning, often require training multiple property predictors and struggle to incorporate substructure constraints. Inspired by the success of Large Language Models (LLMs) in text generation, we propose ChatMol, a novel approach that leverages LLMs for molecule design across diverse constraint settings. Initially, we crafted a molecule representation compatible with LLMs and validated its efficacy across multiple online LLMs. Afterwards, we developed specific prompts geared towards diverse constrained molecule generation tasks to further fine-tune current LLMs while integrating feedback learning derived from property prediction. Finally, to address the limitations of LLMs in numerical recognition, we referred to the position encoding method and incorporated additional encoding for numerical values within the prompt. Experimental results across single-property, substructure-property, and multi-property constrained tasks demonstrate that ChatMol consistently outperforms state-of-the-art baselines, including VAE and RL-based methods. Notably, in multi-objective binding affinity maximization task, ChatMol achieves a significantly lower KD value of 0.25 for the protein target ESR1, while maintaining the highest overall performance, surpassing previous methods by 4.76%. Meanwhile, with numerical enhancement, the Pearson correlation coefficient between the instructed property values and those of the generated molecules increased by up to 0.49. These findings highlight the potential of LLMs as a versatile framework for molecule generation, offering a promising alternative to traditional latent space and RL-based approaches.
<div id='section'>Paperid: <span id='pid'>696, <a href='https://arxiv.org/pdf/2502.19173.pdf' target='_blank'>https://arxiv.org/pdf/2502.19173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gregory W. Kyro, Tianyin Qiu, Victor S. Batista
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19173">A Model-Centric Review of Deep Learning for Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has transformed protein design, enabling accurate structure prediction, sequence optimization, and de novo protein generation. Advances in single-chain protein structure prediction via AlphaFold2, RoseTTAFold, ESMFold, and others have achieved near-experimental accuracy, inspiring successive work extended to biomolecular complexes via AlphaFold Multimer, RoseTTAFold All-Atom, AlphaFold 3, Chai-1, Boltz-1 and others. Generative models such as ProtGPT2, ProteinMPNN, and RFdiffusion have enabled sequence and backbone design beyond natural evolution-based limitations. More recently, joint sequence-structure co-design models, including ESM3, have integrated both modalities into a unified framework, resulting in improved designability. Despite these advances, challenges still exist pertaining to modeling sequence-structure-function relationships and ensuring robust generalization beyond the regions of protein space spanned by the training data. Future advances will likely focus on joint sequence-structure-function co-design frameworks that are able to model the fitness landscape more effectively than models that treat these modalities independently. Current capabilities, coupled with the dizzying rate of progress, suggest that the field will soon enable rapid, rational design of proteins with tailored structures and functions that transcend the limitations imposed by natural evolution. In this review, we discuss the current capabilities of deep learning methods for protein design, focusing on some of the most revolutionary and capable models with respect to their functionality and the applications that they enable, leading up to the current challenges of the field and the optimal path forward.
<div id='section'>Paperid: <span id='pid'>697, <a href='https://arxiv.org/pdf/2502.06846.pdf' target='_blank'>https://arxiv.org/pdf/2502.06846.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhicong Wang, Zicheng Ma, Ziqiang Cao, Changlong Zhou, Jun Zhang, Yiqin Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06846">Prot2Chat: Protein LLM with Early-Fusion of Text, Sequence and Structure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motivation: Proteins are of great significance in living organisms. However, understanding their functions encounters numerous challenges, such as insufficient integration of multimodal information, a large number of training parameters, limited flexibility of classification-based methods, and the lack of systematic evaluation metrics for protein Q&A systems. To tackle these issues, we propose the Prot2Chat framework. Results: We modified ProteinMPNN to encode protein sequence and structural information in a unified way. We used a large language model (LLM) to encode questions into vectors and developed a protein-text adapter to compress protein information into virtual tokens based on these vectors, achieving the early fusion of text and protein information. Finally, the same LLM reads the virtual tokens and the questions to generate answers. To optimize training efficiency, we froze the encoder and employed Low-Rank Adaptation (LoRA) techniques for the LLM. Experiments on two datasets show that both automated metrics and expert evaluations demonstrate the superior performance of our model, and zero-shot prediction results highlight its generalization ability. The models and codes are available at https://github.com/ wangzc1233/Prot2Chat. Contact: zqcao@suda.edu.cn or wangzc025@163.com Key words: Protein Q&A, Early-Fusion, LLM
<div id='section'>Paperid: <span id='pid'>698, <a href='https://arxiv.org/pdf/2502.00529.pdf' target='_blank'>https://arxiv.org/pdf/2502.00529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arijit Khan, Xiangyu Ke, Yinghui Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00529">Graph Data Management and Graph Machine Learning: Synergies and Opportunities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ubiquity of machine learning, particularly deep learning, applied to graphs is evident in applications ranging from cheminformatics (drug discovery) and bioinformatics (protein interaction prediction) to knowledge graph-based query answering, fraud detection, and social network analysis. Concurrently, graph data management deals with the research and development of effective, efficient, scalable, robust, and user-friendly systems and algorithms for storing, processing, and analyzing vast quantities of heterogeneous and complex graph data. Our survey provides a comprehensive overview of the synergies between graph data management and graph machine learning, illustrating how they intertwine and mutually reinforce each other across the entire spectrum of the graph data science and machine learning pipeline. Specifically, the survey highlights two crucial aspects: (1) How graph data management enhances graph machine learning, including contributions such as improved graph neural network performance through graph data cleaning, scalable graph embedding, efficient graph-based vector data management, robust graph neural networks, user-friendly explainability methods; and (2) how graph machine learning, in turn, aids in graph data management, with a focus on applications like query answering over knowledge graphs and various data science tasks. We discuss pertinent open problems and delineate crucial research directions.
<div id='section'>Paperid: <span id='pid'>699, <a href='https://arxiv.org/pdf/2411.11808.pdf' target='_blank'>https://arxiv.org/pdf/2411.11808.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>AdriÃ¡n Morales-Pastor, Raquel VÃ¡zquez-Reza, MiÅosz WieczÃ³r, ClÃ udia Valverde, Manel Gil-Sorribes, Bertran Miquel-Oliver, Ãlvaro Ciudad, Alexis Molina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11808">Character-level Tokenizations as Powerful Inductive Biases for RNA Foundational Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>RNA is a vital biomolecule with numerous roles and functions within cells, and interest in targeting it for therapeutic purposes has grown significantly in recent years. However, fully understanding and predicting RNA behavior, particularly for applications in drug discovery, remains a challenge due to the complexity of RNA structures and interactions. While foundational models in biology have demonstrated success in modeling several biomolecules, especially proteins, achieving similar breakthroughs for RNA has proven more difficult. Current RNA models have yet to match the performance observed in the protein domain, leaving an important gap in computational biology. In this work, we present ChaRNABERT, a suite of sample and parameter-efficient RNA foundational models, that through a learnable tokenization process, are able to reach state-of-the-art performance on several tasks in established benchmarks. We extend its testing in relevant downstream tasks such as RNA-protein and aptamer-protein interaction prediction. Weights and inference code for ChaRNABERT-8M will be provided for academic research use. The other models will be available upon request.
<div id='section'>Paperid: <span id='pid'>700, <a href='https://arxiv.org/pdf/2411.11061.pdf' target='_blank'>https://arxiv.org/pdf/2411.11061.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoliang Luo, Michael Ramscar, Bradley C. Love
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11061">Beyond Human-Like Processing: Large Language Models Perform Equivalently on Forward and Backward Scientific Text</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The impressive performance of large language models (LLMs) has led to their consideration as models of human language processing. Instead, we suggest that the success of LLMs arises from the flexibility of the transformer learning architecture. To evaluate this conjecture, we trained LLMs on scientific texts that were either in a forward or backward format. Despite backward text being inconsistent with the structure of human languages, we found that LLMs performed equally well in either format on a neuroscience benchmark, eclipsing human expert performance for both forward and backward orders. Our results are consistent with the success of transformers across diverse domains, such as weather prediction and protein design. This widespread success is attributable to LLM's ability to extract predictive patterns from any sufficiently structured input. Given their generality, we suggest caution in interpreting LLM's success in linguistic tasks as evidence for human-like mechanisms.
<div id='section'>Paperid: <span id='pid'>701, <a href='https://arxiv.org/pdf/2411.10720.pdf' target='_blank'>https://arxiv.org/pdf/2411.10720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anya Chauhan, Ayush Noori, Zhaozhi Li, Yingnan He, Michelle M Li, Marinka Zitnik, Sudeshna Das
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.10720">Multi Scale Graph Neural Network for Alzheimer's Disease</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Alzheimer's disease (AD) is a complex, progressive neurodegenerative disorder characterized by extracellular A\b{eta} plaques, neurofibrillary tau tangles, glial activation, and neuronal degeneration, involving multiple cell types and pathways. Current models often overlook the cellular context of these pathways. To address this, we developed a multiscale graph neural network (GNN) model, ALZ PINNACLE, using brain omics data from donors spanning the entire aging to AD spectrum. ALZ PINNACLE is based on the PINNACLE GNN framework, which learns context-aware protein, cell type, and tissue representations within a unified latent space. ALZ PINNACLE was trained on 14,951 proteins, 206,850 protein interactions, 7 cell types, and 48 cell subtypes or states. After pretraining, we investigated the learned embedding of APOE, the largest genetic risk factor for AD, across different cell types. Notably, APOE embeddings showed high similarity in microglial, neuronal, and CD8 cells, suggesting a similar role of APOE in these cell types. Fine tuning the model on AD risk genes revealed cell type contexts predictive of the role of APOE in AD. Our results suggest that ALZ PINNACLE may provide a valuable framework for uncovering novel insights into AD neurobiology.
<div id='section'>Paperid: <span id='pid'>702, <a href='https://arxiv.org/pdf/2411.06090.pdf' target='_blank'>https://arxiv.org/pdf/2411.06090.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aya Abdelsalam Ismail, Tuomas Oikarinen, Amy Wang, Julius Adebayo, Samuel Stanton, Taylor Joren, Joseph Kleinhenz, Allen Goodman, HÃ©ctor Corrada Bravo, Kyunghyun Cho, Nathan C. Frey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.06090">Concept Bottleneck Language Models For protein design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Concept Bottleneck Protein Language Models (CB-pLM), a generative masked language model with a layer where each neuron corresponds to an interpretable concept. Our architecture offers three key benefits: i) Control: We can intervene on concept values to precisely control the properties of generated proteins, achieving a 3 times larger change in desired concept values compared to baselines. ii) Interpretability: A linear mapping between concept values and predicted tokens allows transparent analysis of the model's decision-making process. iii) Debugging: This transparency facilitates easy debugging of trained models. Our models achieve pre-training perplexity and downstream task performance comparable to traditional masked protein language models, demonstrating that interpretability does not compromise performance. While adaptable to any language model, we focus on masked protein language models due to their importance in drug discovery and the ability to validate our model's capabilities through real-world experiments and expert knowledge. We scale our CB-pLM from 24 million to 3 billion parameters, making them the largest Concept Bottleneck Models trained and the first capable of generative language modeling.
<div id='section'>Paperid: <span id='pid'>703, <a href='https://arxiv.org/pdf/2411.03972.pdf' target='_blank'>https://arxiv.org/pdf/2411.03972.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenning Liu, Xiantao Li, Chunhao Wang, Jin-Peng Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.03972">Toward end-to-end quantum simulation for protein dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling and simulating the protein folding process overall remains a grand challenge in computational biology. We systematically investigate end-to-end quantum algorithms for simulating various protein dynamics with effects, such as mechanical forces or stochastic noises. A major focus is the read-in of system settings for simulation, for which we discuss (i) efficient quantum algorithms to prepare initial states--whether for ensemble or single-state simulations, in particular, the first efficient procedure for preparing Gaussian pseudo-random amplitude states, and (ii) the first efficient loading of the connectivity matrices of the protein structure. For the read-out stage, our algorithms estimate a range of classical observables, including energy, low-frequency vibrational modes, density of states, displacement correlations, and optimal control parameters. Between these stages, we simulate the dynamic evolution of the protein system, by using normal mode models--such as Gaussian network models (GNM) and all-atom normal mode models. In addition, we conduct classical numerical experiments focused on accurately estimating the density of states and applying optimal control to facilitate conformational changes. These experiments serve to validate our claims regarding potential quantum speedups. Overall, our study demonstrates that quantum simulation of protein dynamics represents a robust, end-to-end application for both early-stage and fully fault-tolerant quantum computing.
<div id='section'>Paperid: <span id='pid'>704, <a href='https://arxiv.org/pdf/2410.21683.pdf' target='_blank'>https://arxiv.org/pdf/2410.21683.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihan Pengmei, Zhengyuan Shen, Zichen Wang, Marcus Collins, Huzefa Rangwala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21683">Pushing the Limits of All-Atom Geometric Graph Neural Networks: Pre-Training, Scaling and Zero-Shot Transfer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constructing transferable descriptors for conformation representation of molecular and biological systems finds numerous applications in drug discovery, learning-based molecular dynamics, and protein mechanism analysis. Geometric graph neural networks (Geom-GNNs) with all-atom information have transformed atomistic simulations by serving as a general learnable geometric descriptors for downstream tasks including prediction of interatomic potential and molecular properties. However, common practices involve supervising Geom-GNNs on specific downstream tasks, which suffer from the lack of high-quality data and inaccurate labels leading to poor generalization and performance degradation on out-of-distribution (OOD) scenarios. In this work, we explored the possibility of using pre-trained Geom-GNNs as transferable and highly effective geometric descriptors for improved generalization. To explore their representation power, we studied the scaling behaviors of Geom-GNNs under self-supervised pre-training, supervised and unsupervised learning setups. We find that the expressive power of different architectures can differ on the pre-training task. Interestingly, Geom-GNNs do not follow the power-law scaling on the pre-training task, and universally lack predictable scaling behavior on the supervised tasks with quantum chemical labels important for screening and design of novel molecules. More importantly, we demonstrate how all-atom graph embedding can be organically combined with other neural architectures to enhance the expressive power. Meanwhile, the low-dimensional projection of the latent space shows excellent agreement with conventional geometrical descriptors.
<div id='section'>Paperid: <span id='pid'>705, <a href='https://arxiv.org/pdf/2410.14946.pdf' target='_blank'>https://arxiv.org/pdf/2410.14946.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanqun Cao, Mutian He, Ning Ma, Chang-yu Hsieh, Chunbin Gu, Pheng-Ann Heng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14946">DEL-Ranking: Ranking-Correction Denoising Framework for Elucidating Molecular Affinities in DNA-Encoded Libraries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>DNA-encoded library (DEL) screening has revolutionized the detection of protein-ligand interactions through read counts, enabling rapid exploration of vast chemical spaces. However, noise in read counts, stemming from nonspecific interactions, can mislead this exploration process. We present DEL-Ranking, a novel distribution-correction denoising framework that addresses these challenges. Our approach introduces two key innovations: (1) a novel ranking loss that rectifies relative magnitude relationships between read counts, enabling the learning of causal features determining activity levels, and (2) an iterative algorithm employing self-training and consistency loss to establish model coherence between activity label and read count predictions. Furthermore, we contribute three new DEL screening datasets, the first to comprehensively include multi-dimensional molecular representations, protein-ligand enrichment values, and their activity labels. These datasets mitigate data scarcity issues in AI-driven DEL screening research. Rigorous evaluation on diverse DEL datasets demonstrates DEL-Ranking's superior performance across multiple correlation metrics, with significant improvements in binding affinity prediction accuracy. Our model exhibits zero-shot generalization ability across different protein targets and successfully identifies potential motifs determining compound binding affinity. This work advances DEL screening analysis and provides valuable resources for future research in this area.
<div id='section'>Paperid: <span id='pid'>706, <a href='https://arxiv.org/pdf/2410.09667.pdf' target='_blank'>https://arxiv.org/pdf/2410.09667.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Allan dos Santos Costa, Ilan Mitnikov, Franco Pellegrini, Ameya Daigavane, Mario Geiger, Zhonglin Cao, Karsten Kreis, Tess Smidt, Emine Kucukbenli, Joseph Jacobson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.09667">EquiJump: Protein Dynamics Simulation via SO(3)-Equivariant Stochastic Interpolants</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mapping the conformational dynamics of proteins is crucial for elucidating their functional mechanisms. While Molecular Dynamics (MD) simulation enables detailed time evolution of protein motion, its computational toll hinders its use in practice. To address this challenge, multiple deep learning models for reproducing and accelerating MD have been proposed drawing on transport-based generative methods. However, existing work focuses on generation through transport of samples from prior distributions, that can often be distant from the data manifold. The recently proposed framework of stochastic interpolants, instead, enables transport between arbitrary distribution endpoints. Building upon this work, we introduce EquiJump, a transferable SO(3)-equivariant model that bridges all-atom protein dynamics simulation time steps directly. Our approach unifies diverse sampling methods and is benchmarked against existing models on trajectory data of fast folding proteins. EquiJump achieves state-of-the-art results on dynamics simulation with a transferable model on all of the fast folding proteins.
<div id='section'>Paperid: <span id='pid'>707, <a href='https://arxiv.org/pdf/2409.18582.pdf' target='_blank'>https://arxiv.org/pdf/2409.18582.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Melis Ilayda Bal, Pier Giuseppe Sessa, Mojmir Mutny, Andreas Krause
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.18582">Optimistic Games for Combinatorial Bayesian Optimization with Application to Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian optimization (BO) is a powerful framework to optimize black-box expensive-to-evaluate functions via sequential interactions. In several important problems (e.g. drug discovery, circuit design, neural architecture search, etc.), though, such functions are defined over large $\textit{combinatorial and unstructured}$ spaces. This makes existing BO algorithms not feasible due to the intractable maximization of the acquisition function over these domains. To address this issue, we propose $\textbf{GameOpt}$, a novel game-theoretical approach to combinatorial BO. $\textbf{GameOpt}$ establishes a cooperative game between the different optimization variables, and selects points that are game $\textit{equilibria}$ of an upper confidence bound acquisition function. These are stable configurations from which no variable has an incentive to deviate$-$ analog to local optima in continuous domains. Crucially, this allows us to efficiently break down the complexity of the combinatorial domain into individual decision sets, making $\textbf{GameOpt}$ scalable to large combinatorial spaces. We demonstrate the application of $\textbf{GameOpt}$ to the challenging $\textit{protein design}$ problem and validate its performance on four real-world protein datasets. Each protein can take up to $20^{X}$ possible configurations, where $X$ is the length of a protein, making standard BO methods infeasible. Instead, our approach iteratively selects informative protein configurations and very quickly discovers highly active protein variants compared to other baselines.
<div id='section'>Paperid: <span id='pid'>708, <a href='https://arxiv.org/pdf/2409.18201.pdf' target='_blank'>https://arxiv.org/pdf/2409.18201.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kevin Borisiak, Gian Marco Visani, Armita Nourmohammad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.18201">Loop-Diffusion: an equivariant diffusion model for designing and scoring protein loops</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting protein functional characteristics from structure remains a central problem in protein science, with broad implications from understanding the mechanisms of disease to designing novel therapeutics. Unfortunately, current machine learning methods are limited by scarce and biased experimental data, and physics-based methods are either too slow to be useful, or too simplified to be accurate. In this work, we present Loop-Diffusion, an energy based diffusion model which leverages a dataset of general protein loops from the entire protein universe to learn an energy function that generalizes to functional prediction tasks. We evaluate Loop-Diffusion's performance on scoring TCR-pMHC interfaces and demonstrate state-of-the-art results in recognizing binding-enhancing mutations.
<div id='section'>Paperid: <span id='pid'>709, <a href='https://arxiv.org/pdf/2409.09057.pdf' target='_blank'>https://arxiv.org/pdf/2409.09057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammed Aledhari, Mohamed Rahouti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.09057">Gene and RNA Editing: Methods, Enabling Technologies, Applications, and Future Directions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gene and RNA editing methods, technologies, and applications are emerging as innovative forms of therapy and medicine, offering more efficient implementation compared to traditional pharmaceutical treatments. Current trends emphasize the urgent need for advanced methods and technologies to detect public health threats, including diseases and viral agents. Gene and RNA editing techniques enhance the ability to identify, modify, and ameliorate the effects of genetic diseases, disorders, and disabilities. Viral detection and identification methods present numerous opportunities for enabling technologies, such as CRISPR, applicable to both RNA and gene editing through the use of specific Cas proteins. This article explores the distinctions and benefits of RNA and gene editing processes, emphasizing their contributions to the future of medical treatment. CRISPR technology, particularly its adaptation via the Cas13 protein for RNA editing, is a significant advancement in gene editing. The article will delve into RNA and gene editing methodologies, focusing on techniques that alter and modify genetic coding. A-to-I and C-to-U editing are currently the most predominant methods of RNA modification. CRISPR stands out as the most cost-effective and customizable technology for both RNA and gene editing. Unlike permanent changes induced by cutting an individual's DNA genetic code, RNA editing offers temporary modifications by altering nucleoside bases in RNA strands, which can then attach to DNA strands as temporary modifiers.
<div id='section'>Paperid: <span id='pid'>710, <a href='https://arxiv.org/pdf/2409.04737.pdf' target='_blank'>https://arxiv.org/pdf/2409.04737.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shrimon Mukherjee, Madhusudan Ghosh, Partha Basuchowdhuri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04737">CrysAtom: Distributed Representation of Atoms for Crystal Property Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Application of artificial intelligence (AI) has been ubiquitous in the growth of research in the areas of basic sciences. Frequent use of machine learning (ML) and deep learning (DL) based methodologies by researchers has resulted in significant advancements in the last decade. These techniques led to notable performance enhancements in different tasks such as protein structure prediction, drug-target binding affinity prediction, and molecular property prediction. In material science literature, it is well-known that crystalline materials exhibit topological structures. Such topological structures may be represented as graphs and utilization of graph neural network (GNN) based approaches could help encoding them into an augmented representation space. Primarily, such frameworks adopt supervised learning techniques targeted towards downstream property prediction tasks on the basis of electronic properties (formation energy, bandgap, total energy, etc.) and crystalline structures. Generally, such type of frameworks rely highly on the handcrafted atom feature representations along with the structural representations. In this paper, we propose an unsupervised framework namely, CrysAtom, using untagged crystal data to generate dense vector representation of atoms, which can be utilized in existing GNN-based property predictor models to accurately predict important properties of crystals. Empirical results show that our dense representation embeds chemical properties of atoms and enhance the performance of the baseline property predictor models significantly.
<div id='section'>Paperid: <span id='pid'>711, <a href='https://arxiv.org/pdf/2408.16068.pdf' target='_blank'>https://arxiv.org/pdf/2408.16068.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huili Zheng, Qimin Zhang, Yiru Gong, Zheyan Liu, Shaohan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16068">Identification of Prognostic Biomarkers for Stage III Non-Small Cell Lung Carcinoma in Female Nonsmokers Using Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Lung cancer remains a leading cause of cancer-related deaths globally, with non-small cell lung cancer (NSCLC) being the most common subtype. This study aimed to identify key biomarkers associated with stage III NSCLC in non-smoking females using gene expression profiling from the GDS3837 dataset. Utilizing XGBoost, a machine learning algorithm, the analysis achieved a strong predictive performance with an AUC score of 0.835. The top biomarkers identified - CCAAT enhancer binding protein alpha (C/EBP-alpha), lactate dehydrogenase A4 (LDHA), UNC-45 myosin chaperone B (UNC-45B), checkpoint kinase 1 (CHK1), and hypoxia-inducible factor 1 subunit alpha (HIF-1-alpha) - have been validated in the literature as being significantly linked to lung cancer. These findings highlight the potential of these biomarkers for early diagnosis and personalized therapy, emphasizing the value of integrating machine learning with molecular profiling in cancer research.
<div id='section'>Paperid: <span id='pid'>712, <a href='https://arxiv.org/pdf/2408.06391.pdf' target='_blank'>https://arxiv.org/pdf/2408.06391.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dingyi Rong, Wenzhuo Zheng, Bozitao Zhong, Zhouhan Lin, Liang Hong, Ning Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.06391">Autoregressive Enzyme Function Prediction with Multi-scale Multi-modality Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of enzyme function is crucial for elucidating biological mechanisms and driving innovation across various sectors. Existing deep learning methods tend to rely solely on either sequence data or structural data and predict the EC number as a whole, neglecting the intrinsic hierarchical structure of EC numbers. To address these limitations, we introduce MAPred, a novel multi-modality and multi-scale model designed to autoregressively predict the EC number of proteins. MAPred integrates both the primary amino acid sequence and the 3D tokens of proteins, employing a dual-pathway approach to capture comprehensive protein characteristics and essential local functional sites. Additionally, MAPred utilizes an autoregressive prediction network to sequentially predict the digits of the EC number, leveraging the hierarchical organization of EC classifications. Evaluations on benchmark datasets, including New-392, Price, and New-815, demonstrate that our method outperforms existing models, marking a significant advance in the reliability and granularity of protein function prediction within bioinformatics.
<div id='section'>Paperid: <span id='pid'>713, <a href='https://arxiv.org/pdf/2407.21028.pdf' target='_blank'>https://arxiv.org/pdf/2407.21028.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>NataÅ¡a Tagasovska, Ji Won Park, Matthieu Kirchmeyer, Nathan C. Frey, Andrew Martin Watkins, Aya Abdelsalam Ismail, Arian Rokkum Jamasb, Edith Lee, Tyler Bryson, Stephen Ra, Kyunghyun Cho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21028">Antibody DomainBed: Out-of-Distribution Generalization in Therapeutic Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) has demonstrated significant promise in accelerating drug design. Active ML-guided optimization of therapeutic molecules typically relies on a surrogate model predicting the target property of interest. The model predictions are used to determine which designs to evaluate in the lab, and the model is updated on the new measurements to inform the next cycle of decisions. A key challenge is that the experimental feedback from each cycle inspires changes in the candidate proposal or experimental protocol for the next cycle, which lead to distribution shifts. To promote robustness to these shifts, we must account for them explicitly in the model training. We apply domain generalization (DG) methods to classify the stability of interactions between an antibody and antigen across five domains defined by design cycles. Our results suggest that foundational models and ensembling improve predictive performance on out-of-distribution domains. We publicly release our codebase extending the DG benchmark ``DomainBed,'' and the associated dataset of antibody sequences and structures emulating distribution shifts across design cycles.
<div id='section'>Paperid: <span id='pid'>714, <a href='https://arxiv.org/pdf/2406.10867.pdf' target='_blank'>https://arxiv.org/pdf/2406.10867.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Grayson Lee, Tony Shen, Martin Ester
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10867">Geometric-informed GFlowNets for Structure-Based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rise of cost involved with drug discovery and current speed of which they are discover, underscore the need for more efficient structure-based drug design (SBDD) methods. We employ Generative Flow Networks (GFlowNets), to effectively explore the vast combinatorial space of drug-like molecules, which traditional virtual screening methods fail to cover. We introduce a novel modification to the GFlowNet framework by incorporating trigonometrically consistent embeddings, previously utilized in tasks involving protein conformation and protein-ligand interactions, to enhance the model's ability to generate molecules tailored to specific protein pockets. We have modified the existing protein conditioning used by GFlowNets, blending geometric information from both protein and ligand embeddings to achieve more geometrically consistent embeddings. Experiments conducted using CrossDocked2020 demonstrated an improvement in the binding affinity between generated molecules and protein pockets for both single and multi-objective tasks, compared to previous work. Additionally, we propose future work aimed at further increasing the geometric information captured in protein-ligand interactions.
<div id='section'>Paperid: <span id='pid'>715, <a href='https://arxiv.org/pdf/2406.07249.pdf' target='_blank'>https://arxiv.org/pdf/2406.07249.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaiza Serrano, Ãlvaro Ciudad, Alexis Molina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.07249">Are Protein Language Models Compute Optimal?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While protein language models (pLMs) have transformed biological research, the scaling laws governing their improvement remain underexplored. By adapting methodologies from NLP scaling laws, we investigated the optimal ratio between model parameters and training tokens within a fixed compute budget. Our study reveals that pLM sizes scale sublinearly with compute budget, showing diminishing returns in performance as model size increases, and we identify a performance plateau in training loss comparable to the one found in relevant works in the field. Our findings suggest that widely-used pLMs might not be compute-optimal, indicating that larger models could achieve convergence more efficiently. Training a 35M model on a reduced token set, we attained perplexity results comparable to larger models like ESM-2 (15B) and xTrimoPGLM (100B) with a single dataset pass. This work paves the way towards more compute-efficient pLMs, democratizing their training and practical application in computational biology.
<div id='section'>Paperid: <span id='pid'>716, <a href='https://arxiv.org/pdf/2406.01636.pdf' target='_blank'>https://arxiv.org/pdf/2406.01636.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Akmal Raheem, Muhammad Ajwad Rahim, Ijaz Gul, Md. Reyad-ul-Ferdous, Liyan Le, Junguo Hui, Shuiwei Xia, Minjiang Chen, Dongmei Yu, Vijay Pandey, Peiwu Qin, Jiansong Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01636">COVID-19: post infection implications in different age groups, mechanism, diagnosis, effective prevention, treatment, and recommendations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>SARS-CoV-2, the highly contagious pathogen responsible for the COVID-19 pandemic, has persistent effects that begin four weeks after initial infection and last for an undetermined duration. These chronic effects are more harmful than acute ones. This review explores the long-term impact of the virus on various human organs, including the pulmonary, cardiovascular, neurological, reproductive, gastrointestinal, musculoskeletal, endocrine, and lymphoid systems, particularly in older adults. Regarding diagnosis, RT-PCR is the gold standard for detecting COVID-19, though it requires specialized equipment, skilled personnel, and considerable time to produce results. To address these limitations, artificial intelligence in imaging and microfluidics technologies offers promising alternatives for diagnosing COVID-19 efficiently. Pharmacological and non-pharmacological strategies are effective in mitigating the persistent impacts of COVID-19. These strategies enhance immunity in post-COVID-19 patients by reducing cytokine release syndrome, improving T cell response, and increasing the circulation of activated natural killer and CD8 T cells in blood and tissues. This, in turn, alleviates symptoms such as fever, nausea, fatigue, muscle weakness, and pain. Vaccines, including inactivated viral, live attenuated viral, protein subunit, viral vectored, mRNA, DNA, and nanoparticle vaccines, significantly reduce the adverse long-term effects of the virus. However, no vaccine has been reported to provide lifetime protection against COVID-19. Consequently, protective measures such as physical distancing, mask usage, and hand hygiene remain essential strategies. This review offers a comprehensive understanding of the persistent effects of COVID-19 on individuals of varying ages, along with insights into diagnosis, treatment, vaccination, and future preventative measures against the spread of SARS-CoV-2.
<div id='section'>Paperid: <span id='pid'>717, <a href='https://arxiv.org/pdf/2405.18075.pdf' target='_blank'>https://arxiv.org/pdf/2405.18075.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>NataÅ¡a Tagasovska, Vladimir GligorijeviÄ, Kyunghyun Cho, Andreas Loukas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18075">Implicitly Guided Design with PropEn: Match your Data to Follow the Gradient</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Across scientific domains, generating new models or optimizing existing ones while meeting specific criteria is crucial. Traditional machine learning frameworks for guided design use a generative model and a surrogate model (discriminator), requiring large datasets. However, real-world scientific applications often have limited data and complex landscapes, making data-hungry models inefficient or impractical. We propose a new framework, PropEn, inspired by ``matching'', which enables implicit guidance without training a discriminator. By matching each sample with a similar one that has a better property value, we create a larger training dataset that inherently indicates the direction of improvement. Matching, combined with an encoder-decoder architecture, forms a domain-agnostic generative framework for property enhancement. We show that training with a matched dataset approximates the gradient of the property of interest while remaining within the data distribution, allowing efficient design optimization. Extensive evaluations in toy problems and scientific applications, such as therapeutic protein design and airfoil optimization, demonstrate PropEn's advantages over common baselines. Notably, the protein design results are validated with wet lab experiments, confirming the competitiveness and effectiveness of our approach.
<div id='section'>Paperid: <span id='pid'>718, <a href='https://arxiv.org/pdf/2405.06658.pdf' target='_blank'>https://arxiv.org/pdf/2405.06658.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiqing Shen, Outongyi Lv, Houying Zhu, Yu Guang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06658">ProteinEngine: Empower LLM with Domain Knowledge for Protein Engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have garnered considerable attention for their proficiency in tackling intricate tasks, particularly leveraging their capacities for zero-shot and in-context learning. However, their utility has been predominantly restricted to general tasks due to an absence of domain-specific knowledge. This constraint becomes particularly pertinent in the realm of protein engineering, where specialized expertise is required for tasks such as protein function prediction, protein evolution analysis, and protein design, with a level of specialization that existing LLMs cannot furnish. In response to this challenge, we introduce \textsc{ProteinEngine}, a human-centered platform aimed at amplifying the capabilities of LLMs in protein engineering by seamlessly integrating a comprehensive range of relevant tools, packages, and software via API calls. Uniquely, \textsc{ProteinEngine} assigns three distinct roles to LLMs, facilitating efficient task delegation, specialized task resolution, and effective communication of results. This design fosters high extensibility and promotes the smooth incorporation of new algorithms, models, and features for future development. Extensive user studies, involving participants from both the AI and protein engineering communities across academia and industry, consistently validate the superiority of \textsc{ProteinEngine} in augmenting the reliability and precision of deep learning in protein engineering tasks. Consequently, our findings highlight the potential of \textsc{ProteinEngine} to bride the disconnected tools for future research in the protein engineering domain.
<div id='section'>Paperid: <span id='pid'>719, <a href='https://arxiv.org/pdf/2405.05349.pdf' target='_blank'>https://arxiv.org/pdf/2405.05349.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yassine Chemingui, Aryan Deshwal, Trong Nghia Hoang, Janardhan Rao Doppa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.05349">Offline Model-Based Optimization via Policy-Guided Gradient Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline optimization is an emerging problem in many experimental engineering domains including protein, drug or aircraft design, where online experimentation to collect evaluation data is too expensive or dangerous. To avoid that, one has to optimize an unknown function given only its offline evaluation at a fixed set of inputs. A naive solution to this problem is to learn a surrogate model of the unknown function and optimize this surrogate instead. However, such a naive optimizer is prone to erroneous overestimation of the surrogate (possibly due to over-fitting on a biased sample of function evaluation) on inputs outside the offline dataset. Prior approaches addressing this challenge have primarily focused on learning robust surrogate models. However, their search strategies are derived from the surrogate model rather than the actual offline data. To fill this important gap, we introduce a new learning-to-search perspective for offline optimization by reformulating it as an offline reinforcement learning problem. Our proposed policy-guided gradient search approach explicitly learns the best policy for a given surrogate model created from the offline data. Our empirical results on multiple benchmarks demonstrate that the learned optimization policy can be combined with existing offline surrogates to significantly improve the optimization performance.
<div id='section'>Paperid: <span id='pid'>720, <a href='https://arxiv.org/pdf/2404.17452.pdf' target='_blank'>https://arxiv.org/pdf/2404.17452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Richard Michael, Simon Bartels, Miguel GonzÃ¡lez-Duque, Yevgen Zainchkovskyy, Jes Frellsen, SÃ¸ren Hauberg, Wouter Boomsma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17452">A Continuous Relaxation for Discrete Bayesian Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To optimize efficiently over discrete data and with only few available target observations is a challenge in Bayesian optimization. We propose a continuous relaxation of the objective function and show that inference and optimization can be computationally tractable. We consider in particular the optimization domain where very few observations and strict budgets exist; motivated by optimizing protein sequences for expensive to evaluate bio-chemical properties. The advantages of our approach are two-fold: the problem is treated in the continuous setting, and available prior knowledge over sequences can be incorporated directly. More specifically, we utilize available and learned distributions over the problem domain for a weighting of the Hellinger distance which yields a covariance function. We show that the resulting acquisition function can be optimized with both continuous or discrete optimization algorithms and empirically assess our method on two bio-chemical sequence optimization tasks.
<div id='section'>Paperid: <span id='pid'>721, <a href='https://arxiv.org/pdf/2404.06481.pdf' target='_blank'>https://arxiv.org/pdf/2404.06481.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>RaÃºl MiÃ±Ã¡n, Javier Gallardo, Ãlvaro Ciudad, Alexis Molina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06481">GeoDirDock: Guiding Docking Along Geodesic Paths</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces GeoDirDock (GDD), a novel approach to molecular docking that enhances the accuracy and physical plausibility of ligand docking predictions. GDD guides the denoising process of a diffusion model along geodesic paths within multiple spaces representing translational, rotational, and torsional degrees of freedom. Our method leverages expert knowledge to direct the generative modeling process, specifically targeting desired protein-ligand interaction regions. We demonstrate that GDD significantly outperforms existing blind docking methods in terms of RMSD accuracy and physicochemical pose realism. Our results indicate that incorporating domain expertise into the diffusion process leads to more biologically relevant docking predictions. Additionally, we explore the potential of GDD for lead optimization in drug discovery through angle transfer in maximal common substructure (MCS) docking, showcasing its capability to predict ligand orientations for chemically similar compounds accurately.
<div id='section'>Paperid: <span id='pid'>722, <a href='https://arxiv.org/pdf/2404.04810.pdf' target='_blank'>https://arxiv.org/pdf/2404.04810.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuqi Song, Rongzhi Dong, Lai Wei, Qin Li, Jianjun Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04810">AlphaCrystal-II: Distance matrix based crystal structure prediction using deep learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational prediction of stable crystal structures has a profound impact on the large-scale discovery of novel functional materials. However, predicting the crystal structure solely from a material's composition or formula is a promising yet challenging task, as traditional ab initio crystal structure prediction (CSP) methods rely on time-consuming global searches and first-principles free energy calculations. Inspired by the recent success of deep learning approaches in protein structure prediction, which utilize pairwise amino acid interactions to describe 3D structures, we present AlphaCrystal-II, a novel knowledge-based solution that exploits the abundant inter-atomic interaction patterns found in existing known crystal structures. AlphaCrystal-II predicts the atomic distance matrix of a target crystal material and employs this matrix to reconstruct its 3D crystal structure. By leveraging the wealth of inter-atomic relationships of known crystal structures, our approach demonstrates remarkable effectiveness and reliability in structure prediction through comprehensive experiments. This work highlights the potential of data-driven methods in accelerating the discovery and design of new materials with tailored properties.
<div id='section'>Paperid: <span id='pid'>723, <a href='https://arxiv.org/pdf/2402.05140.pdf' target='_blank'>https://arxiv.org/pdf/2402.05140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junhong Shen, Neil Tenenholtz, James Brian Hall, David Alvarez-Melis, Nicolo Fusi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.05140">Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have demonstrated remarkable proficiency in understanding and generating natural language. However, their capabilities wane in highly specialized domains underrepresented in the pretraining corpus, such as physical and biomedical sciences. This work explores how to repurpose general LLMs into effective task solvers for specialized domains. We introduce a novel, model-agnostic framework for learning custom input tags, which are parameterized as continuous vectors appended to the LLM's embedding layer, to condition the LLM. We design two types of input tags: domain tags are used to delimit specialized representations (e.g., chemical formulas) and provide domain-relevant context; function tags are used to represent specific functions (e.g., predicting molecular properties) and compress function-solving instructions. We develop a three-stage protocol to learn these tags using auxiliary data and domain knowledge. By explicitly disentangling task domains from task functions, our method enables zero-shot generalization to unseen problems through diverse combinations of the input tags. It also boosts LLM's performance in various specialized domains, such as predicting protein or chemical properties and modeling drug-target interactions, outperforming expert models tailored to these tasks.
<div id='section'>Paperid: <span id='pid'>724, <a href='https://arxiv.org/pdf/2401.14665.pdf' target='_blank'>https://arxiv.org/pdf/2401.14665.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yipin Lei, Xu Wang, Meng Fang, Han Li, Xiang Li, Jianyang Zeng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.14665">PepGB: Facilitating peptide drug discovery via graph neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Peptides offer great biomedical potential and serve as promising drug candidates. Currently, the majority of approved peptide drugs are directly derived from well-explored natural human peptides. It is quite necessary to utilize advanced deep learning techniques to identify novel peptide drugs in the vast, unexplored biochemical space. Despite various in silico methods having been developed to accelerate peptide early drug discovery, existing models face challenges of overfitting and lacking generalizability due to the limited size, imbalanced distribution and inconsistent quality of experimental data. In this study, we propose PepGB, a deep learning framework to facilitate peptide early drug discovery by predicting peptide-protein interactions (PepPIs). Employing graph neural networks, PepGB incorporates a fine-grained perturbation module and a dual-view objective with contrastive learning-based peptide pre-trained representation to predict PepPIs. Through rigorous evaluations, we demonstrated that PepGB greatly outperforms baselines and can accurately identify PepPIs for novel targets and peptide hits, thereby contributing to the target identification and hit discovery processes. Next, we derive an extended version, diPepGB, to tackle the bottleneck of modeling highly imbalanced data prevalent in lead generation and optimization processes. Utilizing directed edges to represent relative binding strength between two peptide nodes, diPepGB achieves superior performance in real-world assays. In summary, our proposed frameworks can serve as potent tools to facilitate peptide early drug discovery.
<div id='section'>Paperid: <span id='pid'>725, <a href='https://arxiv.org/pdf/2312.03016.pdf' target='_blank'>https://arxiv.org/pdf/2312.03016.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuo Zhang, Lei Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.03016">Protein Language Model-Powered 3D Ligand Binding Site Prediction from Protein Sequence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prediction of ligand binding sites of proteins is a fundamental and important task for understanding the function of proteins and screening potential drugs. Most existing methods require experimentally determined protein holo-structures as input. However, such structures can be unavailable on novel or less-studied proteins. To tackle this limitation, we propose LaMPSite, which only takes protein sequences and ligand molecular graphs as input for ligand binding site predictions. The protein sequences are used to retrieve residue-level embeddings and contact maps from the pre-trained ESM-2 protein language model. The ligand molecular graphs are fed into a graph neural network to compute atom-level embeddings. Then we compute and update the protein-ligand interaction embedding based on the protein residue-level embeddings and ligand atom-level embeddings, and the geometric constraints in the inferred protein contact map and ligand distance map. A final pooling on protein-ligand interaction embedding would indicate which residues belong to the binding sites. Without any 3D coordinate information of proteins, our proposed model achieves competitive performance compared to baseline methods that require 3D protein structures when predicting binding sites. Given that less than 50% of proteins have reliable structure information in the current stage, LaMPSite will provide new opportunities for drug discovery.
<div id='section'>Paperid: <span id='pid'>726, <a href='https://arxiv.org/pdf/2311.17134.pdf' target='_blank'>https://arxiv.org/pdf/2311.17134.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zizhang Chen, Ryan Paul Badman, Lachele Foley, Robert Woods, Pengyu Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.17134">GlycoNMR: Dataset and benchmarks for NMR chemical shift prediction of carbohydrates with graph neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular representation learning (MRL) is a powerful tool for bridging the gap between machine learning and chemical sciences, as it converts molecules into numerical representations while preserving their chemical features. These encoded representations serve as a foundation for various downstream biochemical studies, including property prediction and drug design. MRL has had great success with proteins and general biomolecule datasets. Yet, in the growing sub-field of glycoscience (the study of carbohydrates, where longer carbohydrates are also called glycans), MRL methods have been barely explored. This under-exploration can be primarily attributed to the limited availability of comprehensive and well-curated carbohydrate-specific datasets and a lack of Machine learning (ML) pipelines specifically tailored to meet the unique problems presented by carbohydrate data. Since interpreting and annotating carbohydrate-specific data is generally more complicated than protein data, domain experts are usually required to get involved. The existing MRL methods, predominately optimized for proteins and small biomolecules, also cannot be directly used in carbohydrate applications without special modifications. To address this challenge, accelerate progress in glycoscience, and enrich the data resources of the MRL community, we introduce GlycoNMR. GlycoNMR contains two laboriously curated datasets with 2,609 carbohydrate structures and 211,543 annotated nuclear magnetic resonance (NMR) chemical shifts for precise atomic-level prediction. We tailored carbohydrate-specific features and adapted existing MRL models to tackle this problem effectively. For illustration, we benchmark four modified MRL models on our new datasets.
<div id='section'>Paperid: <span id='pid'>727, <a href='https://arxiv.org/pdf/2311.11228.pdf' target='_blank'>https://arxiv.org/pdf/2311.11228.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuo Zhang, Yang Liu, Lei Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.11228">A Universal Framework for Accurate and Efficient Geometric Deep Learning of Molecular Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular sciences address a wide range of problems involving molecules of different types and sizes and their complexes. Recently, geometric deep learning, especially Graph Neural Networks, has shown promising performance in molecular science applications. However, most existing works often impose targeted inductive biases to a specific molecular system, and are inefficient when applied to macromolecules or large-scale tasks, thereby limiting their applications to many real-world problems. To address these challenges, we present PAMNet, a universal framework for accurately and efficiently learning the representations of three-dimensional (3D) molecules of varying sizes and types in any molecular system. Inspired by molecular mechanics, PAMNet induces a physics-informed bias to explicitly model local and non-local interactions and their combined effects. As a result, PAMNet can reduce expensive operations, making it time and memory efficient. In extensive benchmark studies, PAMNet outperforms state-of-the-art baselines regarding both accuracy and efficiency in three diverse learning tasks: small molecule properties, RNA 3D structures, and protein-ligand binding affinities. Our results highlight the potential for PAMNet in a broad range of molecular science applications.
<div id='section'>Paperid: <span id='pid'>728, <a href='https://arxiv.org/pdf/2311.09312.pdf' target='_blank'>https://arxiv.org/pdf/2311.09312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gian Marco Visani, William Galvin, Michael Neal Pun, Armita Nourmohammad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.09312">H-Packer: Holographic Rotationally Equivariant Convolutional Neural Network for Protein Side-Chain Packing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately modeling protein 3D structure is essential for the design of functional proteins. An important sub-task of structure modeling is protein side-chain packing: predicting the conformation of side-chains (rotamers) given the protein's backbone structure and amino-acid sequence. Conventional approaches for this task rely on expensive sampling procedures over hand-crafted energy functions and rotamer libraries. Recently, several deep learning methods have been developed to tackle the problem in a data-driven way, albeit with vastly different formulations (from image-to-image translation to directly predicting atomic coordinates). Here, we frame the problem as a joint regression over the side-chains' true degrees of freedom: the dihedral $Ï$ angles. We carefully study possible objective functions for this task, while accounting for the underlying symmetries of the task. We propose Holographic Packer (H-Packer), a novel two-stage algorithm for side-chain packing built on top of two light-weight rotationally equivariant neural networks. We evaluate our method on CASP13 and CASP14 targets. H-Packer is computationally efficient and shows favorable performance against conventional physics-based algorithms and is competitive against alternative deep learning solutions.
<div id='section'>Paperid: <span id='pid'>729, <a href='https://arxiv.org/pdf/2310.19915.pdf' target='_blank'>https://arxiv.org/pdf/2310.19915.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seongwon Kim, Parisa Mollaei, Akshay Antony, Rishikesh Magar, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19915">GPCR-BERT: Interpreting Sequential Design of G Protein Coupled Receptors Using Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the rise of Transformers and Large Language Models (LLMs) in Chemistry and Biology, new avenues for the design and understanding of therapeutics have opened up to the scientific community. Protein sequences can be modeled as language and can take advantage of recent advances in LLMs, specifically with the abundance of our access to the protein sequence datasets. In this paper, we developed the GPCR-BERT model for understanding the sequential design of G Protein-Coupled Receptors (GPCRs). GPCRs are the target of over one-third of FDA-approved pharmaceuticals. However, there is a lack of comprehensive understanding regarding the relationship between amino acid sequence, ligand selectivity, and conformational motifs (such as NPxxY, CWxP, E/DRY). By utilizing the pre-trained protein model (Prot-Bert) and fine-tuning with prediction tasks of variations in the motifs, we were able to shed light on several relationships between residues in the binding pocket and some of the conserved motifs. To achieve this, we took advantage of attention weights, and hidden states of the model that are interpreted to extract the extent of contributions of amino acids in dictating the type of masked ones. The fine-tuned models demonstrated high accuracy in predicting hidden residues within the motifs. In addition, the analysis of embedding was performed over 3D structures to elucidate the higher-order interactions within the conformations of the receptors.
<div id='section'>Paperid: <span id='pid'>730, <a href='https://arxiv.org/pdf/2310.06177.pdf' target='_blank'>https://arxiv.org/pdf/2310.06177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vignesh Ram Somnath, Pier Giuseppe Sessa, Maria Rodriguez Martinez, Andreas Krause
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06177">DockGame: Cooperative Games for Multimeric Rigid Protein Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein interactions and assembly formation are fundamental to most biological processes. Predicting the assembly structure from constituent proteins -- referred to as the protein docking task -- is thus a crucial step in protein design applications. Most traditional and deep learning methods for docking have focused mainly on binary docking, following either a search-based, regression-based, or generative modeling paradigm. In this paper, we focus on the less-studied multimeric (i.e., two or more proteins) docking problem. We introduce DockGame, a novel game-theoretic framework for docking -- we view protein docking as a cooperative game between proteins, where the final assembly structure(s) constitute stable equilibria w.r.t. the underlying game potential. Since we do not have access to the true potential, we consider two approaches - i) learning a surrogate game potential guided by physics-based energy functions and computing equilibria by simultaneous gradient updates, and ii) sampling from the Gibbs distribution of the true potential by learning a diffusion generative model over the action spaces (rotations and translations) of all proteins. Empirically, on the Docking Benchmark 5.5 (DB5.5) dataset, DockGame has much faster runtimes than traditional docking methods, can generate multiple plausible assembly structures, and achieves comparable performance to existing binary docking baselines, despite solving the harder task of coordinating multiple protein chains.
<div id='section'>Paperid: <span id='pid'>731, <a href='https://arxiv.org/pdf/2310.03320.pdf' target='_blank'>https://arxiv.org/pdf/2310.03320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zifeng Wang, Zichen Wang, Balasubramaniam Srinivasan, Vassilis N. Ioannidis, Huzefa Rangwala, Rishita Anubhai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03320">BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models (FMs) are able to leverage large volumes of unlabeled data to demonstrate superior performance across a wide range of tasks. However, FMs developed for biomedical domains have largely remained unimodal, i.e., independently trained and used for tasks on protein sequences alone, small molecule structures alone, or clinical data alone. To overcome this limitation of biomedical FMs, we present BioBridge, a novel parameter-efficient learning framework, to bridge independently trained unimodal FMs to establish multimodal behavior. BioBridge achieves it by utilizing Knowledge Graphs (KG) to learn transformations between one unimodal FM and another without fine-tuning any underlying unimodal FMs. Our empirical results demonstrate that BioBridge can beat the best baseline KG embedding methods (on average by around 76.3%) in cross-modal retrieval tasks. We also identify BioBridge demonstrates out-of-domain generalization ability by extrapolating to unseen modalities or relations. Additionally, we also show that BioBridge presents itself as a general purpose retriever that can aid biomedical multimodal question answering as well as enhance the guided generation of novel drugs.
<div id='section'>Paperid: <span id='pid'>732, <a href='https://arxiv.org/pdf/2310.03223.pdf' target='_blank'>https://arxiv.org/pdf/2310.03223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tony Shen, Seonghwan Seo, Grayson Lee, Mohit Pandey, Jason R Smith, Artem Cherkasov, Woo Youn Kim, Martin Ester
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03223">TacoGFN: Target-conditioned GFlowNet for Structure-based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Searching the vast chemical space for drug-like molecules that bind with a protein pocket is a challenging task in drug discovery. Recently, structure-based generative models have been introduced which promise to be more efficient by learning to generate molecules for any given protein structure. However, since they learn the distribution of a limited protein-ligand complex dataset, structure-based methods do not yet outperform optimization-based methods that generate binding molecules for just one pocket. To overcome limitations on data while leveraging learning across protein targets, we choose to model the reward distribution conditioned on pocket structure, instead of the training data distribution. We design TacoGFN, a novel GFlowNet-based approach for structure-based drug design, which can generate molecules conditioned on any protein pocket structure with probabilities proportional to its affinity and property rewards. In the generative setting for CrossDocked2020 benchmark, TacoGFN attains a state-of-the-art success rate of $56.0\%$ and $-8.44$ kcal/mol in median Vina Dock score while improving the generation time by multiple orders of magnitude. Fine-tuning TacoGFN further improves the median Vina Dock score to $-10.93$ kcal/mol and the success rate to $88.8\%$, outperforming all optimization-based methods.
<div id='section'>Paperid: <span id='pid'>733, <a href='https://arxiv.org/pdf/2309.15838.pdf' target='_blank'>https://arxiv.org/pdf/2309.15838.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ghizal Fatima, Fadhil G. Al-Amran, Maitham G. Yousif
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.15838">Automated Detection of Persistent Inflammatory Biomarkers in Post-COVID-19 Patients Using Machine Learning Techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The COVID-19 pandemic has left a lasting impact on individuals, with many experiencing persistent symptoms, including inflammation, in the post-acute phase of the disease. Detecting and monitoring these inflammatory biomarkers is critical for timely intervention and improved patient outcomes. This study employs machine learning techniques to automate the identification of persistent inflammatory biomarkers in 290 post-COVID-19 patients, based on medical data collected from hospitals in Iraq. The data encompassed a wide array of clinical parameters, such as C-reactive protein and interleukin-6 levels, patient demographics, comorbidities, and treatment histories. Rigorous data preprocessing and feature selection processes were implemented to optimize the dataset for machine learning analysis. Various machine learning algorithms, including logistic regression, random forests, support vector machines, and gradient boosting, were deployed to construct predictive models. These models exhibited promising results, showcasing high accuracy and precision in the identification of patients with persistent inflammation. The findings of this study underscore the potential of machine learning in automating the detection of persistent inflammatory biomarkers in post-COVID-19 patients. These models can serve as valuable tools for healthcare providers, facilitating early diagnosis and personalized treatment strategies for individuals at risk of persistent inflammation, ultimately contributing to improved post-acute COVID-19 care and patient well-being. Keywords: COVID-19, post-COVID-19, inflammation, biomarkers, machine learning, early detection.
<div id='section'>Paperid: <span id='pid'>734, <a href='https://arxiv.org/pdf/2309.14047.pdf' target='_blank'>https://arxiv.org/pdf/2309.14047.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vudtiwat Ngampruetikorn, David J. Schwab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.14047">Random-Energy Secret Sharing via Extreme Synergy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The random-energy model (REM), a solvable spin-glass model, has impacted an incredibly diverse set of problems, from protein folding to combinatorial optimization to many-body localization. Here, we explore a new connection to secret sharing. We formulate a secret-sharing scheme, based on the REM, and analyze its information-theoretic properties. Our analyses reveal that the correlations between subsystems of the REM are highly synergistic and form the basis for secure secret-sharing schemes. We derive the ranges of temperatures and secret lengths over which the REM satisfies the requirement of secure secret sharing. We show further that a special point in the phase diagram exists at which the REM-based scheme is optimal in its information encoding. Our analytical results for the thermodynamic limit are in good qualitative agreement with numerical simulations of finite systems, for which the strict security requirement is replaced by a tradeoff between secrecy and recoverability. Our work offers a further example of information theory as a unifying concept, connecting problems in statistical physics to those in computation.
<div id='section'>Paperid: <span id='pid'>735, <a href='https://arxiv.org/pdf/2309.05853.pdf' target='_blank'>https://arxiv.org/pdf/2309.05853.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gregory W. Kyro, Anton Morgunov, Rafael I. Brent, Victor S. Batista
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.05853">ChemSpaceAL: An Efficient Active Learning Methodology Applied to Protein-Specific Molecular Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The incredible capabilities of generative artificial intelligence models have inevitably led to their application in the domain of drug discovery. Within this domain, the vastness of chemical space motivates the development of more efficient methods for identifying regions with molecules that exhibit desired characteristics. In this work, we present a computationally efficient active learning methodology that requires evaluation of only a subset of the generated data in the constructed sample space to successfully align a generative model with respect to a specified objective. We demonstrate the applicability of this methodology to targeted molecular generation by fine-tuning a GPT-based molecular generator toward a protein with FDA-approved small-molecule inhibitors, c-Abl kinase. Remarkably, the model learns to generate molecules similar to the inhibitors without prior knowledge of their existence, and even reproduces two of them exactly. We also show that the methodology is effective for a protein without any commercially available small-molecule inhibitors, the HNH domain of the CRISPR-associated protein 9 (Cas9) enzyme. We believe that the inherent generality of this method ensures that it will remain applicable as the exciting field of in silico molecular generation evolves. To facilitate implementation and reproducibility, we have made all of our software available through the open-source ChemSpaceAL Python package.
<div id='section'>Paperid: <span id='pid'>736, <a href='https://arxiv.org/pdf/2308.05027.pdf' target='_blank'>https://arxiv.org/pdf/2308.05027.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karolis Martinkus, Jan Ludwiczak, Kyunghyun Cho, Wei-Ching Liang, Julien Lafrance-Vanasse, Isidro Hotzel, Arvind Rajpal, Yan Wu, Richard Bonneau, Vladimir Gligorijevic, Andreas Loukas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.05027">AbDiffuser: Full-Atom Generation of in vitro Functioning Antibodies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce AbDiffuser, an equivariant and physics-informed diffusion model for the joint generation of antibody 3D structures and sequences. AbDiffuser is built on top of a new representation of protein structure, relies on a novel architecture for aligned proteins, and utilizes strong diffusion priors to improve the denoising process. Our approach improves protein diffusion by taking advantage of domain knowledge and physics-based constraints; handles sequence-length changes; and reduces memory complexity by an order of magnitude, enabling backbone and side chain generation. We validate AbDiffuser in silico and in vitro. Numerical experiments showcase the ability of AbDiffuser to generate antibodies that closely track the sequence and structural properties of a reference set. Laboratory experiments confirm that all 16 HER2 antibodies discovered were expressed at high levels and that 57.1% of the selected designs were tight binders.
<div id='section'>Paperid: <span id='pid'>737, <a href='https://arxiv.org/pdf/2307.12491.pdf' target='_blank'>https://arxiv.org/pdf/2307.12491.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuo Zhang, Yang Liu, Li Xie, Lei Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.12491">Learning Universal and Robust 3D Molecular Representations with Graph Convolutional Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To learn accurate representations of molecules, it is essential to consider both chemical and geometric features. To encode geometric information, many descriptors have been proposed in constrained circumstances for specific types of molecules and do not have the properties to be ``robust": 1. Invariant to rotations and translations; 2. Injective when embedding molecular structures. In this work, we propose a universal and robust Directional Node Pair (DNP) descriptor based on the graph representations of 3D molecules. Our DNP descriptor is robust compared to previous ones and can be applied to multiple molecular types. To combine the DNP descriptor and chemical features in molecules, we construct the Robust Molecular Graph Convolutional Network (RoM-GCN) which is capable to take both node and edge features into consideration when generating molecule representations. We evaluate our model on protein and small molecule datasets. Our results validate the superiority of the DNP descriptor in incorporating 3D geometric information of molecules. RoM-GCN outperforms all compared baselines.
<div id='section'>Paperid: <span id='pid'>738, <a href='https://arxiv.org/pdf/2306.12360.pdf' target='_blank'>https://arxiv.org/pdf/2306.12360.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nathan C. Frey, Daniel Berenberg, Karina Zadorozhny, Joseph Kleinhenz, Julien Lafrance-Vanasse, Isidro Hotzel, Yan Wu, Stephen Ra, Richard Bonneau, Kyunghyun Cho, Andreas Loukas, Vladimir Gligorijevic, Saeed Saremi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.12360">Protein Discovery with Discrete Walk-Jump Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We resolve difficulties in training and sampling from a discrete generative model by learning a smoothed energy function, sampling from the smoothed data manifold with Langevin Markov chain Monte Carlo (MCMC), and projecting back to the true data manifold with one-step denoising. Our Discrete Walk-Jump Sampling formalism combines the contrastive divergence training of an energy-based model and improved sample quality of a score-based model, while simplifying training and sampling by requiring only a single noise level. We evaluate the robustness of our approach on generative modeling of antibody proteins and introduce the distributional conformity score to benchmark protein generative models. By optimizing and sampling from our models for the proposed distributional conformity score, 97-100% of generated samples are successfully expressed and purified and 70% of functional designs show equal or improved binding affinity compared to known functional antibodies on the first attempt in a single round of laboratory experiments. We also report the first demonstration of long-run fast-mixing MCMC chains where diverse antibody protein classes are visited in a single MCMC chain.
<div id='section'>Paperid: <span id='pid'>739, <a href='https://arxiv.org/pdf/2306.04886.pdf' target='_blank'>https://arxiv.org/pdf/2306.04886.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxian Yan, Zhaofeng Ye, Ziyi Yang, Chengqiang Lu, Shengyu Zhang, Qi Liu, Jiezhong Qiu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.04886">Multi-task Bioassay Pre-training for Protein-ligand Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-ligand binding affinity (PLBA) prediction is the fundamental task in drug discovery. Recently, various deep learning-based models predict binding affinity by incorporating the three-dimensional structure of protein-ligand complexes as input and achieving astounding progress. However, due to the scarcity of high-quality training data, the generalization ability of current models is still limited. In addition, different bioassays use varying affinity measurement labels (i.e., IC50, Ki, Kd), and different experimental conditions inevitably introduce systematic noise, which poses a significant challenge to constructing high-precision affinity prediction models. To address these issues, we (1) propose Multi-task Bioassay Pre-training (MBP), a pre-training framework for structure-based PLBA prediction; (2) construct a pre-training dataset called ChEMBL-Dock with more than 300k experimentally measured affinity labels and about 2.8M docked three-dimensional structures. By introducing multi-task pre-training to treat the prediction of different affinity labels as different tasks and classifying relative rankings between samples from the same bioassay, MBP learns robust and transferrable structural knowledge from our new ChEMBL-Dock dataset with varied and noisy labels. Experiments substantiate the capability of MBP as a general framework that can improve and be tailored to mainstream structure-based PLBA prediction tasks. To the best of our knowledge, MBP is the first affinity pre-training model and shows great potential for future development.
<div id='section'>Paperid: <span id='pid'>740, <a href='https://arxiv.org/pdf/2306.02696.pdf' target='_blank'>https://arxiv.org/pdf/2306.02696.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giulia Preti, Gianmarco De Francisci Morales, Francesco Bonchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02696">Hyper-distance Oracles in Hypergraphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study point-to-point distance estimation in hypergraphs, where the query is parameterized by a positive integer s, which defines the required level of overlap for two hyperedges to be considered adjacent. To answer s-distance queries, we first explore an oracle based on the line graph of the given hypergraph and discuss its limitations: the main one is that the line graph is typically orders of magnitude larger than the original hypergraph. We then introduce HypED, a landmark-based oracle with a predefined size, built directly on the hypergraph, thus avoiding constructing the line graph. Our framework allows to approximately answer vertex-to-vertex, vertex-to-hyperedge, and hyperedge-to-hyperedge s-distance queries for any value of s. A key observation at the basis of our framework is that, as s increases, the hypergraph becomes more fragmented. We show how this can be exploited to improve the placement of landmarks, by identifying the s-connected components of the hypergraph. For this task, we devise an efficient algorithm based on the union-find technique and a dynamic inverted index. We experimentally evaluate HypED on several real-world hypergraphs and prove its versatility in answering s-distance queries for different values of s. Our framework allows answering such queries in fractions of a millisecond, while allowing fine-grained control of the trade-off between index size and approximation error at creation time. Finally, we prove the usefulness of the s-distance oracle in two applications, namely, hypergraph-based recommendation and the approximation of the s-closeness centrality of vertices and hyper-edges in the context of protein-to-protein interactions.
<div id='section'>Paperid: <span id='pid'>741, <a href='https://arxiv.org/pdf/2305.08316.pdf' target='_blank'>https://arxiv.org/pdf/2305.08316.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyuan Zhao, Peisheng Qian, Xulei Yang, Zeng Zeng, Cuntai Guan, Wai Leong Tam, Xiaoli Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.08316">SemiGNN-PPI: Self-Ensembling Multi-Graph Neural Network for Efficient and Generalizable Protein-Protein Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interactions (PPIs) are crucial in various biological processes and their study has significant implications for drug development and disease diagnosis. Existing deep learning methods suffer from significant performance degradation under complex real-world scenarios due to various factors, e.g., label scarcity and domain shift. In this paper, we propose a self-ensembling multigraph neural network (SemiGNN-PPI) that can effectively predict PPIs while being both efficient and generalizable. In SemiGNN-PPI, we not only model the protein correlations but explore the label dependencies by constructing and processing multiple graphs from the perspectives of both features and labels in the graph learning process. We further marry GNN with Mean Teacher to effectively leverage unlabeled graph-structured PPI data for self-ensemble graph learning. We also design multiple graph consistency constraints to align the student and teacher graphs in the feature embedding space, enabling the student model to better learn from the teacher model by incorporating more relationships. Extensive experiments on PPI datasets of different scales with different evaluation settings demonstrate that SemiGNN-PPI outperforms state-of-the-art PPI prediction methods, particularly in challenging scenarios such as training with limited annotations and testing on unseen data.
<div id='section'>Paperid: <span id='pid'>742, <a href='https://arxiv.org/pdf/2303.05420.pdf' target='_blank'>https://arxiv.org/pdf/2303.05420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ben Adlam, Jaehoon Lee, Shreyas Padhy, Zachary Nado, Jasper Snoek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.05420">Kernel Regression with Infinite-Width Neural Networks on Millions of Examples</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural kernels have drastically increased performance on diverse and nonstandard data modalities but require significantly more compute, which previously limited their application to smaller datasets. In this work, we address this by massively parallelizing their computation across many GPUs. We combine this with a distributed, preconditioned conjugate gradients algorithm to enable kernel regression at a large scale (i.e. up to five million examples). Using this approach, we study scaling laws of several neural kernels across many orders of magnitude for the CIFAR-5m dataset. Using data augmentation to expand the original CIFAR-10 training dataset by a factor of 20, we obtain a test accuracy of 91.2\% (SotA for a pure kernel method). Moreover, we explore neural kernels on other data modalities, obtaining results on protein and small molecule prediction tasks that are competitive with SotA methods.
<div id='section'>Paperid: <span id='pid'>743, <a href='https://arxiv.org/pdf/2303.04635.pdf' target='_blank'>https://arxiv.org/pdf/2303.04635.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Florence Regol, Mark Coates
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.04635">Diffusing Gaussian Mixtures for Generating Categorical Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning a categorical distribution comes with its own set of challenges. A successful approach taken by state-of-the-art works is to cast the problem in a continuous domain to take advantage of the impressive performance of the generative models for continuous data. Amongst them are the recently emerging diffusion probabilistic models, which have the observed advantage of generating high-quality samples. Recent advances for categorical generative models have focused on log likelihood improvements. In this work, we propose a generative model for categorical data based on diffusion models with a focus on high-quality sample generation, and propose sampled-based evaluation methods. The efficacy of our method stems from performing diffusion in the continuous domain while having its parameterization informed by the structure of the categorical nature of the target distribution. Our method of evaluation highlights the capabilities and limitations of different generative models for generating categorical data, and includes experiments on synthetic and real-world protein datasets.
<div id='section'>Paperid: <span id='pid'>744, <a href='https://arxiv.org/pdf/2303.01569.pdf' target='_blank'>https://arxiv.org/pdf/2303.01569.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soojung Yang, Rafael GÃ³mez-Bombarelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01569">Chemically Transferable Generative Backmapping of Coarse-Grained Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Coarse-graining (CG) accelerates molecular simulations of protein dynamics by simulating sets of atoms as singular beads. Backmapping is the opposite operation of bringing lost atomistic details back from the CG representation. While machine learning (ML) has produced accurate and efficient CG simulations of proteins, fast and reliable backmapping remains a challenge. Rule-based methods produce poor all-atom geometries, needing computationally costly refinement through additional simulations. Recently proposed ML approaches outperform traditional baselines but are not transferable between proteins and sometimes generate unphysical atom placements with steric clashes and implausible torsion angles. This work addresses both issues to build a fast, transferable, and reliable generative backmapping tool for CG protein representations. We achieve generalization and reliability through a combined set of innovations: representation based on internal coordinates; an equivariant encoder/prior; a custom loss function that helps ensure local structure, global structure, and physical constraints; and expert curation of high-quality out-of-equilibrium protein data for training. Our results pave the way for out-of-the-box backmapping of coarse-grained simulations for arbitrary proteins.
<div id='section'>Paperid: <span id='pid'>745, <a href='https://arxiv.org/pdf/2302.13711.pdf' target='_blank'>https://arxiv.org/pdf/2302.13711.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marloes Arts, Jes Frellsen, Wouter Boomsma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.13711">Internal-Coordinate Density Modelling of Protein Structure: Covariance Matters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>After the recent ground-breaking advances in protein structure prediction, one of the remaining challenges in protein machine learning is to reliably predict distributions of structural states. Parametric models of fluctuations are difficult to fit due to complex covariance structures between degrees of freedom in the protein chain, often causing models to either violate local or global structural constraints. In this paper, we present a new strategy for modelling protein densities in internal coordinates, which uses constraints in 3D space to induce covariance structure between the internal degrees of freedom. We illustrate the potential of the procedure by constructing a variational autoencoder with full covariance output induced by the constraints implied by the conditional mean in 3D, and demonstrate that our approach makes it possible to scale density models of internal coordinates to full protein backbones in two settings: 1) a unimodal setting for proteins exhibiting small fluctuations and limited amounts of available data, and 2) a multimodal setting for larger conformational changes in a high data regime.
<div id='section'>Paperid: <span id='pid'>746, <a href='https://arxiv.org/pdf/2302.00294.pdf' target='_blank'>https://arxiv.org/pdf/2302.00294.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucrezia Valeriani, Diego Doimo, Francesca Cuturello, Alessandro Laio, Alessio Ansuini, Alberto Cazzaniga
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.00294">The geometry of hidden representations of large transformer models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large transformers are powerful architectures used for self-supervised data analysis across various data types, including protein sequences, images, and text. In these models, the semantic structure of the dataset emerges from a sequence of transformations between one representation and the next. We characterize the geometric and statistical properties of these representations and how they change as we move through the layers. By analyzing the intrinsic dimension (ID) and neighbor composition, we find that the representations evolve similarly in transformers trained on protein language tasks and image reconstruction tasks. In the first layers, the data manifold expands, becoming high-dimensional, and then contracts significantly in the intermediate layers. In the last part of the model, the ID remains approximately constant or forms a second shallow peak. We show that the semantic information of the dataset is better expressed at the end of the first peak, and this phenomenon can be observed across many models trained on diverse datasets. Based on our findings, we point out an explicit strategy to identify, without supervision, the layers that maximize semantic content: representations at intermediate layers corresponding to a relative minimum of the ID profile are more suitable for downstream learning tasks.
<div id='section'>Paperid: <span id='pid'>747, <a href='https://arxiv.org/pdf/2301.12040.pdf' target='_blank'>https://arxiv.org/pdf/2301.12040.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minghao Xu, Xinyu Yuan, Santiago Miret, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12040">ProtST: Multi-Modality Learning of Protein Sequences and Biomedical Texts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current protein language models (PLMs) learn protein representations mainly based on their sequences, thereby well capturing co-evolutionary information, but they are unable to explicitly acquire protein functions, which is the end goal of protein representation learning. Fortunately, for many proteins, their textual property descriptions are available, where their various functions are also described. Motivated by this fact, we first build the ProtDescribe dataset to augment protein sequences with text descriptions of their functions and other important properties. Based on this dataset, we propose the ProtST framework to enhance Protein Sequence pre-training and understanding by biomedical Texts. During pre-training, we design three types of tasks, i.e., unimodal mask prediction, multimodal representation alignment and multimodal mask prediction, to enhance a PLM with protein property information with different granularities and, at the same time, preserve the PLM's original representation power. On downstream tasks, ProtST enables both supervised learning and zero-shot prediction. We verify the superiority of ProtST-induced PLMs over previous ones on diverse representation learning benchmarks. Under the zero-shot setting, we show the effectiveness of ProtST on zero-shot protein classification, and ProtST also enables functional protein retrieval from a large-scale database without any function annotation.
<div id='section'>Paperid: <span id='pid'>748, <a href='https://arxiv.org/pdf/2301.04093.pdf' target='_blank'>https://arxiv.org/pdf/2301.04093.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ismail Alkhouri, Sumit Jha, Andre Beckus, George Atia, Alvaro Velasquez, Rickard Ewetz, Arvind Ramanathan, Susmit Jha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.04093">On the Robustness of AlphaFold: A COVID-19 Case Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein folding neural networks (PFNNs) such as AlphaFold predict remarkably accurate structures of proteins compared to other approaches. However, the robustness of such networks has heretofore not been explored. This is particularly relevant given the broad social implications of such technologies and the fact that biologically small perturbations in the protein sequence do not generally lead to drastic changes in the protein structure. In this paper, we demonstrate that AlphaFold does not exhibit such robustness despite its high accuracy. This raises the challenge of detecting and quantifying the extent to which these predicted protein structures can be trusted. To measure the robustness of the predicted structures, we utilize (i) the root-mean-square deviation (RMSD) and (ii) the Global Distance Test (GDT) similarity measure between the predicted structure of the original sequence and the structure of its adversarially perturbed version. We prove that the problem of minimally perturbing protein sequences to fool protein folding neural networks is NP-complete. Based on the well-established BLOSUM62 sequence alignment scoring matrix, we generate adversarial protein sequences and show that the RMSD between the predicted protein structure and the structure of the original sequence are very large when the adversarial changes are bounded by (i) 20 units in the BLOSUM62 distance, and (ii) five residues (out of hundreds or thousands of residues) in the given protein sequence. In our experimental evaluation, we consider 111 COVID-19 proteins in the Universal Protein resource (UniProt), a central resource for protein data managed by the European Bioinformatics Institute, Swiss Institute of Bioinformatics, and the US Protein Information Resource. These result in an overall GDT similarity test score average of around 34%, demonstrating a substantial drop in the performance of AlphaFold.
<div id='section'>Paperid: <span id='pid'>749, <a href='https://arxiv.org/pdf/2212.06361.pdf' target='_blank'>https://arxiv.org/pdf/2212.06361.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>InÃ©s Gonzalez Pepe, Yohan Chatelain, Gregory Kiar, Tristan Glatard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.06361">Numerical Stability of DeepGOPlus Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Convolutional neural networks (CNNs) are currently among the most widely-used deep neural network (DNN) architectures available and achieve state-of-the-art performance for many problems. Originally applied to computer vision tasks, CNNs work well with any data with a spatial relationship, besides images, and have been applied to different fields. However, recent works have highlighted numerical stability challenges in DNNs, which also relates to their known sensitivity to noise injection. These challenges can jeopardise their performance and reliability. This paper investigates DeepGOPlus, a CNN that predicts protein function. DeepGOPlus has achieved state-of-the-art performance and can successfully take advantage and annotate the abounding protein sequences emerging in proteomics. We determine the numerical stability of the model's inference stage by quantifying the numerical uncertainty resulting from perturbations of the underlying floating-point data. In addition, we explore the opportunity to use reduced-precision floating point formats for DeepGOPlus inference, to reduce memory consumption and latency. This is achieved by instrumenting DeepGOPlus' execution using Monte Carlo Arithmetic, a technique that experimentally quantifies floating point operation errors and VPREC, a tool that emulates results with customizable floating point precision formats. Focus is placed on the inference stage as it is the primary deliverable of the DeepGOPlus model, widely applicable across different environments. All in all, our results show that although the DeepGOPlus CNN is very stable numerically, it can only be selectively implemented with lower-precision floating-point formats. We conclude that predictions obtained from the pre-trained DeepGOPlus model are very reliable numerically, and use existing floating-point formats efficiently.
<div id='section'>Paperid: <span id='pid'>750, <a href='https://arxiv.org/pdf/2210.13695.pdf' target='_blank'>https://arxiv.org/pdf/2210.13695.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arne Schneuing, Charles Harris, Yuanqi Du, Kieran Didi, Arian Jamasb, Ilia Igashov, Weitao Du, Carla Gomes, Tom Blundell, Pietro Lio, Max Welling, Michael Bronstein, Bruno Correia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.13695">Structure-based Drug Design with Equivariant Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug design (SBDD) aims to design small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets. Generative SBDD methods leverage structural data of drugs in complex with their protein targets to propose new drug candidates. These approaches typically place one atom at a time in an autoregressive fashion using the binding pocket as well as previously added ligand atoms as context in each step. Recently a surge of diffusion generative models has entered this domain which hold promise to capture the statistical properties of natural ligands more faithfully. However, most existing methods focus exclusively on bottom-up de novo design of compounds or tackle other drug development challenges with task-specific models. The latter requires curation of suitable datasets, careful engineering of the models and retraining from scratch for each task. Here we show how a single pre-trained diffusion model can be applied to a broader range of problems, such as off-the-shelf property optimization, explicit negative design, and partial molecular design with inpainting. We formulate SBDD as a 3D-conditional generation problem and present DiffSBDD, an SE(3)-equivariant diffusion model that generates novel ligands conditioned on protein pockets. Our in silico experiments demonstrate that DiffSBDD captures the statistics of the ground truth data effectively. Furthermore, we show how additional constraints can be used to improve the generated drug candidates according to a variety of computational metrics. These results support the assumption that diffusion models represent the complex distribution of structural data more accurately than previous methods, and are able to incorporate additional design objectives and constraints changing nothing but the sampling strategy.
<div id='section'>Paperid: <span id='pid'>751, <a href='https://arxiv.org/pdf/2209.15567.pdf' target='_blank'>https://arxiv.org/pdf/2209.15567.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gian Marco Visani, Michael N. Pun, Arman Angaji, Armita Nourmohammad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.15567">Holographic-(V)AE: an end-to-end SO(3)-Equivariant (Variational) Autoencoder in Fourier Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Group-equivariant neural networks have emerged as a data-efficient approach to solve classification and regression tasks, while respecting the relevant symmetries of the data. However, little work has been done to extend this paradigm to the unsupervised and generative domains. Here, we present Holographic-(Variational) Auto Encoder (H-(V)AE), a fully end-to-end SO(3)-equivariant (variational) autoencoder in Fourier space, suitable for unsupervised learning and generation of data distributed around a specified origin in 3D. H-(V)AE is trained to reconstruct the spherical Fourier encoding of data, learning in the process a low-dimensional representation of the data (i.e., a latent space) with a maximally informative rotationally invariant embedding alongside an equivariant frame describing the orientation of the data. We extensively test the performance of H-(V)AE on diverse datasets. We show that the learned latent space efficiently encodes the categorical features of spherical images. Moreover, H-(V)AE's latent space can be used to extract compact embeddings for protein structure microenvironments, and when paired with a Random Forest Regressor, it enables state-of-the-art predictions of protein-ligand binding affinity.
<div id='section'>Paperid: <span id='pid'>752, <a href='https://arxiv.org/pdf/2208.10230.pdf' target='_blank'>https://arxiv.org/pdf/2208.10230.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaosen Min, Ye Wei, Peizhuo Wang, Xiaoting Wang, Han Li, Nian Wu, Stefan Bauer, Shuxin Zheng, Yu Shi, Yingheng Wang, Ji Wu, Dan Zhao, Jianyang Zeng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.10230">From Static to Dynamic Structures: Improving Binding Affinity Prediction with Graph-Based Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of protein-ligand binding affinities is an essential challenge in structure-based drug design. Despite recent advances in data-driven methods for affinity prediction, their accuracy is still limited, partially because they only take advantage of static crystal structures while the actual binding affinities are generally determined by the thermodynamic ensembles between proteins and ligands. One effective way to approximate such a thermodynamic ensemble is to use molecular dynamics (MD) simulation. Here, an MD dataset containing 3,218 different protein-ligand complexes is curated, and Dynaformer, a graph-based deep learning model is further developed to predict the binding affinities by learning the geometric characteristics of the protein-ligand interactions from the MD trajectories. In silico experiments demonstrated that the model exhibits state-of-the-art scoring and ranking power on the CASF-2016 benchmark dataset, outperforming the methods hitherto reported. Moreover, in a virtual screening on heat shock protein 90 (HSP90) using Dynaformer, 20 candidates are identified and their binding affinities are further experimentally validated. Dynaformer displayed promising results in virtual drug screening, revealing 12 hit compounds (two are in the submicromolar range), including several novel scaffolds. Overall, these results demonstrated that the approach offer a promising avenue for accelerating the early drug discovery process.
<div id='section'>Paperid: <span id='pid'>753, <a href='https://arxiv.org/pdf/2208.02194.pdf' target='_blank'>https://arxiv.org/pdf/2208.02194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peizhen Bai, Filip MiljkoviÄ, Bino John, Haiping Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.02194">Interpretable bilinear attention network with domain adaptation improves drug-target prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting drug-target interaction is key for drug discovery. Recent deep learning-based methods show promising performance but two challenges remain: (i) how to explicitly model and learn local interactions between drugs and targets for better prediction and interpretation; (ii) how to generalize prediction performance on novel drug-target pairs from different distribution. In this work, we propose DrugBAN, a deep bilinear attention network (BAN) framework with domain adaptation to explicitly learn pair-wise local interactions between drugs and targets, and adapt on out-of-distribution data. DrugBAN works on drug molecular graphs and target protein sequences to perform prediction, with conditional domain adversarial learning to align learned interaction representations across different distributions for better generalization on novel drug-target pairs. Experiments on three benchmark datasets under both in-domain and cross-domain settings show that DrugBAN achieves the best overall performance against five state-of-the-art baselines. Moreover, visualizing the learned bilinear attention map provides interpretable insights from prediction results.
<div id='section'>Paperid: <span id='pid'>754, <a href='https://arxiv.org/pdf/2109.08215.pdf' target='_blank'>https://arxiv.org/pdf/2109.08215.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zi Wang, George E. Dahl, Kevin Swersky, Chansoo Lee, Zachary Nado, Justin Gilmer, Jasper Snoek, Zoubin Ghahramani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2109.08215">Pre-trained Gaussian Processes for Bayesian Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian optimization (BO) has become a popular strategy for global optimization of expensive real-world functions. Contrary to a common expectation that BO is suited to optimizing black-box functions, it actually requires domain knowledge about those functions to deploy BO successfully. Such domain knowledge often manifests in Gaussian process (GP) priors that specify initial beliefs on functions. However, even with expert knowledge, it is non-trivial to quantitatively define a prior. This is especially true for hyperparameter tuning problems on complex machine learning models, where landscapes of tuning objectives are often difficult to comprehend. We seek an alternative practice for setting these functional priors. In particular, we consider the scenario where we have data from similar functions that allow us to pre-train a tighter distribution a priori. We detail what pre-training entails for GPs using a KL divergence based loss function, and propose a new pre-training based BO framework named HyperBO. Theoretically, we show bounded posterior predictions and near-zero regrets for HyperBO without assuming the "ground truth" GP prior is known. To verify our approach in realistic setups, we collect a large multi-task hyperparameter tuning dataset by training tens of thousands of configurations of near-state-of-the-art deep learning models on popular image and text datasets, as well as a protein sequence dataset. Our results show that on average, HyperBO is able to locate good hyperparameters at least 3 times more efficiently than the best competing methods on both our new tuning dataset and existing multi-task BO benchmarks.
<div id='section'>Paperid: <span id='pid'>755, <a href='https://arxiv.org/pdf/2104.09310.pdf' target='_blank'>https://arxiv.org/pdf/2104.09310.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Philippe Weitz, Yinxi Wang, Kimmo Kartasalo, Lars Egevad, Johan Lindberg, Henrik GrÃ¶nberg, Martin Eklund, Mattias Rantalainen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2104.09310">Transcriptome-wide prediction of prostate cancer gene expression from histopathology images using co-expression based convolutional neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular phenotyping by gene expression profiling is common in contemporary cancer research and in molecular diagnostics. However, molecular profiling remains costly and resource intense to implement, and is just starting to be introduced into clinical diagnostics. Molecular changes, including genetic alterations and gene expression changes, occuring in tumors cause morphological changes in tissue, which can be observed on the microscopic level. The relationship between morphological patterns and some of the molecular phenotypes can be exploited to predict molecular phenotypes directly from routine haematoxylin and eosin (H&E) stained whole slide images (WSIs) using deep convolutional neural networks (CNNs). In this study, we propose a new, computationally efficient approach for disease specific modelling of relationships between morphology and gene expression, and we conducted the first transcriptome-wide analysis in prostate cancer, using CNNs to predict bulk RNA-sequencing estimates from WSIs of H&E stained tissue. The work is based on the TCGA PRAD study and includes both WSIs and RNA-seq data for 370 patients. Out of 15586 protein coding and sufficiently frequently expressed transcripts, 6618 had predicted expression significantly associated with RNA-seq estimates (FDR-adjusted p-value < 1*10-4) in a cross-validation. 5419 (81.9%) of these were subsequently validated in a held-out test set. We also demonstrate the ability to predict a prostate cancer specific cell cycle progression score directly from WSIs. These findings suggest that contemporary computer vision models offer an inexpensive and scalable solution for prediction of gene expression phenotypes directly from WSIs, providing opportunity for cost-effective large-scale research studies and molecular diagnostics.
<div id='section'>Paperid: <span id='pid'>756, <a href='https://arxiv.org/pdf/2009.01054.pdf' target='_blank'>https://arxiv.org/pdf/2009.01054.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Markus Viljanen, Antti Airola, Tapio Pahikkala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2009.01054">Generalized vec trick for fast learning of pairwise kernel models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pairwise learning corresponds to the supervised learning setting where the goal is to make predictions for pairs of objects. Prominent applications include predicting drug-target or protein-protein interactions, or customer-product preferences. In this work, we present a comprehensive review of pairwise kernels, that have been proposed for incorporating prior knowledge about the relationship between the objects. Specifically, we consider the standard, symmetric and anti-symmetric Kronecker product kernels, metric-learning, Cartesian, ranking, as well as linear, polynomial and Gaussian kernels. Recently, a O(nm + nq) time generalized vec trick algorithm, where n, m, and q denote the number of pairs, drugs and targets, was introduced for training kernel methods with the Kronecker product kernel. This was a significant improvement over previous O(n^2) training methods, since in most real-world applications m,q << n. In this work we show how all the reviewed kernels can be expressed as sums of Kronecker products, allowing the use of generalized vec trick for speeding up their computation. In the experiments, we demonstrate how the introduced approach allows scaling pairwise kernels to much larger data sets than previously feasible, and provide an extensive comparison of the kernels on a number of biological interaction prediction tasks.
<div id='section'>Paperid: <span id='pid'>757, <a href='https://arxiv.org/pdf/2509.20693.pdf' target='_blank'>https://arxiv.org/pdf/2509.20693.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammadsaleh Refahi, Bahrad A. Sokhansanj, James R. Brown, Gail Rosen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.20693">Learning to Align Molecules and Proteins: A Geometry-Aware Approach to Binding Affinity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of drug-target binding affinity can accelerate drug discovery by prioritizing promising compounds before costly wet-lab screening. While deep learning has advanced this task, most models fuse ligand and protein representations via simple concatenation and lack explicit geometric regularization, resulting in poor generalization across chemical space and time. We introduce FIRM-DTI, a lightweight framework that conditions molecular embeddings on protein embeddings through a feature-wise linear modulation (FiLM) layer and enforces metric structure with a triplet loss. An RBF regression head operating on embedding distances yields smooth, interpretable affinity predictions. Despite its modest size, FIRM-DTI achieves state-of-the-art performance on the Therapeutics Data Commons DTI-DG benchmark, as demonstrated by an extensive ablation study and out-of-domain evaluation. Our results underscore the value of conditioning and metric learning for robust drug-target affinity prediction.
<div id='section'>Paperid: <span id='pid'>758, <a href='https://arxiv.org/pdf/2509.20345.pdf' target='_blank'>https://arxiv.org/pdf/2509.20345.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meshi Bashari, Yonghoon Lee, Roy Maor Lotan, Edgar Dobriban, Yaniv Romano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.20345">Statistical Inference Leveraging Synthetic Data with Distribution-Free Guarantees</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid proliferation of high-quality synthetic data -- generated by advanced AI models or collected as auxiliary data from related tasks -- presents both opportunities and challenges for statistical inference. This paper introduces a GEneral Synthetic-Powered Inference (GESPI) framework that wraps around any statistical inference procedure to safely enhance sample efficiency by combining synthetic and real data. Our framework leverages high-quality synthetic data to boost statistical power, yet adaptively defaults to the standard inference method using only real data when synthetic data is of low quality. The error of our method remains below a user-specified bound without any distributional assumptions on the synthetic data, and decreases as the quality of the synthetic data improves. This flexibility enables seamless integration with conformal prediction, risk control, hypothesis testing, and multiple testing procedures, all without modifying the base inference method. We demonstrate the benefits of our method on challenging tasks with limited labeled data, including AlphaFold protein structure prediction, and comparing large reasoning models on complex math problems.
<div id='section'>Paperid: <span id='pid'>759, <a href='https://arxiv.org/pdf/2509.19604.pdf' target='_blank'>https://arxiv.org/pdf/2509.19604.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiayi Xin, Aniruddh Raghu, Nick Bhattacharya, Adam Carr, Melanie Montgomery, Hunter Elliott
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.19604">Improved Therapeutic Antibody Reformatting through Multimodal Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern therapeutic antibody design often involves composing multi-part assemblages of individual functional domains, each of which may be derived from a different source or engineered independently. While these complex formats can expand disease applicability and improve safety, they present a significant engineering challenge: the function and stability of individual domains are not guaranteed in the novel format, and the entire molecule may no longer be synthesizable. To address these challenges, we develop a machine learning framework to predict "reformatting success" -- whether converting an antibody from one format to another will succeed or not. Our framework incorporates both antibody sequence and structural context, incorporating an evaluation protocol that reflects realistic deployment scenarios. In experiments on a real-world antibody reformatting dataset, we find the surprising result that large pretrained protein language models (PLMs) fail to outperform simple, domain-tailored, multimodal representations. This is particularly evident in the most difficult evaluation setting, where we test model generalization to a new starting antibody. In this challenging "new antibody, no data" scenario, our best multimodal model achieves high predictive accuracy, enabling prioritization of promising candidates and reducing wasted experimental effort.
<div id='section'>Paperid: <span id='pid'>760, <a href='https://arxiv.org/pdf/2509.16357.pdf' target='_blank'>https://arxiv.org/pdf/2509.16357.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aniruddh Raghu, Sebastian Ober, Maxwell Kazman, Hunter Elliott
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.16357">Guided Sequence-Structure Generative Modeling for Iterative Antibody Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Therapeutic antibody candidates often require extensive engineering to improve key functional and developability properties before clinical development. This can be achieved through iterative design, where starting molecules are optimized over several rounds of in vitro experiments. While protein structure can provide a strong inductive bias, it is rarely used in iterative design due to the lack of structural data for continually evolving lead molecules over the course of optimization. In this work, we propose a strategy for iterative antibody optimization that leverages both sequence and structure as well as accumulating lab measurements of binding and developability. Building on prior work, we first train a sequence-structure diffusion generative model that operates on antibody-antigen complexes. We then outline an approach to use this model, together with carefully predicted antibody-antigen complexes, to optimize lead candidates throughout the iterative design process. Further, we describe a guided sampling approach that biases generation toward desirable properties by integrating models trained on experimental data from iterative design. We evaluate our approach in multiple in silico and in vitro experiments, demonstrating that it produces high-affinity binders at multiple stages of an active antibody optimization campaign.
<div id='section'>Paperid: <span id='pid'>761, <a href='https://arxiv.org/pdf/2509.14788.pdf' target='_blank'>https://arxiv.org/pdf/2509.14788.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Lan, Hexiao Ding, Hongzhao Chen, Yufeng Jiang, Nga-Chun Ng, Gwing Kei Yip, Gerald W. Y. Cheng, Yunlin Mao, Jing Cai, Liang-ting Lin, Jung Sun Yoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14788">Structure-Aware Contrastive Learning with Fine-Grained Binding Representations for Drug Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate identification of drug-target interactions (DTI) remains a central challenge in computational pharmacology, where sequence-based methods offer scalability. This work introduces a sequence-based drug-target interaction framework that integrates structural priors into protein representations while maintaining high-throughput screening capability. Evaluated across multiple benchmarks, the model achieves state-of-the-art performance on Human and BioSNAP datasets and remains competitive on BindingDB. In virtual screening tasks, it surpasses prior methods on LIT-PCBA, yielding substantial gains in AUROC and BEDROC. Ablation studies confirm the critical role of learned aggregation, bilinear attention, and contrastive alignment in enhancing predictive robustness. Embedding visualizations reveal improved spatial correspondence with known binding pockets and highlight interpretable attention patterns over ligand-residue contacts. These results validate the framework's utility for scalable and structure-aware DTI prediction.
<div id='section'>Paperid: <span id='pid'>762, <a href='https://arxiv.org/pdf/2509.13294.pdf' target='_blank'>https://arxiv.org/pdf/2509.13294.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Allan dos Santos Costa, Manvitha Ponnapati, Dana Rubin, Tess Smidt, Joseph Jacobson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13294">Accelerating Protein Molecular Dynamics Simulation with DeepJump</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unraveling the dynamical motions of biomolecules is essential for bridging their structure and function, yet it remains a major computational challenge. Molecular dynamics (MD) simulation provides a detailed depiction of biomolecular motion, but its high-resolution temporal evolution comes at significant computational cost, limiting its applicability to timescales of biological relevance. Deep learning approaches have emerged as promising solutions to overcome these computational limitations by learning to predict long-timescale dynamics. However, generalizable kinetics models for proteins remain largely unexplored, and the fundamental limits of achievable acceleration while preserving dynamical accuracy are poorly understood. In this work, we fill this gap with DeepJump, an Euclidean-Equivariant Flow Matching-based model for predicting protein conformational dynamics across multiple temporal scales. We train DeepJump on trajectories of the diverse proteins of mdCATH, systematically studying our model's performance in generalizing to long-term dynamics of fast-folding proteins and characterizing the trade-off between computational acceleration and prediction accuracy. We demonstrate the application of DeepJump to ab initio folding, showcasing prediction of folding pathways and native states. Our results demonstrate that DeepJump achieves significant $\approx$1000$\times$ computational acceleration while effectively recovering long-timescale dynamics, providing a stepping stone for enabling routine simulation of proteins.
<div id='section'>Paperid: <span id='pid'>763, <a href='https://arxiv.org/pdf/2509.02069.pdf' target='_blank'>https://arxiv.org/pdf/2509.02069.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Srinivas Anumasa, Barath Chandran. C, Tingting Chen, Dianbo Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02069">Data-Dependent Smoothing for Protein Discovery with Walk-Jump Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have emerged as a powerful class of generative models by learning to iteratively reverse the noising process. Their ability to generate high-quality samples has extended beyond high-dimensional image data to other complex domains such as proteins, where data distributions are typically sparse and unevenly spread. Importantly, the sparsity itself is uneven. Empirically, we observed that while a small fraction of samples lie in dense clusters, the majority occupy regions of varying sparsity across the data space. Existing approaches largely ignore this data-dependent variability. In this work, we introduce a Data-Dependent Smoothing Walk-Jump framework that employs kernel density estimation (KDE) as a preprocessing step to estimate the noise scale $σ$ for each data point, followed by training a score model with these data-dependent $σ$ values. By incorporating local data geometry into the denoising process, our method accounts for the heterogeneous distribution of protein data. Empirical evaluations demonstrate that our approach yields consistent improvements across multiple metrics, highlighting the importance of data-aware sigma prediction for generative modeling in sparse, high-dimensional settings.
<div id='section'>Paperid: <span id='pid'>764, <a href='https://arxiv.org/pdf/2508.18949.pdf' target='_blank'>https://arxiv.org/pdf/2508.18949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenyin Zhou, Christopher Iliffe Sprague, Vsevolod Viliuga, Matteo Tadiello, Arne Elofsson, Hossein Azizpour
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18949">Energy-Based Flow Matching for Generating 3D Molecular Structure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular structure generation is a fundamental problem that involves determining the 3D positions of molecules' constituents. It has crucial biological applications, such as molecular docking, protein folding, and molecular design. Recent advances in generative modeling, such as diffusion models and flow matching, have made great progress on these tasks by modeling molecular conformations as a distribution. In this work, we focus on flow matching and adopt an energy-based perspective to improve training and inference of structure generation models. Our view results in a mapping function, represented by a deep network, that is directly learned to \textit{iteratively} map random configurations, i.e. samples from the source distribution, to target structures, i.e. points in the data manifold. This yields a conceptually simple and empirically effective flow matching setup that is theoretically justified and has interesting connections to fundamental properties such as idempotency and stability, as well as the empirically useful techniques such as structure refinement in AlphaFold. Experiments on protein docking as well as protein backbone generation consistently demonstrate the method's effectiveness, where it outperforms recent baselines of task-associated flow matching and diffusion models, using a similar computational budget.
<div id='section'>Paperid: <span id='pid'>765, <a href='https://arxiv.org/pdf/2508.18567.pdf' target='_blank'>https://arxiv.org/pdf/2508.18567.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Darin Tsui, Kunal Talreja, Amirali Aghazadeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18567">Sparse Autoencoders for Low-$N$ Protein Function Prediction and Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting protein function from amino acid sequence remains a central challenge in data-scarce (low-$N$) regimes, limiting machine learning-guided protein design when only small amounts of assay-labeled sequence-function data are available. Protein language models (pLMs) have advanced the field by providing evolutionary-informed embeddings and sparse autoencoders (SAEs) have enabled decomposition of these embeddings into interpretable latent variables that capture structural and functional features. However, the effectiveness of SAEs for low-$N$ function prediction and protein design has not been systematically studied. Herein, we evaluate SAEs trained on fine-tuned ESM2 embeddings across diverse fitness extrapolation and protein engineering tasks. We show that SAEs, with as few as 24 sequences, consistently outperform or compete with their ESM2 baselines in fitness prediction, indicating that their sparse latent space encodes compact and biologically meaningful representations that generalize more effectively from limited data. Moreover, steering predictive latents exploits biological motifs in pLM representations, yielding top-fitness variants in 83% of cases compared to designing with ESM2 alone.
<div id='section'>Paperid: <span id='pid'>766, <a href='https://arxiv.org/pdf/2508.09499.pdf' target='_blank'>https://arxiv.org/pdf/2508.09499.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liyan Jia, Chuan-Xian Ren, Hong Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.09499">CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting the binding conformation of small-molecule ligands to protein targets is a critical step in rational drug design. Although recent deep learning-based docking surpasses traditional methods in speed and accuracy, many approaches rely on graph representations and language model-inspired encoders while neglecting critical geometric information, resulting in inaccurate pocket localization and unrealistic binding conformations. In this study, we introduce CWFBind, a weighted, fast, and accurate docking method based on local curvature features. Specifically, we integrate local curvature descriptors during the feature extraction phase to enrich the geometric representation of both proteins and ligands, complementing existing chemical, sequence, and structural features. Furthermore, we embed degree-aware weighting mechanisms into the message passing process, enhancing the model's ability to capture spatial structural distinctions and interaction strengths. To address the class imbalance challenge in pocket prediction, CWFBind employs a ligand-aware dynamic radius strategy alongside an enhanced loss function, facilitating more precise identification of binding regions and key residues. Comprehensive experimental evaluations demonstrate that CWFBind achieves competitive performance across multiple docking benchmarks, offering a balanced trade-off between accuracy and efficiency.
<div id='section'>Paperid: <span id='pid'>767, <a href='https://arxiv.org/pdf/2508.04743.pdf' target='_blank'>https://arxiv.org/pdf/2508.04743.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Debanjan Konar, Neerav Sreekumar, Richard Jiang, Vaneet Aggarwal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.04743">Alz-QNet: A Quantum Regression Network for Studying Alzheimer's Gene Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the molecular-level mechanisms underpinning Alzheimer's disease (AD) by studying crucial genes associated with the disease remains a challenge. Alzheimer's, being a multifactorial disease, requires understanding the gene-gene interactions underlying it for theranostics and progress. In this article, a novel attempt has been made using a quantum regression to decode how some crucial genes in the AD Amyloid Beta Precursor Protein ($APP$), Sterol regulatory element binding transcription factor 14 ($FGF14$), Yin Yang 1 ($YY1$), and Phospholipase D Family Member 3 ($PLD3$) etc. become influenced by other prominent switching genes during disease progression, which may help in gene expression-based therapy for AD. Our proposed Quantum Regression Network (Alz-QNet) introduces a pioneering approach with insights from the state-of-the-art Quantum Gene Regulatory Networks (QGRN) to unravel the gene interactions involved in AD pathology, particularly within the Entorhinal Cortex (EC), where early pathological changes occur. Using the proposed Alz-QNet framework, we explore the interactions between key genes ($APP$, $FGF14$, $YY1$, $EGR1$, $GAS7$, $AKT3$, $SREBF2$, and $PLD3$) within the CE microenvironment of AD patients, studying genetic samples from the database $GSE138852$, all of which are believed to play a crucial role in the progression of AD. Our investigation uncovers intricate gene-gene interactions, shedding light on the potential regulatory mechanisms that underlie the pathogenesis of AD, which help us to find potential gene inhibitors or regulators for theranostics.
<div id='section'>Paperid: <span id='pid'>768, <a href='https://arxiv.org/pdf/2508.01799.pdf' target='_blank'>https://arxiv.org/pdf/2508.01799.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Lan, Hexiao Ding, Hongzhao Chen, Yufeng Jiang, Nga-Chun Ng, Gerald W. Y. Cheng, Zongxi Li, Jing Cai, Liang-ting Lin, Jung Sun Yoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.01799">Contrastive Multi-Task Learning with Solvent-Aware Augmentation for Drug Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of protein-ligand interactions is essential for computer-aided drug discovery. However, existing methods often fail to capture solvent-dependent conformational changes and lack the ability to jointly learn multiple related tasks. To address these limitations, we introduce a pre-training method that incorporates ligand conformational ensembles generated under diverse solvent conditions as augmented input. This design enables the model to learn both structural flexibility and environmental context in a unified manner. The training process integrates molecular reconstruction to capture local geometry, interatomic distance prediction to model spatial relationships, and contrastive learning to build solvent-invariant molecular representations. Together, these components lead to significant improvements, including a 3.7% gain in binding affinity prediction, an 82% success rate on the PoseBusters Astex docking benchmarks, and an area under the curve of 97.1% in virtual screening. The framework supports solvent-aware, multi-task modeling and produces consistent results across benchmarks. A case study further demonstrates sub-angstrom docking accuracy with a root-mean-square deviation of 0.157 angstroms, offering atomic-level insight into binding mechanisms and advancing structure-based drug design.
<div id='section'>Paperid: <span id='pid'>769, <a href='https://arxiv.org/pdf/2508.00837.pdf' target='_blank'>https://arxiv.org/pdf/2508.00837.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuqi Zhang, Yuxin Yang, Cheng-Chang Lu, Weiwen Jiang, Feixiong Cheng, Bo Fang, Qiang Guan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00837">QDockBank: A Dataset for Ligand Docking on Protein Fragments Predicted on Utility-Level Quantum Computers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structure prediction is a core challenge in computational biology, particularly for fragments within ligand-binding regions, where accurate modeling is still difficult. Quantum computing offers a novel first-principles modeling paradigm, but its application is currently limited by hardware constraints, high computational cost, and the lack of a standardized benchmarking dataset. In this work, we present QDockBank-the first large-scale protein fragment structure dataset generated entirely using utility-level quantum computers, specifically designed for protein-ligand docking tasks. QDockBank comprises 55 protein fragments extracted from ligand-binding pockets. The dataset was generated through tens of hours of execution on superconducting quantum processors, making it the first quantum-based protein structure dataset with a total computational cost exceeding one million USD. Experimental evaluations demonstrate that structures predicted by QDockBank outperform those predicted by AlphaFold2 and AlphaFold3 in terms of both RMSD and docking affinity scores. QDockBank serves as a new benchmark for evaluating quantum-based protein structure prediction.
<div id='section'>Paperid: <span id='pid'>770, <a href='https://arxiv.org/pdf/2507.18558.pdf' target='_blank'>https://arxiv.org/pdf/2507.18558.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihong Feng, Chaitanya Pallerla, Xiaomin Lin, Pouya Sohrabipour, Philip Crandall, Wan Shou, Yu She, Dongyi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18558">Synthetic Data Augmentation for Enhanced Chicken Carcass Instance Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The poultry industry has been driven by broiler chicken production and has grown into the world's largest animal protein sector. Automated detection of chicken carcasses on processing lines is vital for quality control, food safety, and operational efficiency in slaughterhouses and poultry processing plants. However, developing robust deep learning models for tasks like instance segmentation in these fast-paced industrial environments is often hampered by the need for laborious acquisition and annotation of large-scale real-world image datasets. We present the first pipeline generating photo-realistic, automatically labeled synthetic images of chicken carcasses. We also introduce a new benchmark dataset containing 300 annotated real-world images, curated specifically for poultry segmentation research. Using these datasets, this study investigates the efficacy of synthetic data and automatic data annotation to enhance the instance segmentation of chicken carcasses, particularly when real annotated data from the processing line is scarce. A small real dataset with varying proportions of synthetic images was evaluated in prominent instance segmentation models. Results show that synthetic data significantly boosts segmentation performance for chicken carcasses across all models. This research underscores the value of synthetic data augmentation as a viable and effective strategy to mitigate data scarcity, reduce manual annotation efforts, and advance the development of robust AI-driven automated detection systems for chicken carcasses in the poultry processing industry.
<div id='section'>Paperid: <span id='pid'>771, <a href='https://arxiv.org/pdf/2507.13646.pdf' target='_blank'>https://arxiv.org/pdf/2507.13646.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nimisha Ghosh, Daniele Santoni, Debaleena Nawn, Eleonora Ottaviani, Giovanni Felici
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.13646">A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The impact of Transformer-based language models has been unprecedented in Natural Language Processing (NLP). The success of such models has also led to their adoption in other fields including bioinformatics. Taking this into account, this paper discusses recent advances in Transformer-based models for protein sequence analysis and design. In this review, we have discussed and analysed a significant number of works pertaining to such applications. These applications encompass gene ontology, functional and structural protein identification, generation of de novo proteins and binding of proteins. We attempt to shed light on the strength and weaknesses of the discussed works to provide a comprehensive insight to readers. Finally, we highlight shortcomings in existing research and explore potential avenues for future developments. We believe that this review will help researchers working in this field to have an overall idea of the state of the art in this field, and to orient their future studies.
<div id='section'>Paperid: <span id='pid'>772, <a href='https://arxiv.org/pdf/2507.12470.pdf' target='_blank'>https://arxiv.org/pdf/2507.12470.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jin Xu, XiaoLong Shi, Xin Chen, Fang Wang, Sirui Li, Pali Ye, Boliang Zhang, Di Deng, Zheng Kou, Xiaoli Qiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.12470">DNA Probe Computing System for Solving NP-Complete Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficiently solving NP-complete problems-such as protein structure prediction, cryptographic decryption, and vulnerability detection-remains a central challenge in computer science. Traditional electronic computers, constrained by the Turing machine's one-dimensional data processing and sequential operations, struggle to address these issues effectively. To overcome this bottleneck, computational models must adopt multidimensional data structures and parallel information processing mechanisms. Building on our team's proposed probe machine model (a non-Turing computational framework), this study develops a blocking probe technique that leverages DNA computing's inherent parallelism to identify all valid solutions for NP-complete problems in a single probe operation. Using the 27-vertex 3-coloring problem as a case study, we successfully retrieved all solutions through DNA molecular probe experiments. This breakthrough demonstrates the first implementation of a fully parallel computing system at the molecular level, offering a novel paradigm for tackling computational complexity. Our results indicate that the probe machine, with its parallel architecture and molecular implementation, transcends the limitations of classical models and holds promise for solving intricate real-world problems.
<div id='section'>Paperid: <span id='pid'>773, <a href='https://arxiv.org/pdf/2507.07887.pdf' target='_blank'>https://arxiv.org/pdf/2507.07887.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Achuth Chandrasekhar, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07887">Automating MD simulations for Proteins using Large language Models: NAMD-Agent</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular dynamics simulations are an essential tool in understanding protein structure, dynamics, and function at the atomic level. However, preparing high quality input files for MD simulations can be a time consuming and error prone process. In this work, we introduce an automated pipeline that leverages Large Language Models (LLMs), specifically Gemini 2.0 Flash, in conjunction with python scripting and Selenium based web automation to streamline the generation of MD input files. The pipeline exploits CHARMM GUI's comprehensive web-based interface for preparing simulation-ready inputs for NAMD. By integrating Gemini's code generation and iterative refinement capabilities, simulation scripts are automatically written, executed, and revised to navigate CHARMM GUI, extract appropriate parameters, and produce the required NAMD input files. Post processing is performed using additional software to further refine the simulation outputs, thereby enabling a complete and largely hands free workflow. Our results demonstrate that this approach reduces setup time, minimizes manual errors, and offers a scalable solution for handling multiple protein systems in parallel. This automated framework paves the way for broader application of LLMs in computational structural biology, offering a robust and adaptable platform for future developments in simulation automation.
<div id='section'>Paperid: <span id='pid'>774, <a href='https://arxiv.org/pdf/2507.03318.pdf' target='_blank'>https://arxiv.org/pdf/2507.03318.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zanyu Shi, Yang Wang, Pathum Weerawarna, Jie Zhang, Timothy Richardson, Yijie Wang, Kun Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.03318">Structure-Aware Compound-Protein Affinity Prediction via Graph Neural Network with Group Lasso Regularization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explainable artificial intelligence (XAI) approaches have been increasingly applied in drug discovery to learn molecular representations and identify substructures driving property predictions. However, building end-to-end explainable machine learning models for structure-activity relationship (SAR) modeling for compound property prediction faces many challenges, such as limited activity data per target and the sensitivity of properties to subtle molecular changes. To address this, we leveraged activity-cliff molecule pairs, i.e., compounds sharing a common scaffold but differing sharply in potency, targeting three proto-oncogene tyrosine-protein kinase Src proteins (i.e., PDB IDs 1O42, 2H8H, and 4MXO). We implemented graph neural network (GNN) methods to obtain atom-level feature information and predict compound-protein affinity (i.e., half maximal inhibitory concentration, IC50). In addition, we trained GNN models with different structure-aware loss functions to adequately leverage molecular property and structure information. We also utilized group lasso and sparse group lasso to prune and highlight molecular subgraphs and enhance the structure-specific model explainability for the predicted property difference in molecular activity-cliff pairs. We improved drug property prediction by integrating common and uncommon node information and using sparse group lasso, reducing the average root mean squared error (RMSE) by 12.70%, and achieving the lowest averaged RMSE=0.2551 and the highest PCC=0.9572. Furthermore, applying regularization enhances feature attribution methods that estimate the contribution of each atom in the molecular graphs by boosting global direction scores and atom-level accuracy in atom coloring accuracy, which improves model interpretability in drug discovery pipelines, particularly in investigating important molecular substructures in lead optimization.
<div id='section'>Paperid: <span id='pid'>775, <a href='https://arxiv.org/pdf/2507.03174.pdf' target='_blank'>https://arxiv.org/pdf/2507.03174.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunrui Qiu, Richard John, Lukas Herron, Pratyush Tiwary
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.03174">Latent Thermodynamic Flows: Unified Representation Learning and Generative Modeling of Temperature-Dependent Behaviors from Limited Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate characterization of the equilibrium distributions of complex molecular systems and their dependence on environmental factors such as temperature is essential for understanding thermodynamic properties and transition mechanisms. Projecting these distributions onto meaningful low-dimensional representations enables interpretability and downstream analysis. Recent advances in generative AI, particularly flow models such as Normalizing Flows (NFs), have shown promise in modeling such distributions, but their scope is limited without tailored representation learning. In this work, we introduce Latent Thermodynamic Flows (LaTF), an end-to-end framework that tightly integrates representation learning and generative modeling. LaTF unifies the State Predictive Information Bottleneck (SPIB) with NFs to simultaneously learn low-dimensional latent representations, referred to as Collective Variables (CVs), classify metastable states, and generate equilibrium distributions across temperatures beyond the training data. The two components of representation learning and generative modeling are optimized jointly, ensuring that the learned latent features capture the system's slow, important degrees of freedom while the generative model accurately reproduces the system's equilibrium behavior. We demonstrate LaTF's effectiveness across diverse systems, including a model potential, the Chignolin protein, and cluster of Lennard Jones particles, with thorough evaluations and benchmarking using multiple metrics and extensive simulations. Finally, we apply LaTF to a RNA tetraloop system, where despite using simulation data from only two temperatures, LaTF reconstructs the temperature-dependent structural ensemble and melting behavior, consistent with experimental and prior extensive computational results.
<div id='section'>Paperid: <span id='pid'>776, <a href='https://arxiv.org/pdf/2506.22677.pdf' target='_blank'>https://arxiv.org/pdf/2506.22677.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuqi Zhang, Yuxin Yang, William Martin, Kingsten Lin, Zixu Wang, Cheng-Chang Lu, Weiwen Jiang, Ruth Nussinov, Joseph Loscalzo, Qiang Guan, Feixiong Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22677">Prediction of Protein Three-dimensional Structures via a Hardware-Executable Quantum Computing Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of protein active site structures remains a central challenge in structural biology, particularly for short and flexible peptide fragments where conventional methods often fail. Here, we present a quantum computing framework specifically developed for utility-level quantum processors to address this problem. Starting from an amino acid sequence, we formulate the structure prediction task as a ground-state energy minimization problem using the Variational Quantum Eigensolver (VQE). Amino acid connectivity is encoded on a tetrahedral lattice model, and structural constraints-including steric, geometric, and chirality terms-are mapped into a problem-specific Hamiltonian expressed as sparse Pauli operators. The optimization is executed via a two-stage architecture separating energy estimation and measurement decoding, allowing noise mitigation under realistic quantum device conditions. We evaluate the framework on 23 randomly selected real protein fragments from the PDBbind dataset, as well as 7 real fragments from proteins with therapeutic potential, and run the experiments on the IBM-Cleveland Clinic quantum processor. Structural predictions are benchmarked against AlphaFold3 (AF3) using identical postprocessing and docking procedures. Our quantum method outperformed AF3 in both RMSD (Root-Mean-Square Deviation) and docking efficacy. This work demonstrates, for the first time, a complete end-to-end pipeline for biologically relevant structure prediction on real quantum hardware, highlighting its engineering feasibility and practical advantage over existing classical and deep learning approaches.
<div id='section'>Paperid: <span id='pid'>777, <a href='https://arxiv.org/pdf/2506.10908.pdf' target='_blank'>https://arxiv.org/pdf/2506.10908.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emmanuel J. CandÃ¨s, Andrew Ilyas, Tijana Zrnic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10908">Probably Approximately Correct Labels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Obtaining high-quality labeled datasets is often costly, requiring either extensive human annotation or expensive experiments. We propose a method that supplements such "expert" labels with AI predictions from pre-trained models to construct labeled datasets more cost-effectively. Our approach results in probably approximately correct labels: with high probability, the overall labeling error is small. This solution enables rigorous yet efficient dataset curation using modern AI models. We demonstrate the benefits of the methodology through text annotation with large language models, image labeling with pre-trained vision models, and protein folding analysis with AlphaFold.
<div id='section'>Paperid: <span id='pid'>778, <a href='https://arxiv.org/pdf/2506.07035.pdf' target='_blank'>https://arxiv.org/pdf/2506.07035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixuan Jiang, Renjing Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.07035">AnnoDPO: Protein Functional Annotation Learning with Direct Preference Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deciphering protein function remains a fundamental challenge in protein representation learning. The task presents significant difficulties for protein language models (PLMs) due to the sheer volume of functional annotation categories and the highly imbalanced distribution of annotated instances across biological ontologies. Inspired by the remarkable success of reinforcement learning from human feedback (RLHF) in large language model (LLM) alignment, we propose AnnoDPO, a novel multi-modal framework for protein function prediction that leverages Direct Preference Optimization (DPO) to enhance annotation learning. Our methodology addresses the dual challenges of annotation scarcity and category imbalance through preference-aligned training objectives, establishing a new paradigm for biological knowledge integration in protein representation learning.
<div id='section'>Paperid: <span id='pid'>779, <a href='https://arxiv.org/pdf/2506.04235.pdf' target='_blank'>https://arxiv.org/pdf/2506.04235.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyan Zhao, Yi-Ching Tang, Akshita Singh, Victor J Cantu, KwanHo An, Junseok Lee, Adam E Stogsdill, Ashwin Kumar Ramesh, Zhiqiang An, Xiaoqian Jiang, Yejin Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.04235">Benchmark for Antibody Binding Affinity Maturation and Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce AbBiBench (Antibody Binding Benchmarking), a benchmarking framework for antibody binding affinity maturation and design. Unlike existing antibody evaluation strategies that rely on antibody alone and its similarity to natural ones (e.g., amino acid identity rate, structural RMSD), AbBiBench considers an antibody-antigen (Ab-Ag) complex as a functional unit and evaluates the potential of an antibody design binding to given antigen by measuring protein model's likelihood on the Ab-Ag complex. We first curate, standardize, and share 9 datasets containing 9 antigens (involving influenza, anti-lysozyme, HER2, VEGF, integrin, and SARS-CoV-2) and 155,853 heavy chain mutated antibodies. Using these datasets, we systematically compare 14 protein models including masked language models, autoregressive language models, inverse folding models, diffusion-based generative models, and geometric graph models. The correlation between model likelihood and experimental affinity values is used to evaluate model performance. Additionally, in a case study to increase binding affinity of antibody F045-092 to antigen influenza H1N1, we evaluate the generative power of the top-performing models by sampling a set of new antibodies binding to the antigen and ranking them based on structural integrity and biophysical properties of the Ab-Ag complex. As a result, structure-conditioned inverse folding models outperform others in both affinity correlation and generation tasks. Overall, AbBiBench provides a unified, biologically grounded evaluation framework to facilitate the development of more effective, function-aware antibody design models.
<div id='section'>Paperid: <span id='pid'>780, <a href='https://arxiv.org/pdf/2506.00297.pdf' target='_blank'>https://arxiv.org/pdf/2506.00297.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fanglei Xue, Andrew Kubaney, Zhichun Guo, Joseph K. Min, Ge Liu, Yi Yang, David Baker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00297">Improving Protein Sequence Design through Designability Preference Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein sequence design methods have demonstrated strong performance in sequence generation for de novo protein design. However, as the training objective was sequence recovery, it does not guarantee designability--the likelihood that a designed sequence folds into the desired structure. To bridge this gap, we redefine the training objective by steering sequence generation toward high designability. To do this, we integrate Direct Preference Optimization (DPO), using AlphaFold pLDDT scores as the preference signal, which significantly improves the in silico design success rate. To further refine sequence generation at a finer, residue-level granularity, we introduce Residue-level Designability Preference Optimization (ResiDPO), which applies residue-level structural rewards and decouples optimization across residues. This enables direct improvement in designability while preserving regions that already perform well. Using a curated dataset with residue-level annotations, we fine-tune LigandMPNN with ResiDPO to obtain EnhancedMPNN, which achieves a nearly 3-fold increase in in silico design success rate (from 6.56% to 17.57%) on a challenging enzyme design benchmark.
<div id='section'>Paperid: <span id='pid'>781, <a href='https://arxiv.org/pdf/2505.23354.pdf' target='_blank'>https://arxiv.org/pdf/2505.23354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meital Bojan, Sanketh Vedula, Advaith Maddipatla, Nadav Bojan Sellam, Federico Napoli, Paul Schanda, Alex M. Bronstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23354">Representing local protein environments with atomistic foundation models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The local structure of a protein strongly impacts its function and interactions with other molecules. Therefore, a concise, informative representation of a local protein environment is essential for modeling and designing proteins and biomolecular interactions. However, these environments' extensive structural and chemical variability makes them challenging to model, and such representations remain under-explored. In this work, we propose a novel representation for a local protein environment derived from the intermediate features of atomistic foundation models (AFMs). We demonstrate that this embedding effectively captures both local structure (e.g., secondary motifs), and chemical features (e.g., amino-acid identity and protonation state). We further show that the AFM-derived representation space exhibits meaningful structure, enabling the construction of data-driven priors over the distribution of biomolecular environments. Finally, in the context of biomolecular NMR spectroscopy, we demonstrate that the proposed representations enable a first-of-its-kind physics-informed chemical shift predictor that achieves state-of-the-art accuracy. Our results demonstrate the surprising effectiveness of atomistic foundation models and their emergent representations for protein modeling beyond traditional molecular simulations. We believe this will open new lines of work in constructing effective functional representations for protein environments.
<div id='section'>Paperid: <span id='pid'>782, <a href='https://arxiv.org/pdf/2505.11185.pdf' target='_blank'>https://arxiv.org/pdf/2505.11185.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francesco Madeddu, Lucia Testa, Gianluca De Carlo, Michele Pieroni, Andrea Mastropietro, Aris Anagnostopoulos, Paolo Tieri, Sergio Barbarossa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11185">VitaGraph: Building a Knowledge Graph for Biologically Relevant Learning Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The intrinsic complexity of human biology presents ongoing challenges to scientific understanding. Researchers collaborate across disciplines to expand our knowledge of the biological interactions that define human life. AI methodologies have emerged as powerful tools across scientific domains, particularly in computational biology, where graph data structures effectively model biological entities such as protein-protein interaction (PPI) networks and gene functional networks. Those networks are used as datasets for paramount network medicine tasks, such as gene-disease association prediction, drug repurposing, and polypharmacy side effect studies. Reliable predictions from machine learning models require high-quality foundational data. In this work, we present a comprehensive multi-purpose biological knowledge graph constructed by integrating and refining multiple publicly available datasets. Building upon the Drug Repurposing Knowledge Graph (DRKG), we define a pipeline tasked with a) cleaning inconsistencies and redundancies present in DRKG, b) coalescing information from the main available public data sources, and c) enriching the graph nodes with expressive feature vectors such as molecular fingerprints and gene ontologies. Biologically and chemically relevant features improve the capacity of machine learning models to generate accurate and well-structured embedding spaces. The resulting resource represents a coherent and reliable biological knowledge graph that serves as a state-of-the-art platform to advance research in computational biology and precision medicine. Moreover, it offers the opportunity to benchmark graph-based machine learning and network medicine models on relevant tasks. We demonstrate the effectiveness of the proposed dataset by benchmarking it against the task of drug repurposing, PPI prediction, and side-effect prediction, modeled as link prediction problems.
<div id='section'>Paperid: <span id='pid'>783, <a href='https://arxiv.org/pdf/2504.17624.pdf' target='_blank'>https://arxiv.org/pdf/2504.17624.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jigang Fan, Chunhao Zhu, Xiaobing Lan, Haiming Zhuang, Mingyu Li, Jian Zhang, Shaoyong Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.17624">Deciphering the unique dynamic activation pathway in a G protein-coupled receptor enables unveiling biased signaling and identifying cryptic allosteric sites in conformational intermediates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neurotensin receptor 1 (NTSR1), a member of the Class A G protein-coupled receptor superfamily, plays an important role in modulating dopaminergic neuronal activity and eliciting opioid-independent analgesia. Recent studies suggest that promoting \{beta}-arrestin-biased signaling in NTSR1 may diminish drugs of abuse, such as psychostimulants, thereby offering a potential avenue for treating human addiction-related disorders. In this study, we utilized a novel computational and experimental approach that combined nudged elastic band-based molecular dynamics simulations, Markov state models, temporal communication network analysis, site-directed mutagenesis, and conformational biosensors, to explore the intricate mechanisms underlying NTSR1 activation and biased signaling. Our study reveals a dynamic stepwise transition mechanism and activated transmission network associated with NTSR1 activation. It also yields valuable insights into the complex interplay between the unique polar network, non-conserved ion locks, and aromatic clusters in NTSR1 signaling. Moreover, we identified a cryptic allosteric site located in the intracellular region of the receptor that exists in an intermediate state within the activation pathway. Collectively, these findings contribute to a more profound understanding of NTSR1 activation and biased signaling at the atomic level, thereby providing a potential strategy for the development of NTSR1 allosteric modulators in the realm of G protein-coupled receptor biology, biophysics, and medicine.
<div id='section'>Paperid: <span id='pid'>784, <a href='https://arxiv.org/pdf/2504.04453.pdf' target='_blank'>https://arxiv.org/pdf/2504.04453.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Amaan Sayeed, Engin Tekin, Maryam Nadeem, Nancy A. ElNaker, Aahan Singh, Natalia Vassilieva, Boulbaba Ben Amor
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04453">Prot42: a Novel Family of Protein Language Models for Target-aware Protein Binder Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unlocking the next generation of biotechnology and therapeutic innovation demands overcoming the inherent complexity and resource-intensity of conventional protein engineering methods. Recent GenAI-powered computational techniques often rely on the availability of the target protein's 3D structures and specific binding sites to generate high-affinity binders, constraints exhibited by models such as AlphaProteo and RFdiffusion. In this work, we explore the use of Protein Language Models (pLMs) for high-affinity binder generation. We introduce Prot42, a novel family of Protein Language Models (pLMs) pretrained on vast amounts of unlabeled protein sequences. By capturing deep evolutionary, structural, and functional insights through an advanced auto-regressive, decoder-only architecture inspired by breakthroughs in natural language processing, Prot42 dramatically expands the capabilities of computational protein design based on language only. Remarkably, our models handle sequences up to 8,192 amino acids, significantly surpassing standard limitations and enabling precise modeling of large proteins and complex multi-domain sequences. Demonstrating powerful practical applications, Prot42 excels in generating high-affinity protein binders and sequence-specific DNA-binding proteins. Our innovative models are publicly available, offering the scientific community an efficient and precise computational toolkit for rapid protein engineering.
<div id='section'>Paperid: <span id='pid'>785, <a href='https://arxiv.org/pdf/2504.02899.pdf' target='_blank'>https://arxiv.org/pdf/2504.02899.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giuseppe Russo, Kristina GligoriÄ, Vincent Moreau, Robert West
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02899">Meat-Free Day Reduces Greenhouse Gas Emissions but Poses Challenges for Customer Retention and Adherence to Dietary Guidelines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reducing meat consumption is crucial for achieving global environmental and nutritional targets. Meat-Free Day (MFD) is a widely adopted strategy to address this challenge by encouraging plant-based diets through the removal of animal-based meals. We assessed the environmental, behavioral, and nutritional impacts of MFD by implementing 67 MFDs over 18 months (once a week on a randomly chosen day) across 12 cafeterias on a large university campus, analyzing over 400,000 food purchases. MFD reduced on-campus food-related greenhouse gas (GHG) emissions on treated days by 52.9% and contributed to improved fiber (+26.9%) and cholesterol (-4.5%) consumption without altering caloric intake. These nutritional benefits were, however, accompanied by a 27.6% decrease in protein intake and a 34.2% increase in sugar consumption. Moreover, the increase in plant-based meals did not carry over to subsequent days, as evidenced by a 3.5% rebound in animal-based meal consumption on days immediately following treated days. MFD also led to a 16.8% drop in on-campus meal sales on treated days.Monte Carlo simulations suggest that if 8.7% of diners were to eat burgers off-campus on treated days, MFD's GHG savings would be fully negated. As our analysis identifies on-campus customer retention as the main challenge to MFD effectiveness, we recommend combining MFD with customer retention interventions to ensure environmental and nutritional benefits.
<div id='section'>Paperid: <span id='pid'>786, <a href='https://arxiv.org/pdf/2503.22939.pdf' target='_blank'>https://arxiv.org/pdf/2503.22939.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fadi Alharbi, Nishant Budhiraja, Aleksandar Vakanski, Boyu Zhang, Murtada K. Elbashir, Harshith Guduru, Mohanad Mohammed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22939">Interpretable Graph Kolmogorov-Arnold Networks for Multi-Cancer Classification and Biomarker Identification using Multi-Omics Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The integration of heterogeneous multi-omics datasets at a systems level remains a central challenge for developing analytical and computational models in precision cancer diagnostics. This paper introduces Multi-Omics Graph Kolmogorov-Arnold Network (MOGKAN), a deep learning framework that utilizes messenger-RNA, micro-RNA sequences, and DNA methylation samples together with Protein-Protein Interaction (PPI) networks for cancer classification across 31 different cancer types. The proposed approach combines differential gene expression with DESeq2, Linear Models for Microarray (LIMMA), and Least Absolute Shrinkage and Selection Operator (LASSO) regression to reduce multi-omics data dimensionality while preserving relevant biological features. The model architecture is based on the Kolmogorov-Arnold theorem principle and uses trainable univariate functions to enhance interpretability and feature analysis. MOGKAN achieves classification accuracy of 96.28 percent and exhibits low experimental variability in comparison to related deep learning-based models. The biomarkers identified by MOGKAN were validated as cancer-related markers through Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analysis. By integrating multi-omics data with graph-based deep learning, our proposed approach demonstrates robust predictive performance and interpretability with potential to enhance the translation of complex multi-omics data into clinically actionable cancer diagnostics.
<div id='section'>Paperid: <span id='pid'>787, <a href='https://arxiv.org/pdf/2503.17361.pdf' target='_blank'>https://arxiv.org/pdf/2503.17361.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sophia Tang, Yinuo Zhang, Alexander Tong, Pranam Chatterjee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17361">Gumbel-Softmax Flow Matching with Straight-Through Guidance for Controllable Biological Sequence Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Flow matching in the continuous simplex has emerged as a promising strategy for DNA sequence design, but struggles to scale to higher simplex dimensions required for peptide and protein generation. We introduce Gumbel-Softmax Flow and Score Matching, a generative framework on the simplex based on a novel Gumbel-Softmax interpolant with a time-dependent temperature. Using this interpolant, we introduce Gumbel-Softmax Flow Matching by deriving a parameterized velocity field that transports from smooth categorical distributions to distributions concentrated at a single vertex of the simplex. We alternatively present Gumbel-Softmax Score Matching which learns to regress the gradient of the probability density. Our framework enables high-quality, diverse generation and scales efficiently to higher-dimensional simplices. To enable training-free guidance, we propose Straight-Through Guided Flows (STGFlow), a classifier-based guidance method that leverages straight-through estimators to steer the unconditional velocity field toward optimal vertices of the simplex. STGFlow enables efficient inference-time guidance using classifiers pre-trained on clean sequences, and can be used with any discrete flow method. Together, these components form a robust framework for controllable de novo sequence generation. We demonstrate state-of-the-art performance in conditional DNA promoter design, sequence-only protein generation, and target-binding peptide design for rare disease treatment.
<div id='section'>Paperid: <span id='pid'>788, <a href='https://arxiv.org/pdf/2503.16563.pdf' target='_blank'>https://arxiv.org/pdf/2503.16563.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aahan Singh, Engin Tekin, Maryam Nadeem, Nancy A. ElNaker, Mohammad Amaan Sayeed, Natalia Vassilieva, Boulbaba Ben Amor
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16563">Chem42: a Family of chemical Language Models for Target-aware Ligand Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Revolutionizing drug discovery demands more than just understanding molecular interactions - it requires generative models that can design novel ligands tailored to specific biological targets. While chemical Language Models (cLMs) have made strides in learning molecular properties, most fail to incorporate target-specific insights, restricting their ability to drive de-novo ligand generation. Chem42, a cutting-edge family of generative chemical Language Models, is designed to bridge this gap. By integrating atomic-level interactions with multimodal inputs from Prot42, a complementary protein Language Model, Chem42 achieves a sophisticated cross-modal representation of molecular structures, interactions, and binding patterns. This innovative framework enables the creation of structurally valid, synthetically accessible ligands with enhanced target specificity. Evaluations across diverse protein targets confirm that Chem42 surpasses existing approaches in chemical validity, target-aware design, and predicted binding affinity. By reducing the search space of viable drug candidates, Chem42 could accelerate the drug discovery pipeline, offering a powerful generative AI tool for precision medicine. Our Chem42 models set a new benchmark in molecule property prediction, conditional molecule generation, and target-aware ligand design. The models are publicly available at huggingface.co/inceptionai.
<div id='section'>Paperid: <span id='pid'>789, <a href='https://arxiv.org/pdf/2503.08295.pdf' target='_blank'>https://arxiv.org/pdf/2503.08295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Umberto Borso, Davide Paglieri, Jude Wells, Tim RocktÃ¤schel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08295">Preference-Based Alignment of Discrete Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have achieved state-of-the-art performance across multiple domains, with recent advancements extending their applicability to discrete data. However, aligning discrete diffusion models with task-specific preferences remains challenging, particularly in scenarios where explicit reward functions are unavailable. In this work, we introduce Discrete Diffusion DPO (D2-DPO), the first adaptation of Direct Preference Optimization (DPO) to discrete diffusion models formulated as continuous-time Markov chains. Our approach derives a novel loss function that directly fine-tunes the generative process using preference data while preserving fidelity to a reference distribution. We validate D2-DPO on a structured binary sequence generation task, demonstrating that the method effectively aligns model outputs with preferences while maintaining structural validity. Our results highlight that D2-DPO enables controlled fine-tuning without requiring explicit reward models, making it a practical alternative to reinforcement learning-based approaches. Future research will explore extending D2-DPO to more complex generative tasks, including language modeling and protein sequence generation, as well as investigating alternative noise schedules, such as uniform noising, to enhance flexibility across different applications.
<div id='section'>Paperid: <span id='pid'>790, <a href='https://arxiv.org/pdf/2503.05738.pdf' target='_blank'>https://arxiv.org/pdf/2503.05738.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicolas Wolf, Leif Seute, Vsevolod Viliuga, Simon Wagner, Jan StÃ¼hmer, Frauke GrÃ¤ter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05738">Learning conformational ensembles of proteins based on backbone geometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep generative models have recently been proposed for sampling protein conformations from the Boltzmann distribution, as an alternative to often prohibitively expensive Molecular Dynamics simulations. However, current state-of-the-art approaches rely on fine-tuning pre-trained folding models and evolutionary sequence information, limiting their applicability and efficiency, and introducing potential biases. In this work, we propose a flow matching model for sampling protein conformations based solely on backbone geometry. We introduce a geometric encoding of the backbone equilibrium structure as input and propose to condition not only the flow but also the prior distribution on the respective equilibrium structure, eliminating the need for evolutionary information. The resulting model is orders of magnitudes faster than current state-of-the-art approaches at comparable accuracy and can be trained from scratch in a few GPU days. In our experiments, we demonstrate that the proposed model achieves competitive performance with reduced inference time, across not only an established benchmark of naturally occurring proteins but also de novo proteins, for which evolutionary information is scarce.
<div id='section'>Paperid: <span id='pid'>791, <a href='https://arxiv.org/pdf/2503.04734.pdf' target='_blank'>https://arxiv.org/pdf/2503.04734.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anna T. Thomas, Adam Yee, Andrew Mayne, Maya B. Mathur, Dan Jurafsky, Kristina GligoriÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04734">What can large language models do for sustainable food?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Food systems are responsible for a third of human-caused greenhouse gas emissions. We investigate what Large Language Models (LLMs) can contribute to reducing the environmental impacts of food production. We define a typology of design and prediction tasks based on the sustainable food literature and collaboration with domain experts, and evaluate six LLMs on four tasks in our typology. For example, for a sustainable protein design task, food science experts estimated that collaboration with an LLM can reduce time spent by 45% on average, compared to 22% for collaboration with another expert human food scientist. However, for a sustainable menu design task, LLMs produce suboptimal solutions when instructed to consider both human satisfaction and climate impacts. We propose a general framework for integrating LLMs with combinatorial optimization to improve reasoning capabilities. Our approach decreases emissions of food choices by 79% in a hypothetical restaurant while maintaining participants' satisfaction with their set of choices. Our results demonstrate LLMs' potential, supported by optimization techniques, to accelerate sustainable food development and adoption.
<div id='section'>Paperid: <span id='pid'>792, <a href='https://arxiv.org/pdf/2502.18875.pdf' target='_blank'>https://arxiv.org/pdf/2502.18875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fanglei Xue, Meihan Zhang, Shuqi Li, Xinyu Gao, James A. Wohlschlegel, Wenbing Huang, Yi Yang, Weixian Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18875">SE(3)-Equivariant Ternary Complex Prediction Towards Target Protein Degradation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Targeted protein degradation (TPD) induced by small molecules has emerged as a rapidly evolving modality in drug discovery, targeting proteins traditionally considered "undruggable". Proteolysis-targeting chimeras (PROTACs) and molecular glue degraders (MGDs) are the primary small molecules that induce TPD. Both types of molecules form a ternary complex linking an E3 ligase with a target protein, a crucial step for drug discovery. While significant advances have been made in binary structure prediction for proteins and small molecules, ternary structure prediction remains challenging due to obscure interaction mechanisms and insufficient training data. Traditional methods relying on manually assigned rules perform poorly and are computationally demanding due to extensive random sampling. In this work, we introduce DeepTernary, a novel deep learning-based approach that directly predicts ternary structures in an end-to-end manner using an encoder-decoder architecture. DeepTernary leverages an SE(3)-equivariant graph neural network (GNN) with both intra-graph and ternary inter-graph attention mechanisms to capture intricate ternary interactions from our collected high-quality training dataset, TernaryDB. The proposed query-based Pocket Points Decoder extracts the 3D structure of the final binding ternary complex from learned ternary embeddings, demonstrating state-of-the-art accuracy and speed in existing PROTAC benchmarks without prior knowledge from known PROTACs. It also achieves notable accuracy on the more challenging MGD benchmark under the blind docking protocol. Remarkably, our experiments reveal that the buried surface area calculated from predicted structures correlates with experimentally obtained degradation potency-related metrics. Consequently, DeepTernary shows potential in effectively assisting and accelerating the development of TPDs for previously undruggable targets.
<div id='section'>Paperid: <span id='pid'>793, <a href='https://arxiv.org/pdf/2502.05230.pdf' target='_blank'>https://arxiv.org/pdf/2502.05230.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Etienne Goffinet, Sen Yan, Fabrizio Gabellieri, Laurence Jennings, Lydia Gkoura, Filippo Castiglione, Ryan Young, Idir Malki, Ankita Singh, Thomas Launey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.05230">DiffNMR2: NMR Guided Sampling Acquisition Through Diffusion Model Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nuclear Magnetic Resonance (NMR) spectrometry uses electro-frequency pulses to probe the resonance of a compound's nucleus, which is then analyzed to determine its structure. The acquisition time of high-resolution NMR spectra remains a significant bottleneck, especially for complex biological samples such as proteins. In this study, we propose a novel and efficient sub-sampling strategy based on a diffusion model trained on protein NMR data. Our method iteratively reconstructs under-sampled spectra while using model uncertainty to guide subsequent sampling, significantly reducing acquisition time. Compared to state-of-the-art strategies, our approach improves reconstruction accuracy by 52.9\%, reduces hallucinated peaks by 55.6%, and requires 60% less time in complex NMR experiments. This advancement holds promise for many applications, from drug discovery to materials science, where rapid and high-resolution spectral analysis is critical.
<div id='section'>Paperid: <span id='pid'>794, <a href='https://arxiv.org/pdf/2502.04468.pdf' target='_blank'>https://arxiv.org/pdf/2502.04468.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Denker, Shreyas Padhy, Francisco Vargas, Johannes Hertrich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04468">Iterative Importance Fine-tuning of Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models are an important tool for generative modelling, serving as effective priors in applications such as imaging and protein design. A key challenge in applying diffusion models for downstream tasks is efficiently sampling from resulting posterior distributions, which can be addressed using the $h$-transform. This work introduces a self-supervised algorithm for fine-tuning diffusion models by estimating the $h$-transform, enabling amortised conditional sampling. Our method iteratively refines the $h$-transform using a synthetic dataset resampled with path-based importance weights. We demonstrate the effectiveness of this framework on class-conditional sampling, inverse problems and reward fine-tuning for text-to-image diffusion models.
<div id='section'>Paperid: <span id='pid'>795, <a href='https://arxiv.org/pdf/2502.01809.pdf' target='_blank'>https://arxiv.org/pdf/2502.01809.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianming Huang, Hiroyuki Kasai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01809">Self-supervised Subgraph Neural Network With Deep Reinforcement Walk Exploration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph data, with its structurally variable nature, represents complex real-world phenomena like chemical compounds, protein structures, and social networks. Traditional Graph Neural Networks (GNNs) primarily utilize the message-passing mechanism, but their expressive power is limited and their prediction lacks explainability. To address these limitations, researchers have focused on graph substructures. Subgraph neural networks (SGNNs) and GNN explainers have emerged as potential solutions, but each has its limitations. SGNNs computes graph representations based on the bags of subgraphs to enhance the expressive power. However, they often rely on predefined algorithm-based sampling strategies, which is inefficient. GNN explainers adopt data-driven approaches to generate important subgraphs to provide explanation. Nevertheless, their explanation is difficult to be translated into practical improvements on GNNs. To overcome these issues, we propose a novel self-supervised framework that integrates SGNNs with the generation approach of GNN explainers, named the Reinforcement Walk Exploration SGNN (RWE-SGNN). Our approach features a sampling model trained in an explainer fashion, optimizing subgraphs to enhance model performance. To achieve a data-driven sampling approach, unlike traditional subgraph generation approaches, we propose a novel walk exploration process, which efficiently extracts important substructures, simplifying the embedding process and avoiding isomorphism problems. Moreover, we prove that our proposed walk exploration process has equivalent generation capability to the traditional subgraph generation process. Experimental results on various graph datasets validate the effectiveness of our proposed method, demonstrating significant improvements in performance and precision.
<div id='section'>Paperid: <span id='pid'>796, <a href='https://arxiv.org/pdf/2501.12365.pdf' target='_blank'>https://arxiv.org/pdf/2501.12365.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Darin Tsui, Kunal Talreja, Amirali Aghazadeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12365">Efficient Algorithm for Sparse Fourier Transform of Generalized $q$-ary Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computing the Fourier transform of a $q$-ary function $f:\mathbb{Z}_{q}^n\rightarrow \mathbb{R}$, which maps $q$-ary sequences to real numbers, is an important problem in mathematics with wide-ranging applications in biology, signal processing, and machine learning. Previous studies have shown that, under the sparsity assumption, the Fourier transform can be computed efficiently using fast and sample-efficient algorithms. However, in most practical settings, the function is defined over a more general space -- the space of generalized $q$-ary sequences $\mathbb{Z}_{q_1} \times \mathbb{Z}_{q_2} \times \cdots \times \mathbb{Z}_{q_n}$ -- where each $\mathbb{Z}_{q_i}$ corresponds to integers modulo $q_i$. Herein, we develop GFast, a coding theoretic algorithm that computes the $S$-sparse Fourier transform of $f$ with a sample complexity of $O(Sn)$, computational complexity of $O(Sn \log N)$, and a failure probability that approaches zero as $N=\prod_{i=1}^n q_i \rightarrow \infty$ with $S = N^Î´$ for some $0 \leq Î´< 1$. We show that a noise-robust version of GFast computes the transform with a sample complexity of $O(Sn^2)$ and computational complexity of $O(Sn^2 \log N)$ under the same high probability guarantees. Additionally, we demonstrate that GFast computes the sparse Fourier transform of generalized $q$-ary functions $8\times$ faster using $16\times$ fewer samples on synthetic experiments, and enables explaining real-world heart disease diagnosis and protein fitness models using up to $13\times$ fewer samples compared to existing Fourier algorithms applied to the most efficient parameterization of the models as $q$-ary functions.
<div id='section'>Paperid: <span id='pid'>797, <a href='https://arxiv.org/pdf/2501.01811.pdf' target='_blank'>https://arxiv.org/pdf/2501.01811.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francesc SabanÃ©s Zariquiey, Stephen E. Farr, Stefan Doerr, Gianni De Fabritiis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01811">QuantumBind-RBFE: Accurate Relative Binding Free Energy Calculations Using Neural Network Potentials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of protein-ligand binding affinities is crucial in drug discovery, particularly during hit-to-lead and lead optimization phases, however, limitations in ligand force fields continue to impact prediction accuracy. In this work, we validate relative binding free energy (RBFE) accuracy using neural network potentials (NNPs) for the ligands. We utilize a novel NNP model, AceFF 1.0, based on the TensorNet architecture for small molecules that broadens the applicability to diverse drug-like compounds, including all important chemical elements and supporting charged molecules. Using established benchmarks, we show overall improved accuracy and correlation in binding affinity predictions compared with GAFF2 for molecular mechanics and ANI2-x for NNPs. Slightly less accuracy but comparable correlations with OPLS4. We also show that we can run the NNP simulations at 2 fs timestep, at least two times larger than previous NNP models, providing significant speed gains. The results show promise for further evolutions of free energy calculations using NNPs while demonstrating its practical use already with the current generation. The code and NNP model are publicly available for research use.
<div id='section'>Paperid: <span id='pid'>798, <a href='https://arxiv.org/pdf/2412.19945.pdf' target='_blank'>https://arxiv.org/pdf/2412.19945.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Beyza E. Ortlek, Ozgur B. Akan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.19945">Modeling and Analysis of SCFA-Driven Vagus Nerve Signaling in the Gut-Brain Axis via Molecular Communication</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular communication (MC) is a bio-inspired communication paradigm that utilizes molecules to transfer information and offers a robust framework for understanding biological signaling systems. This paper introduces a novel end-to-end MC framework for short-chain fatty acid (SCFA)-driven vagus nerve signaling within the gut-brain axis (GBA) to enhance our understanding of gut-brain communication mechanisms. SCFA molecules, produced by gut microbiota, serve as important biomarkers in physiological and psychological processes, including neurodegenerative and mental health disorders. The developed end-to-end model integrates SCFA binding to vagal afferent fibers, G protein-coupled receptor (GPCR)-mediated calcium signaling, and Hodgkin-Huxley-based action potential generation into a comprehensive vagus nerve signaling mechanism through GBA. Information-theoretic metrics such as mutual information and delay are used to evaluate the efficiency of this SCFA-driven signaling pathway model. Simulations demonstrate how molecular inputs translate into neural outputs, highlighting critical aspects that govern gut-brain communication. In this work, the integration of SCFA-driven signaling into the MC framework provides a novel perspective on gut-brain communication and paves the way for the development of innovative therapeutic advancements targeting neurological and psychiatric disorders.
<div id='section'>Paperid: <span id='pid'>799, <a href='https://arxiv.org/pdf/2412.15256.pdf' target='_blank'>https://arxiv.org/pdf/2412.15256.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edward Kim, Manil Shrestha, Richard Foty, Tom DeLay, Vicki Seyfert-Margolis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15256">Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Creation and curation of knowledge graphs can accelerate disease discovery and analysis in real-world data. While disease ontologies aid in biological data annotation, codified categories (SNOMED-CT, ICD10, CPT) may not capture patient condition nuances or rare diseases. Multiple disease definitions across data sources complicate ontology mapping and disease clustering. We propose creating patient knowledge graphs using large language model extraction techniques, allowing data extraction via natural language rather than rigid ontological hierarchies. Our method maps to existing ontologies (MeSH, SNOMED-CT, RxNORM, HPO) to ground extracted entities.
  Using a large ambulatory care EHR database with 33.6M patients, we demonstrate our method through the patient search for Dravet syndrome, which received ICD10 recognition in October 2020. We describe our construction of patient-specific knowledge graphs and symptom-based patient searches. Using confirmed Dravet syndrome ICD10 codes as ground truth, we employ LLM-based entity extraction to characterize patients in grounded ontologies. We then apply this method to identify Beta-propeller protein-associated neurodegeneration (BPAN) patients, demonstrating real-world discovery where no ground truth exists.
<div id='section'>Paperid: <span id='pid'>800, <a href='https://arxiv.org/pdf/2412.11082.pdf' target='_blank'>https://arxiv.org/pdf/2412.11082.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingwen Tian, Yuxin Xu, Yixuan Yang, Zhen Wang, Ziqi Liu, Pengju Yan, Xiaolin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.11082">EquiFlow: Equivariant Conditional Flow Matching with Optimal Transport for 3D Molecular Conformation Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular 3D conformations play a key role in determining how molecules interact with other molecules or protein surfaces. Recent deep learning advancements have improved conformation prediction, but slow training speeds and difficulties in utilizing high-degree features limit performance. We propose EquiFlow, an equivariant conditional flow matching model with optimal transport. EquiFlow uniquely applies conditional flow matching in molecular 3D conformation prediction, leveraging simulation-free training to address slow training speeds. It uses a modified Equiformer model to encode Cartesian molecular conformations along with their atomic and bond properties into higher-degree embeddings. Additionally, EquiFlow employs an ODE solver, providing faster inference speeds compared to diffusion models with SDEs. Experiments on the QM9 dataset show that EquiFlow predicts small molecule conformations more accurately than current state-of-the-art models.
<div id='section'>Paperid: <span id='pid'>801, <a href='https://arxiv.org/pdf/2412.03496.pdf' target='_blank'>https://arxiv.org/pdf/2412.03496.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew Ricci, Guy Pelc, Zoe Piran, Noa Moriel, Mor Nitzan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03496">TRENDy: Temporal Regression of Effective Nonlinear Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spatiotemporal dynamics pervade the natural sciences, from the morphogen dynamics underlying patterning in animal pigmentation to the protein waves controlling cell division. A central challenge lies in understanding how controllable parameters induce qualitative changes in system behavior called bifurcations. This endeavor is particularly difficult in realistic settings where governing partial differential equations (PDEs) are unknown and data is limited and noisy. To address this challenge, we propose TRENDy (Temporal Regression of Effective Nonlinear Dynamics), an equation-free approach to learning low-dimensional, predictive models of spatiotemporal dynamics. TRENDy first maps input data to a low-dimensional space of effective dynamics through a cascade of multiscale filtering operations. Our key insight is the recognition that these effective dynamics can be fit by a neural ordinary differential equation (NODE) having the same parameter space as the input PDE. The preceding filtering operations strongly regularize the phase space of the NODE, making TRENDy significantly more robust to noise compared to existing methods. We train TRENDy to predict the effective dynamics of synthetic and real data representing dynamics from across the physical and life sciences. We then demonstrate how we can automatically locate both Turing and Hopf bifurcations in unseen regions of parameter space. We finally apply our method to the analysis of spatial patterning of the ocellated lizard through development. We found that TRENDy's predicted effective state not only accurately predicts spatial changes over time but also identifies distinct pattern features unique to different anatomical regions, such as the tail, neck, and body--an insight that highlights the potential influence of surface geometry on reaction-diffusion mechanisms and their role in driving spatially varying pattern dynamics.
<div id='section'>Paperid: <span id='pid'>802, <a href='https://arxiv.org/pdf/2411.05238.pdf' target='_blank'>https://arxiv.org/pdf/2411.05238.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Wagner, Leif Seute, Vsevolod Viliuga, Nicolas Wolf, Frauke GrÃ¤ter, Jan StÃ¼hmer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05238">Generating Highly Designable Proteins with Geometric Algebra Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a generative model for protein backbone design utilizing geometric products and higher order message passing. In particular, we propose Clifford Frame Attention (CFA), an extension of the invariant point attention (IPA) architecture from AlphaFold2, in which the backbone residue frames and geometric features are represented in the projective geometric algebra. This enables to construct geometrically expressive messages between residues, including higher order terms, using the bilinear operations of the algebra. We evaluate our architecture by incorporating it into the framework of FrameFlow, a state-of-the-art flow matching model for protein backbone generation. The proposed model achieves high designability, diversity and novelty, while also sampling protein backbones that follow the statistical distribution of secondary structure elements found in naturally occurring proteins, a property so far only insufficiently achieved by many state-of-the-art generative models.
<div id='section'>Paperid: <span id='pid'>803, <a href='https://arxiv.org/pdf/2411.04130.pdf' target='_blank'>https://arxiv.org/pdf/2411.04130.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keir Adams, Kento Abeywardane, Jenna Fromer, Connor W. Coley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04130">ShEPhERD: Diffusing shape, electrostatics, and pharmacophores for bioisosteric drug design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Engineering molecules to exhibit precise 3D intermolecular interactions with their environment forms the basis of chemical design. In ligand-based drug design, bioisosteric analogues of known bioactive hits are often identified by virtually screening chemical libraries with shape, electrostatic, and pharmacophore similarity scoring functions. We instead hypothesize that a generative model which learns the joint distribution over 3D molecular structures and their interaction profiles may facilitate 3D interaction-aware chemical design. We specifically design ShEPhERD, an SE(3)-equivariant diffusion model which jointly diffuses/denoises 3D molecular graphs and representations of their shapes, electrostatic potential surfaces, and (directional) pharmacophores to/from Gaussian noise. Inspired by traditional ligand discovery, we compose 3D similarity scoring functions to assess ShEPhERD's ability to conditionally generate novel molecules with desired interaction profiles. We demonstrate ShEPhERD's potential for impact via exemplary drug design tasks including natural product ligand hopping, protein-blind bioactive hit diversification, and bioisosteric fragment merging.
<div id='section'>Paperid: <span id='pid'>804, <a href='https://arxiv.org/pdf/2411.02109.pdf' target='_blank'>https://arxiv.org/pdf/2411.02109.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anton Bushuiev, Roman Bushuiev, Nikola Zadorozhny, Raman Samusevich, Hannes StÃ¤rk, Jiri Sedlar, TomÃ¡Å¡ Pluskal, Josef Sivic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.02109">Training on test proteins improves fitness, structure, and function prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data scarcity and distribution shifts often hinder the ability of machine learning models to generalize when applied to proteins and other biological data. Self-supervised pre-training on large datasets is a common method to enhance generalization. However, striving to perform well on all possible proteins can limit model's capacity to excel on any specific one, even though practitioners are often most interested in accurate predictions for the individual protein they study. To address this limitation, we propose an orthogonal approach to achieve generalization. Building on the prevalence of self-supervised pre-training, we introduce a method for self-supervised fine-tuning at test time, allowing models to adapt to the test protein of interest on the fly and without requiring any additional data. We study our test-time training (TTT) method through the lens of perplexity minimization and show that it consistently enhances generalization across different models, their scales, and datasets. Notably, our method leads to new state-of-the-art results on the standard benchmark for protein fitness prediction, improves protein structure prediction for challenging targets, and enhances function prediction accuracy.
<div id='section'>Paperid: <span id='pid'>805, <a href='https://arxiv.org/pdf/2410.21518.pdf' target='_blank'>https://arxiv.org/pdf/2410.21518.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenxian Shi, Menghua Wu, Regina Barzilay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21518">Predicting sub-population specific viral evolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Forecasting the change in the distribution of viral variants is crucial for therapeutic design and disease surveillance. This task poses significant modeling challenges due to the sharp differences in virus distributions across sub-populations (e.g., countries) and their dynamic interactions. Existing machine learning approaches that model the variant distribution as a whole are incapable of making location-specific predictions and ignore transmissions that shape the viral landscape. In this paper, we propose a sub-population specific protein evolution model, which predicts the time-resolved distributions of viral proteins in different locations. The algorithm explicitly models the transmission rates between sub-populations and learns their interdependence from data. The change in protein distributions across all sub-populations is defined through a linear ordinary differential equation (ODE) parametrized by transmission rates. Solving this ODE yields the likelihood of a given protein occurring in particular sub-populations. Multi-year evaluation on both SARS-CoV-2 and influenza A/H3N2 demonstrates that our model outperforms baselines in accurately predicting distributions of viral proteins across continents and countries. We also find that the transmission rates learned from data are consistent with the transmission pathways discovered by retrospective phylogenetic analysis.
<div id='section'>Paperid: <span id='pid'>806, <a href='https://arxiv.org/pdf/2410.19236.pdf' target='_blank'>https://arxiv.org/pdf/2410.19236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Darin Tsui, Aryan Musharaf, Yigit Efe Erginbas, Justin Singh Kang, Amirali Aghazadeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19236">SHAP zero Explains Biological Sequence Models with Near-zero Marginal Cost for Future Queries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing adoption of machine learning models for biological sequences has intensified the need for interpretable predictions, with Shapley values emerging as a theoretically grounded standard for model explanation. While effective for local explanations of individual input sequences, scaling Shapley-based interpretability to extract global biological insights requires evaluating thousands of sequences--incurring exponential computational cost per query. We introduce SHAP zero, a novel algorithm that amortizes the cost of Shapley value computation across large-scale biological datasets. After a one-time model sketching step, SHAP zero enables near-zero marginal cost for future queries by uncovering an underexplored connection between Shapley values, high-order feature interactions, and the sparse Fourier transform of the model. Applied to models of guide RNA efficacy, DNA repair outcomes, and protein fitness, SHAP zero explains predictions orders of magnitude faster than existing methods, recovering rich combinatorial interactions previously inaccessible at scale. This work opens the door to principled, efficient, and scalable interpretability for black-box sequence models in biology.
<div id='section'>Paperid: <span id='pid'>807, <a href='https://arxiv.org/pdf/2410.07364.pdf' target='_blank'>https://arxiv.org/pdf/2410.07364.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ismail Erbas, Aporva Amarnath, Vikas Pandey, Karthik Swaminathan, Naigang Wang, Xavier Intes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07364">Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fluorescence lifetime imaging (FLI) is a widely used technique in the biomedical field for measuring the decay times of fluorescent molecules, providing insights into metabolic states, protein interactions, and ligand-receptor bindings. However, its broader application in fast biological processes, such as dynamic activity monitoring, and clinical use, such as in guided surgery, is limited by long data acquisition times and computationally demanding data processing. While deep learning has reduced post-processing times, time-resolved data acquisition remains a bottleneck for real-time applications. To address this, we propose a method to achieve real-time FLI using an FPGA-based hardware accelerator. Specifically, we implemented a GRU-based sequence-to-sequence (Seq2Seq) model on an FPGA board compatible with time-resolved cameras. The GRU model balances accurate processing with the resource constraints of FPGAs, which have limited DSP units and BRAM. The limited memory and computational resources on the FPGA require efficient scheduling of operations and memory allocation to deploy deep learning models for low-latency applications. We address these challenges by using STOMP, a queue-based discrete-event simulator that automates and optimizes task scheduling and memory management on hardware. By integrating a GRU-based Seq2Seq model and its compressed version, called Seq2SeqLite, generated through knowledge distillation, we were able to process multiple pixels in parallel, reducing latency compared to sequential processing. We explore various levels of parallelism to achieve an optimal balance between performance and resource utilization. Our results indicate that the proposed techniques achieved a 17.7x and 52.0x speedup over manual scheduling for the Seq2Seq model and the Seq2SeqLite model, respectively.
<div id='section'>Paperid: <span id='pid'>808, <a href='https://arxiv.org/pdf/2410.05325.pdf' target='_blank'>https://arxiv.org/pdf/2410.05325.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fadi Alharbi, Aleksandar Vakanski, Boyu Zhang, Murtada K. Elbashir, Mohanad Mohammed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.05325">Comparative Analysis of Multi-Omics Integration Using Advanced Graph Neural Networks for Cancer Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-omics data is increasingly being utilized to advance computational methods for cancer classification. However, multi-omics data integration poses significant challenges due to the high dimensionality, data complexity, and distinct characteristics of various omics types. This study addresses these challenges and evaluates three graph neural network architectures for multi-omics (MO) integration based on graph-convolutional networks (GCN), graph-attention networks (GAT), and graph-transformer networks (GTN) for classifying 31 cancer types and normal tissues. To address the high-dimensionality of multi-omics data, we employed LASSO (Least Absolute Shrinkage and Selection Operator) regression for feature selection, leading to the creation of LASSO-MOGCN, LASSO-MOGAT, and LASSO-MOTGN models. Graph structures for the networks were constructed using gene correlation matrices and protein-protein interaction networks for multi-omics integration of messenger-RNA, micro-RNA, and DNA methylation data. Such data integration enables the networks to dynamically focus on important relationships between biological entities, improving both model performance and interpretability. Among the models, LASSO-MOGAT with a correlation-based graph structure achieved state-of-the-art accuracy (95.9%) and outperformed the LASSO-MOGCN and LASSO-MOTGN models in terms of precision, recall, and F1-score. Our findings demonstrate that integrating multi-omics data in graph-based architectures enhances cancer classification performance by uncovering distinct molecular patterns that contribute to a better understanding of cancer biology and potential biomarkers for disease progression.
<div id='section'>Paperid: <span id='pid'>809, <a href='https://arxiv.org/pdf/2409.10964.pdf' target='_blank'>https://arxiv.org/pdf/2409.10964.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kairi Furui, Masahito Ohue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10964">Active learning for energy-based antibody optimization and enhanced screening</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction and optimization of protein-protein binding affinity is crucial for therapeutic antibody development. Although machine learning-based prediction methods $ÎÎG$ are suitable for large-scale mutant screening, they struggle to predict the effects of multiple mutations for targets without existing binders. Energy function-based methods, though more accurate, are time consuming and not ideal for large-scale screening. To address this, we propose an active learning workflow that efficiently trains a deep learning model to learn energy functions for specific targets, combining the advantages of both approaches. Our method integrates the RDE-Network deep learning model with Rosetta's energy function-based Flex ddG to efficiently explore mutants. In a case study targeting HER2-binding Trastuzumab mutants, our approach significantly improved the screening performance over random selection and demonstrated the ability to identify mutants with better binding properties without experimental $ÎÎG$ data. This workflow advances computational antibody design by combining machine learning, physics-based computations, and active learning to achieve more efficient antibody development.
<div id='section'>Paperid: <span id='pid'>810, <a href='https://arxiv.org/pdf/2409.10579.pdf' target='_blank'>https://arxiv.org/pdf/2409.10579.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Binghao Yan, Yunbi Nam, Lingyao Li, Rebecca A. Deek, Hongzhe Li, Siyuan Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10579">Recent advances in deep learning and language models for studying the microbiome</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in deep learning, particularly large language models (LLMs), made a significant impact on how researchers study microbiome and metagenomics data. Microbial protein and genomic sequences, like natural languages, form a language of life, enabling the adoption of LLMs to extract useful insights from complex microbial ecologies. In this paper, we review applications of deep learning and language models in analyzing microbiome and metagenomics data. We focus on problem formulations, necessary datasets, and the integration of language modeling techniques. We provide an extensive overview of protein/genomic language modeling and their contributions to microbiome studies. We also discuss applications such as novel viromics language modeling, biosynthetic gene cluster prediction, and knowledge integration for metagenomics studies.
<div id='section'>Paperid: <span id='pid'>811, <a href='https://arxiv.org/pdf/2409.03118.pdf' target='_blank'>https://arxiv.org/pdf/2409.03118.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pratyush Tiwary, Lukas Herron, Richard John, Suemin Lee, Disha Sanwal, Ruiyu Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03118">Generative artificial intelligence for computational chemistry: a roadmap to predicting emergent phenomena</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent surge in Generative Artificial Intelligence (AI) has introduced exciting possibilities for computational chemistry. Generative AI methods have made significant progress in sampling molecular structures across chemical species, developing force fields, and speeding up simulations. This Perspective offers a structured overview, beginning with the fundamental theoretical concepts in both Generative AI and computational chemistry. It then covers widely used Generative AI methods, including autoencoders, generative adversarial networks, reinforcement learning, flow models and language models, and highlights their selected applications in diverse areas including force field development, and protein/RNA structure prediction. A key focus is on the challenges these methods face before they become truly predictive, particularly in predicting emergent chemical phenomena. We believe that the ultimate goal of a simulation method or theory is to predict phenomena not seen before, and that Generative AI should be subject to these same standards before it is deemed useful for chemistry. We suggest that to overcome these challenges, future AI models need to integrate core chemical principles, especially from statistical mechanics.
<div id='section'>Paperid: <span id='pid'>812, <a href='https://arxiv.org/pdf/2408.17384.pdf' target='_blank'>https://arxiv.org/pdf/2408.17384.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fadi Alharbi, Aleksandar Vakanski, Murtada K. Elbashir, Mohanad Mohammed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.17384">LASSO-MOGAT: A Multi-Omics Graph Attention Framework for Cancer Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The application of machine learning methods to analyze changes in gene expression patterns has recently emerged as a powerful approach in cancer research, enhancing our understanding of the molecular mechanisms underpinning cancer development and progression. Combining gene expression data with other types of omics data has been reported by numerous works to improve cancer classification outcomes. Despite these advances, effectively integrating high-dimensional multi-omics data and capturing the complex relationships across different biological layers remains challenging. This paper introduces LASSO-MOGAT (LASSO-Multi-Omics Gated ATtention), a novel graph-based deep learning framework that integrates messenger RNA, microRNA, and DNA methylation data to classify 31 cancer types. Utilizing differential expression analysis with LIMMA and LASSO regression for feature selection, and leveraging Graph Attention Networks (GATs) to incorporate protein-protein interaction (PPI) networks, LASSO-MOGAT effectively captures intricate relationships within multi-omics data. Experimental validation using five-fold cross-validation demonstrates the method's precision, reliability, and capacity for providing comprehensive insights into cancer molecular mechanisms. The computation of attention coefficients for the edges in the graph by the proposed graph-attention architecture based on protein-protein interactions proved beneficial for identifying synergies in multi-omics data for cancer classification.
<div id='section'>Paperid: <span id='pid'>813, <a href='https://arxiv.org/pdf/2408.12682.pdf' target='_blank'>https://arxiv.org/pdf/2408.12682.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shentong Mo, Paul Pu Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12682">MultiMed: Massively Multimodal and Multitask Medical Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biomedical data is inherently multimodal, consisting of electronic health records, medical imaging, digital pathology, genome sequencing, wearable sensors, and more. The application of artificial intelligence tools to these multifaceted sensing technologies has the potential to revolutionize the prognosis, diagnosis, and management of human health and disease. However, current approaches to biomedical AI typically only train and evaluate with one or a small set of medical modalities and tasks. This limitation hampers the development of comprehensive tools that can leverage the rich interconnected information across many heterogeneous biomedical sensors. To address this challenge, we present MultiMed, a benchmark designed to evaluate and enable large-scale learning across a wide spectrum of medical modalities and tasks. MultiMed consists of 2.56 million samples across ten medical modalities such as medical reports, pathology, genomics, and protein data, and is structured into eleven challenging tasks, including disease prognosis, protein structure prediction, and medical question answering. Using MultiMed, we conduct comprehensive experiments benchmarking state-of-the-art unimodal, multimodal, and multitask models. Our analysis highlights the advantages of training large-scale medical models across many related modalities and tasks. Moreover, MultiMed enables studies of generalization across related medical concepts, robustness to real-world noisy data and distribution shifts, and novel modality combinations to improve prediction performance. MultiMed will be publicly available and regularly updated and welcomes inputs from the community.
<div id='section'>Paperid: <span id='pid'>814, <a href='https://arxiv.org/pdf/2407.12053.pdf' target='_blank'>https://arxiv.org/pdf/2407.12053.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shaoning Li, Mingyu Li, Yusong Wang, Xinheng He, Nanning Zheng, Jian Zhang, Pheng-Ann Heng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.12053">Improving AlphaFlow for Efficient Protein Ensembles Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Investigating conformational landscapes of proteins is a crucial way to understand their biological functions and properties. AlphaFlow stands out as a sequence-conditioned generative model that introduces flexibility into structure prediction models by fine-tuning AlphaFold under the flow-matching framework. Despite the advantages of efficient sampling afforded by flow-matching, AlphaFlow still requires multiple runs of AlphaFold to finally generate one single conformation. Due to the heavy consumption of AlphaFold, its applicability is limited in sampling larger set of protein ensembles or the longer chains within a constrained timeframe. In this work, we propose a feature-conditioned generative model called AlphaFlow-Lit to realize efficient protein ensembles generation. In contrast to the full fine-tuning on the entire structure, we focus solely on the light-weight structure module to reconstruct the conformation. AlphaFlow-Lit performs on-par with AlphaFlow and surpasses its distilled version without pretraining, all while achieving a significant sampling acceleration of around 47 times. The advancement in efficiency showcases the potential of AlphaFlow-Lit in enabling faster and more scalable generation of protein ensembles.
<div id='section'>Paperid: <span id='pid'>815, <a href='https://arxiv.org/pdf/2406.14442.pdf' target='_blank'>https://arxiv.org/pdf/2406.14442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elisa GÃ³mez de Lope, Saurabh Deshpande, RamÃ³n ViÃ±as TornÃ©, Pietro LiÃ², Enrico Glaab, StÃ©phane P. A. Bordas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14442">Graph Representation Learning Strategies for Omics Data: A Case Study on Parkinson's Disease</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Omics data analysis is crucial for studying complex diseases, but its high dimensionality and heterogeneity challenge classical statistical and machine learning methods. Graph neural networks have emerged as promising alternatives, yet the optimal strategies for their design and optimization in real-world biomedical challenges remain unclear. This study evaluates various graph representation learning models for case-control classification using high-throughput biological data from Parkinson's disease and control samples. We compare topologies derived from sample similarity networks and molecular interaction networks, including protein-protein and metabolite-metabolite interactions (PPI, MMI). Graph Convolutional Network (GCNs), Chebyshev spectral graph convolution (ChebyNet), and Graph Attention Network (GAT), are evaluated alongside advanced architectures like graph transformers, the graph U-net, and simpler models like multilayer perceptron (MLP).
  These models are systematically applied to transcriptomics and metabolomics data independently. Our comparative analysis highlights the benefits and limitations of various architectures in extracting patterns from omics data, paving the way for more accurate and interpretable models in biomedical research.
<div id='section'>Paperid: <span id='pid'>816, <a href='https://arxiv.org/pdf/2406.14150.pdf' target='_blank'>https://arxiv.org/pdf/2406.14150.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan Jose Garau-Luis, Patrick Bordes, Liam Gonzalez, Masa Roller, Bernardo P. de Almeida, Lorenz Hexemer, Christopher Blum, Stefan Laurent, Jan Grzegorzewski, Maren Lang, Thomas Pierrot, Guillaume Richard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14150">Multi-modal Transfer Learning between Biological Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biological sequences encode fundamental instructions for the building blocks of life, in the form of DNA, RNA, and proteins. Modeling these sequences is key to understand disease mechanisms and is an active research area in computational biology. Recently, Large Language Models have shown great promise in solving certain biological tasks but current approaches are limited to a single sequence modality (DNA, RNA, or protein). Key problems in genomics intrinsically involve multiple modalities, but it remains unclear how to adapt general-purpose sequence models to those cases. In this work we propose a multi-modal model that connects DNA, RNA, and proteins by leveraging information from different pre-trained modality-specific encoders. We demonstrate its capabilities by applying it to the largely unsolved problem of predicting how multiple RNA transcript isoforms originate from the same gene (i.e. same DNA sequence) and map to different transcription expression levels across various human tissues. We show that our model, dubbed IsoFormer, is able to accurately predict differential transcript expression, outperforming existing methods and leveraging the use of multiple modalities. Our framework also achieves efficient transfer knowledge from the encoders pre-training as well as in between modalities. We open-source our model, paving the way for new multi-modal gene expression approaches.
<div id='section'>Paperid: <span id='pid'>817, <a href='https://arxiv.org/pdf/2406.03686.pdf' target='_blank'>https://arxiv.org/pdf/2406.03686.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Artem Zholus, Maksim Kuznetsov, Roman Schutski, Rim Shayakhmetov, Daniil Polykovskiy, Sarath Chandar, Alex Zhavoronkov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03686">BindGPT: A Scalable Framework for 3D Molecular Design via Language Modeling and Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generating novel active molecules for a given protein is an extremely challenging task for generative models that requires an understanding of the complex physical interactions between the molecule and its environment. In this paper, we present a novel generative model, BindGPT which uses a conceptually simple but powerful approach to create 3D molecules within the protein's binding site. Our model produces molecular graphs and conformations jointly, eliminating the need for an extra graph reconstruction step. We pretrain BindGPT on a large-scale dataset and fine-tune it with reinforcement learning using scores from external simulation software. We demonstrate how a single pretrained language model can serve at the same time as a 3D molecular generative model, conformer generator conditioned on the molecular graph, and a pocket-conditioned 3D molecule generator. Notably, the model does not make any representational equivariance assumptions about the domain of generation. We show how such simple conceptual approach combined with pretraining and scaling can perform on par or better than the current best specialized diffusion models, language models, and graph neural networks while being two orders of magnitude cheaper to sample.
<div id='section'>Paperid: <span id='pid'>818, <a href='https://arxiv.org/pdf/2406.01781.pdf' target='_blank'>https://arxiv.org/pdf/2406.01781.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Denker, Francisco Vargas, Shreyas Padhy, Kieran Didi, Simon Mathis, Vincent Dutordoir, Riccardo Barbano, Emile Mathieu, Urszula Julia Komorowska, Pietro Lio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01781">DEFT: Efficient Fine-Tuning of Diffusion Models by Learning the Generalised $h$-transform</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative modelling paradigms based on denoising diffusion processes have emerged as a leading candidate for conditional sampling in inverse problems. In many real-world applications, we often have access to large, expensively trained unconditional diffusion models, which we aim to exploit for improving conditional sampling. Most recent approaches are motivated heuristically and lack a unifying framework, obscuring connections between them. Further, they often suffer from issues such as being very sensitive to hyperparameters, being expensive to train or needing access to weights hidden behind a closed API. In this work, we unify conditional training and sampling using the mathematically well-understood Doob's h-transform. This new perspective allows us to unify many existing methods under a common umbrella. Under this framework, we propose DEFT (Doob's h-transform Efficient FineTuning), a new approach for conditional generation that simply fine-tunes a very small network to quickly learn the conditional $h$-transform, while keeping the larger unconditional network unchanged. DEFT is much faster than existing baselines while achieving state-of-the-art performance across a variety of linear and non-linear benchmarks. On image reconstruction tasks, we achieve speedups of up to 1.6$\times$, while having the best perceptual quality on natural images and reconstruction performance on medical images. Further, we also provide initial experiments on protein motif scaffolding and outperform reconstruction guidance methods.
<div id='section'>Paperid: <span id='pid'>819, <a href='https://arxiv.org/pdf/2405.14925.pdf' target='_blank'>https://arxiv.org/pdf/2405.14925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julian Cremer, Tuan Le, Frank NoÃ©, Djork-ArnÃ© Clevert, Kristof T. SchÃ¼tt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14925">PILOT: Equivariant diffusion for pocket conditioned de novo ligand generation with multi-objective guidance via importance sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The generation of ligands that both are tailored to a given protein pocket and exhibit a range of desired chemical properties is a major challenge in structure-based drug design. Here, we propose an in-silico approach for the $\textit{de novo}$ generation of 3D ligand structures using the equivariant diffusion model PILOT, combining pocket conditioning with a large-scale pre-training and property guidance. Its multi-objective trajectory-based importance sampling strategy is designed to direct the model towards molecules that not only exhibit desired characteristics such as increased binding affinity for a given protein pocket but also maintains high synthetic accessibility. This ensures the practicality of sampled molecules, thus maximizing their potential for the drug discovery pipeline. PILOT significantly outperforms existing methods across various metrics on the common benchmark dataset CrossDocked2020. Moreover, we employ PILOT to generate novel ligands for unseen protein pockets from the Kinodata-3D dataset, which encompasses a substantial portion of the human kinome. The generated structures exhibit predicted $IC_{50}$ values indicative of potent biological activity, which highlights the potential of PILOT as a powerful tool for structure-based drug design.
<div id='section'>Paperid: <span id='pid'>820, <a href='https://arxiv.org/pdf/2405.07622.pdf' target='_blank'>https://arxiv.org/pdf/2405.07622.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Cutting, FrÃ©dÃ©ric A. Dreyer, David Errington, Constantin Schneider, Charlotte M. Deane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.07622">De novo antibody design with SE(3) diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce IgDiff, an antibody variable domain diffusion model based on a general protein backbone diffusion framework which was extended to handle multiple chains. Assessing the designability and novelty of the structures generated with our model, we find that IgDiff produces highly designable antibodies that can contain novel binding regions. The backbone dihedral angles of sampled structures show good agreement with a reference antibody distribution. We verify these designed antibodies experimentally and find that all express with high yield. Finally, we compare our model with a state-of-the-art generative backbone diffusion model on a range of antibody design tasks, such as the design of the complementarity determining regions or the pairing of a light chain to an existing heavy chain, and show improved properties and designability.
<div id='section'>Paperid: <span id='pid'>821, <a href='https://arxiv.org/pdf/2405.00751.pdf' target='_blank'>https://arxiv.org/pdf/2405.00751.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shaoning Li, Yusong Wang, Mingyu Li, Jian Zhang, Bin Shao, Nanning Zheng, Jian Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.00751">F$^3$low: Frame-to-Frame Coarse-grained Molecular Dynamics with SE(3) Guided Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular dynamics (MD) is a crucial technique for simulating biological systems, enabling the exploration of their dynamic nature and fostering an understanding of their functions and properties. To address exploration inefficiency, emerging enhanced sampling approaches like coarse-graining (CG) and generative models have been employed. In this work, we propose a \underline{Frame-to-Frame} generative model with guided \underline{Flow}-matching (F$3$low) for enhanced sampling, which (a) extends the domain of CG modeling to the SE(3) Riemannian manifold; (b) retreating CGMD simulations as autoregressively sampling guided by the former frame via flow-matching models; (c) targets the protein backbone, offering improved insights into secondary structure formation and intricate folding pathways. Compared to previous methods, F$3$low allows for broader exploration of conformational space. The ability to rapidly generate diverse conformations via force-free generative paradigm on SE(3) paves the way toward efficient enhanced sampling methods.
<div id='section'>Paperid: <span id='pid'>822, <a href='https://arxiv.org/pdf/2404.19206.pdf' target='_blank'>https://arxiv.org/pdf/2404.19206.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cenk Demir, Mamadou Diagne, Miroslav Krstic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.19206">Periodic Event-Triggered Boundary Control of Neuron Growth with Actuation at Soma</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Exploring novel strategies for the regulation of axon growth, we introduce a periodic event-triggered control (PETC) to enhance the practical implementation of the associated PDE backstepping control law. Neurological injuries may impair neuronal function, but therapies like Chondroitinase ABC (ChABC) have shown promise in improving axon elongation by influencing the extracellular matrix. This matrix, composed of extracellular macromolecules and minerals, regulates tubulin protein concentration, potentially aiding in neuronal recovery. The concentration and spatial distribution of tubulin influence axon elongation dynamics. Recent research explores feedback control strategies for this model, leading to the development of an event-triggering control (CETC) approach. In this approach, the control law updates when the monitored triggering condition is met, reducing actuation resource consumption. Through the meticulous redesign of the triggering mechanism, we introduce a periodic event-triggering control (PETC), updating control inputs at specific intervals, but evaluating the event-trigger only periodically, an ideal tool for standard time-sliced actuators like ChABC. PETC is a step forward to the design of practically feasible feedback laws for the neuron growth process. The PETC strategy establishes an upper bound on event triggers between periodic examinations, ensuring convergence and preventing Zeno behavior. Through Lyapunov analysis, we demonstrate the local exponential convergence of the system with the periodic event-triggering mechanism in the $L^2$-norm sense. Numerical examples are presented to confirm the theoretical findings.
<div id='section'>Paperid: <span id='pid'>823, <a href='https://arxiv.org/pdf/2404.14970.pdf' target='_blank'>https://arxiv.org/pdf/2404.14970.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rita T. Sousa, Heiko Paulheim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14970">Integrating Heterogeneous Gene Expression Data through Knowledge Graphs for Improving Diabetes Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diabetes is a worldwide health issue affecting millions of people. Machine learning methods have shown promising results in improving diabetes prediction, particularly through the analysis of diverse data types, namely gene expression data. While gene expression data can provide valuable insights, challenges arise from the fact that the sample sizes in expression datasets are usually limited, and the data from different datasets with different gene expressions cannot be easily combined.
  This work proposes a novel approach to address these challenges by integrating multiple gene expression datasets and domain-specific knowledge using knowledge graphs, a unique tool for biomedical data integration. KG embedding methods are then employed to generate vector representations, serving as inputs for a classifier. Experiments demonstrated the efficacy of our approach, revealing improvements in diabetes prediction when integrating multiple gene expression datasets and domain-specific knowledge about protein functions and interactions.
<div id='section'>Paperid: <span id='pid'>824, <a href='https://arxiv.org/pdf/2404.10457.pdf' target='_blank'>https://arxiv.org/pdf/2404.10457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anton Bushuiev, Roman Bushuiev, Jiri Sedlar, Tomas Pluskal, Jiri Damborsky, Stanislav Mazurenko, Josef Sivic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10457">Revealing data leakage in protein interaction benchmarks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, there has been remarkable progress in machine learning for protein-protein interactions. However, prior work has predominantly focused on improving learning algorithms, with less attention paid to evaluation strategies and data preparation. Here, we demonstrate that further development of machine learning methods may be hindered by the quality of existing train-test splits. Specifically, we find that commonly used splitting strategies for protein complexes, based on protein sequence or metadata similarity, introduce major data leakage. This may result in overoptimistic evaluation of generalization, as well as unfair benchmarking of the models, biased towards assessing their overfitting capacity rather than practical utility. To overcome the data leakage, we recommend constructing data splits based on 3D structural similarity of protein-protein interfaces and suggest corresponding algorithms. We believe that addressing the data leakage problem is critical for further progress in this research area.
<div id='section'>Paperid: <span id='pid'>825, <a href='https://arxiv.org/pdf/2404.10450.pdf' target='_blank'>https://arxiv.org/pdf/2404.10450.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingda Xu, Peisheng Qian, Ziyuan Zhao, Zeng Zeng, Jianguo Chen, Weide Liu, Xulei Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10450">Graph Neural Networks for Protein-Protein Interactions -- A Short Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interactions (PPIs) play key roles in a broad range of biological processes. Numerous strategies have been proposed for predicting PPIs, and among them, graph-based methods have demonstrated promising outcomes owing to the inherent graph structure of PPI networks. This paper reviews various graph-based methodologies, and discusses their applications in PPI prediction. We classify these approaches into two primary groups based on their model structures. The first category employs Graph Neural Networks (GNN) or Graph Convolutional Networks (GCN), while the second category utilizes Graph Attention Networks (GAT), Graph Auto-Encoders and Graph-BERT. We highlight the distinctive methodologies of each approach in managing the graph-structured data inherent in PPI networks and anticipate future research directions in this domain.
<div id='section'>Paperid: <span id='pid'>826, <a href='https://arxiv.org/pdf/2404.00050.pdf' target='_blank'>https://arxiv.org/pdf/2404.00050.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leif Seute, Eric Hartmann, Jan StÃ¼hmer, Frauke GrÃ¤ter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00050">Grappa -- A Machine Learned Molecular Mechanics Force Field</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulating large molecular systems over long timescales requires force fields that are both accurate and efficient. In recent years, E(3) equivariant neural networks have lifted the tension between computational efficiency and accuracy of force fields, but they are still several orders of magnitude more expensive than established molecular mechanics (MM) force fields. Here, we propose Grappa, a machine learning framework to predict MM parameters from the molecular graph, employing a graph attentional neural network and a transformer with symmetry-preserving positional encoding. The resulting Grappa force field outperformstabulated and machine-learned MM force fields in terms of accuracy at the same computational efficiency and can be used in existing Molecular Dynamics (MD) engines like GROMACS and OpenMM. It predicts energies and forces of small molecules, peptides, RNA and - showcasing its extensibility to uncharted regions of chemical space - radicals at state-of-the-art MM accuracy. We demonstrate Grappa's transferability to macromolecules in MD simulations from a small fast folding protein up to a whole virus particle. Our force field sets the stage for biomolecular simulations closer to chemical accuracy, but with the same computational cost as established protein force fields.
<div id='section'>Paperid: <span id='pid'>827, <a href='https://arxiv.org/pdf/2403.17889.pdf' target='_blank'>https://arxiv.org/pdf/2403.17889.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Henry Kenlay, FrÃ©dÃ©ric A. Dreyer, Aleksandr Kovaltsuk, Dom Miketa, Douglas Pires, Charlotte M. Deane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17889">Large scale paired antibody language models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibodies are proteins produced by the immune system that can identify and neutralise a wide variety of antigens with high specificity and affinity, and constitute the most successful class of biotherapeutics. With the advent of next-generation sequencing, billions of antibody sequences have been collected in recent years, though their application in the design of better therapeutics has been constrained by the sheer volume and complexity of the data. To address this challenge, we present IgBert and IgT5, the best performing antibody-specific language models developed to date which can consistently handle both paired and unpaired variable region sequences as input. These models are trained comprehensively using the more than two billion unpaired sequences and two million paired sequences of light and heavy chains present in the Observed Antibody Space dataset. We show that our models outperform existing antibody and protein language models on a diverse range of design and regression tasks relevant to antibody engineering. This advancement marks a significant leap forward in leveraging machine learning, large scale data sets and high-performance computing for enhancing antibody design for therapeutic development.
<div id='section'>Paperid: <span id='pid'>828, <a href='https://arxiv.org/pdf/2403.15673.pdf' target='_blank'>https://arxiv.org/pdf/2403.15673.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenyu Bi, Sajib Acharjee Dip, Daniel Hajialigol, Sindhura Kommu, Hanwen Liu, Meng Lu, Xuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15673">AI for Biomedicine in the Era of Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The capabilities of AI for biomedicine span a wide spectrum, from the atomic level, where it solves partial differential equations for quantum systems, to the molecular level, predicting chemical or protein structures, and further extending to societal predictions like infectious disease outbreaks. Recent advancements in large language models, exemplified by models like ChatGPT, have showcased significant prowess in natural language tasks, such as translating languages, constructing chatbots, and answering questions. When we consider biomedical data, we observe a resemblance to natural language in terms of sequences: biomedical literature and health records presented as text, biological sequences or sequencing data arranged in sequences, or sensor data like brain signals as time series. The question arises: Can we harness the potential of recent large language models to drive biomedical knowledge discoveries? In this survey, we will explore the application of large language models to three crucial categories of biomedical data: 1) textual data, 2) biological sequences, and 3) brain signals. Furthermore, we will delve into large language model challenges in biomedical research, including ensuring trustworthiness, achieving personalization, and adapting to multi-modal data representation
<div id='section'>Paperid: <span id='pid'>829, <a href='https://arxiv.org/pdf/2312.09236.pdf' target='_blank'>https://arxiv.org/pdf/2312.09236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kieran Didi, Francisco Vargas, Simon V Mathis, Vincent Dutordoir, Emile Mathieu, Urszula J Komorowska, Pietro Lio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.09236">A framework for conditional diffusion modelling with applications in motif scaffolding for protein design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many protein design applications, such as binder or enzyme design, require scaffolding a structural motif with high precision. Generative modelling paradigms based on denoising diffusion processes emerged as a leading candidate to address this motif scaffolding problem and have shown early experimental success in some cases. In the diffusion paradigm, motif scaffolding is treated as a conditional generation task, and several conditional generation protocols were proposed or imported from the Computer Vision literature. However, most of these protocols are motivated heuristically, e.g. via analogies to Langevin dynamics, and lack a unifying framework, obscuring connections between the different approaches. In this work, we unify conditional training and conditional sampling procedures under one common framework based on the mathematically well-understood Doob's h-transform. This new perspective allows us to draw connections between existing methods and propose a new variation on existing conditional training protocols. We illustrate the effectiveness of this new protocol in both, image outpainting and motif scaffolding and find that it outperforms standard methods.
<div id='section'>Paperid: <span id='pid'>830, <a href='https://arxiv.org/pdf/2312.02235.pdf' target='_blank'>https://arxiv.org/pdf/2312.02235.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiakai Zhang, Qihe Chen, Yan Zeng, Wenyuan Gao, Xuming He, Zhijie Liu, Jingyi Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.02235">CryoGEM: Physics-Informed Generative Cryo-Electron Microscopy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the past decade, deep conditional generative models have revolutionized the generation of realistic images, extending their application from entertainment to scientific domains. Single-particle cryo-electron microscopy (cryo-EM) is crucial in resolving near-atomic resolution 3D structures of proteins, such as the SARS- COV-2 spike protein. To achieve high-resolution reconstruction, a comprehensive data processing pipeline has been adopted. However, its performance is still limited as it lacks high-quality annotated datasets for training. To address this, we introduce physics-informed generative cryo-electron microscopy (CryoGEM), which for the first time integrates physics-based cryo-EM simulation with a generative unpaired noise translation to generate physically correct synthetic cryo-EM datasets with realistic noises. Initially, CryoGEM simulates the cryo-EM imaging process based on a virtual specimen. To generate realistic noises, we leverage an unpaired noise translation via contrastive learning with a novel mask-guided sampling scheme. Extensive experiments show that CryoGEM is capable of generating authentic cryo-EM images. The generated dataset can used as training data for particle picking and pose estimation models, eventually improving the reconstruction resolution.
<div id='section'>Paperid: <span id='pid'>831, <a href='https://arxiv.org/pdf/2311.18725.pdf' target='_blank'>https://arxiv.org/pdf/2311.18725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhan Li, Hongtao Zhang, Keaven Anderson, Songzi Li, Ruoqing Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18725">AI in Pharma for Personalized Sequential Decision-Making: Methods, Applications and Opportunities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the pharmaceutical industry, the use of artificial intelligence (AI) has seen consistent growth over the past decade. This rise is attributed to major advancements in statistical machine learning methodologies, computational capabilities and the increased availability of large datasets. AI techniques are applied throughout different stages of drug development, ranging from drug discovery to post-marketing benefit-risk assessment. Kolluri et al. provided a review of several case studies that span these stages, featuring key applications such as protein structure prediction, success probability estimation, subgroup identification, and AI-assisted clinical trial monitoring. From a regulatory standpoint, there was a notable uptick in submissions incorporating AI components in 2021. The most prevalent therapeutic areas leveraging AI were oncology (27%), psychiatry (15%), gastroenterology (12%), and neurology (11%). The paradigm of personalized or precision medicine has gained significant traction in recent research, partly due to advancements in AI techniques \cite{hamburg2010path}. This shift has had a transformative impact on the pharmaceutical industry. Departing from the traditional "one-size-fits-all" model, personalized medicine incorporates various individual factors, such as environmental conditions, lifestyle choices, and health histories, to formulate customized treatment plans. By utilizing sophisticated machine learning algorithms, clinicians and researchers are better equipped to make informed decisions in areas such as disease prevention, diagnosis, and treatment selection, thereby optimizing health outcomes for each individual.
<div id='section'>Paperid: <span id='pid'>832, <a href='https://arxiv.org/pdf/2311.16328.pdf' target='_blank'>https://arxiv.org/pdf/2311.16328.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peter Eckmann, Jake Anderson, Michael K. Gilson, Rose Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16328">Target-Free Compound Activity Prediction via Few-Shot Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the activities of compounds against protein-based or phenotypic assays using only a few known compounds and their activities is a common task in target-free drug discovery. Existing few-shot learning approaches are limited to predicting binary labels (active/inactive). However, in real-world drug discovery, degrees of compound activity are highly relevant. We study Few-Shot Compound Activity Prediction (FS-CAP) and design a novel neural architecture to meta-learn continuous compound activities across large bioactivity datasets. Our model aggregates encodings generated from the known compounds and their activities to capture assay information. We also introduce a separate encoder for the unknown compound. We show that FS-CAP surpasses traditional similarity-based techniques as well as other state of the art few-shot learning methods on a variety of target-free drug discovery settings and datasets.
<div id='section'>Paperid: <span id='pid'>833, <a href='https://arxiv.org/pdf/2311.16132.pdf' target='_blank'>https://arxiv.org/pdf/2311.16132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sourabh Patil, Archana Mathur, Raviprasad Aduri, Snehanshu Saha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16132">A novel RNA pseudouridine site prediction model using Utility Kernel and data-driven parameters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>RNA protein Interactions (RPIs) play an important role in biological systems. Recently, we have enumerated the RPIs at the residue level and have elucidated the minimum structural unit (MSU) in these interactions to be a stretch of five residues (Nucleotides/amino acids). Pseudouridine is the most frequent modification in RNA. The conversion of uridine to pseudouridine involves interactions between pseudouridine synthase and RNA. The existing models to predict the pseudouridine sites in a given RNA sequence mainly depend on user-defined features such as mono and dinucleotide composition/propensities of RNA sequences. Predicting pseudouridine sites is a non-linear classification problem with limited data points. Deep Learning models are efficient discriminators when the data set size is reasonably large and fail when there is a paucity of data ($<1000$ samples). To mitigate this problem, we propose a Support Vector Machine (SVM) Kernel based on utility theory from Economics, and using data-driven parameters (i.e. MSU) as features. For this purpose, we have used position-specific tri/quad/pentanucleotide composition/propensity (PSPC/PSPP) besides nucleotide and dineculeotide composition as features. SVMs are known to work well in small data regimes and kernels in SVM are designed to classify non-linear data. The proposed model outperforms the existing state-of-the-art models significantly (10%-15% on average).
<div id='section'>Paperid: <span id='pid'>834, <a href='https://arxiv.org/pdf/2311.14003.pdf' target='_blank'>https://arxiv.org/pdf/2311.14003.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tian Huang, Shengbo Wang, Ke Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.14003">Direct Preference-Based Evolutionary Multi-Objective Optimization with Dueling Bandit</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optimization problems find widespread use in both single-objective and multi-objective scenarios. In practical applications, users aspire for solutions that converge to the region of interest (ROI) along the Pareto front (PF). While the conventional approach involves approximating a fitness function or an objective function to reflect user preferences, this paper explores an alternative avenue. Specifically, we aim to discover a method that sidesteps the need for calculating the fitness function, relying solely on human feedback. Our proposed approach entails conducting direct preference learning facilitated by an active dueling bandit algorithm. The experimental phase is structured into three sessions. Firstly, we assess the performance of our active dueling bandit algorithm. Secondly, we implement our proposed method within the context of Multi-objective Evolutionary Algorithms (MOEAs). Finally, we deploy our method in a practical problem, specifically in protein structure prediction (PSP). This research presents a novel interactive preference-based MOEA framework that not only addresses the limitations of traditional techniques but also unveils new possibilities for optimization problems.
<div id='section'>Paperid: <span id='pid'>835, <a href='https://arxiv.org/pdf/2310.19513.pdf' target='_blank'>https://arxiv.org/pdf/2310.19513.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>FrÃ©dÃ©ric A. Dreyer, Daniel Cutting, Constantin Schneider, Henry Kenlay, Charlotte M. Deane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19513">Inverse folding for antibody sequence design using deep learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the problem of antibody sequence design given 3D structural information. Building on previous work, we propose a fine-tuned inverse folding model that is specifically optimised for antibody structures and outperforms generic protein models on sequence recovery and structure robustness when applied on antibodies, with notable improvement on the hypervariable CDR-H3 loop. We study the canonical conformations of complementarity-determining regions and find improved encoding of these loops into known clusters. Finally, we consider the applications of our model to drug discovery and binder design and evaluate the quality of proposed sequences using physics-based methods.
<div id='section'>Paperid: <span id='pid'>836, <a href='https://arxiv.org/pdf/2310.18515.pdf' target='_blank'>https://arxiv.org/pdf/2310.18515.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anton Bushuiev, Roman Bushuiev, Petr Kouba, Anatolii Filkin, Marketa Gabrielova, Michal Gabriel, Jiri Sedlar, Tomas Pluskal, Jiri Damborsky, Stanislav Mazurenko, Josef Sivic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18515">Learning to design protein-protein interactions with enhanced generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discovering mutations enhancing protein-protein interactions (PPIs) is critical for advancing biomedical research and developing improved therapeutics. While machine learning approaches have substantially advanced the field, they often struggle to generalize beyond training data in practical scenarios. The contributions of this work are three-fold. First, we construct PPIRef, the largest and non-redundant dataset of 3D protein-protein interactions, enabling effective large-scale learning. Second, we leverage the PPIRef dataset to pre-train PPIformer, a new SE(3)-equivariant model generalizing across diverse protein-binder variants. We fine-tune PPIformer to predict effects of mutations on protein-protein interactions via a thermodynamically motivated adjustment of the pre-training loss function. Finally, we demonstrate the enhanced generalization of our new PPIformer approach by outperforming other state-of-the-art methods on new, non-leaking splits of standard labeled PPI mutational data and independent case studies optimizing a human antibody against SARS-CoV-2 and increasing the thrombolytic activity of staphylokinase.
<div id='section'>Paperid: <span id='pid'>837, <a href='https://arxiv.org/pdf/2310.07487.pdf' target='_blank'>https://arxiv.org/pdf/2310.07487.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>V. S. D. S. Mahesh Akavarapu, Arnab Bhattacharya
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.07487">Cognate Transformer for Automated Phonological Reconstruction and Cognate Reflex Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Phonological reconstruction is one of the central problems in historical linguistics where a proto-word of an ancestral language is determined from the observed cognate words of daughter languages. Computational approaches to historical linguistics attempt to automate the task by learning models on available linguistic data. Several ideas and techniques drawn from computational biology have been successfully applied in the area of computational historical linguistics. Following these lines, we adapt MSA Transformer, a protein language model, to the problem of automated phonological reconstruction. MSA Transformer trains on multiple sequence alignments as input and is, thus, apt for application on aligned cognate words. We, hence, name our model as Cognate Transformer. We also apply the model on another associated task, namely, cognate reflex prediction, where a reflex word in a daughter language is predicted based on cognate words from other daughter languages. We show that our model outperforms the existing models on both tasks, especially when it is pre-trained on masked word prediction task.
<div id='section'>Paperid: <span id='pid'>838, <a href='https://arxiv.org/pdf/2310.03899.pdf' target='_blank'>https://arxiv.org/pdf/2310.03899.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Dun, Qiutai Pan, Shikai Jin, Ria Stevens, Mitchell D. Miller, George N. Phillips,, Anastasios Kyrillidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03899">CrysFormer: Protein Structure Prediction via 3d Patterson Maps and Partial Structure Attention</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Determining the structure of a protein has been a decades-long open question. A protein's three-dimensional structure often poses nontrivial computation costs, when classical simulation algorithms are utilized. Advances in the transformer neural network architecture -- such as AlphaFold2 -- achieve significant improvements for this problem, by learning from a large dataset of sequence information and corresponding protein structures. Yet, such methods only focus on sequence information; other available prior knowledge, such as protein crystallography and partial structure of amino acids, could be potentially utilized. To the best of our knowledge, we propose the first transformer-based model that directly utilizes protein crystallography and partial structure information to predict the electron density maps of proteins. Via two new datasets of peptide fragments (2-residue and 15-residue) , we demonstrate our method, dubbed \texttt{CrysFormer}, can achieve accurate predictions, based on a much smaller dataset size and with reduced computation costs.
<div id='section'>Paperid: <span id='pid'>839, <a href='https://arxiv.org/pdf/2310.03121.pdf' target='_blank'>https://arxiv.org/pdf/2310.03121.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peter Eastman, Raimondas Galvelis, RaÃºl P. PelÃ¡ez, Charlles R. A. Abreu, Stephen E. Farr, Emilio Gallicchio, Anton Gorenko, Michael M. Henry, Frank Hu, Jing Huang, Andreas KrÃ¤mer, Julien Michel, Joshua A. Mitchell, Vijay S. Pande, JoÃ£o PGLM Rodrigues, Jaime Rodriguez-Guerra, Andrew C. Simmonett, Sukrit Singh, Jason Swails, Philip Turner, Yuanqing Wang, Ivy Zhang, John D. Chodera, Gianni De Fabritiis, Thomas E. Markland
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03121">OpenMM 8: Molecular Dynamics Simulation with Machine Learning Potentials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning plays an important and growing role in molecular simulation. The newest version of the OpenMM molecular dynamics toolkit introduces new features to support the use of machine learning potentials. Arbitrary PyTorch models can be added to a simulation and used to compute forces and energy. A higher-level interface allows users to easily model their molecules of interest with general purpose, pretrained potential functions. A collection of optimized CUDA kernels and custom PyTorch operations greatly improves the speed of simulations. We demonstrate these features on simulations of cyclin-dependent kinase 8 (CDK8) and the green fluorescent protein (GFP) chromophore in water. Taken together, these features make it practical to use machine learning to improve the accuracy of simulations at only a modest increase in cost.
<div id='section'>Paperid: <span id='pid'>840, <a href='https://arxiv.org/pdf/2310.02508.pdf' target='_blank'>https://arxiv.org/pdf/2310.02508.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Allan dos Santos Costa, Ilan Mitnikov, Mario Geiger, Manvitha Ponnapati, Tess Smidt, Joseph Jacobson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02508">Ophiuchus: Scalable Modeling of Protein Structures through Hierarchical Coarse-graining SO(3)-Equivariant Autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Three-dimensional native states of natural proteins display recurring and hierarchical patterns. Yet, traditional graph-based modeling of protein structures is often limited to operate within a single fine-grained resolution, and lacks hourglass neural architectures to learn those high-level building blocks. We narrow this gap by introducing Ophiuchus, an SO(3)-equivariant coarse-graining model that efficiently operates on all-atom protein structures. Our model departs from current approaches that employ graph modeling, instead focusing on local convolutional coarsening to model sequence-motif interactions with efficient time complexity in protein length. We measure the reconstruction capabilities of Ophiuchus across different compression rates, and compare it to existing models. We examine the learned latent space and demonstrate its utility through conformational interpolation. Finally, we leverage denoising diffusion probabilistic models (DDPM) in the latent space to efficiently sample protein structures. Our experiments demonstrate Ophiuchus to be a scalable basis for efficient protein modeling and generation.
<div id='section'>Paperid: <span id='pid'>841, <a href='https://arxiv.org/pdf/2310.00681.pdf' target='_blank'>https://arxiv.org/pdf/2310.00681.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seonghwan Seo, Woo Youn Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.00681">PharmacoNet: Accelerating Large-Scale Virtual Screening by Deep Pharmacophore Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As the size of accessible compound libraries expands to over 10 billion, the need for more efficient structure-based virtual screening methods is emerging. Different pre-screening methods have been developed for rapid screening, but there is still a lack of structure-based methods applicable to various proteins that perform protein-ligand binding conformation prediction and scoring in an extremely short time. Here, we describe for the first time a deep-learning framework for structure-based pharmacophore modeling to address this challenge. We frame pharmacophore modeling as an instance segmentation problem to determine each protein hotspot and the location of corresponding pharmacophores, and protein-ligand binding pose prediction as a graph-matching problem. PharmacoNet is significantly faster than state-of-the-art structure-based approaches, yet reasonably accurate with a simple scoring function. Furthermore, we show the promising result that PharmacoNet effectively retains hit candidates even under the high pre-screening filtration rates. Overall, our study uncovers the hitherto untapped potential of a pharmacophore modeling approach in deep learning-based drug discovery.
<div id='section'>Paperid: <span id='pid'>842, <a href='https://arxiv.org/pdf/2309.16598.pdf' target='_blank'>https://arxiv.org/pdf/2309.16598.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tijana Zrnic, Emmanuel J. CandÃ¨s
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16598">Cross-Prediction-Powered Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While reliable data-driven decision-making hinges on high-quality labeled data, the acquisition of quality labels often involves laborious human annotations or slow and expensive scientific measurements. Machine learning is becoming an appealing alternative as sophisticated predictive techniques are being used to quickly and cheaply produce large amounts of predicted labels; e.g., predicted protein structures are used to supplement experimentally derived structures, predictions of socioeconomic indicators from satellite imagery are used to supplement accurate survey data, and so on. Since predictions are imperfect and potentially biased, this practice brings into question the validity of downstream inferences. We introduce cross-prediction: a method for valid inference powered by machine learning. With a small labeled dataset and a large unlabeled dataset, cross-prediction imputes the missing labels via machine learning and applies a form of debiasing to remedy the prediction inaccuracies. The resulting inferences achieve the desired error probability and are more powerful than those that only leverage the labeled data. Closely related is the recent proposal of prediction-powered inference, which assumes that a good pre-trained model is already available. We show that cross-prediction is consistently more powerful than an adaptation of prediction-powered inference in which a fraction of the labeled data is split off and used to train the model. Finally, we observe that cross-prediction gives more stable conclusions than its competitors; its confidence intervals typically have significantly lower variability.
<div id='section'>Paperid: <span id='pid'>843, <a href='https://arxiv.org/pdf/2309.12906.pdf' target='_blank'>https://arxiv.org/pdf/2309.12906.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Wang, Zanyu Shi, Timothy Richardson, Kun Huang, Pathum Weerawarna, Yijie Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.12906">Building explainable graph neural network by sparse learning for the drug-protein binding prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explainable Graph Neural Networks (GNNs) have been developed and applied to drug-protein binding prediction to identify the key chemical structures in a drug that have active interactions with the target proteins. However, the key structures identified by the current explainable GNN models are typically chemically invalid. Furthermore, a threshold needs to be manually selected to pinpoint the key structures from the rest. To overcome the limitations of the current explainable GNN models, we propose our SLGNN, which stands for using Sparse Learning to Graph Neural Networks. Our SLGNN relies on using a chemical-substructure-based graph (where nodes are chemical substructures) to represent a drug molecule. Furthermore, SLGNN incorporates generalized fussed lasso with message-passing algorithms to identify connected subgraphs that are critical for the drug-protein binding prediction. Due to the use of the chemical-substructure-based graph, it is guaranteed that any subgraphs in a drug identified by our SLGNN are chemically valid structures. These structures can be further interpreted as the key chemical structures for the drug to bind to the target protein. We demonstrate the explanatory power of our SLGNN by first showing all the key structures identified by our SLGNN are chemically valid. In addition, we illustrate that the key structures identified by our SLGNN have more predictive power than the key structures identified by the competing methods. At last, we use known drug-protein binding data to show the key structures identified by our SLGNN contain most of the binding sites.
<div id='section'>Paperid: <span id='pid'>844, <a href='https://arxiv.org/pdf/2308.09482.pdf' target='_blank'>https://arxiv.org/pdf/2308.09482.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Flam-Shepherd, Kevin Zhu, AlÃ¡n Aspuru-Guzik
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09482">Atom-by-atom protein generation and beyond with language models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models learn powerful representations directly from sequences of amino acids. However, they are constrained to generate proteins with only the set of amino acids represented in their vocabulary. In contrast, chemical language models learn atom-level representations of smaller molecules that include every atom, bond, and ring. In this work, we show that chemical language models can learn atom-level representations of proteins enabling protein generation unconstrained to the standard genetic code and far beyond it. In doing so, we show that language models can generate entire proteins atom by atom -- effectively learning the multiple hierarchical layers of molecular information that define proteins from their primary sequence to their secondary, and tertiary structure. We demonstrate language models are able to explore beyond protein space -- generating proteins with modified sidechains that form unnatural amino acids. Even further, we find that language models can explore chemical space and protein space simultaneously and generate novel examples of protein-drug conjugates. The results demonstrate the potential for biomolecular design at the atom level using language models.
<div id='section'>Paperid: <span id='pid'>845, <a href='https://arxiv.org/pdf/2308.07954.pdf' target='_blank'>https://arxiv.org/pdf/2308.07954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyun Park, Parth Patel, Roland Haas, E. A. Huerta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07954">APACE: AlphaFold2 and advanced computing as a service for accelerated discovery in biophysics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The prediction of protein 3D structure from amino acid sequence is a computational grand challenge in biophysics, and plays a key role in robust protein structure prediction algorithms, from drug discovery to genome interpretation. The advent of AI models, such as AlphaFold, is revolutionizing applications that depend on robust protein structure prediction algorithms. To maximize the impact, and ease the usability, of these novel AI tools we introduce APACE, AlphaFold2 and advanced computing as a service, a novel computational framework that effectively handles this AI model and its TB-size database to conduct accelerated protein structure prediction analyses in modern supercomputing environments. We deployed APACE in the Delta and Polaris supercomputers, and quantified its performance for accurate protein structure predictions using four exemplar proteins: 6AWO, 6OAN, 7MEZ, and 6D6U. Using up to 300 ensembles, distributed across 200 NVIDIA A100 GPUs, we found that APACE is up to two orders of magnitude faster than off-the-self AlphaFold2 implementations, reducing time-to-solution from weeks to minutes. This computational approach may be readily linked with robotics laboratories to automate and accelerate scientific discovery.
<div id='section'>Paperid: <span id='pid'>846, <a href='https://arxiv.org/pdf/2308.03447.pdf' target='_blank'>https://arxiv.org/pdf/2308.03447.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rita T. Sousa, Sara Silva, Heiko Paulheim, Catia Pesquita
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.03447">Biomedical Knowledge Graph Embeddings with Negative Statements</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A knowledge graph is a powerful representation of real-world entities and their relations. The vast majority of these relations are defined as positive statements, but the importance of negative statements is increasingly recognized, especially under an Open World Assumption. Explicitly considering negative statements has been shown to improve performance on tasks such as entity summarization and question answering or domain-specific tasks such as protein function prediction. However, no attention has been given to the exploration of negative statements by knowledge graph embedding approaches despite the potential of negative statements to produce more accurate representations of entities in a knowledge graph.
  We propose a novel approach, TrueWalks, to incorporate negative statements into the knowledge graph representation learning process. In particular, we present a novel walk-generation method that is able to not only differentiate between positive and negative statements but also take into account the semantic implications of negation in ontology-rich knowledge graphs. This is of particular importance for applications in the biomedical domain, where the inadequacy of embedding approaches regarding negative statements at the ontology level has been identified as a crucial limitation.
  We evaluate TrueWalks in ontology-rich biomedical knowledge graphs in two different predictive tasks based on KG embeddings: protein-protein interaction prediction and gene-disease association prediction. We conduct an extensive analysis over established benchmarks and demonstrate that our method is able to improve the performance of knowledge graph embeddings on all tasks.
<div id='section'>Paperid: <span id='pid'>847, <a href='https://arxiv.org/pdf/2307.07085.pdf' target='_blank'>https://arxiv.org/pdf/2307.07085.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kenichiro Takaba, IvÃ¡n Pulido, Pavan Kumar Behara, Chapin E. Cavender, Anika J. Friedman, Michael M. Henry, Hugo MacDermott Opeskin, Christopher R. Iacovella, Arnav M. Nagle, Alexander Matthew Payne, Michael R. Shirts, David L. Mobley, John D. Chodera, Yuanqing Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.07085">Machine-learned molecular mechanics force field for the simulation of protein-ligand systems and beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The development of reliable and extensible molecular mechanics (MM) force fields -- fast, empirical models characterizing the potential energy surface of molecular systems -- is indispensable for biomolecular simulation and computer-aided drug design. Here, we introduce a generalized and extensible machine-learned MM force field, \texttt{espaloma-0.3}, and an end-to-end differentiable framework using graph neural networks to overcome the limitations of traditional rule-based methods. Trained in a single GPU-day to fit a large and diverse quantum chemical dataset of over 1.1M energy and force calculations, \texttt{espaloma-0.3} reproduces quantum chemical energetic properties of chemical domains highly relevant to drug discovery, including small molecules, peptides, and nucleic acids. Moreover, this force field maintains the quantum chemical energy-minimized geometries of small molecules and preserves the condensed phase properties of peptides, self-consistently parametrizing proteins and ligands to produce stable simulations leading to highly accurate predictions of binding free energies. This methodology demonstrates significant promise as a path forward for systematically building more accurate force fields that are easily extensible to new chemical domains of interest.
<div id='section'>Paperid: <span id='pid'>848, <a href='https://arxiv.org/pdf/2307.01066.pdf' target='_blank'>https://arxiv.org/pdf/2307.01066.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seokhyun Moon, Sang-Yeon Hwang, Jaechang Lim, Woo Youn Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.01066">PIGNet2: A Versatile Deep Learning-based Protein-Ligand Interaction Prediction Model for Binding Affinity Scoring and Virtual Screening</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prediction of protein-ligand interactions (PLI) plays a crucial role in drug discovery as it guides the identification and optimization of molecules that effectively bind to target proteins. Despite remarkable advances in deep learning-based PLI prediction, the development of a versatile model capable of accurately scoring binding affinity and conducting efficient virtual screening remains a challenge. The main obstacle in achieving this lies in the scarcity of experimental structure-affinity data, which limits the generalization ability of existing models. Here, we propose a viable solution to address this challenge by introducing a novel data augmentation strategy combined with a physics-informed graph neural network. The model showed significant improvements in both scoring and screening, outperforming task-specific deep learning models in various tests including derivative benchmarks, and notably achieving results comparable to the state-of-the-art performance based on distance likelihood learning. This demonstrates the potential of this approach to drug discovery.
<div id='section'>Paperid: <span id='pid'>849, <a href='https://arxiv.org/pdf/2306.17202.pdf' target='_blank'>https://arxiv.org/pdf/2306.17202.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazuma Inoue, Ryosuke Kojima, Mayumi Kamada, Yasushi Okuno
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.17202">An end-to-end framework for gene expression classification by integrating a background knowledge graph: application to cancer prognosis prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biological data may be separated into primary data, such as gene expression, and secondary data, such as pathways and protein-protein interactions. Methods using secondary data to enhance the analysis of primary data are promising, because secondary data have background information that is not included in primary data. In this study, we proposed an end-to-end framework to integrally handle secondary data to construct a classification model for primary data. We applied this framework to cancer prognosis prediction using gene expression data and a biological network. Cross-validation results indicated that our model achieved higher accuracy compared with a deep neural network model without background biological network information. Experiments conducted in patient groups by cancer type showed improvement in ROC-area under the curve for many groups. Visualizations of high accuracy cancer types identified contributing genes and pathways by enrichment analysis. Known biomarkers and novel biomarker candidates were identified through these experiments.
<div id='section'>Paperid: <span id='pid'>850, <a href='https://arxiv.org/pdf/2306.12802.pdf' target='_blank'>https://arxiv.org/pdf/2306.12802.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hoang Thanh Lam, Marco Luca Sbodio, Marcos MartÃ­nez Galindo, Mykhaylo Zayats, RaÃºl FernÃ¡ndez-DÃ­az, VÃ­ctor Valls, Gabriele Picco, Cesar Berrospi Ramis, Vanessa LÃ³pez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.12802">Otter-Knowledge: benchmarks of multimodal knowledge graph representation learning from different sources for drug discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent research on predicting the binding affinity between drug molecules and proteins use representations learned, through unsupervised learning techniques, from large databases of molecule SMILES and protein sequences. While these representations have significantly enhanced the predictions, they are usually based on a limited set of modalities, and they do not exploit available knowledge about existing relations among molecules and proteins. In this study, we demonstrate that by incorporating knowledge graphs from diverse sources and modalities into the sequences or SMILES representation, we can further enrich the representation and achieve state-of-the-art results for drug-target binding affinity prediction in the established Therapeutic Data Commons (TDC) benchmarks. We release a set of multimodal knowledge graphs, integrating data from seven public data sources, and containing over 30 million triples. Our intention is to foster additional research to explore how multimodal knowledge enhanced protein/molecule embeddings can improve prediction tasks, including prediction of binding affinity. We also release some pretrained models learned from our multimodal knowledge graphs, along with source code for running standard benchmark tasks for prediction of biding affinity.
<div id='section'>Paperid: <span id='pid'>851, <a href='https://arxiv.org/pdf/2306.03911.pdf' target='_blank'>https://arxiv.org/pdf/2306.03911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yurong Zhong, Zhe Xie, Weiling Li, Xin Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03911">Multi-constrained Symmetric Nonnegative Latent Factor Analysis for Accurately Representing Large-scale Undirected Weighted Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An Undirected Weighted Network (UWN) is frequently encountered in a big-data-related application concerning the complex interactions among numerous nodes, e.g., a protein interaction network from a bioinformatics application. A Symmetric High-Dimensional and Incomplete (SHDI) matrix can smoothly illustrate such an UWN, which contains rich knowledge like node interaction behaviors and local complexes. To extract desired knowledge from an SHDI matrix, an analysis model should carefully consider its symmetric-topology for describing an UWN's intrinsic symmetry. Representation learning to an UWN borrows the success of a pyramid of symmetry-aware models like a Symmetric Nonnegative Matrix Factorization (SNMF) model whose objective function utilizes a sole Latent Factor (LF) matrix for representing SHDI's symmetry rigorously. However, they suffer from the following drawbacks: 1) their computational complexity is high; and 2) their modeling strategy narrows their representation features, making them suffer from low learning ability. Aiming at addressing above critical issues, this paper proposes a Multi-constrained Symmetric Nonnegative Latent-factor-analysis (MSNL) model with two-fold ideas: 1) introducing multi-constraints composed of multiple LF matrices, i.e., inequality and equality ones into a data-density-oriented objective function for precisely representing the intrinsic symmetry of an SHDI matrix with broadened feature space; and 2) implementing an Alternating Direction Method of Multipliers (ADMM)-incorporated learning scheme for precisely solving such a multi-constrained model. Empirical studies on three SHDI matrices from a real bioinformatics or industrial application demonstrate that the proposed MSNL model achieves stronger representation learning ability to an SHDI matrix than state-of-the-art models do.
<div id='section'>Paperid: <span id='pid'>852, <a href='https://arxiv.org/pdf/2305.08057.pdf' target='_blank'>https://arxiv.org/pdf/2305.08057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Colin A. Grambow, Hayley Weir, Christian N. Cunningham, Tommaso Biancalani, Kangway V. Chuang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.08057">CREMP: Conformer-rotamer ensembles of macrocyclic peptides for machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational and machine learning approaches to model the conformational landscape of macrocyclic peptides have the potential to enable rational design and optimization. However, accurate, fast, and scalable methods for modeling macrocycle geometries remain elusive. Recent deep learning approaches have significantly accelerated protein structure prediction and the generation of small-molecule conformational ensembles, yet similar progress has not been made for macrocyclic peptides due to their unique properties. Here, we introduce CREMP, a resource generated for the rapid development and evaluation of machine learning models for macrocyclic peptides. CREMP contains 36,198 unique macrocyclic peptides and their high-quality structural ensembles generated using the Conformer-Rotamer Ensemble Sampling Tool (CREST). Altogether, this new dataset contains nearly 31.3 million unique macrocycle geometries, each annotated with energies derived from semi-empirical extended tight-binding (xTB) DFT calculations. Additionally, we include 3,258 macrocycles with reported passive permeability data to couple conformational ensembles to experiment. We anticipate that this dataset will enable the development of machine learning models that can improve peptide design and optimization for novel therapeutics.
<div id='section'>Paperid: <span id='pid'>853, <a href='https://arxiv.org/pdf/2305.05708.pdf' target='_blank'>https://arxiv.org/pdf/2305.05708.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Flam-Shepherd, AlÃ¡n Aspuru-Guzik
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.05708">Language models can generate molecules, materials, and protein binding sites directly in three dimensions as XYZ, CIF, and PDB files</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Language models are powerful tools for molecular design. Currently, the dominant paradigm is to parse molecular graphs into linear string representations that can easily be trained on. This approach has been very successful, however, it is limited to chemical structures that can be completely represented by a graph -- like organic molecules -- while materials and biomolecular structures like protein binding sites require a more complete representation that includes the relative positioning of their atoms in space. In this work, we show how language models, without any architecture modifications, trained using next-token prediction -- can generate novel and valid structures in three dimensions from various substantially different distributions of chemical structures. In particular, we demonstrate that language models trained directly on sequences derived directly from chemical file formats like XYZ files, Crystallographic Information files (CIFs), or Protein Data Bank files (PDBs) can directly generate molecules, crystals, and protein binding sites in three dimensions. Furthermore, despite being trained on chemical file sequences -- language models still achieve performance comparable to state-of-the-art models that use graph and graph-derived string representations, as well as other domain-specific 3D generative models. In doing so, we demonstrate that it is not necessary to use simplified molecular representations to train chemical language models -- that they are powerful generative models capable of directly exploring chemical space in three dimensions for very different structures.
<div id='section'>Paperid: <span id='pid'>854, <a href='https://arxiv.org/pdf/2305.00006.pdf' target='_blank'>https://arxiv.org/pdf/2305.00006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meenakshi S. Kagda, Bonita Lam, Casey Litton, Corinn Small, Cricket A. Sloan, Emma Spragins, Forrest Tanaka, Ian Whaling, Idan Gabdank, Ingrid Youngworth, J. Seth Strattan, Jason Hilton, Jennifer Jou, Jessica Au, Jin-Wook Lee, Kalina Andreeva, Keenan Graham, Khine Lin, Matt Simison, Otto Jolanki, Paul Sud, Pedro Assis, Philip Adenekan, Eric Douglas, Mingjie Li, Pedro Assis, Keenan Graham, Paul Sud, Stuart Miyasato, Weiwei Zhong, Yunhai Luo, Zachary Myers, J. Michael Cherry, Benjamin C. Hitz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.00006">Data navigation on the ENCODE portal</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spanning two decades, the Encyclopaedia of DNA Elements (ENCODE) is a collaborative research project that aims to identify all the functional elements in the human and mouse genomes. To best serve the scientific community, all data generated by the consortium is shared through a web-portal (https://www.encodeproject.org/) with no access restrictions. The fourth and final phase of the project added a diverse set of new samples (including those associated with human disease), and a wide range of new assays aimed at detection, characterization and validation of functional genomic elements. The ENCODE data portal hosts results from over 23,000 functional genomics experiments, over 800 functional elements characterization experiments (including in vivo transgenic enhancer assays, reporter assays and CRISPR screens) along with over 60,000 results of computational and integrative analyses (including imputations, predictions and genome annotations). The ENCODE Data Coordination Center (DCC) is responsible for development and maintenance of the data portal, along with the implementation and utilisation of the ENCODE uniform processing pipelines to generate uniformly processed data. Here we report recent updates to the data portal. Specifically, we have completely redesigned the home page, improved search interface, added several new pages to highlight collections of biologically related data (deeply profiled cell lines, immune cells, Alzheimer's Disease, RNA-Protein interactions, degron matrix and a matrix of experiments organised by human donors), added single-cell experiments, and enhanced the cart interface for visualisation and download of user-selected datasets.
<div id='section'>Paperid: <span id='pid'>855, <a href='https://arxiv.org/pdf/2304.10494.pdf' target='_blank'>https://arxiv.org/pdf/2304.10494.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haotian Zhang, Jintu Zhang, Huifeng Zhao, Dejun Jiang, Yafeng Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10494">Infinite Physical Monkey: Do Deep Learning Methods Really Perform Better in Conformation Generation?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conformation Generation is a fundamental problem in drug discovery and cheminformatics. And organic molecule conformation generation, particularly in vacuum and protein pocket environments, is most relevant to drug design. Recently, with the development of geometric neural networks, the data-driven schemes have been successfully applied in this field, both for molecular conformation generation (in vacuum) and binding pose generation (in protein pocket). The former beats the traditional ETKDG method, while the latter achieves similar accuracy compared with the widely used molecular docking software. Although these methods have shown promising results, some researchers have recently questioned whether deep learning (DL) methods perform better in molecular conformation generation via a parameter-free method. To our surprise, what they have designed is some kind analogous to the famous infinite monkey theorem, the monkeys that are even equipped with physics education. To discuss the feasibility of their proving, we constructed a real infinite stochastic monkey for molecular conformation generation, showing that even with a more stochastic sampler for geometry generation, the coverage of the benchmark QM-computed conformations are higher than those of most DL-based methods. By extending their physical monkey algorithm for binding pose prediction, we also discover that the successful docking rate also achieves near-best performance among existing DL-based docking models. Thus, though their conclusions are right, their proof process needs more concern.
<div id='section'>Paperid: <span id='pid'>856, <a href='https://arxiv.org/pdf/2303.15604.pdf' target='_blank'>https://arxiv.org/pdf/2303.15604.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Derek Jones, Jonathan E. Allen, Xiaohua Zhang, Behnam Khaleghi, Jaeyoung Kang, Weihong Xu, Niema Moshiri, Tajana S. Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.15604">HD-Bind: Encoding of Molecular Structure with Low Precision, Hyperdimensional Binary Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Publicly available collections of drug-like molecules have grown to comprise 10s of billions of possibilities in recent history due to advances in chemical synthesis. Traditional methods for identifying ``hit'' molecules from a large collection of potential drug-like candidates have relied on biophysical theory to compute approximations to the Gibbs free energy of the binding interaction between the drug to its protein target. A major drawback of the approaches is that they require exceptional computing capabilities to consider for even relatively small collections of molecules.
  Hyperdimensional Computing (HDC) is a recently proposed learning paradigm that is able to leverage low-precision binary vector arithmetic to build efficient representations of the data that can be obtained without the need for gradient-based optimization approaches that are required in many conventional machine learning and deep learning approaches. This algorithmic simplicity allows for acceleration in hardware that has been previously demonstrated for a range of application areas. We consider existing HDC approaches for molecular property classification and introduce two novel encoding algorithms that leverage the extended connectivity fingerprint (ECFP) algorithm.
  We show that HDC-based inference methods are as much as 90 times more efficient than more complex representative machine learning methods and achieve an acceleration of nearly 9 orders of magnitude as compared to inference with molecular docking. We demonstrate multiple approaches for the encoding of molecular data for HDC and examine their relative performance on a range of challenging molecular property prediction and drug-protein binding classification tasks. Our work thus motivates further investigation into molecular representation learning to develop ultra-efficient pre-screening tools.
<div id='section'>Paperid: <span id='pid'>857, <a href='https://arxiv.org/pdf/2303.15520.pdf' target='_blank'>https://arxiv.org/pdf/2303.15520.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiqun Wang, Yuning Shen, Shi Chen, Lihao Wang, Fei Ye, Hao Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.15520">Learning Harmonic Molecular Representations on Riemannian Manifold</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular representation learning plays a crucial role in AI-assisted drug discovery research. Encoding 3D molecular structures through Euclidean neural networks has become the prevailing method in the geometric deep learning community. However, the equivariance constraints and message passing in Euclidean space may limit the network expressive power. In this work, we propose a Harmonic Molecular Representation learning (HMR) framework, which represents a molecule using the Laplace-Beltrami eigenfunctions of its molecular surface. HMR offers a multi-resolution representation of molecular geometric and chemical features on 2D Riemannian manifold. We also introduce a harmonic message passing method to realize efficient spectral message passing over the surface manifold for better molecular encoding. Our proposed method shows comparable predictive power to current models in small molecule property prediction, and outperforms the state-of-the-art deep learning models for ligand-binding protein pocket classification and the rigid protein docking challenge, demonstrating its versatility in molecular representation learning.
<div id='section'>Paperid: <span id='pid'>858, <a href='https://arxiv.org/pdf/2302.12177.pdf' target='_blank'>https://arxiv.org/pdf/2302.12177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Zhang, Zhewei Wei, Ye Yuan, Chongxuan Li, Wenbing Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12177">EquiPocket: an E(3)-Equivariant Geometric Graph Neural Network for Ligand Binding Site Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the binding sites of target proteins plays a fundamental role in drug discovery. Most existing deep-learning methods consider a protein as a 3D image by spatially clustering its atoms into voxels and then feed the voxelized protein into a 3D CNN for prediction. However, the CNN-based methods encounter several critical issues: 1) defective in representing irregular protein structures; 2) sensitive to rotations; 3) insufficient to characterize the protein surface; 4) unaware of protein size shift. To address the above issues, this work proposes EquiPocket, an E(3)-equivariant Graph Neural Network (GNN) for binding site prediction, which comprises three modules: the first one to extract local geometric information for each surface atom, the second one to model both the chemical and spatial structure of protein and the last one to capture the geometry of the surface via equivariant message passing over the surface atoms. We further propose a dense attention output layer to alleviate the effect incurred by variable protein size. Extensive experiments on several representative benchmarks demonstrate the superiority of our framework to the state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>859, <a href='https://arxiv.org/pdf/2302.04737.pdf' target='_blank'>https://arxiv.org/pdf/2302.04737.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Md. Rezaul Karim, Lina Molinas Comet, Oya Beyan, Dietrich Rebholz-Schuhmann, Stefan Decker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.04737">A Biomedical Knowledge Graph for Biomarker Discovery in Cancer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structured and unstructured data and facts about drugs, genes, protein, viruses, and their mechanism are spread across a huge number of scientific articles. These articles are a large-scale knowledge source and can have a huge impact on disseminating knowledge about the mechanisms of certain biological processes. A domain-specific knowledge graph~(KG) is an explicit conceptualization of a specific subject-matter domain represented w.r.t semantically interrelated entities and relations. A KG can be constructed by integrating such facts and data and be used for data integration, exploration, and federated queries. However, exploration and querying large-scale KGs is tedious for certain groups of users due to a lack of knowledge about underlying data assets or semantic technologies. Such a KG will not only allow deducing new knowledge and question answering(QA) but also allows domain experts to explore. Since cross-disciplinary explanations are important for accurate diagnosis, it is important to query the KG to provide interactive explanations about learned biomarkers. Inspired by these, we construct a domain-specific KG, particularly for cancer-specific biomarker discovery. The KG is constructed by integrating cancer-related knowledge and facts from multiple sources. First, we construct a domain-specific ontology, which we call OncoNet Ontology (ONO). The ONO ontology is developed to enable semantic reasoning for verification of the predictions for relations between diseases and genes. The KG is then developed and enriched by harmonizing the ONO, additional metadata schemas, ontologies, controlled vocabularies, and additional concepts from external sources using a BERT-based information extraction method. BioBERT and SciBERT are finetuned with the selected articles crawled from PubMed. We listed down some queries and some examples of QA and deducing knowledge based on the KG.
<div id='section'>Paperid: <span id='pid'>860, <a href='https://arxiv.org/pdf/2301.07568.pdf' target='_blank'>https://arxiv.org/pdf/2301.07568.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abbi Abdel-Rehim, Oghenejokpeme Orhobor, Hang Lou, Hao Ni, Ross D. King
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.07568">Beating the Best: Improving on AlphaFold2 at Protein Structure Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of Protein Structure Prediction (PSP) problem is to predict a protein's 3D structure (confirmation) from its amino acid sequence. The problem has been a 'holy grail' of science since the Noble prize-winning work of Anfinsen demonstrated that protein conformation was determined by sequence. A recent and important step towards this goal was the development of AlphaFold2, currently the best PSP method. AlphaFold2 is probably the highest profile application of AI to science. Both AlphaFold2 and RoseTTAFold (another impressive PSP method) have been published and placed in the public domain (code & models). Stacking is a form of ensemble machine learning ML in which multiple baseline models are first learnt, then a meta-model is learnt using the outputs of the baseline level model to form a model that outperforms the base models. Stacking has been successful in many applications. We developed the ARStack PSP method by stacking AlphaFold2 and RoseTTAFold. ARStack significantly outperforms AlphaFold2. We rigorously demonstrate this using two sets of non-homologous proteins, and a test set of protein structures published after that of AlphaFold2 and RoseTTAFold. As more high quality prediction methods are published it is likely that ensemble methods will increasingly outperform any single method.
<div id='section'>Paperid: <span id='pid'>861, <a href='https://arxiv.org/pdf/2212.07492.pdf' target='_blank'>https://arxiv.org/pdf/2212.07492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maciej Majewski, AdriÃ  PÃ©rez, Philipp ThÃ¶lke, Stefan Doerr, Nicholas E. Charron, Toni Giorgino, Brooke E. Husic, Cecilia Clementi, Frank NoÃ©, Gianni De Fabritiis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.07492">Machine Learning Coarse-Grained Potentials of Protein Thermodynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A generalized understanding of protein dynamics is an unsolved scientific problem, the solution of which is critical to the interpretation of the structure-function relationships that govern essential biological processes. Here, we approach this problem by constructing coarse-grained molecular potentials based on artificial neural networks and grounded in statistical mechanics. For training, we build a unique dataset of unbiased all-atom molecular dynamics simulations of approximately 9 ms for twelve different proteins with multiple secondary structure arrangements. The coarse-grained models are capable of accelerating the dynamics by more than three orders of magnitude while preserving the thermodynamics of the systems. Coarse-grained simulations identify relevant structural states in the ensemble with comparable energetics to the all-atom systems. Furthermore, we show that a single coarse-grained potential can integrate all twelve proteins and can capture experimental structural features of mutated proteins. These results indicate that machine learning coarse-grained potentials could provide a feasible approach to simulate and understand protein dynamics.
<div id='section'>Paperid: <span id='pid'>862, <a href='https://arxiv.org/pdf/2207.00982.pdf' target='_blank'>https://arxiv.org/pdf/2207.00982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mai Ha Vu, Rahmad Akbar, Philippe A. Robert, Bartlomiej Swiatczak, Victor Greiff, Geir Kjetil Sandve, Dag Trygve Truslew Haug
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.00982">Linguistically inspired roadmap for building biologically reliable protein language models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural-network-based language models (LMs) are increasingly applied to large-scale protein sequence data to predict protein function. However, being largely black-box models and thus challenging to interpret, current protein LM approaches do not contribute to a fundamental understanding of sequence-function mappings, hindering rule-based biotherapeutic drug development. We argue that guidance drawn from linguistics, a field specialized in analytical rule extraction from natural language data, can aid with building more interpretable protein LMs that are more likely to learn relevant domain-specific rules. Differences between protein sequence data and linguistic sequence data require the integration of more domain-specific knowledge in protein LMs compared to natural language LMs. Here, we provide a linguistics-based roadmap for protein LM pipeline choices with regard to training data, tokenization, token embedding, sequence embedding, and model interpretation. Incorporating linguistic ideas into protein LMs enables the development of next-generation interpretable machine-learning models with the potential of uncovering the biological mechanisms underlying sequence-function relationships.
<div id='section'>Paperid: <span id='pid'>863, <a href='https://arxiv.org/pdf/2207.00812.pdf' target='_blank'>https://arxiv.org/pdf/2207.00812.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Magdalena Wysocka, Oskar Wysocki, Marie Zufferey, DÃ³nal Landers, AndrÃ© Freitas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.00812">A systematic review of biologically-informed deep learning models for cancer: fundamental trends for encoding and interpreting oncology data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There is an increasing interest in the use of Deep Learning (DL) based methods as a supporting analytical framework in oncology. However, most direct applications of DL will deliver models with limited transparency and explainability, which constrain their deployment in biomedical settings. This systematic review discusses DL models used to support inference in cancer biology with a particular emphasis on multi-omics analysis. It focuses on how existing models address the need for better dialogue with prior knowledge, biological plausibility and interpretability, fundamental properties in the biomedical domain. For this, we retrieved and analyzed 42 studies focusing on emerging architectural and methodological advances, the encoding of biological domain knowledge and the integration of explainability methods. We discuss the recent evolutionary arch of DL models in the direction of integrating prior biological relational and network knowledge to support better generalisation (e.g. pathways or Protein-Protein-Interaction networks) and interpretability. This represents a fundamental functional shift towards models which can integrate mechanistic and statistical inference aspects. We introduce a concept of bio-centric interpretability and according to its taxonomy, we discuss representational methodologies for the integration of domain prior knowledge in such models. The paper provides a critical outlook into contemporary methods for explainability and interpretabiltiy used in DL for cancer. The analysis points in the direction of a convergence between encoding prior knowledge and improved interpretability. We introduce bio-centric interpretability which is an important step towards formalisation of biological interpretability of DL models and developing methods that are less problem- or application-specific.
<div id='section'>Paperid: <span id='pid'>864, <a href='https://arxiv.org/pdf/2201.08110.pdf' target='_blank'>https://arxiv.org/pdf/2201.08110.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Raimondas Galvelis, Alejandro Varela-Rial, Stefan Doerr, Roberto Fino, Peter Eastman, Thomas E. Markland, John D. Chodera, Gianni De Fabritiis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.08110">NNP/MM: Accelerating molecular dynamics simulations with machine learning potentials and molecular mechanic</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning potentials have emerged as a means to enhance the accuracy of biomolecular simulations. However, their application is constrained by the significant computational cost arising from the vast number of parameters compared to traditional molecular mechanics. To tackle this issue, we introduce an optimized implementation of the hybrid method (NNP/MM), which combines neural network potentials (NNP) and molecular mechanics (MM). This approach models a portion of the system, such as a small molecule, using NNP while employing MM for the remaining system to boost efficiency. By conducting molecular dynamics (MD) simulations on various protein-ligand complexes and metadynamics (MTD) simulations on a ligand, we showcase the capabilities of our implementation of NNP/MM. It has enabled us to increase the simulation speed by 5 times and achieve a combined sampling of one microsecond for each complex, marking the longest simulations ever reported for this class of simulation.
<div id='section'>Paperid: <span id='pid'>865, <a href='https://arxiv.org/pdf/2006.12717.pdf' target='_blank'>https://arxiv.org/pdf/2006.12717.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ratan Othayoth, George Thoms, Chen Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2006.12717">An energy landscape approach to locomotor transitions in complex 3D terrain</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective locomotion in nature happens by transitioning across multiple modes (e.g., walk, run, climb). Despite this, far more mechanistic understanding of terrestrial locomotion has been on how to generate and stabilize around near-steady-state movement in a single mode. We still know little about how locomotor transitions emerge from physical interaction with complex terrain. Consequently, robots largely rely on geometric maps to avoid obstacles, not traverse them. Recent studies revealed that locomotor transitions in complex 3-D terrain occur probabilistically via multiple pathways. Here, we show that an energy landscape approach elucidates the underlying physical principles. We discovered that locomotor transitions of animals and robots self-propelled through complex 3-D terrain correspond to barrier-crossing transitions on a potential energy landscape. Locomotor modes are attracted to landscape basins separated by potential energy barriers. Kinetic energy fluctuation from oscillatory self-propulsion helps the system stochastically escape from one basin and reach another to make transitions. Escape is more likely towards lower barrier direction. These principles are surprisingly similar to those of near-equilibrium, microscopic systems. Analogous to free energy landscapes for multi-pathway protein folding transitions, our energy landscape approach from first principles is the beginning of a statistical physics theory of multi-pathway locomotor transitions in complex terrain. This will not only help understand how the organization of animal behavior emerges from multi-scale interactions between their neural and mechanical systems and the physical environment, but also guide robot design, control, and planning over the large, intractable locomotor-terrain parameter space to generate robust locomotor transitions through the real world.
<div id='section'>Paperid: <span id='pid'>866, <a href='https://arxiv.org/pdf/2006.11523.pdf' target='_blank'>https://arxiv.org/pdf/2006.11523.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leo Liberti, Gabriele Iommazzo, Carlile Lavor, Nelson Maculan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2006.11523">Cycle-based formulations in Distance Geometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The distance geometry problem asks to find a realization of a given simple edge-weighted graph in a Euclidean space of given dimension K, where the edges are realized as straight segments of lengths equal (or as close as possible) to the edge weights. The problem is often modelled as a mathematical programming formulation involving decision variables that determine the position of the vertices in the given Euclidean space. Solution algorithms are generally constructed using local or global nonlinear optimization techniques. We present a new modelling technique for this problem where, instead of deciding vertex positions, formulations decide the length of the segments representing the edges in each cycle in the graph, projected in every dimension. We propose an exact formulation and a relaxation based on a Eulerian cycle. We then compare computational results from protein conformation instances obtained with stochastic global optimization techniques on the new cycle-based formulation and on the existing edge-based formulation. While edge-based formulations take less time to reach termination, cycle-based formulations are generally better on solution quality measures.
<div id='section'>Paperid: <span id='pid'>867, <a href='https://arxiv.org/pdf/2509.07983.pdf' target='_blank'>https://arxiv.org/pdf/2509.07983.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Long-Kai Huang, Rongyi Zhu, Bing He, Jianhua Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07983">Steering Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein Language Models (PLMs), pre-trained on extensive evolutionary data from natural proteins, have emerged as indispensable tools for protein design. While powerful, PLMs often struggle to produce proteins with precisely specified functionalities or properties due to inherent challenges in controlling their outputs. In this work, we investigate the potential of Activation Steering, a technique originally developed for controlling text generation in Large Language Models (LLMs), to direct PLMs toward generating protein sequences with targeted properties. We propose a simple yet effective method that employs activation editing to steer PLM outputs, and extend this approach to protein optimization through a novel editing site identification module. Through comprehensive experiments on lysozyme-like sequence generation and optimization, we demonstrate that our methods can be seamlessly integrated into both auto-encoding and autoregressive PLMs without requiring additional training. These results highlight a promising direction for precise protein engineering using foundation models.
<div id='section'>Paperid: <span id='pid'>868, <a href='https://arxiv.org/pdf/2509.03425.pdf' target='_blank'>https://arxiv.org/pdf/2509.03425.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Phuc Pham, Viet Thanh Duy Nguyen, Truong-Son Hy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03425">LINKER: Learning Interactions Between Functional Groups and Residues With Chemical Knowledge-Enhanced Reasoning and Explainability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate identification of interactions between protein residues and ligand functional groups is essential to understand molecular recognition and guide rational drug design. Existing deep learning approaches for protein-ligand interpretability often rely on 3D structural input or use distance-based contact labels, limiting both their applicability and biological relevance. We introduce LINKER, the first sequence-based model to predict residue-functional group interactions in terms of biologically defined interaction types, using only protein sequences and the ligand SMILES as input. LINKER is trained with structure-supervised attention, where interaction labels are derived from 3D protein-ligand complexes via functional group-based motif extraction. By abstracting ligand structures into functional groups, the model focuses on chemically meaningful substructures while predicting interaction types rather than mere spatial proximity. Crucially, LINKER requires only sequence-level input at inference time, enabling large-scale application in settings where structural data is unavailable. Experiments on the LP-PDBBind benchmark demonstrate that structure-informed supervision over functional group abstractions yields interaction predictions closely aligned with ground-truth biochemical annotations.
<div id='section'>Paperid: <span id='pid'>869, <a href='https://arxiv.org/pdf/2507.20130.pdf' target='_blank'>https://arxiv.org/pdf/2507.20130.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi He, Ailun Wang, Zhi Wang, Yu Liu, Xingyuan Xu, Wen Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.20130">Generative molecule evolution using 3D pharmacophore for efficient Structure-Based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in generative models, particularly diffusion and auto-regressive models, have revolutionized fields like computer vision and natural language processing. However, their application to structure-based drug design (SBDD) remains limited due to critical data constraints. To address the limitation of training data for models targeting SBDD tasks, we propose an evolutionary framework named MEVO, which bridges the gap between billion-scale small molecule dataset and the scarce protein-ligand complex dataset, and effectively increase the abundance of training data for generative SBDD models. MEVO is composed of three key components: a high-fidelity VQ-VAE for molecule representation in latent space, a diffusion model for pharmacophore-guided molecule generation, and a pocket-aware evolutionary strategy for molecule optimization with physics-based scoring function. This framework efficiently generate high-affinity binders for various protein targets, validated with predicted binding affinities using free energy perturbation (FEP) methods. In addition, we showcase the capability of MEVO in designing potent inhibitors to KRAS$^{\textrm{G12D}}$, a challenging target in cancer therapeutics, with similar affinity to the known highly active inhibitor evaluated by FEP calculations. With high versatility and generalizability, MEVO offers an effective and data-efficient model for various tasks in structure-based ligand design.
<div id='section'>Paperid: <span id='pid'>870, <a href='https://arxiv.org/pdf/2507.18603.pdf' target='_blank'>https://arxiv.org/pdf/2507.18603.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zinan Ling, Yi Shi, Da Yan, Yang Zhou, Bo Hui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18603">Demystify Protein Generation with Hierarchical Conditional Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generating novel and functional protein sequences is critical to a wide range of applications in biology. Recent advancements in conditional diffusion models have shown impressive empirical performance in protein generation tasks. However, reliable generations of protein remain an open research question in de novo protein design, especially when it comes to conditional diffusion models. Considering the biological function of a protein is determined by multi-level structures, we propose a novel multi-level conditional diffusion model that integrates both sequence-based and structure-based information for efficient end-to-end protein design guided by specified functions. By generating representations at different levels simultaneously, our framework can effectively model the inherent hierarchical relations between different levels, resulting in an informative and discriminative representation of the generated protein. We also propose a Protein-MMD, a new reliable evaluation metric, to evaluate the quality of generated protein with conditional diffusion models. Our new metric is able to capture both distributional and functional similarities between real and generated protein sequences while ensuring conditional consistency. We experiment with the benchmark datasets, and the results on conditional protein generation tasks demonstrate the efficacy of the proposed generation framework and evaluation metric.
<div id='section'>Paperid: <span id='pid'>871, <a href='https://arxiv.org/pdf/2507.14245.pdf' target='_blank'>https://arxiv.org/pdf/2507.14245.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hengjie Yu, Kenneth A. Dawson, Haiyun Yang, Shuya Liu, Yan Yan, Yaochu Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14245">A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unlocking the potential of nanomaterials in medicine and environmental science hinges on understanding their interactions with proteins, a complex decision space where AI is poised to make a transformative impact. However, progress has been hindered by limited datasets and the restricted generalizability of existing models. Here, we propose NanoPro-3M, the largest nanomaterial-protein interaction dataset to date, comprising over 3.2 million samples and 37,000 unique proteins. Leveraging this, we present NanoProFormer, a foundational model that predicts nanomaterial-protein affinities through multimodal representation learning, demonstrating strong generalization, handling missing features, and unseen nanomaterials or proteins. We show that multimodal modeling significantly outperforms single-modality approaches and identifies key determinants of corona formation. Furthermore, we demonstrate its applicability to a range of downstream tasks through zero-shot inference and fine-tuning. Together, this work establishes a solid foundation for high-performance and generalized prediction of nanomaterial-protein interaction endpoints, reducing experimental reliance and accelerating various in vitro applications.
<div id='section'>Paperid: <span id='pid'>872, <a href='https://arxiv.org/pdf/2507.13580.pdf' target='_blank'>https://arxiv.org/pdf/2507.13580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Tuo, Yan Li, Xuanning Hu, Haishi Zhao, Xueyan Liu, Bo Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.13580">A Collaborative Framework Integrating Large Language Model and Chemical Fragment Space: Mutual Inspiration for Lead Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Combinatorial optimization algorithm is essential in computer-aided drug design by progressively exploring chemical space to design lead compounds with high affinity to target protein. However current methods face inherent challenges in integrating domain knowledge, limiting their performance in identifying lead compounds with novel and valid binding mode. Here, we propose AutoLeadDesign, a lead compounds design framework that inspires extensive domain knowledge encoded in large language models with chemical fragments to progressively implement efficient exploration of vast chemical space. The comprehensive experiments indicate that AutoLeadDesign outperforms baseline methods. Significantly, empirical lead design campaigns targeting two clinically relevant targets (PRMT5 and SARS-CoV-2 PLpro) demonstrate AutoLeadDesign's competence in de novo generation of lead compounds achieving expert-competitive design efficacy. Structural analysis further confirms their mechanism-validated inhibitory patterns. By tracing the process of design, we find that AutoLeadDesign shares analogous mechanisms with fragment-based drug design which traditionally rely on the expert decision-making, further revealing why it works. Overall, AutoLeadDesign offers an efficient approach for lead compounds design, suggesting its potential utility in drug design.
<div id='section'>Paperid: <span id='pid'>873, <a href='https://arxiv.org/pdf/2507.11818.pdf' target='_blank'>https://arxiv.org/pdf/2507.11818.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrei Rekesh, Miruna Cretu, Dmytro Shevchuk, Vignesh Ram Somnath, Pietro LiÃ², Robert A. Batey, Mike Tyers, MichaÅ Koziarski, Cheng-Hao Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11818">SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensuring synthesizability in generative small molecule design remains a major challenge. While recent developments in synthesizable molecule generation have demonstrated promising results, these efforts have been largely confined to 2D molecular graph representations, limiting the ability to perform geometry-based conditional generation. In this work, we present SynCoGen (Synthesizable Co-Generation), a single framework that combines simultaneous masked graph diffusion and flow matching for synthesizable 3D molecule generation. SynCoGen samples from the joint distribution of molecular building blocks, chemical reactions, and atomic coordinates. To train the model, we curated SynSpace, a dataset containing over 600K synthesis-aware building block graphs and 3.3M conformers. SynCoGen achieves state-of-the-art performance in unconditional small molecule graph and conformer generation, and the model delivers competitive performance in zero-shot molecular linker design for protein ligand generation in drug discovery. Overall, this multimodal formulation represents a foundation for future applications enabled by non-autoregressive molecular generation, including analog expansion, lead optimization, and direct structure conditioning.
<div id='section'>Paperid: <span id='pid'>874, <a href='https://arxiv.org/pdf/2506.20598.pdf' target='_blank'>https://arxiv.org/pdf/2506.20598.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander D. Kalian, Jaewook Lee, Stefan P. Johannesson, Lennart Otte, Christer Hogstrand, Miao Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.20598">Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The global demand for sustainable protein sources has accelerated the need for intelligent tools that can rapidly process and synthesise domain-specific scientific knowledge. In this study, we present a proof-of-concept multi-agent Artificial Intelligence (AI) framework designed to support sustainable protein production research, with an initial focus on microbial protein sources. Our Retrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based LLM agents: (1) a literature search agent that retrieves relevant scientific literature on microbial protein production for a specified microbial strain, and (2) an information extraction agent that processes the retrieved content to extract relevant biological and chemical information. Two parallel methodologies, fine-tuning and prompt engineering, were explored for agent optimisation. Both methods demonstrated effectiveness at improving the performance of the information extraction agent in terms of transformer-based cosine similarity scores between obtained and ideal outputs. Mean cosine similarity scores were increased by up to 25%, while universally reaching mean scores of $\geq 0.89$ against ideal output text. Fine-tuning overall improved the mean scores to a greater extent (consistently of $\geq 0.94$) compared to prompt engineering, although lower statistical uncertainties were observed with the latter approach. A user interface was developed and published for enabling the use of the multi-agent AI system, alongside preliminary exploration of additional chemical safety-based search capabilities
<div id='section'>Paperid: <span id='pid'>875, <a href='https://arxiv.org/pdf/2506.17963.pdf' target='_blank'>https://arxiv.org/pdf/2506.17963.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Nie, Hongyu Zhang, Hao Jiang, Yutian Liu, Xiansong Huang, Fan Xu, Jie Fu, Zhixiang Ren, Yonghong Tian, Wen-Bin Zhang, Jie Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17963">OmniESI: A unified framework for enzyme-substrate interaction prediction with progressive conditional deep learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding and modeling enzyme-substrate interactions is crucial for catalytic mechanism research, enzyme engineering, and metabolic engineering. Although a large number of predictive methods have emerged, they do not incorporate prior knowledge of enzyme catalysis to rationally modulate general protein-molecule features that are misaligned with catalytic patterns. To address this issue, we introduce a two-stage progressive framework, OmniESI, for enzyme-substrate interaction prediction through conditional deep learning. By decomposing the modeling of enzyme-substrate interactions into a two-stage progressive process, OmniESI incorporates two conditional networks that respectively emphasize enzymatic reaction specificity and crucial catalysis-related interactions, facilitating a gradual feature modulation in the latent space from general protein-molecule domain to catalysis-aware domain. On top of this unified architecture, OmniESI can adapt to a variety of downstream tasks, including enzyme kinetic parameter prediction, enzyme-substrate pairing prediction, enzyme mutational effect prediction, and enzymatic active site annotation. Under the multi-perspective performance evaluation of in-distribution and out-of-distribution settings, OmniESI consistently delivered superior performance than state-of-the-art specialized methods across seven benchmarks. More importantly, the proposed conditional networks were shown to internalize the fundamental patterns of catalytic efficiency while significantly improving prediction performance, with only negligible parameter increases (0.16%), as demonstrated by ablation studies on key components. Overall, OmniESI represents a unified predictive approach for enzyme-substrate interactions, providing an effective tool for catalytic mechanism cracking and enzyme engineering with strong generalization and broad applicability.
<div id='section'>Paperid: <span id='pid'>876, <a href='https://arxiv.org/pdf/2506.15782.pdf' target='_blank'>https://arxiv.org/pdf/2506.15782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicolas BoullÃ©, Matthew J. Colbrook, Gustav Conradie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15782">Convergent Methods for Koopman Operators on Reproducing Kernel Hilbert Spaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven spectral analysis of Koopman operators is a powerful tool for understanding numerous real-world dynamical systems, from neuronal activity to variations in sea surface temperature. The Koopman operator acts on a function space and is most commonly studied on the space of square-integrable functions. However, defining it on a suitable reproducing kernel Hilbert space (RKHS) offers numerous practical advantages, including pointwise predictions with error bounds, improved spectral properties that facilitate computations, and more efficient algorithms, particularly in high dimensions. We introduce the first general, provably convergent, data-driven algorithms for computing spectral properties of Koopman and Perron--Frobenius operators on RKHSs. These methods efficiently compute spectra and pseudospectra with error control and spectral measures while exploiting the RKHS structure to avoid the large-data limits required in the $L^2$ settings. The function space is determined by a user-specified kernel, eliminating the need for quadrature-based sampling as in $L^2$ and enabling greater flexibility with finite, externally provided datasets. Using the Solvability Complexity Index hierarchy, we construct adversarial dynamical systems for these problems to show that no algorithm can succeed in fewer limits, thereby proving the optimality of our algorithms. Notably, this impossibility extends to randomized algorithms and datasets. We demonstrate the effectiveness of our algorithms on challenging, high-dimensional datasets arising from real-world measurements and high-fidelity numerical simulations, including turbulent channel flow, molecular dynamics of a binding protein, Antarctic sea ice concentration, and Northern Hemisphere sea surface height. The algorithms are publicly available in the software package $\texttt{SpecRKHS}$.
<div id='section'>Paperid: <span id='pid'>877, <a href='https://arxiv.org/pdf/2506.09496.pdf' target='_blank'>https://arxiv.org/pdf/2506.09496.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dingyi Rong, Haotian Lu, Wenzhuo Zheng, Fan Zhang, Shuangjia Zheng, Ning Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09496">EnerBridge-DPO: Energy-Guided Protein Inverse Folding with Markov Bridges and Direct Preference Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing protein sequences with optimal energetic stability is a key challenge in protein inverse folding, as current deep learning methods are primarily trained by maximizing sequence recovery rates, often neglecting the energy of the generated sequences. This work aims to overcome this limitation by developing a model that directly generates low-energy, stable protein sequences. We propose EnerBridge-DPO, a novel inverse folding framework focused on generating low-energy, high-stability protein sequences. Our core innovation lies in: First, integrating Markov Bridges with Direct Preference Optimization (DPO), where energy-based preferences are used to fine-tune the Markov Bridge model. The Markov Bridge initiates optimization from an information-rich prior sequence, providing DPO with a pool of structurally plausible sequence candidates. Second, an explicit energy constraint loss is introduced, which enhances the energy-driven nature of DPO based on prior sequences, enabling the model to effectively learn energy representations from a wealth of prior knowledge and directly predict sequence energy values, thereby capturing quantitative features of the energy landscape. Our evaluations demonstrate that EnerBridge-DPO can design protein complex sequences with lower energy while maintaining sequence recovery rates comparable to state-of-the-art models, and accurately predicts $ÎÎG$ values between various sequences.
<div id='section'>Paperid: <span id='pid'>878, <a href='https://arxiv.org/pdf/2506.08954.pdf' target='_blank'>https://arxiv.org/pdf/2506.08954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruben Weitzman, Peter MÃ¸rch Groth, Lood Van Niekerk, Aoi Otani, Yarin Gal, Debora Marks, Pascal Notin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08954">Protriever: End-to-End Differentiable Protein Homology Search for Fitness Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Retrieving homologous protein sequences is essential for a broad range of protein modeling tasks such as fitness prediction, protein design, structure modeling, and protein-protein interactions. Traditional workflows have relied on a two-step process: first retrieving homologs via Multiple Sequence Alignments (MSA), then training models on one or more of these alignments. However, MSA-based retrieval is computationally expensive, struggles with highly divergent sequences or complex insertions & deletions patterns, and operates independently of the downstream modeling objective. We introduce Protriever, an end-to-end differentiable framework that learns to retrieve relevant homologs while simultaneously training for the target task. When applied to protein fitness prediction, Protriever achieves state-of-the-art performance compared to sequence-based models that rely on MSA-based homolog retrieval, while being two orders of magnitude faster through efficient vector search. Protriever is both architecture- and task-agnostic, and can flexibly adapt to different retrieval strategies and protein databases at inference time -- offering a scalable alternative to alignment-centric approaches.
<div id='section'>Paperid: <span id='pid'>879, <a href='https://arxiv.org/pdf/2506.06450.pdf' target='_blank'>https://arxiv.org/pdf/2506.06450.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Antonio JesÃºs Banegas-Luna, Baldomero ImbernÃ³n Tudela, Carlos MartÃ­nez-CortÃ©s, JosÃ© MarÃ­a Cecilia, Horacio PÃ©rez-SÃ¡nchez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06450">Performance Impact of Containerized METADOCK 2 on Heterogeneous Platforms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Virtual screening (VS) is a computationally intensive process crucial for drug discovery, often requiring significant resources to analyze large chemical libraries and predict ligand-protein interactions. This study evaluates the performance impact of containerization on METADOCK 2, a high-throughput docking software when deployed on heterogeneous high-performance computing (HPC) platforms. By testing three containerization technologies - Docker, Singularity, and Apptainer - across varying CPU and GPU configurations, the experiments reveal that containerization introduces negligible performance overhead, with deviations below 1%. Moreover, METADOCK 2 demonstrated the capability to efficiently process large molecular complexes, surpassing the limitations of commercial tools such as AutoDock Vina. The results underscore the advantages of container-based deployment for ensuring portability, reproducibility, and scalability in scientific computing. This study concludes that containerized METADOCK 2 is a robust and efficient solution for VS tasks on heterogeneous HPC platforms.
<div id='section'>Paperid: <span id='pid'>880, <a href='https://arxiv.org/pdf/2505.23823.pdf' target='_blank'>https://arxiv.org/pdf/2505.23823.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youngseung Jeon, Ziwen Li, Thomas Li, JiaSyuan Chang, Morteza Ziyadi, Xiang 'Anthony' Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23823">RAGPPI: RAG Benchmark for Protein-Protein Interactions in Drug Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Retrieving the biological impacts of protein-protein interactions (PPIs) is essential for target identification (Target ID) in drug development. Given the vast number of proteins involved, this process remains time-consuming and challenging. Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) frameworks have supported Target ID; however, no benchmark currently exists for identifying the biological impacts of PPIs. To bridge this gap, we introduce the RAG Benchmark for PPIs (RAGPPI), a factual question-answer benchmark of 4,420 question-answer pairs that focus on the potential biological impacts of PPIs. Through interviews with experts, we identified criteria for a benchmark dataset, such as a type of QA and source. We built a gold-standard dataset (500 QA pairs) through expert-driven data annotation. We developed an ensemble auto-evaluation LLM that reflected expert labeling characteristics, which facilitates the construction of a silver-standard dataset (3,720 QA pairs). We are committed to maintaining RAGPPI as a resource to support the research community in advancing RAG systems for drug discovery QA solutions.
<div id='section'>Paperid: <span id='pid'>881, <a href='https://arxiv.org/pdf/2505.20052.pdf' target='_blank'>https://arxiv.org/pdf/2505.20052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hazem Alsamkary, Mohamed Elshaffei, Mohamed Elkerdawy, Ahmed Elnaggar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20052">Ankh3: Multi-Task Pretraining with Sequence Denoising and Completion Enhances Protein Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models (PLMs) have emerged as powerful tools to detect complex patterns of protein sequences. However, the capability of PLMs to fully capture information on protein sequences might be limited by focusing on single pre-training tasks. Although adding data modalities or supervised objectives can improve the performance of PLMs, pre-training often remains focused on denoising corrupted sequences. To push the boundaries of PLMs, our research investigated a multi-task pre-training strategy. We developed Ankh3, a model jointly optimized on two objectives: masked language modeling with multiple masking probabilities and protein sequence completion relying only on protein sequences as input. This multi-task pre-training demonstrated that PLMs can learn richer and more generalizable representations solely from protein sequences. The results demonstrated improved performance in downstream tasks, such as secondary structure prediction, fluorescence, GB1 fitness, and contact prediction. The integration of multiple tasks gave the model a more comprehensive understanding of protein properties, leading to more robust and accurate predictions.
<div id='section'>Paperid: <span id='pid'>882, <a href='https://arxiv.org/pdf/2505.20036.pdf' target='_blank'>https://arxiv.org/pdf/2505.20036.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hazem Alsamkary, Mohamed Elshaffei, Mohamed Soudy, Sara Ossman, Abdallah Amr, Nehal Adel Abdelsalam, Mohamed Elkerdawy, Ahmed Elnaggar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20036">Beyond Simple Concatenation: Fairly Assessing PLM Architectures for Multi-Chain Protein-Protein Interactions Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interactions (PPIs) are fundamental to numerous cellular processes, and their characterization is vital for understanding disease mechanisms and guiding drug discovery. While protein language models (PLMs) have demonstrated remarkable success in predicting protein structure and function, their application to sequence-based PPI binding affinity prediction remains relatively underexplored. This gap is often attributed to the scarcity of high-quality, rigorously refined datasets and the reliance on simple strategies for concatenating protein representations. In this work, we address these limitations. First, we introduce a meticulously curated version of the PPB-Affinity dataset of a total of 8,207 unique protein-protein interaction entries, by resolving annotation inconsistencies and duplicate entries for multi-chain protein interactions. This dataset incorporates a stringent, less than or equal to 30%, sequence identity threshold to ensure robust splitting into training, validation, and test sets, minimizing data leakage. Second, we propose and systematically evaluate four architectures for adapting PLMs to PPI binding affinity prediction: embeddings concatenation (EC), sequences concatenation (SC), hierarchical pooling (HP), and pooled attention addition (PAD). These architectures were assessed using two training methods: full fine-tuning and a lightweight approach employing ConvBERT heads over frozen PLM features. Our comprehensive experiments across multiple leading PLMs (ProtT5, ESM2, Ankh, Ankh2, and ESM3) demonstrated that the HP and PAD architectures consistently outperform conventional concatenation methods, achieving up to 12% increase in terms of Spearman correlation. These results highlight the necessity of sophisticated architectural designs to fully exploit the capabilities of PLMs for nuanced PPI binding affinity prediction.
<div id='section'>Paperid: <span id='pid'>883, <a href='https://arxiv.org/pdf/2505.18890.pdf' target='_blank'>https://arxiv.org/pdf/2505.18890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Morteza Rakhshaninejad, Mira Jurgens, Nicolas Dewolf, Willem Waegeman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18890">Conformal Prediction for Uncertainty Estimation in Drug-Target Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate drug-target interaction (DTI) prediction with machine learning models is essential for drug discovery. Such models should also provide a credible representation of their uncertainty, but applying classical marginal conformal prediction (CP) in DTI prediction often overlooks variability across drug and protein subgroups. In this work, we analyze three cluster-conditioned CP methods for DTI prediction, and compare them with marginal and group-conditioned CP. Clusterings are obtained via nonconformity scores, feature similarity, and nearest neighbors, respectively. Experiments on the KIBA dataset using four data-splitting strategies show that nonconformity-based clustering yields the tightest intervals and most reliable subgroup coverage, especially in random and fully unseen drug-protein splits. Group-conditioned CP works well when one entity is familiar, but residual-driven clustering provides robust uncertainty estimates even in sparse or novel scenarios. These results highlight the potential of cluster-based CP for improving DTI prediction under uncertainty.
<div id='section'>Paperid: <span id='pid'>884, <a href='https://arxiv.org/pdf/2505.18150.pdf' target='_blank'>https://arxiv.org/pdf/2505.18150.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nic Fishman, Gokul Gowri, Peng Yin, Jonathan Gootenberg, Omar Abudayyeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18150">Generative Distribution Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many real-world problems require reasoning across multiple scales, demanding models which operate not on single data points, but on entire distributions. We introduce generative distribution embeddings (GDE), a framework that lifts autoencoders to the space of distributions. In GDEs, an encoder acts on sets of samples, and the decoder is replaced by a generator which aims to match the input distribution. This framework enables learning representations of distributions by coupling conditional generative models with encoder networks which satisfy a criterion we call distributional invariance. We show that GDEs learn predictive sufficient statistics embedded in the Wasserstein space, such that latent GDE distances approximately recover the $W_2$ distance, and latent interpolation approximately recovers optimal transport trajectories for Gaussian and Gaussian mixture distributions. We systematically benchmark GDEs against existing approaches on synthetic datasets, demonstrating consistently stronger performance. We then apply GDEs to six key problems in computational biology: learning representations of cell populations from lineage-tracing data (150K cells), predicting perturbation effects on single-cell transcriptomes (1M cells), predicting perturbation effects on cellular phenotypes (20M single-cell images), modeling tissue-specific DNA methylation patterns (253M sequences), designing synthetic yeast promoters (34M sequences), and spatiotemporal modeling of viral protein sequences (1M sequences).
<div id='section'>Paperid: <span id='pid'>885, <a href='https://arxiv.org/pdf/2505.13375.pdf' target='_blank'>https://arxiv.org/pdf/2505.13375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christopher Kolloff, Tobias HÃ¶ppe, Emmanouil Angelis, Mathias Jacob Schreiner, Stefan Bauer, Andrea Dittadi, Simon Olsson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13375">Minimum-Excess-Work Guidance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a regularization framework inspired by thermodynamic work for guiding pre-trained probability flow generative models (e.g., continuous normalizing flows or diffusion models) by minimizing excess work, a concept rooted in statistical mechanics and with strong conceptual connections to optimal transport. Our approach enables efficient guidance in sparse-data regimes common to scientific applications, where only limited target samples or partial density constraints are available. We introduce two strategies: Path Guidance for sampling rare transition states by concentrating probability mass on user-defined subsets, and Observable Guidance for aligning generated distributions with experimental observables while preserving entropy. We demonstrate the framework's versatility on a coarse-grained protein model, guiding it to sample transition configurations between folded/unfolded states and correct systematic biases using experimental data. The method bridges thermodynamic principles with modern generative architectures, offering a principled, efficient, and physics-inspired alternative to standard fine-tuning in data-scarce domains. Empirical results highlight improved sample efficiency and bias reduction, underscoring its applicability to molecular simulations and beyond.
<div id='section'>Paperid: <span id='pid'>886, <a href='https://arxiv.org/pdf/2505.11023.pdf' target='_blank'>https://arxiv.org/pdf/2505.11023.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kutalmış Coşkun, Ivo Kavisanczki, Amin Mirzaei, Tom Siegl, Bjarne C. Hiller, Stefan Lüdtke, Martin Becker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11023">Informed, but Not Always Improved: Challenging the Benefit of Background Knowledge in GNNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In complex and low-data domains such as biomedical research, incorporating background knowledge (BK) graphs, such as protein-protein interaction (PPI) networks, into graph-based machine learning pipelines is a promising research direction. However, while BK is often assumed to improve model performance, its actual contribution and the impact of imperfect knowledge remain poorly understood. In this work, we investigate the role of BK in an important real-world task: cancer subtype classification. Surprisingly, we find that (i) state-of-the-art GNNs using BK perform no better than uninformed models like linear regression, and (ii) their performance remains largely unchanged even when the BK graph is heavily perturbed. To understand these unexpected results, we introduce an evaluation framework, which employs (i) a synthetic setting where the BK is clearly informative and (ii) a set of perturbations that simulate various imperfections in BK graphs. With this, we test the robustness of BK-aware models in both synthetic and real-world biomedical settings. Our findings reveal that careful alignment of GNN architectures and BK characteristics is necessary but holds the potential for significant performance improvements.
<div id='section'>Paperid: <span id='pid'>887, <a href='https://arxiv.org/pdf/2505.05893.pdf' target='_blank'>https://arxiv.org/pdf/2505.05893.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seunghee Han, Soongyu Choi, Joo-Young Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.05893">LightNobel: Improving Sequence Length Limitation in Protein Structure Prediction Model via Adaptive Activation Quantization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in Protein Structure Prediction Models (PPMs), such as AlphaFold2 and ESMFold, have revolutionized computational biology by achieving unprecedented accuracy in predicting three-dimensional protein folding structures. However, these models face significant scalability challenges, particularly when processing proteins with long amino acid sequences (e.g., sequence length > 1,000). The primary bottleneck that arises from the exponential growth in activation sizes is driven by the unique data structure in PPM, which introduces an additional dimension that leads to substantial memory and computational demands. These limitations have hindered the effective scaling of PPM for real-world applications, such as analyzing large proteins or complex multimers with critical biological and pharmaceutical relevance.
  In this paper, we present LightNobel, the first hardware-software co-designed accelerator developed to overcome scalability limitations on the sequence length in PPM. At the software level, we propose Token-wise Adaptive Activation Quantization (AAQ), which leverages unique token-wise characteristics, such as distogram patterns in PPM activations, to enable fine-grained quantization techniques without compromising accuracy. At the hardware level, LightNobel integrates the multi-precision reconfigurable matrix processing unit (RMPU) and versatile vector processing unit (VVPU) to enable the efficient execution of AAQ. Through these innovations, LightNobel achieves up to 8.44x, 8.41x speedup and 37.29x, 43.35x higher power efficiency over the latest NVIDIA A100 and H100 GPUs, respectively, while maintaining negligible accuracy loss. It also reduces the peak memory requirement up to 120.05x in PPM, enabling scalable processing for proteins with long sequences.
<div id='section'>Paperid: <span id='pid'>888, <a href='https://arxiv.org/pdf/2505.05874.pdf' target='_blank'>https://arxiv.org/pdf/2505.05874.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anjie Qiao, Hao Zhang, Qianmu Yuan, Qirui Deng, Jingtian Su, Weifeng Huang, Huihao Zhou, Guo-Bo Li, Zhen Wang, Jinping Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.05874">A 3D pocket-aware and evolutionary conserved interaction guided diffusion model for molecular optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generating molecules that bind to specific protein targets via diffusion models has shown good promise for structure-based drug design and molecule optimization. Especially, the diffusion models with binding interaction guidance enables molecule generation with high affinity through forming favorable interaction within protein pocket. However, the generated molecules may not form interactions with the highly conserved residues, which are important for protein functions and bioactivities of the ligands. Herein, we developed a new 3D target-aware diffusion model DiffDecip, which explicitly incorporates the protein-ligand binding interactions and evolutionary conservation information of protein residues into both diffusion and sampling process, for molecule optimization through scaffold decoration. The model performance revealed that DiffDecip outperforms baseline model DiffDec on molecule optimization towards higher affinity through forming more non-covalent interactions with highly conserved residues in the protein pocket.
<div id='section'>Paperid: <span id='pid'>889, <a href='https://arxiv.org/pdf/2505.01433.pdf' target='_blank'>https://arxiv.org/pdf/2505.01433.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cong Qi, Hanzhang Fang, Siqi jiang, Tianxing Hu, Wei Zhi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.01433">Enhancing TCR-Peptide Interaction Prediction with Pretrained Language Models and Molecular Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the binding specificity between T-cell receptors (TCRs) and peptide-major histocompatibility complexes (pMHCs) is central to immunotherapy and vaccine development. However, current predictive models struggle with generalization, especially in data-scarce settings and when faced with novel epitopes. We present LANTERN (Large lAnguage model-powered TCR-Enhanced Recognition Network), a deep learning framework that combines large-scale protein language models with chemical representations of peptides. By encoding TCR \b{eta}-chain sequences using ESM-1b and transforming peptide sequences into SMILES strings processed by MolFormer, LANTERN captures rich biological and chemical features critical for TCR-peptide recognition. Through extensive benchmarking against existing models such as ChemBERTa, TITAN, and NetTCR, LANTERN demonstrates superior performance, particularly in zero-shot and few-shot learning scenarios. Our model also benefits from a robust negative sampling strategy and shows significant clustering improvements via embedding analysis. These results highlight the potential of LANTERN to advance TCR-pMHC binding prediction and support the development of personalized immunotherapies.
<div id='section'>Paperid: <span id='pid'>890, <a href='https://arxiv.org/pdf/2504.21065.pdf' target='_blank'>https://arxiv.org/pdf/2504.21065.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anjie Qiao, Junjie Xie, Weifeng Huang, Hao Zhang, Jiahua Rao, Shuangjia Zheng, Yuedong Yang, Zhen Wang, Guo-Bo Li, Jinping Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.21065">A 3D pocket-aware and affinity-guided diffusion model for lead optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular optimization, aimed at improving binding affinity or other molecular properties, is a crucial task in drug discovery that often relies on the expertise of medicinal chemists. Recently, deep learning-based 3D generative models showed promise in enhancing the efficiency of molecular optimization. However, these models often struggle to adequately consider binding affinities with protein targets during lead optimization. Herein, we propose a 3D pocket-aware and affinity-guided diffusion model, named Diffleop, to optimize molecules with enhanced binding affinity. The model explicitly incorporates the knowledge of protein-ligand binding affinity to guide the denoising sampling for molecule generation with high affinity. The comprehensive evaluations indicated that Diffleop outperforms baseline models across multiple metrics, especially in terms of binding affinity.
<div id='section'>Paperid: <span id='pid'>891, <a href='https://arxiv.org/pdf/2504.16941.pdf' target='_blank'>https://arxiv.org/pdf/2504.16941.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zakaria Lamine, Abdelatif Hafid, Mohamed Rahouti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16941">Mathematical Modeling of Protein Structures: A Cohomology-Based Approach to the Flagellar Motor</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a novel mathematical model derived from cohomology, leveraging the KEEL-proven theorem that establishes cohomology as tautological, generated by boundary classes of curves with fixed dual graphs. Simplicial complexes are constructed using skew-commutative graded algebra, and the structure theorem is applied to connect distinct homologies, enabling precise interpretations of the resulting geometric forms. The proposed model is utilized for protein structure analysis and prediction, with a specific application to the Flagellar Motor structure. This approach offers new insights into the geometric and algebraic foundations of biological macromolecular modeling, highlighting its potential for advancement in structural biology.
<div id='section'>Paperid: <span id='pid'>892, <a href='https://arxiv.org/pdf/2504.11091.pdf' target='_blank'>https://arxiv.org/pdf/2504.11091.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maximilian G. Schuh, Joshua Hesse, Stephan A. Sieber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11091">AI-guided Antibiotic Discovery Pipeline from Target Selection to Compound Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibiotic resistance presents a growing global health crisis, demanding new therapeutic strategies that target novel bacterial mechanisms. Recent advances in protein structure prediction and machine learning-driven molecule generation offer a promising opportunity to accelerate drug discovery. However, practical guidance on selecting and integrating these models into real-world pipelines remains limited. In this study, we develop an end-to-end, artificial intelligence-guided antibiotic discovery pipeline that spans target identification to compound realization. We leverage structure-based clustering across predicted proteomes of multiple pathogens to identify conserved, essential, and non-human-homologous targets. We then systematically evaluate six leading 3D-structure-aware generative models$\unicode{x2014}$spanning diffusion, autoregressive, graph neural network, and language model architectures$\unicode{x2014}$on their usability, chemical validity, and biological relevance. Rigorous post-processing filters and commercial analogue searches reduce over 100 000 generated compounds to a focused, synthesizable set. Our results highlight DeepBlock and TamGen as top performers across diverse criteria, while also revealing critical trade-offs between model complexity, usability, and output quality. This work provides a comparative benchmark and blueprint for deploying artificial intelligence in early-stage antibiotic development.
<div id='section'>Paperid: <span id='pid'>893, <a href='https://arxiv.org/pdf/2504.10564.pdf' target='_blank'>https://arxiv.org/pdf/2504.10564.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julian Cremer, Ross Irwin, Alessandro Tibo, Jon Paul Janet, Simon Olsson, Djork-ArnÃ© Clevert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.10564">FLOWR: Flow Matching for Structure-Aware De Novo, Interaction- and Fragment-Based Ligand Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce FLOWR, a novel structure-based framework for the generation and optimization of three-dimensional ligands. FLOWR integrates continuous and categorical flow matching with equivariant optimal transport, enhanced by an efficient protein pocket conditioning. Alongside FLOWR, we present SPINDR, a thoroughly curated dataset comprising ligand-pocket co-crystal complexes specifically designed to address existing data quality issues. Empirical evaluations demonstrate that FLOWR surpasses current state-of-the-art diffusion- and flow-based methods in terms of PoseBusters-validity, pose accuracy, and interaction recovery, while offering a significant inference speedup, achieving up to 70-fold faster performance. In addition, we introduce FLOWR:multi, a highly accurate multi-purpose model allowing for the targeted sampling of novel ligands that adhere to predefined interaction profiles and chemical substructures for fragment-based design without the need of re-training or any re-sampling strategies
<div id='section'>Paperid: <span id='pid'>894, <a href='https://arxiv.org/pdf/2504.09365.pdf' target='_blank'>https://arxiv.org/pdf/2504.09365.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aspen Erlandsson Brisebois, Jason Broderick, Zahed Khatooni, Heather L. Wilson, Steven Rayan, Gordon Broderick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.09365">Identifying Protein Co-regulatory Network Logic by Solving B-SAT Problems through Gate-based Quantum Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There is growing awareness that the success of pharmacologic interventions on living organisms is significantly impacted by context and timing of exposure. In turn, this complexity has led to an increased focus on regulatory network dynamics in biology and our ability to represent them in a high-fidelity way, in silico. Logic network models show great promise here and their parameter estimation can be formulated as a constraint satisfaction problem (CSP) that is well-suited to the often sparse, incomplete data in biology. Unfortunately, even in the case of Boolean logic, the combinatorial complexity of these problems grows rapidly, challenging the creation of models at physiologically-relevant scales. That said, quantum computing, while still nascent, facilitates novel information-processing paradigms with the potential for transformative impact in problems such as this one. In this work, we take a first step at actualizing this potential by identifying the structure and Boolean decisional logic of a well-studied network linking 5 proteins involved in the neural development of the mammalian cortical area of the brain. We identify the protein-protein connectivity and binary decisional logic governing this network by formulating it as a Boolean Satisfiability (B-SAT) problem. We employ Grover's algorithm to solve the NP-hard problem faster than the exponential time complexity required by deterministic classical algorithms. Using approaches deployed on both quantum simulators and actual noisy intermediate scale quantum (NISQ) hardware, we accurately recover several high-likelihood models from very sparse protein expression data. The results highlight the differential roles of data types in supporting accurate models; the impact of quantum algorithm design as it pertains to the mutability of quantum hardware; and the opportunities for accelerated discovery enabled by this approach.
<div id='section'>Paperid: <span id='pid'>895, <a href='https://arxiv.org/pdf/2504.05271.pdf' target='_blank'>https://arxiv.org/pdf/2504.05271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yusef Ahsini, Marc Escoto, J. Alberto Conejero
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.05271">AnomalousNet: A Hybrid Approach with Attention U-Nets and Change Point Detection for Accurate Characterization of Anomalous Diffusion in Video Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomalous diffusion occurs in a wide range of systems, including protein transport within cells, animal movement in complex habitats, pollutant dispersion in groundwater, and nanoparticle motion in synthetic materials. Accurately estimating the anomalous diffusion exponent and the diffusion coefficient from the particle trajectories is essential to distinguish between sub-diffusive, super-diffusive, or normal diffusion regimes. These estimates provide a deeper insight into the underlying dynamics of the system, facilitating the identification of particle behaviors and the detection of changes in diffusion states. However, analyzing short and noisy video data, which often yield incomplete and heterogeneous trajectories, poses a significant challenge for traditional statistical approaches. We introduce a data-driven method that integrates particle tracking, an attention
  U-Net architecture, and a change-point detection algorithm to address these issues. This approach not only infers the anomalous diffusion parameters with high accuracy but also identifies temporal transitions between different states, even in the presence of noise and limited temporal resolution. Our methodology demonstrated strong performance in the 2nd Anomalous Diffusion (AnDi) Challenge benchmark within the top submissions for video tasks.
<div id='section'>Paperid: <span id='pid'>896, <a href='https://arxiv.org/pdf/2504.01973.pdf' target='_blank'>https://arxiv.org/pdf/2504.01973.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christoph Brunken, Sebastien Boyer, Mustafa Omar, Martin Maarand, Olivier Peltre, Solal Attias, Bakary N'tji Diallo, Anastasia Markina, Olaf Othersen, Oliver Bent
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01973">Universally applicable and tunable graph-based coarse-graining for Machine learning force fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Coarse-grained (CG) force field methods for molecular systems are a crucial tool to simulate large biological macromolecules and are therefore essential for characterisations of biomolecular systems. While state-of-the-art deep learning (DL)-based models for all-atom force fields have improved immensely over recent years, we observe and analyse significant limitations of the currently available approaches for DL-based CG simulations. In this work, we present the first transferable DL-based CG force field approach (i.e., not specific to only one narrowly defined system type) applicable to a wide range of biosystems. To achieve this, our CG algorithm does not rely on hard-coded rules and is tuned to output coarse-grained systems optimised for minimal statistical noise in the ground truth CG forces, which results in significant improvement of model training. Our force field model is also the first CG variant that is based on the MACE architecture and is trained on a custom dataset created by a new approach based on the fragmentation of large biosystems covering protein, RNA and lipid chemistry. We demonstrate that our model can be applied in molecular dynamics simulations to obtain stable and qualitatively accurate trajectories for a variety of systems, while also discussing cases for which we observe limited reliability.
<div id='section'>Paperid: <span id='pid'>897, <a href='https://arxiv.org/pdf/2503.16659.pdf' target='_blank'>https://arxiv.org/pdf/2503.16659.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Viet Thanh Duy Nguyen, Truong-Son Hy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16659">Advances in Protein Representation Learning: Methods, Applications, and Future Directions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are complex biomolecules that play a central role in various biological processes, making them critical targets for breakthroughs in molecular biology, medical research, and drug discovery. Deciphering their intricate, hierarchical structures, and diverse functions is essential for advancing our understanding of life at the molecular level. Protein Representation Learning (PRL) has emerged as a transformative approach, enabling the extraction of meaningful computational representations from protein data to address these challenges. In this paper, we provide a comprehensive review of PRL research, categorizing methodologies into five key areas: feature-based, sequence-based, structure-based, multimodal, and complex-based approaches. To support researchers in this rapidly evolving field, we introduce widely used databases for protein sequences, structures, and functions, which serve as essential resources for model development and evaluation. We also explore the diverse applications of these approaches in multiple domains, demonstrating their broad impact. Finally, we discuss pressing technical challenges and outline future directions to advance PRL, offering insights to inspire continued innovation in this foundational field.
<div id='section'>Paperid: <span id='pid'>898, <a href='https://arxiv.org/pdf/2503.08160.pdf' target='_blank'>https://arxiv.org/pdf/2503.08160.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taojie Kuang, Qianli Ma, Athanasios V. Vasilakos, Yu Wang, Qiang, Cheng, Zhixiang Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08160">Concept-Driven Deep Learning for Enhanced Protein-Specific Molecular Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, deep learning techniques have made significant strides in molecular generation for specific targets, driving advancements in drug discovery. However, existing molecular generation methods present significant limitations: those operating at the atomic level often lack synthetic feasibility, drug-likeness, and interpretability, while fragment-based approaches frequently overlook comprehensive factors that influence protein-molecule interactions. To address these challenges, we propose a novel fragment-based molecular generation framework tailored for specific proteins. Our method begins by constructing a protein subpocket and molecular arm concept-based neural network, which systematically integrates interaction force information and geometric complementarity to sample molecular arms for specific protein subpockets. Subsequently, we introduce a diffusion model to generate molecular backbones that connect these arms, ensuring structural integrity and chemical diversity. Our approach significantly improves synthetic feasibility and binding affinity, with a 4% increase in drug-likeness and a 6% improvement in synthetic feasibility. Furthermore, by integrating explicit interaction data through a concept-based model, our framework enhances interpretability, offering valuable insights into the molecular design process.
<div id='section'>Paperid: <span id='pid'>899, <a href='https://arxiv.org/pdf/2502.20050.pdf' target='_blank'>https://arxiv.org/pdf/2502.20050.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Fang, Yihan He, Xiao Gong, Gengchiau Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.20050">A Novel P-bit-based Probabilistic Computing Approach for Solving the 3-D Protein Folding Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the post-Moore era, the need for efficient solutions to non-deterministic polynomial-time (NP) problems is becoming more pressing. In this context, the Ising model implemented by the probabilistic computing systems with probabilistic bits (p-bits) has attracted attention due to the widespread availability of p-bits and support for large-scale simulations. This study marks the first work to apply probabilistic computing to tackle protein folding, a significant NP-complete problem challenge in biology. We represent proteins as sequences of hydrophobic (H) and polar (P) beads within a three-dimensional (3-D) grid and introduce a novel many-body interaction-based encoding method to map the problem onto an Ising model. Our simulations show that this approach significantly simplifies the energy landscape for short peptide sequences of six amino acids, halving the number of energy levels. Furthermore, the proposed mapping method achieves approximately 100 times acceleration for sequences consisting of ten amino acids in identifying the correct folding configuration. We predicted the optimal folding configuration for a peptide sequence of 36 amino acids by identifying the ground state. These findings highlight the unique potential of the proposed encoding method for solving protein folding and, importantly, provide new tools for solving similar NP-complete problems in biology by probabilistic computing approach.
<div id='section'>Paperid: <span id='pid'>900, <a href='https://arxiv.org/pdf/2502.17189.pdf' target='_blank'>https://arxiv.org/pdf/2502.17189.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Havrilla, David Alvarez-Melis, Nicolo Fusi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.17189">IGDA: Interactive Graph Discovery through Large Language Model Agents</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models ($\textbf{LLMs}$) have emerged as a powerful method for discovery. Instead of utilizing numerical data, LLMs utilize associated variable $\textit{semantic metadata}$ to predict variable relationships. Simultaneously, LLMs demonstrate impressive abilities to act as black-box optimizers when given an objective $f$ and sequence of trials. We study LLMs at the intersection of these two capabilities by applying LLMs to the task of $\textit{interactive graph discovery}$: given a ground truth graph $G^*$ capturing variable relationships and a budget of $I$ edge experiments over $R$ rounds, minimize the distance between the predicted graph $\hat{G}_R$ and $G^*$ at the end of the $R$-th round. To solve this task we propose $\textbf{IGDA}$, a LLM-based pipeline incorporating two key components: 1) an LLM uncertainty-driven method for edge experiment selection 2) a local graph update strategy utilizing binary feedback from experiments to improve predictions for unselected neighboring edges. Experiments on eight different real-world graphs show our approach often outperforms all baselines including a state-of-the-art numerical method for interactive graph discovery. Further, we conduct a rigorous series of ablations dissecting the impact of each pipeline component. Finally, to assess the impact of memorization, we apply our interactive graph discovery strategy to a complex, new (as of July 2024) causal graph on protein transcription factors, finding strong performance in a setting where memorization is impossible. Overall, our results show IGDA to be a powerful method for graph discovery complementary to existing numerically driven approaches.
<div id='section'>Paperid: <span id='pid'>901, <a href='https://arxiv.org/pdf/2502.12479.pdf' target='_blank'>https://arxiv.org/pdf/2502.12479.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoqi Zheng, Bo Zhang, Kieran Didi, Kevin K. Yang, Jason Yim, Joseph L. Watson, Hai-Feng Chen, Brian L. Trippe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12479">MotifBench: A standardized protein design benchmark for motif-scaffolding problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The motif-scaffolding problem is a central task in computational protein design: Given the coordinates of atoms in a geometry chosen to confer a desired biochemical function (a motif), the task is to identify diverse protein structures (scaffolds) that include the motif and maintain its geometry. Significant recent progress on motif-scaffolding has been made due to computational evaluation with reliable protein structure prediction and fixed-backbone sequence design methods. However, significant variability in evaluation strategies across publications has hindered comparability of results, challenged reproducibility, and impeded robust progress. In response we introduce MotifBench, comprising (1) a precisely specified pipeline and evaluation metrics, (2) a collection of 30 benchmark problems, and (3) an implementation of this benchmark and leaderboard at github.com/blt2114/MotifBench. The MotifBench test cases are more difficult compared to earlier benchmarks, and include protein design problems for which solutions are known but on which, to the best of our knowledge, state-of-the-art methods fail to identify any solution.
<div id='section'>Paperid: <span id='pid'>902, <a href='https://arxiv.org/pdf/2502.10365.pdf' target='_blank'>https://arxiv.org/pdf/2502.10365.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Chen, Karla-Luise Herpoldt, Chenchao Zhao, Zichen Wang, Marcus Collins, Shang Shang, Ron Benson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.10365">AffinityFlow: Guided Flows for Antibody Affinity Maturation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibodies are widely used as therapeutics, but their development requires costly affinity maturation, involving iterative mutations to enhance binding affinity.This paper explores a sequence-only scenario for affinity maturation, using solely antibody and antigen sequences. Recently AlphaFlow wraps AlphaFold within flow matching to generate diverse protein structures, enabling a sequence-conditioned generative model of structure. Building on this, we propose an alternating optimization framework that (1) fixes the sequence to guide structure generation toward high binding affinity using a structure-based affinity predictor, then (2) applies inverse folding to create sequence mutations, refined by a sequence-based affinity predictor for post selection. A key challenge is the lack of labeled data for training both predictors. To address this, we develop a co-teaching module that incorporates valuable information from noisy biophysical energies into predictor refinement. The sequence-based predictor selects consensus samples to teach the structure-based predictor, and vice versa. Our method, AffinityFlow, achieves state-of-the-art performance in affinity maturation experiments. We plan to open-source our code after acceptance.
<div id='section'>Paperid: <span id='pid'>903, <a href='https://arxiv.org/pdf/2502.10173.pdf' target='_blank'>https://arxiv.org/pdf/2502.10173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Ni, Markus J. Buehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.10173">Agentic End-to-End De Novo Protein Design for Tailored Dynamics Using a Language Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are dynamic molecular machines whose biological functions, spanning enzymatic catalysis, signal transduction, and structural adaptation, are intrinsically linked to their motions. Designing proteins with targeted dynamic properties, however, remains a challenge due to the complex, degenerate relationships between sequence, structure, and molecular motion. Here, we introduce VibeGen, a generative AI framework that enables end-to-end de novo protein design conditioned on normal mode vibrations. VibeGen employs an agentic dual-model architecture, comprising a protein designer that generates sequence candidates based on specified vibrational modes and a protein predictor that evaluates their dynamic accuracy. This approach synergizes diversity, accuracy, and novelty during the design process. Via full-atom molecular simulations as direct validation, we demonstrate that the designed proteins accurately reproduce the prescribed normal mode amplitudes across the backbone while adopting various stable, functionally relevant structures. Notably, generated sequences are de novo, exhibiting no significant similarity to natural proteins, thereby expanding the accessible protein space beyond evolutionary constraints. Our work integrates protein dynamics into generative protein design, and establishes a direct, bidirectional link between sequence and vibrational behavior, unlocking new pathways for engineering biomolecules with tailored dynamical and functional properties. This framework holds broad implications for the rational design of flexible enzymes, dynamic scaffolds, and biomaterials, paving the way toward dynamics-informed AI-driven protein engineering.
<div id='section'>Paperid: <span id='pid'>904, <a href='https://arxiv.org/pdf/2502.06914.pdf' target='_blank'>https://arxiv.org/pdf/2502.06914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenao Li, Shuo Yan, Enyan Dai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06914">UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enzyme-catalyzed protein cleavage is essential for many biological functions. Accurate prediction of cleavage sites can facilitate various applications such as drug development, enzyme design, and a deeper understanding of biological mechanisms. However, most existing models are restricted to an individual enzyme, which neglects shared knowledge of enzymes and fails generalize to novel enzymes. Thus, we introduce a unified protein cleavage site predictor named UniZyme, which can generalize across diverse enzymes. To enhance the enzyme encoding for the protein cleavage site prediction, UniZyme employs a novel biochemically-informed model architecture along with active-site knowledge of proteolytic enzymes. Extensive experiments demonstrate that UniZyme achieves high accuracy in predicting cleavage sites across a range of proteolytic enzymes, including unseen enzymes. The code is available in https://anonymous.4open.science/r/UniZyme-4A67.
<div id='section'>Paperid: <span id='pid'>905, <a href='https://arxiv.org/pdf/2502.01533.pdf' target='_blank'>https://arxiv.org/pdf/2502.01533.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Isaac Ellmen, Constantin Schneider, Matthew I. J. Raybould, Charlotte M. Deane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01533">Transformers trained on proteins can learn to attend to Euclidean distance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While conventional Transformers generally operate on sequence data, they can be used in conjunction with structure models, typically SE(3)-invariant or equivariant graph neural networks (GNNs), for 3D applications such as protein structure modelling. These hybrids typically involve either (1) preprocessing/tokenizing structural features as input for Transformers or (2) taking Transformer embeddings and processing them within a structural representation. However, there is evidence that Transformers can learn to process structural information on their own, such as the AlphaFold3 structural diffusion model. In this work we show that Transformers can function independently as structure models when passed linear embeddings of coordinates. We first provide a theoretical explanation for how Transformers can learn to filter attention as a 3D Gaussian with learned variance. We then validate this theory using both simulated 3D points and in the context of masked token prediction for proteins. Finally, we show that pre-training protein Transformer encoders with structure improves performance on a downstream task, yielding better performance than custom structural models. Together, this work provides a basis for using standard Transformers as hybrid structure-language models.
<div id='section'>Paperid: <span id='pid'>906, <a href='https://arxiv.org/pdf/2502.00001.pdf' target='_blank'>https://arxiv.org/pdf/2502.00001.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Md Rownak Hossain Chowdhury, Mostafizur Rahman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00001">Accelerating PageRank Algorithmic Tasks with a new Programmable Hardware Architecture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Addressing the growing demands of artificial intelligence (AI) and data analytics requires new computing approaches. In this paper, we propose a reconfigurable hardware accelerator designed specifically for AI and data-intensive applications. Our architecture features a messaging-based intelligent computing scheme that allows for dynamic programming at runtime using a minimal instruction set. To assess our hardware's effectiveness, we conducted a case study in TSMC 28nm technology node. The simulation-based study involved analyzing a protein network using the computationally demanding PageRank algorithm. The results demonstrate that our hardware can analyze a 5,000-node protein network in just 213.6 milliseconds over 100 iterations. These outcomes signify the potential of our design to achieve cutting-edge performance in next-generation AI applications.
<div id='section'>Paperid: <span id='pid'>907, <a href='https://arxiv.org/pdf/2501.16382.pdf' target='_blank'>https://arxiv.org/pdf/2501.16382.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziwen Li, Xiang 'Anthony' Chen, Youngseung Jeon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16382">GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drug discovery (DD) has tremendously contributed to maintaining and improving public health. Hypothesizing that inhibiting protein misfolding can slow disease progression, researchers focus on target identification (Target ID) to find protein structures for drug binding. While Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) frameworks have accelerated drug discovery, integrating models into cohesive workflows remains challenging. We conducted a user study with drug discovery researchers to identify the applicability of LLMs and RAGs in Target ID. We identified two main findings: 1) an LLM should provide multiple Protein-Protein Interactions (PPIs) based on an initial protein and protein candidates that have a therapeutic impact; 2) the model must provide the PPI and relevant explanations for better understanding. Based on these observations, we identified three limitations in previous approaches for Target ID: 1) semantic ambiguity, 2) lack of explainability, and 3) short retrieval units. To address these issues, we propose GraPPI, a large-scale knowledge graph (KG)-based retrieve-divide-solve agent pipeline RAG framework to support large-scale PPI signaling pathway exploration in understanding therapeutic impacts by decomposing the analysis of entire PPI pathways into sub-tasks focused on the analysis of PPI edges.
<div id='section'>Paperid: <span id='pid'>908, <a href='https://arxiv.org/pdf/2501.09938.pdf' target='_blank'>https://arxiv.org/pdf/2501.09938.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sajjad Saleem, Adil Hussain, Nabila Majeed, Zahid Akhtar, Kamran Siddique
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.09938">A Multi-Scale Feature Extraction and Fusion Deep Learning Method for Classification of Wheat Diseases</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wheat is an important source of dietary fiber and protein that is negatively impacted by a number of risks to its growth. The difficulty of identifying and classifying wheat diseases is discussed with an emphasis on wheat loose smut, leaf rust, and crown and root rot. Addressing conditions like crown and root rot, this study introduces an innovative approach that integrates multi-scale feature extraction with advanced image segmentation techniques to enhance classification accuracy. The proposed method uses neural network models Xception, Inception V3, and ResNet 50 to train on a large wheat disease classification dataset 2020 in conjunction with an ensemble of machine vision classifiers, including voting and stacking. The study shows that the suggested methodology has a superior accuracy of 99.75% in the classification of wheat diseases when compared to current state-of-the-art approaches. A deep learning ensemble model Xception showed the highest accuracy.
<div id='section'>Paperid: <span id='pid'>909, <a href='https://arxiv.org/pdf/2412.20744.pdf' target='_blank'>https://arxiv.org/pdf/2412.20744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhinav Roy, Bhavesh Gyanchandani, Aditya Oza, Abhishek Sharma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20744">Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Parkinson's Disease (PD) is a degenerative neurological disorder that impairs motor and non-motor functions, significantly reducing quality of life and increasing mortality risk. Early and accurate detection of PD progression is vital for effective management and improved patient outcomes. Current diagnostic methods, however, are often costly, time-consuming, and require specialized equipment and expertise. This work proposes an innovative approach to predicting PD progression using regression methods, Long Short-Term Memory (LSTM) networks, and Kolmogorov Arnold Networks (KAN). KAN, utilizing spline-parametrized univariate functions, allows for dynamic learning of activation patterns, unlike traditional linear models.
  The Movement Disorder Society-Sponsored Revision of the Unified Parkinson's Disease Rating Scale (MDS-UPDRS) is a comprehensive tool for evaluating PD symptoms and is commonly used to measure disease progression. Additionally, protein or peptide abnormalities are linked to PD onset and progression. Identifying these associations can aid in predicting disease progression and understanding molecular changes.
  Comparing multiple models, including LSTM and KAN, this study aims to identify the method that delivers the highest metrics. The analysis reveals that KAN, with its dynamic learning capabilities, outperforms other approaches in predicting PD progression. This research highlights the potential of AI and machine learning in healthcare, paving the way for advanced computational models to enhance clinical predictions and improve patient care and treatment strategies in PD management.
<div id='section'>Paperid: <span id='pid'>910, <a href='https://arxiv.org/pdf/2412.17799.pdf' target='_blank'>https://arxiv.org/pdf/2412.17799.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akarsh Kumar, Chris Lu, Louis Kirsch, Yujin Tang, Kenneth O. Stanley, Phillip Isola, David Ha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.17799">Automating the Search for Artificial Life with Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the recent Nobel Prize awarded for radical advances in protein discovery, foundation models (FMs) for exploring large combinatorial spaces promise to revolutionize many scientific fields. Artificial Life (ALife) has not yet integrated FMs, thus presenting a major opportunity for the field to alleviate the historical burden of relying chiefly on manual design and trial-and-error to discover the configurations of lifelike simulations. This paper presents, for the first time, a successful realization of this opportunity using vision-language FMs. The proposed approach, called Automated Search for Artificial Life (ASAL), (1) finds simulations that produce target phenomena, (2) discovers simulations that generate temporally open-ended novelty, and (3) illuminates an entire space of interestingly diverse simulations. Because of the generality of FMs, ASAL works effectively across a diverse range of ALife substrates including Boids, Particle Life, Game of Life, Lenia, and Neural Cellular Automata. A major result highlighting the potential of this technique is the discovery of previously unseen Lenia and Boids lifeforms, as well as cellular automata that are open-ended like Conway's Game of Life. Additionally, the use of FMs allows for the quantification of previously qualitative phenomena in a human-aligned way. This new paradigm promises to accelerate ALife research beyond what is possible through human ingenuity alone.
<div id='section'>Paperid: <span id='pid'>911, <a href='https://arxiv.org/pdf/2412.13223.pdf' target='_blank'>https://arxiv.org/pdf/2412.13223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sai Advaith Maddipatla, Nadav Bojan Sellam, Sanketh Vedula, Ailie Marx, Alex Bronstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13223">Generative modeling of protein ensembles guided by crystallographic electron densities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are dynamic, adopting ensembles of conformations. The nature of this conformational heterogenity is imprinted in the raw electron density measurements obtained from X-ray crystallography experiments. Fitting an ensemble of protein structures to these measurements is a challenging, ill-posed inverse problem. We propose a non-i.i.d. ensemble guidance approach to solve this problem using existing protein structure generative models and demonstrate that it accurately recovers complicated multi-modal alternate protein backbone conformations observed in certain single crystal measurements.
<div id='section'>Paperid: <span id='pid'>912, <a href='https://arxiv.org/pdf/2412.10743.pdf' target='_blank'>https://arxiv.org/pdf/2412.10743.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoran Qiao, Feizhi Ding, Thomas Dresselhaus, Mia A. Rosenfeld, Xiaotian Han, Owen Howell, Aniketh Iyengar, Stephen Opalenski, Anders S. Christensen, Sai Krishna Sirumalla, Frederick R. Manby, Thomas F. Miller, Matthew Welborn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.10743">NeuralPLexer3: Accurate Biomolecular Complex Structure Prediction with Flow Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure determination is essential to a mechanistic understanding of diseases and the development of novel therapeutics. Machine-learning-based structure prediction methods have made significant advancements by computationally predicting protein and bioassembly structures from sequences and molecular topology alone. Despite substantial progress in the field, challenges remain to deliver structure prediction models to real-world drug discovery. Here, we present NeuralPLexer3 -- a physics-inspired flow-based generative model that achieves state-of-the-art prediction accuracy on key biomolecular interaction types and improves training and sampling efficiency compared to its predecessors and alternative methodologies. Examined through newly developed benchmarking strategies, NeuralPLexer3 excels in vital areas that are crucial to structure-based drug design, such as physical validity and ligand-induced conformational changes.
<div id='section'>Paperid: <span id='pid'>913, <a href='https://arxiv.org/pdf/2411.15418.pdf' target='_blank'>https://arxiv.org/pdf/2411.15418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew T. McNutt, Abhinav K. Adduri, Caleb N. Ellington, Monica T. Dayao, Eric P. Xing, Hosein Mohimani, David R. Koes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15418">Scaling Structure Aware Virtual Screening to Billions of Molecules with SPRINT</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Virtual screening of small molecules against protein targets can accelerate drug discovery and development by predicting drug-target interactions (DTIs). However, structure-based methods like molecular docking are too slow to allow for broad proteome-scale screens, limiting their application in screening for off-target effects or new molecular mechanisms. Recently, vector-based methods using protein language models (PLMs) have emerged as a complementary approach that bypasses explicit 3D structure modeling. Here, we develop SPRINT, a vector-based approach for screening entire chemical libraries against whole proteomes for DTIs and novel mechanisms of action. SPRINT improves on prior work by using a self-attention based architecture and structure-aware PLMs to learn drug-target co-embeddings for binder prediction, search, and retrieval. SPRINT achieves SOTA enrichment factors in virtual screening on LIT-PCBA, DTI classification benchmarks, and binding affinity prediction benchmarks, while providing interpretability in the form of residue-level attention maps. In addition to being both accurate and interpretable, SPRINT is ultra-fast: querying the whole human proteome against the ENAMINE Real Database (6.7B drugs) for the 100 most likely binders per protein takes 16 minutes. SPRINT promises to enable virtual screening at an unprecedented scale, opening up new opportunities for in silico drug repurposing and development. SPRINT is available on the web as ColabScreen: https://bit.ly/colab-screen
<div id='section'>Paperid: <span id='pid'>914, <a href='https://arxiv.org/pdf/2411.12098.pdf' target='_blank'>https://arxiv.org/pdf/2411.12098.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Li, Gagan Agrawal, Rajiv Ramnath, Ruoming Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.12098">Federated Contrastive Learning of Graph-Level Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph-level representations (and clustering/classification based on these representations) are required in a variety of applications. Examples include identifying malicious network traffic, prediction of protein properties, and many others. Often, data has to stay in isolated local systems (i.e., cannot be centrally shared for analysis) due to a variety of considerations like privacy concerns, lack of trust between the parties, regulations, or simply because the data is too large to be shared sufficiently quickly. This points to the need for federated learning for graph-level representations, a topic that has not been explored much, especially in an unsupervised setting.
  Addressing this problem, this paper presents a new framework we refer to as Federated Contrastive Learning of Graph-level Representations (FCLG). As the name suggests, our approach builds on contrastive learning. However, what is unique is that we apply contrastive learning at two levels. The first application is for local unsupervised learning of graph representations. The second level is to address the challenge associated with data distribution variation (i.e. the ``Non-IID issue") when combining local models. Through extensive experiments on the downstream task of graph-level clustering, we demonstrate FCLG outperforms baselines (which apply existing federated methods on existing graph-level clustering methods) with significant margins.
<div id='section'>Paperid: <span id='pid'>915, <a href='https://arxiv.org/pdf/2411.08286.pdf' target='_blank'>https://arxiv.org/pdf/2411.08286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jin Han, Wu-Jun Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08286">Hashing for Protein Structure Similarity Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structure similarity search (PSSS), which tries to search proteins with similar structures, plays a crucial role across diverse domains from drug design to protein function prediction and molecular evolution. Traditional alignment-based PSSS methods, which directly calculate alignment on the protein structures, are highly time-consuming with high memory cost. Recently, alignment-free methods, which represent protein structures as fixed-length real-valued vectors, are proposed for PSSS. Although these methods have lower time and memory cost than alignment-based methods, their time and memory cost is still too high for large-scale PSSS, and their accuracy is unsatisfactory. In this paper, we propose a novel method, called $\underline{\text{p}}$r$\underline{\text{o}}$tein $\underline{\text{s}}$tructure $\underline{\text{h}}$ashing (POSH), for PSSS. POSH learns a binary vector representation for each protein structure, which can dramatically reduce the time and memory cost for PSSS compared with real-valued vector representation based methods. Furthermore, in POSH we also propose expressive hand-crafted features and a structure encoder to well model both node and edge interactions in proteins. Experimental results on real datasets show that POSH can outperform other methods to achieve state-of-the-art accuracy. Furthermore, POSH achieves a memory saving of more than six times and speed improvement of more than four times, compared with other methods.
<div id='section'>Paperid: <span id='pid'>916, <a href='https://arxiv.org/pdf/2411.05055.pdf' target='_blank'>https://arxiv.org/pdf/2411.05055.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youssef Boulaimen, Gabriele Fossi, Leila Outemzabet, Nathalie Jeanray, Oleksandr Levenets, Stephane Gerart, Sebastien Vachenc, Salvatore Raieli, Joanna Giemza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05055">Integrating Large Language Models for Genetic Variant Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The classification of genetic variants, particularly Variants of Uncertain Significance (VUS), poses a significant challenge in clinical genetics and precision medicine. Large Language Models (LLMs) have emerged as transformative tools in this realm. These models can uncover intricate patterns and predictive insights that traditional methods might miss, thus enhancing the predictive accuracy of genetic variant pathogenicity.
  This study investigates the integration of state-of-the-art LLMs, including GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data alongside structural insights to form a comprehensive analytical framework for variant classification. Our approach evaluates these integrated models using the well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in classification performance. The models were rigorously tested on a set of challenging variants, demonstrating substantial improvements over existing state-of-the-art tools, especially in handling ambiguous and clinically uncertain variants.
  The results of this research underline the efficacy of combining multiple modeling approaches to significantly refine the accuracy and reliability of genetic variant classification systems. These findings support the deployment of these advanced computational models in clinical environments, where they can significantly enhance the diagnostic processes for genetic disorders, ultimately pushing the boundaries of personalized medicine by offering more detailed and actionable genetic insights.
<div id='section'>Paperid: <span id='pid'>917, <a href='https://arxiv.org/pdf/2411.04863.pdf' target='_blank'>https://arxiv.org/pdf/2411.04863.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Klemens FlÃ¶ge, Srisruthi Udayakumar, Johanna Sommer, Marie Piraud, Stefan Kesselheim, Vincent Fortuin, Stephan GÃ¼nneman, Karel J van der Weg, Holger Gohlke, Erinc Merdivan, Alina Bazarova
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04863">OneProt: Towards Multi-Modal Protein Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in Artificial Intelligence have enabled multi-modal systems to model and translate diverse information spaces. Extending beyond text and vision, we introduce OneProt, a multi-modal AI for proteins that integrates structural, sequence, text, and binding site data. Using the ImageBind framework, OneProt aligns the latent spaces of protein modality encoders in a lightweight fine-tuning scheme that focuses on pairwise alignment with sequence data rather than requiring full matches. This novel approach comprises a mix of Graph Neural Networks and transformer architectures. It demonstrates strong performance in retrieval tasks and showcases the efficacy of multi-modal systems in Protein Machine Learning through a broad spectrum of downstream baselines, including enzyme function prediction and binding site analysis. Furthermore, OneProt enables the transfer of representational information from specialized encoders to the sequence encoder, enhancing capabilities for distinguishing evolutionarily related and unrelated sequences and exhibiting representational properties where evolutionarily related proteins align in similar directions within the latent space. In addition, we extensively investigate modality ablations to identify the encoders that contribute most to predictive performance, highlighting the significance of the binding site encoder, which has not been used in similar models previously. This work expands the horizons of multi-modal protein models, paving the way for transformative applications in drug discovery, biocatalytic reaction planning, and protein engineering.
<div id='section'>Paperid: <span id='pid'>918, <a href='https://arxiv.org/pdf/2411.00593.pdf' target='_blank'>https://arxiv.org/pdf/2411.00593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhili Feng, Tanya Marwah, Nicolo Fusi, David Alvarez-Melis, Lester Mackey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00593">Adapting Language Models via Token Translation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern large language models use a fixed tokenizer to effectively compress text drawn from a source domain. However, applying the same tokenizer to a new target domain often leads to inferior compression, more costly inference, and reduced semantic alignment. To address this deficiency, we introduce Sparse Sinkhorn Token Translation (S2T2). S2T2 trains a tailored tokenizer for the target domain and learns to translate between target and source tokens, enabling more effective reuse of the pre-trained next-source-token predictor. In our experiments with finetuned English language models, S2T2 improves both the perplexity and the compression of out-of-domain protein sequences, outperforming direct finetuning with either the source or target tokenizer. In addition, we find that token translations learned for smaller, less expensive models can be directly transferred to larger, more powerful models to reap the benefits of S2T2 at lower cost.
<div id='section'>Paperid: <span id='pid'>919, <a href='https://arxiv.org/pdf/2410.19704.pdf' target='_blank'>https://arxiv.org/pdf/2410.19704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Parthasarathy Suryanarayanan, Yunguang Qiu, Shreyans Sethi, Diwakar Mahajan, Hongyang Li, Yuxin Yang, Elif Eyigoz, Aldo Guzman Saenz, Daniel E. Platt, Timothy H. Rumbell, Kenney Ng, Sanjoy Dey, Myson Burch, Bum Chul Kwon, Pablo Meyer, Feixiong Cheng, Jianying Hu, Joseph A. Morrone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19704">Multi-view biomedical foundation models for molecule-target and property prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quality molecular representations are key to foundation model development in bio-medical research. Previous efforts have typically focused on a single representation or molecular view, which may have strengths or weaknesses on a given task. We develop Multi-view Molecular Embedding with Late Fusion (MMELON), an approach that integrates graph, image and text views in a foundation model setting and may be readily extended to additional representations. Single-view foundation models are each pre-trained on a dataset of up to 200M molecules. The multi-view model performs robustly, matching the performance of the highest-ranked single-view. It is validated on over 120 tasks, including molecular solubility, ADME properties, and activity against G Protein-Coupled receptors (GPCRs). We identify 33 GPCRs that are related to Alzheimer's disease and employ the multi-view model to select strong binders from a compound screen. Predictions are validated through structure-based modeling and identification of key binding motifs.
<div id='section'>Paperid: <span id='pid'>920, <a href='https://arxiv.org/pdf/2410.14433.pdf' target='_blank'>https://arxiv.org/pdf/2410.14433.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rabea Khatun, Wahia Tasnim, Maksuda Akter, Md Manowarul Islam, Md. Ashraf Uddin, Md. Zulfiker Mahmud, Saurav Chandra Das
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14433">A Bioinformatic Approach Validated Utilizing Machine Learning Algorithms to Identify Relevant Biomarkers and Crucial Pathways in Gallbladder Cancer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gallbladder cancer (GBC) is the most frequent cause of disease among biliary tract neoplasms. Identifying the molecular mechanisms and biomarkers linked to GBC progression has been a significant challenge in scientific research. Few recent studies have explored the roles of biomarkers in GBC. Our study aimed to identify biomarkers in GBC using machine learning (ML) and bioinformatics techniques. We compared GBC tumor samples with normal samples to identify differentially expressed genes (DEGs) from two microarray datasets (GSE100363, GSE139682) obtained from the NCBI GEO database. A total of 146 DEGs were found, with 39 up-regulated and 107 down-regulated genes. Functional enrichment analysis of these DEGs was performed using Gene Ontology (GO) terms and REACTOME pathways through DAVID. The protein-protein interaction network was constructed using the STRING database. To identify hub genes, we applied three ranking algorithms: Degree, MNC, and Closeness Centrality. The intersection of hub genes from these algorithms yielded 11 hub genes. Simultaneously, two feature selection methods (Pearson correlation and recursive feature elimination) were used to identify significant gene subsets. We then developed ML models using SVM and RF on the GSE100363 dataset, with validation on GSE139682, to determine the gene subset that best distinguishes GBC samples. The hub genes outperformed the other gene subsets. Finally, NTRK2, COL14A1, SCN4B, ATP1A2, SLC17A7, SLIT3, COL7A1, CLDN4, CLEC3B, ADCYAP1R1, and MFAP4 were identified as crucial genes, with SLIT3, COL7A1, and CLDN4 being strongly linked to GBC development and prediction.
<div id='section'>Paperid: <span id='pid'>921, <a href='https://arxiv.org/pdf/2410.08631.pdf' target='_blank'>https://arxiv.org/pdf/2410.08631.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Zhou, Yilai Li, Jing Yuan, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08631">CryoFM: A Flow-based Foundation Model for Cryo-EM Densities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryo-electron microscopy (cryo-EM) is a powerful technique in structural biology and drug discovery, enabling the study of biomolecules at high resolution. Significant advancements by structural biologists using cryo-EM have led to the production of over 38,626 protein density maps at various resolutions1. However, cryo-EM data processing algorithms have yet to fully benefit from our knowledge of biomolecular density maps, with only a few recent models being data-driven but limited to specific tasks. In this study, we present CryoFM, a foundation model designed as a generative model, learning the distribution of high-quality density maps and generalizing effectively to downstream tasks. Built on flow matching, CryoFM is trained to accurately capture the prior distribution of biomolecular density maps. Furthermore, we introduce a flow posterior sampling method that leverages CRYOFM as a flexible prior for several downstream tasks in cryo-EM and cryo-electron tomography (cryo-ET) without the need for fine-tuning, achieving state-of-the-art performance on most tasks and demonstrating its potential as a foundational model for broader applications in these fields.
<div id='section'>Paperid: <span id='pid'>922, <a href='https://arxiv.org/pdf/2410.07968.pdf' target='_blank'>https://arxiv.org/pdf/2410.07968.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xu Wang, Yiquan Wang, Longji Xu, Yuhua Dong, Tin-Yeh Huang, Xiang Li, Jia Deng, Rui He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07968">Octopus Inspired Optimization (OIO): A Hierarchical Framework for Navigating Protein Fitness Landscapes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Navigating the vast, rugged, and multi-modal fitness landscapes of protein sequences presents a formidable challenge for computational protein engineering, often trapping algorithms in suboptimal solutions. Existing methods struggle with the exploration-exploitation dilemma, failing to synergize global search with deep local refinement. To overcome this critical barrier, we introduce the Octopus Inspired Optimization (OIO), a novel hierarchical metaheuristic that mimics the octopus's unique neural architecture of centralized control and decentralized, parallel execution. OIO's "individual-tentacle-sucker" framework provides an intrinsic unification of global exploration and parallelized local exploitation, making it structurally ideal for complex combinatorial problems. We validated OIO's efficacy through a rigorous three-tiered experimental framework. On a real-world Green Fluorescent Protein (GFP) design benchmark, OIO surpassed a comprehensive suite of 15 competing metaheuristics, including 7 classic algorithms and 8 state-of-the-art methods from the past two years, delivering performance comparable only to a specialized local search algorithm. This success is explained by its fundamental strengths: OIO ranked first on the NK-Landscape benchmark, confirming its architectural suitability for protein-like fitness landscapes, and also ranked first on the gold-standard CEC2022 benchmark, demonstrating the raw power and efficiency of its optimization engine. OIO establishes a new, nature-inspired paradigm for protein engineering, offering a robust and powerful tool with significant potential for advancing therapeutic and enzymatic design.
<div id='section'>Paperid: <span id='pid'>923, <a href='https://arxiv.org/pdf/2410.04543.pdf' target='_blank'>https://arxiv.org/pdf/2410.04543.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Friso de Kruiff, Erik Bekkers, Ozan Ãktem, Carola-Bibiane SchÃ¶nlieb, Willem Diepeveen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04543">Pullback Flow Matching on Data Manifolds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose Pullback Flow Matching (PFM), a novel framework for generative modeling on data manifolds. Unlike existing methods that assume or learn restrictive closed-form manifold mappings for training Riemannian Flow Matching (RFM) models, PFM leverages pullback geometry and isometric learning to preserve the underlying manifold's geometry while enabling efficient generation and precise interpolation in latent space. This approach not only facilitates closed-form mappings on the data manifold but also allows for designable latent spaces, using assumed metrics on both data and latent manifolds. By enhancing isometric learning through Neural ODEs and proposing a scalable training objective, we achieve a latent space more suitable for interpolation, leading to improved manifold learning and generative performance. We demonstrate PFM's effectiveness through applications in synthetic data, protein dynamics and protein sequence data, generating novel proteins with specific properties. This method shows strong potential for drug discovery and materials science, where generating novel samples with specific properties is of great interest.
<div id='section'>Paperid: <span id='pid'>924, <a href='https://arxiv.org/pdf/2409.17852.pdf' target='_blank'>https://arxiv.org/pdf/2409.17852.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Antonio Mirarchi, Raul P. Pelaez, Guillem Simeon, Gianni De Fabritiis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17852">AMARO: All Heavy-Atom Transferable Neural Network Potentials of Protein Thermodynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>All-atom molecular simulations offer detailed insights into macromolecular phenomena, but their substantial computational cost hinders the exploration of complex biological processes. We introduce Advanced Machine-learning Atomic Representation Omni-force-field (AMARO), a new neural network potential (NNP) that combines an O(3)-equivariant message-passing neural network architecture, TensorNet, with a coarse-graining map that excludes hydrogen atoms. AMARO demonstrates the feasibility of training coarser NNP, without prior energy terms, to run stable protein dynamics with scalability and generalization capabilities.
<div id='section'>Paperid: <span id='pid'>925, <a href='https://arxiv.org/pdf/2409.17726.pdf' target='_blank'>https://arxiv.org/pdf/2409.17726.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luiz Felipe Vecchietti, Minji Lee, Begench Hangeldiyev, Hyunkyu Jung, Hahnbeom Park, Tae-Kyun Kim, Meeyoung Cha, Ho Min Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17726">Recent advances in interpretable machine learning using structure-based protein representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in machine learning (ML) are transforming the field of structural biology. For example, AlphaFold, a groundbreaking neural network for protein structure prediction, has been widely adopted by researchers. The availability of easy-to-use interfaces and interpretable outcomes from the neural network architecture, such as the confidence scores used to color the predicted structures, have made AlphaFold accessible even to non-ML experts. In this paper, we present various methods for representing protein 3D structures from low- to high-resolution, and show how interpretable ML methods can support tasks such as predicting protein structures, protein function, and protein-protein interactions. This survey also emphasizes the significance of interpreting and visualizing ML-based inference for structure-based protein representations that enhance interpretability and knowledge discovery. Developing such interpretable approaches promises to further accelerate fields including drug development and protein design.
<div id='section'>Paperid: <span id='pid'>926, <a href='https://arxiv.org/pdf/2409.06722.pdf' target='_blank'>https://arxiv.org/pdf/2409.06722.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Jiao, Hananeh Derakhshan, Barbara St. Pierre Schneider, Emma Regentova, Mei Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06722">Automated Quantification of White Blood Cells in Light Microscopic Images of Injured Skeletal Muscle</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>White blood cells (WBCs) are the most diverse cell types observed in the healing process of injured skeletal muscles. In the course of healing, WBCs exhibit dynamic cellular response and undergo multiple protein expression changes. The progress of healing can be analyzed by quantifying the number of WBCs or the amount of specific proteins in light microscopic images obtained at different time points after injury. In this paper, we propose an automated quantifying and analysis framework to analyze WBCs using light microscopic images of uninjured and injured muscles. The proposed framework is based on the Localized Iterative Otsu's threshold method with muscle edge detection and region of interest extraction. Compared with the threshold methods used in ImageJ, the LI Otsu's threshold method has high resistance to background area and achieves better accuracy. The CD68-positive cell results are presented for demonstrating the effectiveness of the proposed work.
<div id='section'>Paperid: <span id='pid'>927, <a href='https://arxiv.org/pdf/2409.06142.pdf' target='_blank'>https://arxiv.org/pdf/2409.06142.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel M. Steinberg, Rafael Oliveira, Cheng Soon Ong, Edwin V. Bonilla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06142">Variational Search Distributions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop VSD, a method for conditioning a generative model of discrete, combinatorial designs on a rare desired class by efficiently evaluating a black-box (e.g. experiment, simulation) in a batch sequential manner. We call this task active generation; we formalize active generation's requirements and desiderata, and formulate a solution via variational inference. VSD uses off-the-shelf gradient based optimization routines, can learn powerful generative models for desirable designs, and can take advantage of scalable predictive models. We derive asymptotic convergence rates for learning the true conditional generative distribution of designs with certain configurations of our method. After illustrating the generative model on images, we empirically demonstrate that VSD can outperform existing baseline methods on a set of real sequence-design problems in various protein and DNA/RNA engineering tasks.
<div id='section'>Paperid: <span id='pid'>928, <a href='https://arxiv.org/pdf/2409.02732.pdf' target='_blank'>https://arxiv.org/pdf/2409.02732.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gokul Gowri, Xiao-Kang Lun, Allon M. Klein, Peng Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02732">Approximating mutual information of high-dimensional variables using learned representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mutual information (MI) is a general measure of statistical dependence with widespread application across the sciences. However, estimating MI between multi-dimensional variables is challenging because the number of samples necessary to converge to an accurate estimate scales unfavorably with dimensionality. In practice, existing techniques can reliably estimate MI in up to tens of dimensions, but fail in higher dimensions, where sufficient sample sizes are infeasible. Here, we explore the idea that underlying low-dimensional structure in high-dimensional data can be exploited to faithfully approximate MI in high-dimensional settings with realistic sample sizes. We develop a method that we call latent MI (LMI) approximation, which applies a nonparametric MI estimator to low-dimensional representations learned by a simple, theoretically-motivated model architecture. Using several benchmarks, we show that unlike existing techniques, LMI can approximate MI well for variables with $> 10^3$ dimensions if their dependence structure has low intrinsic dimensionality. Finally, we showcase LMI on two open problems in biology. First, we approximate MI between protein language model (pLM) representations of interacting proteins, and find that pLMs encode non-trivial information about protein-protein interactions. Second, we quantify cell fate information contained in single-cell RNA-seq (scRNA-seq) measurements of hematopoietic stem cells, and find a sharp transition during neutrophil differentiation when fate information captured by scRNA-seq increases dramatically.
<div id='section'>Paperid: <span id='pid'>929, <a href='https://arxiv.org/pdf/2408.09048.pdf' target='_blank'>https://arxiv.org/pdf/2408.09048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Honggen Zhang, Xiangrui Gao, June Zhang, Lipeng Lai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09048">mRNA2vec: mRNA Embedding with Language Model in the 5'UTR-CDS for mRNA Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Messenger RNA (mRNA)-based vaccines are accelerating the discovery of new drugs and revolutionizing the pharmaceutical industry. However, selecting particular mRNA sequences for vaccines and therapeutics from extensive mRNA libraries is costly. Effective mRNA therapeutics require carefully designed sequences with optimized expression levels and stability. This paper proposes a novel contextual language model (LM)-based embedding method: mRNA2vec. In contrast to existing mRNA embedding approaches, our method is based on the self-supervised teacher-student learning framework of data2vec. We jointly use the 5' untranslated region (UTR) and coding sequence (CDS) region as the input sequences. We adapt our LM-based approach specifically to mRNA by 1) considering the importance of location on the mRNA sequence with probabilistic masking, 2) using Minimum Free Energy (MFE) prediction and Secondary Structure (SS) classification as additional pretext tasks. mRNA2vec demonstrates significant improvements in translation efficiency (TE) and expression level (EL) prediction tasks in UTR compared to SOTA methods such as UTR-LM. It also gives a competitive performance in mRNA stability and protein production level tasks in CDS such as CodonBERT.
<div id='section'>Paperid: <span id='pid'>930, <a href='https://arxiv.org/pdf/2408.00040.pdf' target='_blank'>https://arxiv.org/pdf/2408.00040.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maximilian G. Schuh, Davide Boldini, Annkathrin I. Bohne, Stephan A. Sieber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00040">Barlow Twins Deep Neural Network for Advanced 1D Drug-Target Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of drug-target interactions is critical for advancing drug discovery. By reducing time and cost, machine learning and deep learning can accelerate this laborious discovery process. In a novel approach, BarlowDTI, we utilise the powerful Barlow Twins architecture for feature-extraction while considering the structure of the target protein. Our method achieves state-of-the-art predictive performance against multiple established benchmarks using only one-dimensional input. The use of gradient boosting machine as the underlying predictor ensures fast and efficient predictions without the need for substantial computational resources. We also investigate how the model reaches its decision based on individual training samples. By comparing co-crystal structures, we find that BarlowDTI effectively exploits catalytically active and stabilising residues, highlighting the model's ability to generalise from one-dimensional input data. In addition, we further benchmark new baselines against existing methods. Together, these innovations improve the efficiency and effectiveness of drug-target interaction predictions, providing robust tools for accelerating drug development and deepening the understanding of molecular interactions. Therefore, we provide an easy-to-use web interface that can be freely accessed at https://www.bio.nat.tum.de/oc2/barlowdti .
<div id='section'>Paperid: <span id='pid'>931, <a href='https://arxiv.org/pdf/2407.20054.pdf' target='_blank'>https://arxiv.org/pdf/2407.20054.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Filip OpÃ¡lenÃ½, Pavol Ulbrich, Joan Planas-Iglesias, Jan ByÅ¡ka, Jan Å touraÄ, David BednÃ¡Å, KatarÃ­na FurmanovÃ¡, Barbora KozlÃ­kovÃ¡
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.20054">Visual Support for the Loop Grafting Workflow on Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In understanding and redesigning the function of proteins in modern biochemistry, protein engineers are increasingly focusing on exploring regions in proteins called loops. Analyzing various characteristics of these regions helps the experts design the transfer of the desired function from one protein to another. This process is denoted as loop grafting. We designed a set of interactive visualizations that provide experts with visual support through all the loop grafting pipeline steps. The workflow is divided into several phases, reflecting the steps of the pipeline. Each phase is supported by a specific set of abstracted 2D visual representations of proteins and their loops that are interactively linked with the 3D View of proteins. By sequentially passing through the individual phases, the user shapes the list of loops that are potential candidates for loop grafting. Finally, the actual in-silico insertion of the loop candidates from one protein to the other is performed, and the results are visually presented to the user. In this way, the fully computational rational design of proteins and their loops results in newly designed protein structures that can be further assembled and tested through in-vitro experiments. We showcase the contribution of our visual support design on a real case scenario changing the enantiomer selectivity of the engineered enzyme. Moreover, we provide the readers with the experts' feedback.
<div id='section'>Paperid: <span id='pid'>932, <a href='https://arxiv.org/pdf/2407.19790.pdf' target='_blank'>https://arxiv.org/pdf/2407.19790.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jin Han, Yun Hong, Wu-Jun Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.19790">Hashing based Contrastive Learning for Virtual Screening</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Virtual screening (VS) is a critical step in computer-aided drug discovery, aiming to identify molecules that bind to a specific target receptor like protein. Traditional VS methods, such as docking, are often too time-consuming for screening large-scale molecular databases. Recent advances in deep learning have demonstrated that learning vector representations for both proteins and molecules using contrastive learning can outperform traditional docking methods. However, given that target databases often contain billions of molecules, real-valued vector representations adopted by existing methods can still incur significant memory and time costs in VS. To address this problem, in this paper we propose a hashing-based contrastive learning method, called DrugHash, for VS. DrugHash treats VS as a retrieval task that uses efficient binary hash codes for retrieval. In particular, DrugHash designs a simple yet effective hashing strategy to enable end-to-end learning of binary hash codes for both protein and molecule modalities, which can dramatically reduce the memory and time costs with higher accuracy compared with existing methods. Experimental results show that DrugHash can outperform existing methods to achieve state-of-the-art accuracy, with a memory saving of 32$\times$ and a speed improvement of 3.5$\times$.
<div id='section'>Paperid: <span id='pid'>933, <a href='https://arxiv.org/pdf/2407.15220.pdf' target='_blank'>https://arxiv.org/pdf/2407.15220.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuliya Burankova, Miriam Abele, Mohammad Bakhtiari, Christine von TÃ¶rne, Teresa Barth, Lisa Schweizer, Pieter Giesbertz, Johannes R. Schmidt, Stefan Kalkhof, Janina MÃ¼ller-Deile, Peter A van Veelen, Yassene Mohammed, Elke Hammer, Lis Arend, Klaudia Adamowicz, Tanja Laske, Anne Hartebrodt, Tobias Frisch, Chen Meng, Julian Matschinske, Julian SpÃ¤th, Richard RÃ¶ttger, Veit SchwÃ¤mmle, Stefanie M. Hauck, Stefan Lichtenthaler, Axel Imhof, Matthias Mann, Christina Ludwig, Bernhard Kuster, Jan Baumbach, Olga Zolotareva
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.15220">Privacy-Preserving Multi-Center Differential Protein Abundance Analysis with FedProt</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantitative mass spectrometry has revolutionized proteomics by enabling simultaneous quantification of thousands of proteins. Pooling patient-derived data from multiple institutions enhances statistical power but raises significant privacy concerns. Here we introduce FedProt, the first privacy-preserving tool for collaborative differential protein abundance analysis of distributed data, which utilizes federated learning and additive secret sharing. In the absence of a multicenter patient-derived dataset for evaluation, we created two, one at five centers from LFQ E.coli experiments and one at three centers from TMT human serum. Evaluations using these datasets confirm that FedProt achieves accuracy equivalent to DEqMS applied to pooled data, with completely negligible absolute differences no greater than $\text{$4 \times 10^{-12}$}$. In contrast, -log10(p-values) computed by the most accurate meta-analysis methods diverged from the centralized analysis results by up to 25-27. FedProt is available as a web tool with detailed documentation as a FeatureCloud App.
<div id='section'>Paperid: <span id='pid'>934, <a href='https://arxiv.org/pdf/2407.13023.pdf' target='_blank'>https://arxiv.org/pdf/2407.13023.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Abdi, Marko Djukanovic, Hesam Tahmasebi Boldaji, Hadis Salehi, Aleksandar Kartelj
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13023">A Three-Stage Algorithm for the Closest String Problem on Artificial and Real Gene Sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Closest String Problem is an NP-hard problem that aims to find a string that has the minimum distance from all sequences that belong to the given set of strings. Its applications can be found in coding theory, computational biology, and designing degenerated primers, among others. There are efficient exact algorithms that have reached high-quality solutions for binary sequences. However, there is still room for improvement concerning the quality of solutions over DNA and protein sequences. In this paper, we introduce a three-stage algorithm that comprises the following process: first, we apply a novel alphabet pruning method to reduce the search space for effectively finding promising search regions. Second, a variant of beam search to find a heuristic solution is employed. This method utilizes a newly developed guiding function based on an expected distance heuristic score of partial solutions. Last, we introduce a local search to improve the quality of the solution obtained from the beam search. Furthermore, due to the lack of real-world benchmarks, two real-world datasets are introduced to verify the robustness of the method. The extensive experimental results show that the proposed method outperforms the previous approaches from the literature.
<div id='section'>Paperid: <span id='pid'>935, <a href='https://arxiv.org/pdf/2407.11057.pdf' target='_blank'>https://arxiv.org/pdf/2407.11057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seungyeon Choi, Sangmin Seo, Sanghyun Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11057">SPIN: SE(3)-Invariant Physics Informed Network for Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of protein-ligand binding affinity is crucial for rapid and efficient drug development. Recently, the importance of predicting binding affinity has led to increased attention on research that models the three-dimensional structure of protein-ligand complexes using graph neural networks to predict binding affinity. However, traditional methods often fail to accurately model the complex's spatial information or rely solely on geometric features, neglecting the principles of protein-ligand binding. This can lead to overfitting, resulting in models that perform poorly on independent datasets and ultimately reducing their usefulness in real drug development. To address this issue, we propose SPIN, a model designed to achieve superior generalization by incorporating various inductive biases applicable to this task, beyond merely training on empirical data from datasets. For prediction, we defined two types of inductive biases: a geometric perspective that maintains consistent binding affinity predictions regardless of the complexs rotations and translations, and a physicochemical perspective that necessitates minimal binding free energy along their reaction coordinate for effective protein-ligand binding. These prior knowledge inputs enable the SPIN to outperform comparative models in benchmark sets such as CASF-2016 and CSAR HiQ. Furthermore, we demonstrated the practicality of our model through virtual screening experiments and validated the reliability and potential of our proposed model based on experiments assessing its interpretability.
<div id='section'>Paperid: <span id='pid'>936, <a href='https://arxiv.org/pdf/2407.04465.pdf' target='_blank'>https://arxiv.org/pdf/2407.04465.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tanujit Chakraborty, Swarup Chattopadhyay, Suchismita Das, Shraddha M. Naik, Chittaranjan Hens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04465">A Compounded Burr Probability Distribution for Fitting Heavy-Tailed Data with Applications to Biological Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Complex biological networks, encompassing metabolic pathways, gene regulatory systems, and protein-protein interaction networks, often exhibit scale-free structures characterized by heavy-tailed degree distributions. However, empirical studies reveal significant deviations from ideal power law behavior, underscoring the need for more flexible and accurate probabilistic models. In this work, we propose the Compounded Burr (CBurr) distribution, a novel four parameter family derived by compounding the Burr distribution with a discrete mixing process. This model is specifically designed to capture both the body and tail behavior of real-world network degree distributions with applications to biological networks. We rigorously derive its statistical properties, including moments, hazard and risk functions, and tail behavior, and develop an efficient maximum likelihood estimation framework. The CBurr model demonstrates broad applicability to networks with complex connectivity patterns, particularly in biological, social, and technological domains. Extensive experiments on large-scale biological network datasets show that CBurr consistently outperforms classical power-law, log-normal, and other heavy-tailed models across the full degree spectrum. By providing a statistically grounded and interpretable framework, the CBurr model enhances our ability to characterize the structural heterogeneity of biological networks.
<div id='section'>Paperid: <span id='pid'>937, <a href='https://arxiv.org/pdf/2407.03655.pdf' target='_blank'>https://arxiv.org/pdf/2407.03655.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fuqiang Chen, Ranran Zhang, Boyun Zheng, Yiwen Sun, Jiahui He, Wenjian Qin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03655">Pathological Semantics-Preserving Learning for H&E-to-IHC Virtual Staining</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conventional hematoxylin-eosin (H&E) staining is limited to revealing cell morphology and distribution, whereas immunohistochemical (IHC) staining provides precise and specific visualization of protein activation at the molecular level. Virtual staining technology has emerged as a solution for highly efficient IHC examination, which directly transforms H&E-stained images to IHC-stained images. However, virtual staining is challenged by the insufficient mining of pathological semantics and the spatial misalignment of pathological semantics. To address these issues, we propose the Pathological Semantics-Preserving Learning method for Virtual Staining (PSPStain), which directly incorporates the molecular-level semantic information and enhances semantics interaction despite any spatial inconsistency. Specifically, PSPStain comprises two novel learning strategies: 1) Protein-Aware Learning Strategy (PALS) with Focal Optical Density (FOD) map maintains the coherence of protein expression level, which represents molecular-level semantic information; 2) Prototype-Consistent Learning Strategy (PCLS), which enhances cross-image semantic interaction by prototypical consistency learning. We evaluate PSPStain on two public datasets using five metrics: three clinically relevant metrics and two for image quality. Extensive experiments indicate that PSPStain outperforms current state-of-the-art H&E-to-IHC virtual staining methods and demonstrates a high pathological correlation between the staging of real and virtual stains.
<div id='section'>Paperid: <span id='pid'>938, <a href='https://arxiv.org/pdf/2407.03154.pdf' target='_blank'>https://arxiv.org/pdf/2407.03154.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jithendaraa Subramanian, Shivakanth Sujit, Niloy Irtisam, Umong Sain, Riashat Islam, Derek Nowrouzezahrai, Samira Ebrahimi Kahou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03154">Reinforcement Learning for Sequence Design Leveraging Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein sequence design, determined by amino acid sequences, are essential to protein engineering problems in drug discovery. Prior approaches have resorted to evolutionary strategies or Monte-Carlo methods for protein design, but often fail to exploit the structure of the combinatorial search space, to generalize to unseen sequences. In the context of discrete black box optimization over large search spaces, learning a mutation policy to generate novel sequences with reinforcement learning is appealing. Recent advances in protein language models (PLMs) trained on large corpora of protein sequences offer a potential solution to this problem by scoring proteins according to their biological plausibility (such as the TM-score). In this work, we propose to use PLMs as a reward function to generate new sequences. Yet the PLM can be computationally expensive to query due to its large size. To this end, we propose an alternative paradigm where optimization can be performed on scores from a smaller proxy model that is periodically finetuned, jointly while learning the mutation policy. We perform extensive experiments on various sequence lengths to benchmark RL-based approaches, and provide comprehensive evaluations along biological plausibility and diversity of the protein. Our experimental results include favorable evaluations of the proposed sequences, along with high diversity scores, demonstrating that RL is a strong candidate for biological sequence design. Finally, we provide a modular open source implementation can be easily integrated in most RL training loops, with support for replacing the reward model with other PLMs, to spur further research in this domain. The code for all experiments is provided in the supplementary material.
<div id='section'>Paperid: <span id='pid'>939, <a href='https://arxiv.org/pdf/2406.15534.pdf' target='_blank'>https://arxiv.org/pdf/2406.15534.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianyu Liu, Yijia Xiao, Xiao Luo, Hua Xu, W. Jim Zheng, Hongyu Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.15534">Geneverse: A collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The applications of large language models (LLMs) are promising for biomedical and healthcare research. Despite the availability of open-source LLMs trained using a wide range of biomedical data, current research on the applications of LLMs to genomics and proteomics is still limited. To fill this gap, we propose a collection of finetuned LLMs and multimodal LLMs (MLLMs), known as Geneverse, for three novel tasks in genomic and proteomic research. The models in Geneverse are trained and evaluated based on domain-specific datasets, and we use advanced parameter-efficient finetuning techniques to achieve the model adaptation for tasks including the generation of descriptions for gene functions, protein function inference from its structure, and marker gene selection from spatial transcriptomic data. We demonstrate that adapted LLMs and MLLMs perform well for these tasks and may outperform closed-source large-scale models based on our evaluations focusing on both truthfulness and structural correctness. All of the training strategies and base models we used are freely accessible.
<div id='section'>Paperid: <span id='pid'>940, <a href='https://arxiv.org/pdf/2406.06419.pdf' target='_blank'>https://arxiv.org/pdf/2406.06419.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Berghaus, Kostadin Cvejoski, Patrick Seifner, Cesar Ojeda, Ramses J. Sanchez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.06419">Foundation Inference Models for Markov Jump Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Markov jump processes are continuous-time stochastic processes which describe dynamical systems evolving in discrete state spaces. These processes find wide application in the natural sciences and machine learning, but their inference is known to be far from trivial. In this work we introduce a methodology for zero-shot inference of Markov jump processes (MJPs), on bounded state spaces, from noisy and sparse observations, which consists of two components. First, a broad probability distribution over families of MJPs, as well as over possible observation times and noise mechanisms, with which we simulate a synthetic dataset of hidden MJPs and their noisy observation process. Second, a neural network model that processes subsets of the simulated observations, and that is trained to output the initial condition and rate matrix of the target MJP in a supervised way. We empirically demonstrate that one and the same (pretrained) model can infer, in a zero-shot fashion, hidden MJPs evolving in state spaces of different dimensionalities. Specifically, we infer MJPs which describe (i) discrete flashing ratchet systems, which are a type of Brownian motors, and the conformational dynamics in (ii) molecular simulations, (iii) experimental ion channel data and (iv) simple protein folding models. What is more, we show that our model performs on par with state-of-the-art models which are finetuned to the target datasets.
<div id='section'>Paperid: <span id='pid'>941, <a href='https://arxiv.org/pdf/2406.06397.pdf' target='_blank'>https://arxiv.org/pdf/2406.06397.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuta Nagano, Andrew Pyo, Martina Milighetti, James Henderson, John Shawe-Taylor, Benny Chain, Andreas Tiffeau-Mayer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.06397">Contrastive learning of T cell receptor representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational prediction of the interaction of T cell receptors (TCRs) and their ligands is a grand challenge in immunology. Despite advances in high-throughput assays, specificity-labelled TCR data remains sparse. In other domains, the pre-training of language models on unlabelled data has been successfully used to address data bottlenecks. However, it is unclear how to best pre-train protein language models for TCR specificity prediction. Here we introduce a TCR language model called SCEPTR (Simple Contrastive Embedding of the Primary sequence of T cell Receptors), capable of data-efficient transfer learning. Through our model, we introduce a novel pre-training strategy combining autocontrastive learning and masked-language modelling, which enables SCEPTR to achieve its state-of-the-art performance. In contrast, existing protein language models and a variant of SCEPTR pre-trained without autocontrastive learning are outperformed by sequence alignment-based methods. We anticipate that contrastive learning will be a useful paradigm to decode the rules of TCR specificity.
<div id='section'>Paperid: <span id='pid'>942, <a href='https://arxiv.org/pdf/2406.04739.pdf' target='_blank'>https://arxiv.org/pdf/2406.04739.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Miguel GonzÃ¡lez-Duque, Richard Michael, Simon Bartels, Yevgen Zainchkovskyy, SÃ¸ren Hauberg, Wouter Boomsma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04739">A survey and benchmark of high-dimensional Bayesian optimization of discrete sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optimizing discrete black-box functions is key in several domains, e.g. protein engineering and drug design. Due to the lack of gradient information and the need for sample efficiency, Bayesian optimization is an ideal candidate for these tasks. Several methods for high-dimensional continuous and categorical Bayesian optimization have been proposed recently. However, our survey of the field reveals highly heterogeneous experimental set-ups across methods and technical barriers for the replicability and application of published algorithms to real-world tasks. To address these issues, we develop a unified framework to test a vast array of high-dimensional Bayesian optimization methods and a collection of standardized black-box functions representing real-world application domains in chemistry and biology. These two components of the benchmark are each supported by flexible, scalable, and easily extendable software libraries (poli and poli-baselines), allowing practitioners to readily incorporate new optimization objectives or discrete optimizers. Project website: https://machinelearninglifescience.github.io/hdbo_benchmark
<div id='section'>Paperid: <span id='pid'>943, <a href='https://arxiv.org/pdf/2405.18986.pdf' target='_blank'>https://arxiv.org/pdf/2405.18986.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minji Lee, Luiz Felipe Vecchietti, Hyunkyu Jung, Hyun Joo Ro, Meeyoung Cha, Ho Min Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18986">Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are complex molecules responsible for different functions in nature. Enhancing the functionality of proteins and cellular fitness can significantly impact various industries. However, protein optimization using computational methods remains challenging, especially when starting from low-fitness sequences. We propose LatProtRL, an optimization method to efficiently traverse a latent space learned by an encoder-decoder leveraging a large protein language model. To escape local optima, our optimization is modeled as a Markov decision process using reinforcement learning acting directly in latent space. We evaluate our approach on two important fitness optimization tasks, demonstrating its ability to achieve comparable or superior fitness over baseline methods. Our findings and in vitro evaluation show that the generated sequences can reach high-fitness regions, suggesting a substantial potential of LatProtRL in lab-in-the-loop scenarios.
<div id='section'>Paperid: <span id='pid'>944, <a href='https://arxiv.org/pdf/2405.08699.pdf' target='_blank'>https://arxiv.org/pdf/2405.08699.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenrui Li, Wei Zhang, Qinghao Zhang, Xuegong Zhang, Xiaowo Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08699">Weakly-supervised causal discovery based on fuzzy knowledge and complex data complementarity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Causal discovery based on observational data is important for deciphering the causal mechanism behind complex systems. However, the effectiveness of existing causal discovery methods is limited due to inferior prior knowledge, domain inconsistencies, and the challenges of high-dimensional datasets with small sample sizes. To address this gap, we propose a novel weakly-supervised fuzzy knowledge and data co-driven causal discovery method named KEEL. KEEL adopts a fuzzy causal knowledge schema to encapsulate diverse types of fuzzy knowledge, and forms corresponding weakened constraints. This schema not only lessens the dependency on expertise but also allows various types of limited and error-prone fuzzy knowledge to guide causal discovery. It can enhance the generalization and robustness of causal discovery, especially in high-dimensional and small-sample scenarios. In addition, we integrate the extended linear causal model (ELCM) into KEEL for dealing with the multi-distribution and incomplete data. Extensive experiments with different datasets demonstrate the superiority of KEEL over several state-of-the-art methods in accuracy, robustness and computational efficiency. For causal discovery in real protein signal transduction processes, KEEL outperforms the benchmark method with limited data. In summary, KEEL is effective to tackle the causal discovery tasks with higher accuracy while alleviating the requirement for extensive domain expertise.
<div id='section'>Paperid: <span id='pid'>945, <a href='https://arxiv.org/pdf/2405.06657.pdf' target='_blank'>https://arxiv.org/pdf/2405.06657.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emanuele Triuzzi, Riccardo Mengoni, Francesco Micucci, Domenico Bonanni, Daniele Ottaviani, Andrea Beccari, Gianluca Palermo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06657">Molecular Docking via Weighted Subgraph Isomorphism on Quantum Annealers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking is an essential step in the drug discovery process involving the detection of three-dimensional poses of a ligand inside the active site of the protein. In this paper, we address the Molecular Docking search phase by formulating the problem in QUBO terms, suitable for an annealing approach. We propose a problem formulation as a weighted subgraph isomorphism between the ligand graph and the grid of the target protein pocket. In particular, we applied a graph representation to the ligand embedding all the geometrical properties of the molecule including its flexibility, and we created a weighted spatial grid to the 3D space region inside the pocket. Results and performance obtained with quantum annealers are compared with classical simulated annealing solvers.
<div id='section'>Paperid: <span id='pid'>946, <a href='https://arxiv.org/pdf/2405.02374.pdf' target='_blank'>https://arxiv.org/pdf/2405.02374.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arturo Fiorellini-Bernardis, Sebastien Boyer, Christoph Brunken, Bakary Diallo, Karim Beguir, Nicolas Lopez-Carranza, Oliver Bent
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02374">Protein binding affinity prediction under multiple substitutions applying eGNNs on Residue and Atomic graphs combined with Language model information: eGRAL</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interactions (PPIs) play a crucial role in numerous biological processes. Developing methods that predict binding affinity changes under substitution mutations is fundamental for modelling and re-engineering biological systems. Deep learning is increasingly recognized as a powerful tool capable of bridging the gap between in-silico predictions and in-vitro observations. With this contribution, we propose eGRAL, a novel SE(3) equivariant graph neural network (eGNN) architecture designed for predicting binding affinity changes from multiple amino acid substitutions in protein complexes. eGRAL leverages residue, atomic and evolutionary scales, thanks to features extracted from protein large language models. To address the limited availability of large-scale affinity assays with structural information, we generate a simulated dataset comprising approximately 500,000 data points. Our model is pre-trained on this dataset, then fine-tuned and tested on experimental data.
<div id='section'>Paperid: <span id='pid'>947, <a href='https://arxiv.org/pdf/2404.17041.pdf' target='_blank'>https://arxiv.org/pdf/2404.17041.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adith Jeyasangar, Abdullah Alsalemi, Shan E Ahmed Raza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17041">Nuclei-Location Based Point Set Registration of Multi-Stained Whole Slide Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Whole Slide Images (WSIs) provide exceptional detail for studying tissue architecture at the cell level. To study tumour microenvironment (TME) with the context of various protein biomarkers and cell sub-types, analysis and registration of features using multi-stained WSIs is often required. Multi-stained WSI pairs normally suffer from rigid and non-rigid deformities in addition to slide artefacts and control tissue which present challenges at precise registration. Traditional registration methods mainly focus on global rigid/non-rigid registration but struggle with aligning slides with complex tissue deformations at the nuclei level. However, nuclei level non-rigid registration is essential for downstream tasks such as cell sub-type analysis in the context of protein biomarker signatures. This paper focuses on local level non-rigid registration using a nuclei-location based point set registration approach for aligning multi-stained WSIs. We exploit the spatial distribution of nuclei that is prominent and consistent (to a large level) across different stains to establish a spatial correspondence. We evaluate our approach using the HYRECO dataset consisting of 54 re-stained images of H\&E and PHH3 image pairs. The approach can be extended to other IHC and IF stained WSIs considering a good nuclei detection algorithm is accessible. The performance of the model is tested against established registration algorithms and is shown to outperform the model for nuclei level registration.
<div id='section'>Paperid: <span id='pid'>948, <a href='https://arxiv.org/pdf/2404.12565.pdf' target='_blank'>https://arxiv.org/pdf/2404.12565.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>James Henderson, Yuta Nagano, Martina Milighetti, Andreas Tiffeau-Mayer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.12565">Limits on Inferring T-cell Specificity from Partial Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A key challenge in molecular biology is to decipher the mapping of protein sequence to function. To perform this mapping requires the identification of sequence features most informative about function. Here, we quantify the amount of information (in bits) that T-cell receptor (TCR) sequence features provide about antigen specificity. We identify informative features by their degree of conservation among antigen-specific receptors relative to null expectations. We find that TCR specificity synergistically depends on the hypervariable regions of both receptor chains, with a degree of synergy that strongly depends on the ligand. Using a coincidence-based approach to measuring information enables us to directly bound the accuracy with which TCR specificity can be predicted from partial matches to reference sequences. We anticipate that our statistical framework will be of use for developing machine learning models for TCR specificity prediction and for optimizing TCRs for cell therapies. The proposed coincidence-based information measures might find further applications in bounding the performance of pairwise classifiers in other fields.
<div id='section'>Paperid: <span id='pid'>949, <a href='https://arxiv.org/pdf/2404.10573.pdf' target='_blank'>https://arxiv.org/pdf/2404.10573.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lijun Liu, Jiali Yang, Jianfei Song, Xinglin Yang, Lele Niu, Zeqi Cai, Hui Shi, Tingjun Hou, Chang-yu Hsieh, Weiran Shen, Yafeng Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10573">AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recombinant adeno-associated virus (rAAV) vectors have revolutionized gene therapy, but their broad tropism and suboptimal transduction efficiency limit their clinical applications. To overcome these limitations, researchers have focused on designing and screening capsid libraries to identify improved vectors. However, the large sequence space and limited resources present challenges in identifying viable capsid variants. In this study, we propose an end-to-end diffusion model to generate capsid sequences with enhanced viability. Using publicly available AAV2 data, we generated 38,000 diverse AAV2 viral protein (VP) sequences, and evaluated 8,000 for viral selection. The results attested the superiority of our model compared to traditional methods. Additionally, in the absence of AAV9 capsid data, apart from one wild-type sequence, we used the same model to directly generate a number of viable sequences with up to 9 mutations. we transferred the remaining 30,000 samples to the AAV9 domain. Furthermore, we conducted mutagenesis on AAV9 VP hypervariable regions VI and V, contributing to the continuous improvement of the AAV9 VP sequence. This research represents a significant advancement in the design and functional validation of rAAV vectors, offering innovative solutions to enhance specificity and transduction efficiency in gene therapy applications.
<div id='section'>Paperid: <span id='pid'>950, <a href='https://arxiv.org/pdf/2403.01158.pdf' target='_blank'>https://arxiv.org/pdf/2403.01158.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seungwon Kim, D. ChangMo Yang, Soohaeng Yoo Willow, Chang Woo Myung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01158">A Bayesian Committee Machine Potential for Oxygen-containing Organic Compounds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the pivotal role of oxygen-containing organic compounds in serving as an energy source for living organisms and contributing to protein formation is crucial in the field of biochemistry. This study addresses the challenge of comprehending protein-protein interactions (PPI) and developing predicitive models for proteins and organic compounds, with a specific focus on quantifying their binding affinity. Here, we introduce the active Bayesian Committee Machine (BCM) potential, specifically designed to predict oxygen-containing organic compounds within eight groups of CHO. The BCM potential adopts a committee-based approach to tackle scalability issues associated with kernel regressors, particularly when dealing with large datasets. Its adaptable structure allows for efficient and cost-effective expansion, maintaing both transferability and scalability. Through systematic benchmarking, we position the sparse BCM potential as a promising contender in the pursuit of a universal machine learning potential.
<div id='section'>Paperid: <span id='pid'>951, <a href='https://arxiv.org/pdf/2402.15020.pdf' target='_blank'>https://arxiv.org/pdf/2402.15020.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Creston Brooks, Robert Calef, Charlie Cowen-Breen, Anna Sappington
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.15020">Towards Probabilistically-Sound Beam Search with Masked Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Beam search with masked language models (MLMs) is challenging in part because joint probability distributions over sequences are not readily available, unlike for autoregressive models. However, estimating such distributions has important domain-specific applications such as ancient text restoration and protein engineering. Here we present probabilistically-sound methods for beam search with MLMs. First, we clarify the conditions under which it is theoretically sound to perform text infilling with MLMs using standard beam search. When these conditions fail, we provide a probabilistically-sound inference time modification with no additional computational complexity and demonstrate that it is superior to the aforementioned beam search in the expected conditions. We then present empirical results comparing several infilling approaches with MLMs across several domains. Notably, our method probes the inductive biases of MLMs and explores the surprising contextual sensitivity of mask tokens for text infilling.
<div id='section'>Paperid: <span id='pid'>952, <a href='https://arxiv.org/pdf/2402.07631.pdf' target='_blank'>https://arxiv.org/pdf/2402.07631.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xue Gong, Desmond J. Higham, Konstantinos Zygalakis, Ginestra Bianconi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07631">Higher-order Connection Laplacians for Directed Simplicial Complexes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Higher-order networks encode the many-body interactions existing in complex systems, such as the brain, protein complexes, and social interactions. Simplicial complexes are higher-order networks that allow a comprehensive investigation of the interplay between topology and dynamics. However, simplicial complexes have the limitation that they only capture undirected higher-order interactions while in real-world scenarios, often there is a need to introduce the direction of simplices, extending the popular notion of direction of edges. On graphs and networks the Magnetic Laplacian, a special case of Connection Laplacian, is becoming a popular operator to treat edge directionality. Here we tackle the challenge of treating directional simplicial complexes by formulating Higher-order Connection Laplacians taking into account the configurations induced by the simplices' directions. Specifically, we define all the Connection Laplacians of directed simplicial complexes of dimension two and we discuss the induced higher-order diffusion dynamics by considering instructive synthetic examples of simplicial complexes. The proposed higher-order diffusion processes can be adopted in real scenarios when we want to consider higher-order diffusion displaying non-trivial frustration effects due to conflicting directionalities of the incident simplices.
<div id='section'>Paperid: <span id='pid'>953, <a href='https://arxiv.org/pdf/2402.01744.pdf' target='_blank'>https://arxiv.org/pdf/2402.01744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Salvatore Contino, Paolo Sortino, Maria Rita Gulotta, Ugo Perricone, Roberto Pirrone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01744">Unveiling Molecular Moieties through Hierarchical Grad-CAM Graph Explainability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: Virtual Screening (VS) has become an essential tool in drug discovery, enabling the rapid and cost-effective identification of potential bioactive molecules. Among recent advancements, Graph Neural Networks (GNNs) have gained prominence for their ability to model complex molecular structures using graph-based representations. However, the integration of explainable methods to elucidate the specific contributions of molecular substructures to biological activity remains a significant challenge. This limitation hampers both the interpretability of predictive models and the rational design of novel therapeutics. Results: We trained 20 GNN models on a dataset of small molecules with the goal of predicting their activity on 20 distinct protein targets from the Kinase family. These classifiers achieved state-of-the-art performance in virtual screening tasks, demonstrating high accuracy and robustness on different targets. Building upon these models, we implemented the Hierarchical Grad-CAM graph Explainer (HGE) framework, enabling an in-depth analysis of the molecular moieties driving protein-ligand binding stabilization. HGE exploits Grad-CAM explanations at the atom, ring, and whole-molecule levels, leveraging the message-passing mechanism to highlight the most relevant chemical moieties. Validation against experimental data from the literature confirmed the ability of the explainer to recognize a molecular pattern of drugs and correctly annotate them to the known target. Conclusion: Our approach may represent a valid support to shorten both the screening and the hit discovery process. Detailed knowledge of the molecular substructures that play a role in the binding process can help the computational chemist to gain insights into the structure optimization, as well as in drug repurposing tasks.
<div id='section'>Paperid: <span id='pid'>954, <a href='https://arxiv.org/pdf/2401.09840.pdf' target='_blank'>https://arxiv.org/pdf/2401.09840.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Telepov, Artem Tsypin, Kuzma Khrabrov, Sergey Yakukhnov, Pavel Strashnov, Petr Zhilyaev, Egor Rumiantsev, Daniel Ezhov, Manvel Avetisian, Olga Popova, Artur Kadurin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.09840">FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (arXiv:2110.01219). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches.
<div id='section'>Paperid: <span id='pid'>955, <a href='https://arxiv.org/pdf/2401.08519.pdf' target='_blank'>https://arxiv.org/pdf/2401.08519.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanbang Wang, Jon Kleinberg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08519">From Graphs to Hypergraphs: Hypergraph Projection and its Remediation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the implications of the modeling choice to use a graph, instead of a hypergraph, to represent real-world interconnected systems whose constituent relationships are of higher order by nature. Such a modeling choice typically involves an underlying projection process that maps the original hypergraph onto a graph, and is common in graph-based analysis. While hypergraph projection can potentially lead to loss of higher-order relations, there exists very limited studies on the consequences of doing so, as well as its remediation. This work fills this gap by doing two things: (1) we develop analysis based on graph and set theory, showing two ubiquitous patterns of hyperedges that are root to structural information loss in all hypergraph projections; we also quantify the combinatorial impossibility of recovering the lost higher-order structures if no extra help is provided; (2) we still seek to recover the lost higher-order structures in hypergraph projection, and in light of (1)'s findings we propose to relax the problem into a learning-based setting. Under this setting, we develop a learning-based hypergraph reconstruction method based on an important statistic of hyperedge distributions that we find. Our reconstruction method is evaluated on 8 real-world datasets under different settings, and exhibits consistently good performance. We also demonstrate benefits of the reconstructed hypergraphs via use cases of protein rankings and link predictions.
<div id='section'>Paperid: <span id='pid'>956, <a href='https://arxiv.org/pdf/2312.08987.pdf' target='_blank'>https://arxiv.org/pdf/2312.08987.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junbo Shen, Qinze Yu, Shenyang Chen, Qingxiong Tan, Jingcheng Li, Yu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.08987">Unbiased organism-agnostic and highly sensitive signal peptide predictor with deep protein language model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Signal peptide (SP) is a short peptide located in the N-terminus of proteins. It is essential to target and transfer transmembrane and secreted proteins to correct positions. Compared with traditional experimental methods to identify signal peptides, computational methods are faster and more efficient, which are more practical for analyzing thousands or even millions of protein sequences, especially for metagenomic data. Here we present Unbiased Organism-agnostic Signal Peptide Network (USPNet), a signal peptide classification and cleavage site prediction deep learning method that takes advantage of protein language models. We propose to apply label distribution-aware margin loss to handle data imbalance problems and use evolutionary information of protein to enrich representation and overcome species information dependence.
<div id='section'>Paperid: <span id='pid'>957, <a href='https://arxiv.org/pdf/2311.13729.pdf' target='_blank'>https://arxiv.org/pdf/2311.13729.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shashank Gupta, Xuguang Ai, Ramakanth Kavuluru
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13729">Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>End-to-end relation extraction (E2ERE) is an important and realistic application of natural language processing (NLP) in biomedicine. In this paper, we aim to compare three prevailing paradigms for E2ERE using a complex dataset focused on rare diseases involving discontinuous and nested entities. We use the RareDis information extraction dataset to evaluate three competing approaches (for E2ERE): NER $\rightarrow$ RE pipelines, joint sequence to sequence models, and generative pre-trained transformer (GPT) models. We use comparable state-of-the-art models and best practices for each of these approaches and conduct error analyses to assess their failure modes. Our findings reveal that pipeline models are still the best, while sequence-to-sequence models are not far behind; GPT models with eight times as many parameters are worse than even sequence-to-sequence models and lose to pipeline models by over 10 F1 points. Partial matches and discontinuous entities caused many NER errors contributing to lower overall E2E performances. We also verify these findings on a second E2ERE dataset for chemical-protein interactions. Although generative LM-based methods are more suitable for zero-shot settings, when training data is available, our results show that it is better to work with more conventional models trained and tailored for E2ERE. More innovative methods are needed to marry the best of the both worlds from smaller encoder-decoder pipeline models and the larger GPT models to improve E2ERE. As of now, we see that well designed pipeline models offer substantial performance gains at a lower cost and carbon footprint for E2ERE. Our contribution is also the first to conduct E2ERE for the RareDis dataset.
<div id='section'>Paperid: <span id='pid'>958, <a href='https://arxiv.org/pdf/2311.13466.pdf' target='_blank'>https://arxiv.org/pdf/2311.13466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ian Dunn, David Ryan Koes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13466">Accelerating Inference in Molecular Diffusion Models with Latent Representations of Protein Structure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion generative models have emerged as a powerful framework for addressing problems in structural biology and structure-based drug design. These models operate directly on 3D molecular structures. Due to the unfavorable scaling of graph neural networks (GNNs) with graph size as well as the relatively slow inference speeds inherent to diffusion models, many existing molecular diffusion models rely on coarse-grained representations of protein structure to make training and inference feasible. However, such coarse-grained representations discard essential information for modeling molecular interactions and impair the quality of generated structures. In this work, we present a novel GNN-based architecture for learning latent representations of molecular structure. When trained end-to-end with a diffusion model for de novo ligand design, our model achieves comparable performance to one with an all-atom protein representation while exhibiting a 3-fold reduction in inference time.
<div id='section'>Paperid: <span id='pid'>959, <a href='https://arxiv.org/pdf/2311.09767.pdf' target='_blank'>https://arxiv.org/pdf/2311.09767.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Renjie Li, Yuanhao Gong, Hai Huang, Yuze Zhou, Sixuan Mao, Zhijian Wei, Zhaoyu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.09767">Photonics for Neuromorphic Computing: Fundamentals, Devices, and Opportunities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the dynamic landscape of Artificial Intelligence (AI), two notable phenomena are becoming predominant: the exponential growth of large AI model sizes and the explosion of massive amount of data. Meanwhile, scientific research such as quantum computing and protein synthesis increasingly demand higher computing capacities. Neuromorphic computing, inspired by the mechanism and functionality of human brains, uses physical artificial neurons to do computations and is drawing widespread attention. Conventional electronic computing has experienced certain difficulties, particularly concerning the latency, crosstalk, and energy consumption of digital processors. As the Moore's law approaches its terminus, there is a urgent need for alternative computing architectures that can satisfy this growing computing demand and break through the von Neumann model. Recently, the expansion of optoelectronic devices on photonic integration platforms has led to significant growth in photonic computing, where photonic integrated circuits (PICs) have enabled ultrafast artificial neural networks (ANN) with sub-nanosecond latencies, low heat dissipation, and high parallelism. Such non-von Neumann photonic computing systems hold the promise to cater to the escalating requirements of AI and scientific computing. In this review, we study recent advancements in integrated photonic neuromorphic systems, and from the perspective of materials and device engineering, we lay out the scientific and technological breakthroughs necessary to advance the state-of-the-art. In particular, we examine various technologies and devices employed in neuromorphic photonic AI accelerators, spanning from traditional optics to PICs. We evaluate the performances of different designs by energy efficiency in operations per joule (OP/J) and compute density in operations per squared millimeter per ...
<div id='section'>Paperid: <span id='pid'>960, <a href='https://arxiv.org/pdf/2311.04042.pdf' target='_blank'>https://arxiv.org/pdf/2311.04042.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ole-Christian Galbo EngstrÃ¸m, Erik Schou Dreier, Birthe MÃ¸ller Jespersen, Kim Steenstrup Pedersen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.04042">Analyzing Near-Infrared Hyperspectral Imaging for Protein Content Regression and Grain Variety Classification Using Bulk References and Varying Grain-to-Background Ratios</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Based on previous work, we assess the use of NIR-HSI images for calibrating models on two datasets, focusing on protein content regression and grain variety classification. Limited reference data for protein content is expanded by subsampling and associating it with the bulk sample. However, this method introduces significant biases due to skewed leptokurtic prediction distributions, affecting both PLS-R and deep CNN models. We propose adjustments to mitigate these biases, improving mean protein reference predictions. Additionally, we investigate the impact of grain-to-background ratios on both tasks. Higher ratios yield more accurate predictions, but including lower-ratio images in calibration enhances model robustness for such scenarios.
<div id='section'>Paperid: <span id='pid'>961, <a href='https://arxiv.org/pdf/2311.03429.pdf' target='_blank'>https://arxiv.org/pdf/2311.03429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huixin Zhan, Zijun Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.03429">ProPath: Disease-Specific Protein Language Model for Variant Pathogenicity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clinical variant classification of pathogenic versus benign genetic variants remains a pivotal challenge in clinical genetics. Recently, the proposition of protein language models has improved the generic variant effect prediction (VEP) accuracy via weakly-supervised or unsupervised training. However, these VEPs are not disease-specific, limiting their adaptation at point-of-care. To address this problem, we propose a disease-specific \textsc{pro}tein language model for variant \textsc{path}ogenicity, termed ProPath, to capture the pseudo-log-likelihood ratio in rare missense variants through a siamese network. We evaluate the performance of ProPath against pre-trained language models, using clinical variant sets in inherited cardiomyopathies and arrhythmias that were not seen during training. Our results demonstrate that ProPath surpasses the pre-trained ESM1b with an over $5\%$ improvement in AUC across both datasets. Furthermore, our model achieved the highest performances across all baselines for both datasets. Thus, our ProPath offers a potent disease-specific variant effect prediction, particularly valuable for disease associations and clinical applicability.
<div id='section'>Paperid: <span id='pid'>962, <a href='https://arxiv.org/pdf/2310.19849.pdf' target='_blank'>https://arxiv.org/pdf/2310.19849.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiwei Liu, Tian Zhu, Milong Ren, Chungong Yu, Dongbo Bu, Haicang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19849">Predicting mutational effects on protein-protein binding via a side-chain diffusion probabilistic model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many crucial biological processes rely on networks of protein-protein interactions. Predicting the effect of amino acid mutations on protein-protein binding is vital in protein engineering and therapeutic discovery. However, the scarcity of annotated experimental data on binding energy poses a significant challenge for developing computational approaches, particularly deep learning-based methods. In this work, we propose SidechainDiff, a representation learning-based approach that leverages unlabelled experimental protein structures. SidechainDiff utilizes a Riemannian diffusion model to learn the generative process of side-chain conformations and can also give the structural context representations of mutations on the protein-protein interface. Leveraging the learned representations, we achieve state-of-the-art performance in predicting the mutational effects on protein-protein binding. Furthermore, SidechainDiff is the first diffusion-based generative model for side-chains, distinguishing it from prior efforts that have predominantly focused on generating protein backbone structures.
<div id='section'>Paperid: <span id='pid'>963, <a href='https://arxiv.org/pdf/2310.19624.pdf' target='_blank'>https://arxiv.org/pdf/2310.19624.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuang Peng, Fei Yang, Ning Sun, Sheng Chen, Yanfeng Jiang, Aimin Pan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19624">Exploring Post-Training Quantization of Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in unsupervised protein language models (ProteinLMs), like ESM-1b and ESM-2, have shown promise in different protein prediction tasks. However, these models face challenges due to their high computational demands, significant memory needs, and latency, restricting their usage on devices with limited resources. To tackle this, we explore post-training quantization (PTQ) for ProteinLMs, focusing on ESMFold, a simplified version of AlphaFold based on ESM-2 ProteinLM. Our study is the first attempt to quantize all weights and activations of ProteinLMs. We observed that the typical uniform quantization method performs poorly on ESMFold, causing a significant drop in TM-Score when using 8-bit quantization. We conducted extensive quantization experiments, uncovering unique challenges associated with ESMFold, particularly highly asymmetric activation ranges before Layer Normalization, making representation difficult using low-bit fixed-point formats. To address these challenges, we propose a new PTQ method for ProteinLMs, utilizing piecewise linear quantization for asymmetric activation values to ensure accurate approximation. We demonstrated the effectiveness of our method in protein structure prediction tasks, demonstrating that ESMFold can be accurately quantized to low-bit widths without compromising accuracy. Additionally, we applied our method to the contact prediction task, showcasing its versatility. In summary, our study introduces an innovative PTQ method for ProteinLMs, addressing specific quantization challenges and potentially leading to the development of more efficient ProteinLMs with significant implications for various protein-related applications.
<div id='section'>Paperid: <span id='pid'>964, <a href='https://arxiv.org/pdf/2310.10605.pdf' target='_blank'>https://arxiv.org/pdf/2310.10605.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Ni, David L. Kaplan, Markus J. Buehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.10605">ForceGen: End-to-end de novo protein generation based on nonlinear mechanical unfolding responses using a protein language diffusion model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Through evolution, nature has presented a set of remarkable protein materials, including elastins, silks, keratins and collagens with superior mechanical performances that play crucial roles in mechanobiology. However, going beyond natural designs to discover proteins that meet specified mechanical properties remains challenging. Here we report a generative model that predicts protein designs to meet complex nonlinear mechanical property-design objectives. Our model leverages deep knowledge on protein sequences from a pre-trained protein language model and maps mechanical unfolding responses to create novel proteins. Via full-atom molecular simulations for direct validation, we demonstrate that the designed proteins are novel, and fulfill the targeted mechanical properties, including unfolding energy and mechanical strength, as well as the detailed unfolding force-separation curves. Our model offers rapid pathways to explore the enormous mechanobiological protein sequence space unconstrained by biological synthesis, using mechanical features as target to enable the discovery of protein materials with superior mechanical properties.
<div id='section'>Paperid: <span id='pid'>965, <a href='https://arxiv.org/pdf/2310.07682.pdf' target='_blank'>https://arxiv.org/pdf/2310.07682.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kshitij Ingale, Sun Hae Hong, Josh S. K. Bell, Abbas Rizvi, Amy Welch, Lingdao Sha, Irvin Ho, Kunal Nagpal, Aicha BenTaieb, Rohan P Joshi, Martin C Stumpe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.07682">Prediction of MET Overexpression in Non-Small Cell Lung Adenocarcinomas from Hematoxylin and Eosin Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>MET protein overexpression is a targetable event in non-small cell lung cancer (NSCLC) and is the subject of active drug development. Challenges in identifying patients for these therapies include lack of access to validated testing, such as standardized immunohistochemistry (IHC) assessment, and consumption of valuable tissue for a single gene/protein assay. Development of pre-screening algorithms using routinely available digitized hematoxylin and eosin (H&E)-stained slides to predict MET overexpression could promote testing for those who will benefit most. While assessment of MET expression using IHC is currently not routinely performed in NSCLC, next-generation sequencing is common and in some cases includes RNA expression panel testing. In this work, we leveraged a large database of matched H&E slides and RNA expression data to train a weakly supervised model to predict MET RNA overexpression directly from H&E images. This model was evaluated on an independent holdout test set of 300 over-expressed and 289 normal patients, demonstrating an ROC-AUC of 0.70 (95th percentile interval: 0.66 - 0.74) with stable performance characteristics across different patient clinical variables and robust to synthetic noise on the test set. These results suggest that H&E-based predictive models could be useful to prioritize patients for confirmatory testing of MET protein or MET gene expression status.
<div id='section'>Paperid: <span id='pid'>966, <a href='https://arxiv.org/pdf/2310.03812.pdf' target='_blank'>https://arxiv.org/pdf/2310.03812.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>T. Lucas Makinen, Justin Alsing, Benjamin D. Wandelt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03812">Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Set-based learning is an essential component of modern deep learning and network science. Graph Neural Networks (GNNs) and their edge-free counterparts Deepsets have proven remarkably useful on ragged and topologically challenging datasets. The key to learning informative embeddings for set members is a specified aggregation function, usually a sum, max, or mean. We propose Fishnets, an aggregation strategy for learning information-optimal embeddings for sets of data for both Bayesian inference and graph aggregation. We demonstrate that i) Fishnets neural summaries can be scaled optimally to an arbitrary number of data objects, ii) Fishnets aggregations are robust to changes in data distribution, unlike standard deepsets, iii) Fishnets saturate Bayesian information content and extend to regimes where MCMC techniques fail and iv) Fishnets can be used as a drop-in aggregation scheme within GNNs. We show that by adopting a Fishnets aggregation scheme for message passing, GNNs can achieve state-of-the-art performance versus architecture size on ogbn-protein data over existing benchmarks with a fraction of learnable parameters and faster training time.
<div id='section'>Paperid: <span id='pid'>967, <a href='https://arxiv.org/pdf/2310.02902.pdf' target='_blank'>https://arxiv.org/pdf/2310.02902.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Raj Ghugare, Santiago Miret, Adriana Hugessen, Mariano Phielipp, Glen Berseth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02902">Searching for High-Value Molecules Using Reinforcement Learning and Transformers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement learning (RL) over text representations can be effective for finding high-value policies that can search over graphs. However, RL requires careful structuring of the search space and algorithm design to be effective in this challenge. Through extensive experiments, we explore how different design choices for text grammar and algorithmic choices for training can affect an RL policy's ability to generate molecules with desired properties. We arrive at a new RL-based molecular design algorithm (ChemRLformer) and perform a thorough analysis using 25 molecule design tasks, including computationally complex protein docking simulations. From this analysis, we discover unique insights in this problem space and show that ChemRLformer achieves state-of-the-art performance while being more straightforward than prior work by demystifying which design choices are actually helpful for text-based molecule design.
<div id='section'>Paperid: <span id='pid'>968, <a href='https://arxiv.org/pdf/2309.10170.pdf' target='_blank'>https://arxiv.org/pdf/2309.10170.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Lu, David L. Kaplan, Markus J. Buehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.10170">Generative modeling, design and analysis of spider silk protein sequences for enhanced mechanical properties</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spider silks are remarkable materials characterized by superb mechanical properties such as strength, extensibility and lightweightedness. Yet, to date, limited models are available to fully explore sequence-property relationships for analysis and design. Here we propose a custom generative large-language model to enable design of novel spider silk protein sequences to meet complex combinations of target mechanical properties. The model, pretrained on a large set of protein sequences, is fine-tuned on ~1,000 major ampullate spidroin (MaSp) sequences for which associated fiber-level mechanical properties exist, to yield an end-to-end forward and inverse generative strategy. Performance is assessed through: (1), a novelty analysis and protein type classification for generated spidroin sequences through BLAST searches, (2) property evaluation and comparison with similar sequences, (3) comparison of molecular structures, as well as, and (4) a detailed sequence motif analyses. We generate silk sequences with property combinations that do not exist in nature, and develop a deep understanding the mechanistic roles of sequence patterns in achieving overarching key mechanical properties (elastic modulus, strength, toughness, failure strain). The model provides an efficient approach to expand the silkome dataset, facilitating further sequence-structure analyses of silks, and establishes a foundation for synthetic silk design and optimization.
<div id='section'>Paperid: <span id='pid'>969, <a href='https://arxiv.org/pdf/2309.09609.pdf' target='_blank'>https://arxiv.org/pdf/2309.09609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manuel Costanzo, Enzo Rucci, Carlos GarcÃ­a SÃ¡nchez, Marcelo Naiouf, Manuel Prieto-MatÃ­as
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.09609">Comparing Performance and Portability between CUDA and SYCL for Protein Database Search on NVIDIA, AMD, and Intel GPUs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The heterogeneous computing paradigm has led to the need for portable and efficient programming solutions that can leverage the capabilities of various hardware devices, such as NVIDIA, Intel, and AMD GPUs. This study evaluates the portability and performance of the SYCL and CUDA languages for one fundamental bioinformatics application (Smith-Waterman protein database search) across different GPU architectures, considering single and multi-GPU configurations from different vendors. The experimental work showed that, while both CUDA and SYCL versions achieve similar performance on NVIDIA devices, the latter demonstrated remarkable code portability to other GPU architectures, such as AMD and Intel. Furthermore, the architectural efficiency rates achieved on these devices were superior in 3 of the 4 cases tested. This brief study highlights the potential of SYCL as a viable solution for achieving both performance and portability in the heterogeneous computing ecosystem.
<div id='section'>Paperid: <span id='pid'>970, <a href='https://arxiv.org/pdf/2309.09191.pdf' target='_blank'>https://arxiv.org/pdf/2309.09191.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vijay Arvind. R, Haribharathi Sivakumar, Brindha. R
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.09191">End-to-End Optimized Pipeline for Prediction of Protein Folding Kinetics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein folding is the intricate process by which a linear sequence of amino acids self-assembles into a unique three-dimensional structure. Protein folding kinetics is the study of pathways and time-dependent mechanisms a protein undergoes when it folds. Understanding protein kinetics is essential as a protein needs to fold correctly for it to perform its biological functions optimally, and a misfolded protein can sometimes be contorted into shapes that are not ideal for a cellular environment giving rise to many degenerative, neuro-degenerative disorders and amyloid diseases. Monitoring at-risk individuals and detecting protein discrepancies in a protein's folding kinetics at the early stages could majorly result in public health benefits, as preventive measures can be taken. This research proposes an efficient pipeline for predicting protein folding kinetics with high accuracy and low memory footprint. The deployed machine learning (ML) model outperformed the state-of-the-art ML models by 4.8% in terms of accuracy while consuming 327x lesser memory and being 7.3% faster.
<div id='section'>Paperid: <span id='pid'>971, <a href='https://arxiv.org/pdf/2309.01384.pdf' target='_blank'>https://arxiv.org/pdf/2309.01384.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanyuan Wei, Sai Mu Dalike Abaxi, Nawaz Mehmood, Luoquan Li, Fuyang Qu, Guangyao Cheng, Dehua Hu, Yi-Ping Ho, Scott Wu Yuan, Ho-Pui Ho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.01384">Deep Learning Approach for Large-Scale, Real-Time Quantification of Green Fluorescent Protein-Labeled Biological Samples in Microreactors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Absolute quantification of biological samples entails determining expression levels in precise numerical copies, offering enhanced accuracy and superior performance for rare templates. However, existing methodologies suffer from significant limitations: flow cytometers are both costly and intricate, while fluorescence imaging relying on software tools or manual counting is time-consuming and prone to inaccuracies. In this study, we have devised a comprehensive deep-learning-enabled pipeline that enables the automated segmentation and classification of GFP (green fluorescent protein)-labeled microreactors, facilitating real-time absolute quantification. Our findings demonstrate the efficacy of this technique in accurately predicting the sizes and occupancy status of microreactors using standard laboratory fluorescence microscopes, thereby providing precise measurements of template concentrations. Notably, our approach exhibits an analysis speed of quantifying over 2,000 microreactors (across 10 images) within remarkably 2.5 seconds, and a dynamic range spanning from 56.52 to 1569.43 copies per micron-liter. Furthermore, our Deep-dGFP algorithm showcases remarkable generalization capabilities, as it can be directly applied to various GFP-labeling scenarios, including droplet-based, microwell-based, and agarose-based biological applications. To the best of our knowledge, this represents the first successful implementation of an all-in-one image analysis algorithm in droplet digital PCR (polymerase chain reaction), microwell digital PCR, droplet single-cell sequencing, agarose digital PCR, and bacterial quantification, without necessitating any transfer learning steps, modifications, or retraining procedures. We firmly believe that our Deep-dGFP technique will be readily embraced by biomedical laboratories and holds potential for further development in related clinical applications.
<div id='section'>Paperid: <span id='pid'>972, <a href='https://arxiv.org/pdf/2309.00408.pdf' target='_blank'>https://arxiv.org/pdf/2309.00408.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bobak Pezeshki, Radu Marinescu, Alexander Ihler, Rina Dechter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.00408">Boosting AND/OR-Based Computational Protein Design: Dynamic Heuristics and Generalizable UFO</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific computing has experienced a surge empowered by advancements in technologies such as neural networks. However, certain important tasks are less amenable to these technologies, benefiting from innovations to traditional inference schemes. One such task is protein re-design. Recently a new re-design algorithm, AOBB-K*, was introduced and was competitive with state-of-the-art BBK* on small protein re-design problems. However, AOBB-K* did not scale well. In this work we focus on scaling up AOBB-K* and introduce three new versions: AOBB-K*-b (boosted), AOBB-K*-DH (with dynamic heuristics), and AOBB-K*-UFO (with underflow optimization) that significantly enhance scalability.
<div id='section'>Paperid: <span id='pid'>973, <a href='https://arxiv.org/pdf/2308.16744.pdf' target='_blank'>https://arxiv.org/pdf/2308.16744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohsen Koohi Esfahani, Paolo Boldi, Hans Vandierendonck, Peter Kilpatrick, Sebastiano Vigna
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16744">MS-BioGraphs: Sequence Similarity Graph Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Progress in High-Performance Computing in general, and High-Performance Graph Processing in particular, is highly dependent on the availability of publicly-accessible, relevant, and realistic data sets.
  To ensure continuation of this progress, we (i) investigate and optimize the process of generating large sequence similarity graphs as an HPC challenge and (ii) demonstrate this process in creating MS-BioGraphs, a new family of publicly available real-world edge-weighted graph datasets with up to $2.5$ trillion edges, that is, $6.6$ times greater than the largest graph published recently. The largest graph is created by matching (i.e., all-to-all similarity aligning) $1.7$ billion protein sequences. The MS-BioGraphs family includes also seven subgraphs with different sizes and direction types.
  We describe two main challenges we faced in generating large graph datasets and our solutions, that are, (i) optimizing data structures and algorithms for this multi-step process and (ii) WebGraph parallel compression technique. We present a comparative study of structural characteristics of MS-BioGraphs.
  The datasets are available online on https://blogs.qub.ac.uk/DIPSA/MS-BioGraphs .
<div id='section'>Paperid: <span id='pid'>974, <a href='https://arxiv.org/pdf/2308.08561.pdf' target='_blank'>https://arxiv.org/pdf/2308.08561.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Zhou, Yan Shing Liang, Yew Kee Wong, Haichuan Qiu, Yu Xi Wu, Bin He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08561">Implementation of The Future of Drug Discovery: QuantumBased Machine Learning Simulation (QMLS)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Research & Development (R&D) phase of drug development is a lengthy and costly process. To revolutionize this process, we introduce our new concept QMLS to shorten the whole R&D phase to three to six months and decrease the cost to merely fifty to eighty thousand USD. For Hit Generation, Machine Learning Molecule Generation (MLMG) generates possible hits according to the molecular structure of the target protein while the Quantum Simulation (QS) filters molecules from the primary essay based on the reaction and binding effectiveness with the target protein. Then, For Lead Optimization, the resultant molecules generated and filtered from MLMG and QS are compared, and molecules that appear as a result of both processes will be made into dozens of molecular variations through Machine Learning Molecule Variation (MLMV), while others will only be made into a few variations. Lastly, all optimized molecules would undergo multiple rounds of QS filtering with a high standard for reaction effectiveness and safety, creating a few dozen pre-clinical-trail-ready drugs. This paper is based on our first paper, where we pitched the concept of machine learning combined with quantum simulations. In this paper we will go over the detailed design and framework of QMLS, including MLMG, MLMV, and QS.
<div id='section'>Paperid: <span id='pid'>975, <a href='https://arxiv.org/pdf/2308.07818.pdf' target='_blank'>https://arxiv.org/pdf/2308.07818.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Willem Diepeveen, Carlos Esteve-YagÃ¼e, Jan Lellmann, Ozan Ãktem, Carola-Bibiane SchÃ¶nlieb
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07818">Riemannian geometry for efficient analysis of protein dynamics data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An increasingly common viewpoint is that protein dynamics data sets reside in a non-linear subspace of low conformational energy. Ideal data analysis tools for such data sets should therefore account for such non-linear geometry. The Riemannian geometry setting can be suitable for a variety of reasons. First, it comes with a rich structure to account for a wide range of geometries that can be modelled after an energy landscape. Second, many standard data analysis tools initially developed for data in Euclidean space can also be generalised to data on a Riemannian manifold. In the context of protein dynamics, a conceptual challenge comes from the lack of a suitable smooth manifold and the lack of guidelines for constructing a smooth Riemannian structure based on an energy landscape. In addition, computational feasibility in computing geodesics and related mappings poses a major challenge. This work considers these challenges. The first part of the paper develops a novel local approximation technique for computing geodesics and related mappings on Riemannian manifolds in a computationally feasible manner. The second part constructs a smooth manifold of point clouds modulo rigid body group actions and a Riemannian structure that is based on an energy landscape for protein conformations. The resulting Riemannian geometry is tested on several data analysis tasks relevant for protein dynamics data. It performs exceptionally well on coarse-grained molecular dynamics simulated data. In particular, the geodesics with given start- and end-points approximately recover corresponding molecular dynamics trajectories for proteins that undergo relatively ordered transitions with medium sized deformations. The Riemannian protein geometry also gives physically realistic summary statistics and retrieves the underlying dimension even for large-sized deformations within seconds on a laptop.
<div id='section'>Paperid: <span id='pid'>976, <a href='https://arxiv.org/pdf/2308.05326.pdf' target='_blank'>https://arxiv.org/pdf/2308.05326.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gustaf Ahdritz, Nazim Bouatta, Sachin Kadyan, Lukas Jarosch, Daniel Berenberg, Ian Fisk, Andrew M. Watkins, Stephen Ra, Richard Bonneau, Mohammed AlQuraishi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.05326">OpenProteinSet: Training data for structural biology at scale</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiple sequence alignments (MSAs) of proteins encode rich biological information and have been workhorses in bioinformatic methods for tasks like protein design and protein structure prediction for decades. Recent breakthroughs like AlphaFold2 that use transformers to attend directly over large quantities of raw MSAs have reaffirmed their importance. Generation of MSAs is highly computationally intensive, however, and no datasets comparable to those used to train AlphaFold2 have been made available to the research community, hindering progress in machine learning for proteins. To remedy this problem, we introduce OpenProteinSet, an open-source corpus of more than 16 million MSAs, associated structural homologs from the Protein Data Bank, and AlphaFold2 protein structure predictions. We have previously demonstrated the utility of OpenProteinSet by successfully retraining AlphaFold2 on it. We expect OpenProteinSet to be broadly useful as training and validation data for 1) diverse tasks focused on protein structure, function, and design and 2) large-scale multimodal machine learning research.
<div id='section'>Paperid: <span id='pid'>977, <a href='https://arxiv.org/pdf/2308.05125.pdf' target='_blank'>https://arxiv.org/pdf/2308.05125.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mamata Das, Selvakumar K., P. J. A. Alphonse
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.05125">Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The capacity to identify and analyze protein-protein interactions, along with their internal modular organization, plays a crucial role in comprehending the intricate mechanisms underlying biological processes at the molecular level. We can learn a lot about the structure and dynamics of these interactions by using network analysis. We can improve our understanding of the biological roots of disease pathogenesis by recognizing network communities. This knowledge, in turn, holds significant potential for driving advancements in drug discovery and facilitating personalized medicine approaches for disease treatment. In this study, we aimed to uncover the communities within the variant B.1.1.529 (Omicron virus) using two proposed novel algorithm (ABCDE and ALCDE) and four widely recognized algorithms: Girvan-Newman, Louvain, Leiden, and Label Propagation algorithm. Each of these algorithms has established prominence in the field and offers unique perspectives on identifying communities within complex networks. We also compare the networks by the global properties, statistic summary, subgraph count, graphlet and validate by the modulaity. By employing these approaches, we sought to gain deeper insights into the structural organization and interconnections present within the Omicron virus network.
<div id='section'>Paperid: <span id='pid'>978, <a href='https://arxiv.org/pdf/2308.04697.pdf' target='_blank'>https://arxiv.org/pdf/2308.04697.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mamata Das, P. J. A. Alphonse, Selvakumar K
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04697">An Analytical Study of Covid-19 Dataset using Graph-Based Clustering Algorithms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Corona VIrus Disease abbreviated as COVID-19 is a novel virus which is initially identified in Wuhan of China in December of 2019 and now this deadly disease has spread all over the world. According to World Health Organization (WHO), a total of 3,124,905 people died from 2019 to 2021, April. In this case, many methods, AI base techniques, and machine learning algorithms have been researched and are being used to save people from this pandemic. The SARS-CoV and the 2019-nCoV, SARS-CoV-2 virus invade our bodies, causing some differences in the structure of cell proteins. Protein-protein interaction (PPI) is an essential process in our cells and plays a very important role in the development of medicines and gives ideas about the disease. In this study, we performed clustering on PPI networks generated from 92 genes of the Covi-19 dataset. We have used three graph-based clustering algorithms to give intuition to the analysis of clusters.
<div id='section'>Paperid: <span id='pid'>979, <a href='https://arxiv.org/pdf/2308.02796.pdf' target='_blank'>https://arxiv.org/pdf/2308.02796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mrinmoy Roy, Srabonti Das, Anica Tasnim Protity
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02796">OBESEYE: Interpretable Diet Recommender for Obesity Management using Machine Learning and Explainable AI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Obesity, the leading cause of many non-communicable diseases, occurs mainly for eating more than our body requirements and lack of proper activity. So, being healthy requires heathy diet plans, especially for patients with comorbidities. But it is difficult to figure out the exact quantity of each nutrient because nutrients requirement varies based on physical and disease conditions. In our study we proposed a novel machine learning based system to predict the amount of nutrients one individual requires for being healthy. We applied different machine learning algorithms: linear regression, support vector machine (SVM), decision tree, random forest, XGBoost, LightGBM on fluid and 3 other major micronutrients: carbohydrate, protein, fat consumption prediction. We achieved high accuracy with low root mean square error (RMSE) by using linear regression in fluid prediction, random forest in carbohydrate prediction and LightGBM in protein and fat prediction. We believe our diet recommender system, OBESEYE, is the only of its kind which recommends diet with the consideration of comorbidities and physical conditions and promote encouragement to get rid of obesity.
<div id='section'>Paperid: <span id='pid'>980, <a href='https://arxiv.org/pdf/2307.16167.pdf' target='_blank'>https://arxiv.org/pdf/2307.16167.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jacob Bendsen, Peter Emil Carstensen, AsbjÃ¸rn Thode Reenberg, Tobias K. S. Ritschel, John Bagterp JÃ¸rgensen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.16167">Quantitative modeling and simulation of biochemical processes in the human body</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a whole-body model of human metabolism that utilizes a system of organs and blood vessels to simulate the enzymatic reactions. The model focuses on key organs, including the brain, heart and lungs, liver, gut, and kidney, as well as muscle and adipose tissue. The model equations are formulated using stoichiometry and Michaelis-Menten kinetics to describe the enzymatic reactions. We demonstrate how the model can be used to simulate the effects of prolonged fasting and intermittent fasting on selected metabolite concentrations and glucose flux. Furthermore, by simulating intermittent fasting the effect on the carbohydrate, the protein and the lipid storage is examined. We propose this method as a simple and intuitive approach for modeling the human metabolism, which is general, systematic and easy to incorporate. This could have potential applications in PK/PD drug development and in understanding metabolic disorders.
<div id='section'>Paperid: <span id='pid'>981, <a href='https://arxiv.org/pdf/2307.14530.pdf' target='_blank'>https://arxiv.org/pdf/2307.14530.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fedor Noskov, Maxim Panov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.14530">Optimal Noise Reduction in Dense Mixed-Membership Stochastic Block Models under Diverging Spiked Eigenvalues Condition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Community detection is one of the most critical problems in modern network science. Its applications can be found in various fields, from protein modeling to social network analysis. Recently, many papers appeared studying the problem of overlapping community detection, where each node of a network may belong to several communities. In this work, we consider Mixed-Membership Stochastic Block Model (MMSB) first proposed by Airoldi et al. MMSB provides quite a general setting for modeling overlapping community structure in graphs. The central question of this paper is to reconstruct relations between communities given an observed network. We compare different approaches and establish the minimax lower bound on the estimation error. Then, we propose a new estimator that matches this lower bound. Theoretical results are proved under fairly general conditions on the considered model. Finally, we illustrate the theory in a series of experiments.
<div id='section'>Paperid: <span id='pid'>982, <a href='https://arxiv.org/pdf/2307.11719.pdf' target='_blank'>https://arxiv.org/pdf/2307.11719.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rita T. Sousa, Sara Silva, Catia Pesquita
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.11719">Benchmark datasets for biomedical knowledge graphs with negative statements</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge graphs represent facts about real-world entities. Most of these facts are defined as positive statements. The negative statements are scarce but highly relevant under the open-world assumption. Furthermore, they have been demonstrated to improve the performance of several applications, namely in the biomedical domain. However, no benchmark dataset supports the evaluation of the methods that consider these negative statements.
  We present a collection of datasets for three relation prediction tasks - protein-protein interaction prediction, gene-disease association prediction and disease prediction - that aim at circumventing the difficulties in building benchmarks for knowledge graphs with negative statements. These datasets include data from two successful biomedical ontologies, Gene Ontology and Human Phenotype Ontology, enriched with negative statements.
  We also generate knowledge graph embeddings for each dataset with two popular path-based methods and evaluate the performance in each task. The results show that the negative statements can improve the performance of knowledge graph embeddings.
<div id='section'>Paperid: <span id='pid'>983, <a href='https://arxiv.org/pdf/2307.05794.pdf' target='_blank'>https://arxiv.org/pdf/2307.05794.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Long Chen, Jian Jiang, Bozheng Dou, Hongsong Feng, Jie Liu, Yueying Zhu, Bengong Zhang, Tianshou Zhou, Guo-Wei Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.05794">Machine Learning Study of the Extended Drug-target Interaction Network informed by Pain Related Voltage-Gated Sodium Channels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pain is a significant global health issue, and the current treatment options for pain management have limitations in terms of effectiveness, side effects, and potential for addiction. There is a pressing need for improved pain treatments and the development of new drugs. Voltage-gated sodium channels, particularly Nav1.3, Nav1.7, Nav1.8, and Nav1.9, play a crucial role in neuronal excitability and are predominantly expressed in the peripheral nervous system. Targeting these channels may provide a means to treat pain while minimizing central and cardiac adverse effects. In this study, we construct protein-protein interaction (PPI) networks based on pain-related sodium channels and develop a corresponding drug-target interaction (DTI) network to identify potential lead compounds for pain management. To ensure reliable machine learning predictions, we carefully select 111 inhibitor datasets from a pool of over 1,000 targets in the PPI network. We employ three distinct machine learning algorithms combined with advanced natural language processing (NLP)-based embeddings, specifically pre-trained transformer and autoencoder representations. Through a systematic screening process, we evaluate the side effects and repurposing potential of over 150,000 drug candidates targeting Nav1.7 and Nav1.8 sodium channels. Additionally, we assess the ADMET (absorption, distribution, metabolism, excretion, and toxicity) properties of these candidates to identify leads with near-optimal characteristics. Our strategy provides an innovative platform for the pharmacological development of pain treatments, offering the potential for improved efficacy and reduced side effects.
<div id='section'>Paperid: <span id='pid'>984, <a href='https://arxiv.org/pdf/2306.12687.pdf' target='_blank'>https://arxiv.org/pdf/2306.12687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rita T. Sousa, Sara Silva, Catia Pesquita
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.12687">Explainable Representations for Relation Prediction in Knowledge Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge graphs represent real-world entities and their relations in a semantically-rich structure supported by ontologies. Exploring this data with machine learning methods often relies on knowledge graph embeddings, which produce latent representations of entities that preserve structural and local graph neighbourhood properties, but sacrifice explainability. However, in tasks such as link or relation prediction, understanding which specific features better explain a relation is crucial to support complex or critical applications.
  We propose SEEK, a novel approach for explainable representations to support relation prediction in knowledge graphs. It is based on identifying relevant shared semantic aspects (i.e., subgraphs) between entities and learning representations for each subgraph, producing a multi-faceted and explainable representation.
  We evaluate SEEK on two real-world highly complex relation prediction tasks: protein-protein interaction prediction and gene-disease association prediction. Our extensive analysis using established benchmarks demonstrates that SEEK achieves significantly better performance than standard learning representation methods while identifying both sufficient and necessary explanations based on shared semantic aspects.
<div id='section'>Paperid: <span id='pid'>985, <a href='https://arxiv.org/pdf/2306.07274.pdf' target='_blank'>https://arxiv.org/pdf/2306.07274.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bongjin Koo, Julien Martel, Ariana Peck, Axel Levy, FrÃ©dÃ©ric Poitevin, Nina Miolane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.07274">CryoChains: Heterogeneous Reconstruction of Molecular Assembly of Semi-flexible Chains from Cryo-EM Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryogenic electron microscopy (cryo-EM) has transformed structural biology by allowing to reconstruct 3D biomolecular structures up to near-atomic resolution. However, the 3D reconstruction process remains challenging, as the 3D structures may exhibit substantial shape variations, while the 2D image acquisition suffers from a low signal-to-noise ratio, requiring to acquire very large datasets that are time-consuming to process. Current reconstruction methods are precise but computationally expensive, or faster but lack a physically-plausible model of large molecular shape variations. To fill this gap, we propose CryoChains that encodes large deformations of biomolecules via rigid body transformation of their chains, while representing their finer shape variations with the normal mode analysis framework of biophysics. Our synthetic data experiments on the human GABA\textsubscript{B} and heat shock protein show that CryoChains gives a biophysically-grounded quantification of the heterogeneous conformations of biomolecules, while reconstructing their 3D molecular structures at an improved resolution compared to the current fastest, interpretable deep learning method.
<div id='section'>Paperid: <span id='pid'>986, <a href='https://arxiv.org/pdf/2306.05587.pdf' target='_blank'>https://arxiv.org/pdf/2306.05587.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanhua Xu, Dominik Wojtczak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.05587">MC-NN: An End-to-End Multi-Channel Neural Network Approach for Predicting Influenza A Virus Hosts and Antigenic Types</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Influenza poses a significant threat to public health, particularly among the elderly, young children, and people with underlying dis-eases. The manifestation of severe conditions, such as pneumonia, highlights the importance of preventing the spread of influenza. An accurate and cost-effective prediction of the host and antigenic sub-types of influenza A viruses is essential to addressing this issue, particularly in resource-constrained regions. In this study, we propose a multi-channel neural network model to predict the host and antigenic subtypes of influenza A viruses from hemagglutinin and neuraminidase protein sequences. Our model was trained on a comprehensive data set of complete protein sequences and evaluated on various test data sets of complete and incomplete sequences. The results demonstrate the potential and practicality of using multi-channel neural networks in predicting the host and antigenic subtypes of influenza A viruses from both full and partial protein sequences.
<div id='section'>Paperid: <span id='pid'>987, <a href='https://arxiv.org/pdf/2306.04014.pdf' target='_blank'>https://arxiv.org/pdf/2306.04014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nan Ding, Pieter Maris, Hai Ah Nam, Taylor Groves, Muaaz Gul Awan, LeAnn Lindsey, Christopher Daley, Oguz Selvitopi, Leonid Oliker, Nicholas Wright, Samuel Williams
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.04014">Evaluating the Potential of Disaggregated Memory Systems for HPC applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Disaggregated memory is a promising approach that addresses the limitations of traditional memory architectures by enabling memory to be decoupled from compute nodes and shared across a data center. Cloud platforms have deployed such systems to improve overall system memory utilization, but performance can vary across workloads. High-performance computing (HPC) is crucial in scientific and engineering applications, where HPC machines also face the issue of underutilized memory. As a result, improving system memory utilization while understanding workload performance is essential for HPC operators. Therefore, learning the potential of a disaggregated memory system before deployment is a critical step. This paper proposes a methodology for exploring the design space of a disaggregated memory system. It incorporates key metrics that affect performance on disaggregated memory systems: memory capacity, local and remote memory access ratio, injection bandwidth, and bisection bandwidth, providing an intuitive approach to guide machine configurations based on technology trends and workload characteristics. We apply our methodology to analyze thirteen diverse workloads, including AI training, data analysis, genomics, protein, fusion, atomic nuclei, and traditional HPC bookends. Our methodology demonstrates the ability to comprehend the potential and pitfalls of a disaggregated memory system and provides motivation for machine configurations. Our results show that eleven of our thirteen applications can leverage injection bandwidth disaggregated memory without affecting performance, while one pays a rack bisection bandwidth penalty and two pay the system-wide bisection bandwidth penalty. In addition, we also show that intra-rack memory disaggregation would meet the application's memory requirement and provide enough remote memory bandwidth.
<div id='section'>Paperid: <span id='pid'>988, <a href='https://arxiv.org/pdf/2306.03009.pdf' target='_blank'>https://arxiv.org/pdf/2306.03009.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Germans Savcisens, Tina Eliassi-Rad, Lars Kai Hansen, Laust Mortensen, Lau Lilleholt, Anna Rogers, Ingo Zettler, Sune Lehmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03009">Using Sequences of Life-events to Predict Human Lives</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over the past decade, machine learning has revolutionized computers' ability to analyze text through flexible computational models. Due to their structural similarity to written language, transformer-based architectures have also shown promise as tools to make sense of a range of multi-variate sequences from protein-structures, music, electronic health records to weather-forecasts. We can also represent human lives in a way that shares this structural similarity to language. From one perspective, lives are simply sequences of events: People are born, visit the pediatrician, start school, move to a new location, get married, and so on. Here, we exploit this similarity to adapt innovations from natural language processing to examine the evolution and predictability of human lives based on detailed event sequences. We do this by drawing on arguably the most comprehensive registry data in existence, available for an entire nation of more than six million individuals across decades. Our data include information about life-events related to health, education, occupation, income, address, and working hours, recorded with day-to-day resolution. We create embeddings of life-events in a single vector space showing that this embedding space is robust and highly structured. Our models allow us to predict diverse outcomes ranging from early mortality to personality nuances, outperforming state-of-the-art models by a wide margin. Using methods for interpreting deep learning models, we probe the algorithm to understand the factors that enable our predictions. Our framework allows researchers to identify new potential mechanisms that impact life outcomes and associated possibilities for personalized interventions.
<div id='section'>Paperid: <span id='pid'>989, <a href='https://arxiv.org/pdf/2306.01824.pdf' target='_blank'>https://arxiv.org/pdf/2306.01824.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Le Zhang, Jiayang Chen, Tao Shen, Yu Li, Siqi Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.01824">Enhancing the Protein Tertiary Structure Prediction by Multiple Sequence Alignment Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The field of protein folding research has been greatly advanced by deep learning methods, with AlphaFold2 (AF2) demonstrating exceptional performance and atomic-level precision. As co-evolution is integral to protein structure prediction, AF2's accuracy is significantly influenced by the depth of multiple sequence alignment (MSA), which requires extensive exploration of a large protein database for similar sequences. However, not all protein sequences possess abundant homologous families, and consequently, AF2's performance can degrade on such queries, at times failing to produce meaningful results. To address this, we introduce a novel generative language model, MSA-Augmenter, which leverages protein-specific attention mechanisms and large-scale MSAs to generate useful, novel protein sequences not currently found in databases. These sequences supplement shallow MSAs, enhancing the accuracy of structural property predictions. Our experiments on CASP14 demonstrate that MSA-Augmenter can generate de novo sequences that retain co-evolutionary information from inferior MSAs, thereby improving protein structure prediction quality on top of strong AF2.
<div id='section'>Paperid: <span id='pid'>990, <a href='https://arxiv.org/pdf/2305.19801.pdf' target='_blank'>https://arxiv.org/pdf/2305.19801.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastien Boyer, Sam Money-Kyrle, Oliver Bent
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.19801">Predicting protein stability changes under multiple amino acid substitutions using equivariant graph neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The accurate prediction of changes in protein stability under multiple amino acid substitutions is essential for realising true in-silico protein re-design. To this purpose, we propose improvements to state-of-the-art Deep learning (DL) protein stability prediction models, enabling first-of-a-kind predictions for variable numbers of amino acid substitutions, on structural representations, by decoupling the atomic and residue scales of protein representations. This was achieved using E(3)-equivariant graph neural networks (EGNNs) for both atomic environment (AE) embedding and residue-level scoring tasks. Our AE embedder was used to featurise a residue-level graph, then trained to score mutant stability ($ÎÎG$). To achieve effective training of this predictive EGNN we have leveraged the unprecedented scale of a new high-throughput protein stability experimental data-set, Mega-scale. Finally, we demonstrate the immediately promising results of this procedure, discuss the current shortcomings, and highlight potential future strategies.
<div id='section'>Paperid: <span id='pid'>991, <a href='https://arxiv.org/pdf/2305.17592.pdf' target='_blank'>https://arxiv.org/pdf/2305.17592.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mircea Petrache, Shubhendu Trivedi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.17592">Approximation-Generalization Trade-offs under (Approximate) Group Equivariance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The explicit incorporation of task-specific inductive biases through symmetry has emerged as a general design precept in the development of high-performance machine learning models. For example, group equivariant neural networks have demonstrated impressive performance across various domains and applications such as protein and drug design. A prevalent intuition about such models is that the integration of relevant symmetry results in enhanced generalization. Moreover, it is posited that when the data and/or the model may only exhibit $\textit{approximate}$ or $\textit{partial}$ symmetry, the optimal or best-performing model is one where the model symmetry aligns with the data symmetry. In this paper, we conduct a formal unified investigation of these intuitions. To begin, we present general quantitative bounds that demonstrate how models capturing task-specific symmetries lead to improved generalization. In fact, our results do not require the transformations to be finite or even form a group and can work with partial or approximate equivariance. Utilizing this quantification, we examine the more general question of model mis-specification i.e. when the model symmetries don't align with the data symmetries. We establish, for a given symmetry group, a quantitative comparison between the approximate/partial equivariance of the model and that of the data distribution, precisely connecting model equivariance error and data equivariance error. Our result delineates conditions under which the model equivariance error is optimal, thereby yielding the best-performing model for the given task and data. Our results are the most general results of their type in the literature.
<div id='section'>Paperid: <span id='pid'>992, <a href='https://arxiv.org/pdf/2304.05364.pdf' target='_blank'>https://arxiv.org/pdf/2304.05364.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nic Fishman, Leo Klarner, Valentin De Bortoli, Emile Mathieu, Michael Hutchinson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.05364">Diffusion Models for Constrained Domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Denoising diffusion models are a novel class of generative algorithms that achieve state-of-the-art performance across a range of domains, including image generation and text-to-image tasks. Building on this success, diffusion models have recently been extended to the Riemannian manifold setting, broadening their applicability to a range of problems from the natural and engineering sciences. However, these Riemannian diffusion models are built on the assumption that their forward and backward processes are well-defined for all times, preventing them from being applied to an important set of tasks that consider manifolds defined via a set of inequality constraints. In this work, we introduce a principled framework to bridge this gap. We present two distinct noising processes based on (i) the logarithmic barrier metric and (ii) the reflected Brownian motion induced by the constraints. As existing diffusion model techniques cannot be applied in this setting, we derive new tools to define such models in our framework. We then demonstrate the practical utility of our methods on a number of synthetic and real-world tasks, including applications from robotics and protein design.
<div id='section'>Paperid: <span id='pid'>993, <a href='https://arxiv.org/pdf/2303.17728.pdf' target='_blank'>https://arxiv.org/pdf/2303.17728.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hasin Rehana, Nur Bengisu Ãam, Mert Basmaci, Jie Zheng, Christianah Jemiyo, Yongqun He, Arzucan ÃzgÃ¼r, Junguk Hur
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.17728">Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting protein-protein interactions (PPIs) is crucial for understanding genetic mechanisms, disease pathogenesis, and drug design. However, with the fast-paced growth of biomedical literature, there is a growing need for automated and accurate extraction of PPIs to facilitate scientific knowledge discovery. Pre-trained language models, such as generative pre-trained transformers (GPT) and bidirectional encoder representations from transformers (BERT), have shown promising results in natural language processing (NLP) tasks. We evaluated the performance of PPI identification of multiple GPT and BERT models using three manually curated gold-standard corpora: Learning Language in Logic (LLL) with 164 PPIs in 77 sentences, Human Protein Reference Database with 163 PPIs in 145 sentences, and Interaction Extraction Performance Assessment with 335 PPIs in 486 sentences. BERT-based models achieved the best overall performance, with BioBERT achieving the highest recall (91.95%) and F1-score (86.84%) and PubMedBERT achieving the highest precision (85.25%). Interestingly, despite not being explicitly trained for biomedical texts, GPT-4 achieved commendable performance, comparable to the top-performing BERT models. It achieved a precision of 88.37%, a recall of 85.14%, and an F1-score of 86.49% on the LLL dataset. These results suggest that GPT models can effectively detect PPIs from text data, offering promising avenues for application in biomedical literature mining. Further research could explore how these models might be fine-tuned for even more specialized tasks within the biomedical domain.
<div id='section'>Paperid: <span id='pid'>994, <a href='https://arxiv.org/pdf/2303.01845.pdf' target='_blank'>https://arxiv.org/pdf/2303.01845.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Oguz Selvitopi, Saliya Ekanayake, Giulia Guidi, Muaaz G. Awan, Georgios A. Pavlopoulos, Ariful Azad, Nikos Kyrpides, Leonid Oliker, Katherine Yelick, AydÄ±n BuluÃ§
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01845">Extreme-scale many-against-many protein similarity search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Similarity search is one of the most fundamental computations that are regularly performed on ever-increasing protein datasets. Scalability is of paramount importance for uncovering novel phenomena that occur at very large scales. We unleash the power of over 20,000 GPUs on the Summit system to perform all-vs-all protein similarity search on one of the largest publicly available datasets with 405 million proteins, in less than 3.5 hours, cutting the time-to-solution for many use cases from weeks. The variability of protein sequence lengths, as well as the sparsity of the space of pairwise comparisons, make this a challenging problem in distributed memory. Due to the need to construct and maintain a data structure holding indices to all other sequences, this application has a huge memory footprint that makes it hard to scale the problem sizes. We overcome this memory limitation by innovative matrix-based blocking techniques, without introducing additional load imbalance.
<div id='section'>Paperid: <span id='pid'>995, <a href='https://arxiv.org/pdf/2302.10907.pdf' target='_blank'>https://arxiv.org/pdf/2302.10907.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiye Guo, Jian Liu, Yanli Wang, Mengrui Chen, Duolin Wang, Dong Xu, Jianlin Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10907">Diffusion Models in Bioinformatics: A New Wave of Deep Learning Revolution in Action</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Denoising diffusion models have emerged as one of the most powerful generative models in recent years. They have achieved remarkable success in many fields, such as computer vision, natural language processing (NLP), and bioinformatics. Although there are a few excellent reviews on diffusion models and their applications in computer vision and NLP, there is a lack of an overview of their applications in bioinformatics. This review aims to provide a rather thorough overview of the applications of diffusion models in bioinformatics to aid their further development in bioinformatics and computational biology. We start with an introduction of the key concepts and theoretical foundations of three cornerstone diffusion modeling frameworks (denoising diffusion probabilistic models, noise-conditioned scoring networks, and stochastic differential equations), followed by a comprehensive description of diffusion models employed in the different domains of bioinformatics, including cryo-EM data enhancement, single-cell data analysis, protein design and generation, drug and small molecule design, and protein-ligand interaction. The review is concluded with a summary of the potential new development and applications of diffusion models in bioinformatics.
<div id='section'>Paperid: <span id='pid'>996, <a href='https://arxiv.org/pdf/2302.00600.pdf' target='_blank'>https://arxiv.org/pdf/2302.00600.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marloes Arts, Victor Garcia Satorras, Chin-Wei Huang, Daniel Zuegner, Marco Federici, Cecilia Clementi, Frank NoÃ©, Robert Pinsler, Rianne van den Berg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.00600">Two for One: Diffusion Models and Force Fields for Coarse-Grained Molecular Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Coarse-grained (CG) molecular dynamics enables the study of biological processes at temporal and spatial scales that would be intractable at an atomistic resolution. However, accurately learning a CG force field remains a challenge. In this work, we leverage connections between score-based generative models, force fields and molecular dynamics to learn a CG force field without requiring any force inputs during training. Specifically, we train a diffusion generative model on protein structures from molecular dynamics simulations, and we show that its score function approximates a force field that can directly be used to simulate CG molecular dynamics. While having a vastly simplified training setup compared to previous work, we demonstrate that our approach leads to improved performance across several small- to medium-sized protein simulations, reproducing the CG equilibrium distribution, and preserving dynamics of all-atom simulations such as protein folding events.
<div id='section'>Paperid: <span id='pid'>997, <a href='https://arxiv.org/pdf/2301.11898.pdf' target='_blank'>https://arxiv.org/pdf/2301.11898.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Valentina Zantedeschi, Luca Franceschi, Jean Kaddour, Matt J. Kusner, Vlad Niculae
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.11898">DAG Learning on the Permutahedron</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a continuous optimization framework for discovering a latent directed acyclic graph (DAG) from observational data. Our approach optimizes over the polytope of permutation vectors, the so-called Permutahedron, to learn a topological ordering. Edges can be optimized jointly, or learned conditional on the ordering via a non-differentiable subroutine. Compared to existing continuous optimization approaches our formulation has a number of advantages including: 1. validity: optimizes over exact DAGs as opposed to other relaxations optimizing approximate DAGs; 2. modularity: accommodates any edge-optimization procedure, edge structural parameterization, and optimization loss; 3. end-to-end: either alternately iterates between node-ordering and edge-optimization, or optimizes them jointly. We demonstrate, on real-world data problems in protein-signaling and transcriptional network discovery, that our approach lies on the Pareto frontier of two key metrics, the SID and SHD.
<div id='section'>Paperid: <span id='pid'>998, <a href='https://arxiv.org/pdf/2301.06568.pdf' target='_blank'>https://arxiv.org/pdf/2301.06568.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmed Elnaggar, Hazem Essam, Wafaa Salah-Eldin, Walid Moustafa, Mohamed Elkerdawy, Charlotte Rochereau, Burkhard Rost
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.06568">Ankh: Optimized Protein Language Model Unlocks General-Purpose Modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As opposed to scaling-up protein language models (PLMs), we seek improving performance via protein-specific optimization. Although the proportionality between the language model size and the richness of its learned representations is validated, we prioritize accessibility and pursue a path of data-efficient, cost-reduced, and knowledge-guided optimization. Through over twenty experiments ranging from masking, architecture, and pre-training data, we derive insights from protein-specific experimentation into building a model that interprets the language of life, optimally. We present Ankh, the first general-purpose PLM trained on Google's TPU-v4 surpassing the state-of-the-art performance with fewer parameters (<10% for pre-training, <7% for inference, and <30% for the embedding dimension). We provide a representative range of structure and function benchmarks where Ankh excels. We further provide a protein variant generation analysis on High-N and One-N input data scales where Ankh succeeds in learning protein evolutionary conservation-mutation trends and introducing functional diversity while retaining key structural-functional characteristics. We dedicate our work to promoting accessibility to research innovation via attainable resources.
<div id='section'>Paperid: <span id='pid'>999, <a href='https://arxiv.org/pdf/2301.01618.pdf' target='_blank'>https://arxiv.org/pdf/2301.01618.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pavlos Papadopoulos, William J Buchanan, Sarwar Sayeed, Nikolaos Pitropakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.01618">Towards The Creation Of The Future Fish Farm</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A fish farm is an area where fish raise and bred for food. Fish farm environments support the care and management of seafood within a controlled environment. Over the past few decades, there has been a remarkable increase in the calorie intake of protein attributed to seafood. Along with this, there are significant opportunities within the fish farming industry for economic development. Determining the fish diseases, monitoring the aquatic organisms, and examining the imbalance in the water element are some key factors that require precise observation to determine the accuracy of the acquired data. Similarly, due to the rapid expansion of aquaculture, new technologies are constantly being implemented in this sector to enhance efficiency. However, the existing approaches have often failed to provide an efficient method of farming fish. This work has kept aside the traditional approaches and opened up new dimensions to perform accurate analysis by adopting a distributed ledger technology. Our work analyses the current state-of-the-art of fish farming and proposes a fish farm ecosystem that relies on a private-by-design architecture based on the Hyperledger Fabric private-permissioned distributed ledger technology. The proposed method puts forward accurate and secure storage of the retrieved data from multiple sensors across the ecosystem so that the adhering entities can exercise their decision based on the acquired data. This study demonstrates a proof-of-concept to signify the efficiency and usability of the future fish farm.
<div id='section'>Paperid: <span id='pid'>1000, <a href='https://arxiv.org/pdf/2301.00984.pdf' target='_blank'>https://arxiv.org/pdf/2301.00984.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan P. Mailoa, Zhaofeng Ye, Jiezhong Qiu, Chang-Yu Hsieh, Shengyu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.00984">Protein-Ligand Complex Generator & Drug Screening via Tiered Tensor Transform</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The generation of small molecule candidate (ligand) binding poses in its target protein pocket is important for computer-aided drug discovery. Typical rigid-body docking methods ignore the pocket flexibility of protein, while the more accurate pose generation using molecular dynamics is hindered by slow protein dynamics. We develop a tiered tensor transform (3T) algorithm to rapidly generate diverse protein-ligand complex conformations for both pose and affinity estimation in drug screening, requiring neither machine learning training nor lengthy dynamics computation, while maintaining both coarse-grain-like coordinated protein dynamics and atomistic-level details of the complex pocket. The 3T conformation structures we generate achieve significantly higher accuracy in active ligand classification than traditional ensemble docking using hundreds of experimental protein conformations. Furthermore, we demonstrate that 3T can be used to explore distant protein-ligand binding poses within the protein pocket. 3T structure transformation is decoupled from the system physics, making future usage in other computational scientific domains possible.
<div id='section'>Paperid: <span id='pid'>1001, <a href='https://arxiv.org/pdf/2212.05776.pdf' target='_blank'>https://arxiv.org/pdf/2212.05776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Kobelski, Arne-Jens Hempel, Murali Padmanabha, Luiz-Carlos Wille, Stefan Streif
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.05776">Process Optimization of Black Soldier Fly Egg Production via Model Based Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Black soldier fly (BSF) larvae (\textit{Hermetia illucens}) are a valuable protein source for manufacturing animal feed. To maximize their production, both the quantity and quality of their reproductive cycle, i.e. egg production during oviposition, must be increased. In artificial environments, flies often sit idle in cages without mating, depleting their energy reserves and resulting in lower egg production per female.
  By controlling environmental conditions such as temperature and light inside breeding cages, the flies may be stimulated in a way that improves egg output. However, this stimulation increases the energy demand of the process and may stress the flies, resulting in reduced egg production. Therefore, control must be applied in a careful way, which requires knowledge of the egg production cycle.
  In this work, a mathematical model describing the various fly life stages and their transition to the egg production process is developed. Relevant factors are identified and their effect on the fly life and egg production is mathematically described. Parameters are identified using data from literature and goodness of fit is evaluated. Using the model, an optimal control problem is formulated with the goal of minimizing the energy costs and increasing the egg production quantity. In Simulation, our approach showed 13\% higher output in shorter time at reduced energy costs compared to a (standard) constant setpoint approach. Optimal control could reach same amount of egg in 60~\% of time compared to standard scenario.
<div id='section'>Paperid: <span id='pid'>1002, <a href='https://arxiv.org/pdf/2211.14939.pdf' target='_blank'>https://arxiv.org/pdf/2211.14939.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaiyuan Yang, Houjing Huang, Olafs Vandans, Adithya Murali, Fujia Tian, Roland H. C. Yap, Liang Dai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.14939">Applying Deep Reinforcement Learning to the HP Model for Protein Structure Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A central problem in computational biophysics is protein structure prediction, i.e., finding the optimal folding of a given amino acid sequence. This problem has been studied in a classical abstract model, the HP model, where the protein is modeled as a sequence of H (hydrophobic) and P (polar) amino acids on a lattice. The objective is to find conformations maximizing H-H contacts. It is known that even in this reduced setting, the problem is intractable (NP-hard). In this work, we apply deep reinforcement learning (DRL) to the two-dimensional HP model. We can obtain the conformations of best known energies for benchmark HP sequences with lengths from 20 to 50. Our DRL is based on a deep Q-network (DQN). We find that a DQN based on long short-term memory (LSTM) architecture greatly enhances the RL learning ability and significantly improves the search process. DRL can sample the state space efficiently, without the need of manual heuristics. Experimentally we show that it can find multiple distinct best-known solutions per trial. This study demonstrates the effectiveness of deep reinforcement learning in the HP model for protein folding.
<div id='section'>Paperid: <span id='pid'>1003, <a href='https://arxiv.org/pdf/2210.08308.pdf' target='_blank'>https://arxiv.org/pdf/2210.08308.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>NicolÃ¡s A. Barnafi, Luis Miguel De Oliveira Vilaca, Michel C. Milinkovitch, Ricardo Ruiz-Baier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.08308">Coupling chemotaxis and growth poromechanics for the modelling of feather primordia patterning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a new mathematical model for the interaction of skin cell populations with fibroblast growth factor and bone morphogenetic protein, occurring within deformable porous media. The equations for feather primordia pattering are based on the work by K.J. Painter et al. [J. Theoret. Biol., 437 (2018) 225--238]. We perform a linear stability analysis to identify relevant parameters in the coupling mechanisms, focusing in the regime of infinitesimal strains. We also extend the model to the case of nonlinear poroelasticity and include solid growth by means of Lee decompositions of the deformation gradient. We present a few illustrative computational examples in 2D and 3D, and briefly discuss the design of tailored efficient solvers.
<div id='section'>Paperid: <span id='pid'>1004, <a href='https://arxiv.org/pdf/2207.13842.pdf' target='_blank'>https://arxiv.org/pdf/2207.13842.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanhua Xu, Dominik Wojtczak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.13842">Dive into Machine Learning Algorithms for Influenza Virus Host Prediction with Hemagglutinin Sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Influenza viruses mutate rapidly and can pose a threat to public health, especially to those in vulnerable groups. Throughout history, influenza A viruses have caused pandemics between different species. It is important to identify the origin of a virus in order to prevent the spread of an outbreak. Recently, there has been increasing interest in using machine learning algorithms to provide fast and accurate predictions for viral sequences. In this study, real testing data sets and a variety of evaluation metrics were used to evaluate machine learning algorithms at different taxonomic levels. As hemagglutinin is the major protein in the immune response, only hemagglutinin sequences were used and represented by position-specific scoring matrix and word embedding. The results suggest that the 5-grams-transformer neural network is the most effective algorithm for predicting viral sequence origins, with approximately 99.54% AUCPR, 98.01% F1 score and 96.60% MCC at a higher classification level, and approximately 94.74% AUCPR, 87.41% F1 score and 80.79% MCC at a lower classification level.
<div id='section'>Paperid: <span id='pid'>1005, <a href='https://arxiv.org/pdf/2207.06606.pdf' target='_blank'>https://arxiv.org/pdf/2207.06606.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Tian, Hedong Hou, Guangzheng Xu, Ziyang Zhang, Pei Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.06606">Network comparison via encoding, decoding, and causality</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantifying the relations (e.g., similarity) between complex networks paves the way for studying the latent information shared across networks. However, fundamental relation metrics are not well-defined between networks. As a compromise, prevalent techniques measure network relations in data-driven manners, which are inapplicable to analytic derivations in physics. To resolve this issue, we present a theory for obtaining an optimal characterization of network topological properties. We show that a network can be fully represented by a Gaussian variable defined by a function of the Laplacian, which simultaneously satisfies network-topology-dependent smoothness and maximum entropy properties. Based on it, we can analytically measure diverse relations between complex networks. As illustrations, we define encoding (e.g., information divergence and mutual information), decoding (e.g., Fisher information), and causality (e.g., Granger causality and conditional mutual information) between networks. We validate our framework on representative networks (e.g., random networks, protein structures, and chemical compounds) to demonstrate that a series of science and engineering challenges (e.g., network evolution, embedding, and query) can be tackled from a new perspective. An implementation of our theory is released as a multi-platform toolbox.
<div id='section'>Paperid: <span id='pid'>1006, <a href='https://arxiv.org/pdf/2207.02911.pdf' target='_blank'>https://arxiv.org/pdf/2207.02911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Chen, Yang-Yu Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.02911">A Survey on Hyperlink Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a natural extension of link prediction on graphs, hyperlink prediction aims for the inference of missing hyperlinks in hypergraphs, where a hyperlink can connect more than two nodes. Hyperlink prediction has applications in a wide range of systems, from chemical reaction networks, social communication networks, to protein-protein interaction networks. In this paper, we provide a systematic and comprehensive survey on hyperlink prediction. We propose a new taxonomy to classify existing hyperlink prediction methods into four categories: similarity-based, probability-based, matrix optimization-based, and deep learning-based methods. To compare the performance of methods from different categories, we perform a benchmark study on various hypergraph applications using representative methods from each category. Notably, deep learning-based methods prevail over other methods in hyperlink prediction.
<div id='section'>Paperid: <span id='pid'>1007, <a href='https://arxiv.org/pdf/2206.02970.pdf' target='_blank'>https://arxiv.org/pdf/2206.02970.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinru Wei, Chunyu Pan, Xizhe Zhang, Weixiong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.02970">Total controllability analysis discovers explainable drugs for Covid-19 treatment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Network medicine has been pursued for Covid-19 drug repurposing. One such approach adopts structural controllability, a theory for controlling a network (the cell). Motivated to protect the cell from viral infections, we extended this theory to total controllability and introduced a new concept of control hubs. Perturbation to any control hub renders the cell uncontrollable by exogenous stimuli, e.g., viral infections, so control hubs are ideal drug targets. We developed an efficient algorithm for finding all control hubs and applied it to the largest homogenous human protein-protein interaction network. Our new method outperforms several popular gene-selection methods, including that based on structural controllability. The final 65 druggable control hubs are enriched with functions of cell proliferation, regulation of apoptosis, and responses to cellular stress and nutrient levels, revealing critical pathways induced by SARS-CoV-2. These druggable control hubs led to drugs in 4 major categories: antiviral and anti-inflammatory agents, drugs on central nerve systems, and dietary supplements and hormones that boost immunity. Their functions also provided deep insights into the therapeutic mechanisms of the drugs for Covid-19 therapy, making the new approach an explainable drug repurposing method. A remarkable example is Fostamatinib that has been shown to lower mortality, shorten the length of ICU stay, and reduce disease severity of hospitalized Covid-19 patients. The drug targets 10 control hubs, 9 of which are kinases that play key roles in cell differentiation and programmed death. One such kinase is RIPK1 that directly interacts with viral protein nsp12, the RdRp of the virus. The study produced many control hubs that were not targets of existing drugs but were enriched with proteins on membranes and the NF-$Îº$B pathway, so are excellent candidate targets for new drugs.
<div id='section'>Paperid: <span id='pid'>1008, <a href='https://arxiv.org/pdf/2205.09548.pdf' target='_blank'>https://arxiv.org/pdf/2205.09548.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lixue Cheng, Ziyi Yang, Changyu Hsieh, Benben Liao, Shengyu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.09548">ODBO: Bayesian Optimization with Search Space Prescreening for Directed Protein Evolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Directed evolution is a versatile technique in protein engineering that mimics the process of natural selection by iteratively alternating between mutagenesis and screening in order to search for sequences that optimize a given property of interest, such as catalytic activity and binding affinity to a specified target. However, the space of possible proteins is too large to search exhaustively in the laboratory, and functional proteins are scarce in the vast sequence space. Machine learning (ML) approaches can accelerate directed evolution by learning to map protein sequences to functions without building a detailed model of the underlying physics, chemistry and biological pathways. Despite the great potentials held by these ML methods, they encounter severe challenges in identifying the most suitable sequences for a targeted function. These failures can be attributed to the common practice of adopting a high-dimensional feature representation for protein sequences and inefficient search methods. To address these issues, we propose an efficient, experimental design-oriented closed-loop optimization framework for protein directed evolution, termed ODBO, which employs a combination of novel low-dimensional protein encoding strategy and Bayesian optimization enhanced with search space prescreening via outlier detection. We further design an initial sample selection strategy to minimize the number of experimental samples for training ML models. We conduct and report four protein directed evolution experiments that substantiate the capability of the proposed framework for finding of the variants with properties of interest. We expect the ODBO framework to greatly reduce the experimental cost and time cost of directed evolution, and can be further generalized as a powerful tool for adaptive experimental design in a broader context.
<div id='section'>Paperid: <span id='pid'>1009, <a href='https://arxiv.org/pdf/2204.01467.pdf' target='_blank'>https://arxiv.org/pdf/2204.01467.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mario Krenn, Robert Pollice, Si Yue Guo, Matteo Aldeghi, Alba Cervera-Lierta, Pascal Friederich, Gabriel dos Passos Gomes, Florian HÃ¤se, Adrian Jinich, AkshatKumar Nigam, Zhenpeng Yao, AlÃ¡n Aspuru-Guzik
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.01467">On scientific understanding with artificial intelligence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Imagine an oracle that correctly predicts the outcome of every particle physics experiment, the products of every chemical reaction, or the function of every protein. Such an oracle would revolutionize science and technology as we know them. However, as scientists, we would not be satisfied with the oracle itself. We want more. We want to comprehend how the oracle conceived these predictions. This feat, denoted as scientific understanding, has frequently been recognized as the essential aim of science. Now, the ever-growing power of computers and artificial intelligence poses one ultimate question: How can advanced artificial systems contribute to scientific understanding or achieve it autonomously?
  We are convinced that this is not a mere technical question but lies at the core of science. Therefore, here we set out to answer where we are and where we can go from here. We first seek advice from the philosophy of science to understand scientific understanding. Then we review the current state of the art, both from literature and by collecting dozens of anecdotes from scientists about how they acquired new conceptual understanding with the help of computers. Those combined insights help us to define three dimensions of android-assisted scientific understanding: The android as a I) computational microscope, II) resource of inspiration and the ultimate, not yet existent III) agent of understanding. For each dimension, we explain new avenues to push beyond the status quo and unleash the full power of artificial intelligence's contribution to the central aim of science. We hope our perspective inspires and focuses research towards androids that get new scientific understanding and ultimately bring us closer to true artificial scientists.
<div id='section'>Paperid: <span id='pid'>1010, <a href='https://arxiv.org/pdf/2112.10154.pdf' target='_blank'>https://arxiv.org/pdf/2112.10154.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tony Gracious, Ambedkar Dukkipati
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.10154">Dynamic Representation Learning with Temporal Point Processes for Higher-Order Interaction Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The explosion of digital information and the growing involvement of people in social networks led to enormous research activity to develop methods that can extract meaningful information from interaction data. Commonly, interactions are represented by edges in a network or a graph, which implicitly assumes that the interactions are pairwise and static. However, real-world interactions deviate from these assumptions: (i) interactions can be multi-way, involving more than two nodes or individuals (e.g., family relationships, protein interactions), and (ii) interactions can change over a period of time (e.g., change of opinions and friendship status). While pairwise interactions have been studied in a dynamic network setting and multi-way interactions have been studied using hypergraphs in static networks, there exists no method, at present, that can predict multi-way interactions or hyperedges in dynamic settings. Existing related methods cannot answer temporal queries like what type of interaction will occur next and when it will occur. This paper proposes a temporal point process model for hyperedge prediction to address these problems. Our proposed model uses dynamic representation learning techniques for nodes in a neural point process framework to forecast hyperedges. We present several experimental results and set benchmark results. As far as our knowledge, this is the first work that uses the temporal point process to forecast hyperedges in dynamic networks.
<div id='section'>Paperid: <span id='pid'>1011, <a href='https://arxiv.org/pdf/2111.14889.pdf' target='_blank'>https://arxiv.org/pdf/2111.14889.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew J. Colbrook, Alex Townsend
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2111.14889">Rigorous data-driven computation of spectral properties of Koopman operators for dynamical systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Koopman operators are infinite-dimensional operators that globally linearize nonlinear dynamical systems, making their spectral information valuable for understanding dynamics. However, Koopman operators can have continuous spectra and infinite-dimensional invariant subspaces, making computing their spectral information a considerable challenge. This paper describes data-driven algorithms with rigorous convergence guarantees for computing spectral information of Koopman operators from trajectory data. We introduce residual dynamic mode decomposition (ResDMD), which provides the first scheme for computing the spectra and pseudospectra of general Koopman operators from snapshot data without spectral pollution. Using the resolvent operator and ResDMD, we compute smoothed approximations of spectral measures associated with general measure-preserving dynamical systems. We prove explicit convergence theorems for our algorithms, which can achieve high-order convergence even for chaotic systems when computing the density of the continuous spectrum and the discrete spectrum. Since our algorithms come with error control, ResDMD allows aposteri verification of spectral quantities, Koopman mode decompositions, and learned dictionaries. We demonstrate our algorithms on the tent map, circle rotations, Gauss iterated map, nonlinear pendulum, double pendulum, and Lorenz system. Finally, we provide kernelized variants of our algorithms for dynamical systems with a high-dimensional state space. This allows us to compute the spectral measure associated with the dynamics of a protein molecule with a 20,046-dimensional state space and compute nonlinear Koopman modes with error bounds for turbulent flow past aerofoils with Reynolds number $>10^5$ that has a 295,122-dimensional state space.
<div id='section'>Paperid: <span id='pid'>1012, <a href='https://arxiv.org/pdf/2111.02272.pdf' target='_blank'>https://arxiv.org/pdf/2111.02272.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas C. Ditz, Bernhard Reuter, Nico Pfeifer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2111.02272">Convolutional Motif Kernel Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial neural networks show promising performance in detecting correlations within data that are associated with specific outcomes. However, the black-box nature of such models can hinder the knowledge advancement in research fields by obscuring the decision process and preventing scientist to fully conceptualize predicted outcomes. Furthermore, domain experts like healthcare providers need explainable predictions to assess whether a predicted outcome can be trusted in high stakes scenarios and to help them integrating a model into their own routine. Therefore, interpretable models play a crucial role for the incorporation of machine learning into high stakes scenarios like healthcare. In this paper we introduce Convolutional Motif Kernel Networks, a neural network architecture that involves learning a feature representation within a subspace of the reproducing kernel Hilbert space of the position-aware motif kernel function. The resulting model enables to directly interpret and evaluate prediction outcomes by providing a biologically and medically meaningful explanation without the need for additional post-hoc analysis. We show that our model is able to robustly learn on small datasets and reaches state-of-the-art performance on relevant healthcare prediction tasks. Our proposed method can be utilized on DNA and protein sequences. Furthermore, we show that the proposed method learns biologically meaningful concepts directly from data using an end-to-end learning scheme.
<div id='section'>Paperid: <span id='pid'>1013, <a href='https://arxiv.org/pdf/2006.08052.pdf' target='_blank'>https://arxiv.org/pdf/2006.08052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Clara Fannjiang, Jennifer Listgarten
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2006.08052">Autofocused oracles for model-based design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven design is making headway into a number of application areas, including protein, small-molecule, and materials engineering. The design goal is to construct an object with desired properties, such as a protein that binds to a therapeutic target, or a superconducting material with a higher critical temperature than previously observed. To that end, costly experimental measurements are being replaced with calls to high-capacity regression models trained on labeled data, which can be leveraged in an in silico search for design candidates. However, the design goal necessitates moving into regions of the design space beyond where such models were trained. Therefore, one can ask: should the regression model be altered as the design algorithm explores the design space, in the absence of new data? Herein, we answer this question in the affirmative. In particular, we (i) formalize the data-driven design problem as a non-zero-sum game, (ii) develop a principled strategy for retraining the regression model as the design algorithm proceeds---what we refer to as autofocusing, and (iii) demonstrate the promise of autofocusing empirically.
<div id='section'>Paperid: <span id='pid'>1014, <a href='https://arxiv.org/pdf/2509.19930.pdf' target='_blank'>https://arxiv.org/pdf/2509.19930.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Tabish, Benedict Leimkuhler, Stefan Klus
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.19930">How deep is your network? Deep vs. shallow learning of transfer operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a randomized neural network approach called RaNNDy for learning transfer operators and their spectral decompositions from data. The weights of the hidden layers of the neural network are randomly selected and only the output layer is trained. The main advantage is that without a noticeable reduction in accuracy, this approach significantly reduces the training time and resources while avoiding common problems associated with deep learning such as sensitivity to hyperparameters and slow convergence. Additionally, the proposed framework allows us to compute a closed-form solution for the output layer which directly represents the eigenfunctions of the operator. Moreover, it is possible to estimate uncertainties associated with the computed spectral properties via ensemble learning. We present results for different dynamical operators, including Koopman and Perron-Frobenius operators, which have important applications in analyzing the behavior of complex dynamical systems, and the Schrödinger operator. The numerical examples, which highlight the strengths but also weaknesses of the proposed framework, include several stochastic dynamical systems, protein folding processes, and the quantum harmonic oscillator.
<div id='section'>Paperid: <span id='pid'>1015, <a href='https://arxiv.org/pdf/2509.17208.pdf' target='_blank'>https://arxiv.org/pdf/2509.17208.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kevin Bachelor, Sanya Murdeshwar, Daniel Sabo, Razvan Marinescu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17208">Active Learning for Machine Learning Driven Molecular Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learned coarse grained (CG) potentials are fast, but degrade over time when simulations reach undersampled biomolecular conformations, and generating widespread all atom (AA) data to combat this is computationally infeasible. We propose a novel active learning framework for CG neural network potentials in molecular dynamics (MD). Building on the CGSchNet model, our method employs root mean squared deviation (RMSD) based frame selection from MD simulations in order to generate data on the fly by querying an oracle during the training of a neural network potential. This framework preserves CG level efficiency while correcting the model at precise, RMSD identified coverage gaps. By training CGSchNet, a coarse grained neural network potential, we empirically show that our framework explores previously unseen configurations and trains the model on unexplored regions of conformational space. Our active learning framework enables a CGSchNet model trained on the Chignolin protein to achieve a 33.05% improvement in the Wasserstein 1 (W1) metric in Time lagged Independent Component Analysis (TICA) space on an in house benchmark suite.
<div id='section'>Paperid: <span id='pid'>1016, <a href='https://arxiv.org/pdf/2509.14600.pdf' target='_blank'>https://arxiv.org/pdf/2509.14600.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Aghili, Andy Bruce, Daniel Sabo, Razvan Marinescu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14600">TICA-Based Free Energy Matching for Machine-Learned Molecular Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular dynamics (MD) simulations provide atomistic insight into biomolecular systems but are often limited by high computational costs required to access long timescales. Coarse-grained machine learning models offer a promising avenue for accelerating sampling, yet conventional force matching approaches often fail to capture the full thermodynamic landscape as fitting a model on the gradient may not fit the absolute differences between low-energy conformational states. In this work, we incorporate a complementary energy matching term into the loss function. We evaluate our framework on the Chignolin protein using the CGSchNet model, systematically varying the weight of the energy loss term. While energy matching did not yield statistically significant improvements in accuracy, it revealed distinct tendencies in how models generalize the free energy surface. Our results suggest future opportunities to enhance coarse-grained modeling through improved energy estimation techniques and multi-modal loss formulations.
<div id='section'>Paperid: <span id='pid'>1017, <a href='https://arxiv.org/pdf/2509.13476.pdf' target='_blank'>https://arxiv.org/pdf/2509.13476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Md Masud Rana, Farjana Tasnim Mukta, Duc D. Nguyen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13476">A Geometric Graph-Based Deep Learning Model for Drug-Target Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In structure-based drug design, accurately estimating the binding affinity between a candidate ligand and its protein receptor is a central challenge. Recent advances in artificial intelligence, particularly deep learning, have demonstrated superior performance over traditional empirical and physics-based methods for this task, enabled by the growing availability of structural and experimental affinity data. In this work, we introduce DeepGGL, a deep convolutional neural network that integrates residual connections and an attention mechanism within a geometric graph learning framework. By leveraging multiscale weighted colored bipartite subgraphs, DeepGGL effectively captures fine-grained atom-level interactions in protein-ligand complexes across multiple scales. We benchmarked DeepGGL against established models on CASF-2013 and CASF-2016, where it achieved state-of-the-art performance with significant improvements across diverse evaluation metrics. To further assess robustness and generalization, we tested the model on the CSAR-NRC-HiQ dataset and the PDBbind v2019 holdout set. DeepGGL consistently maintained high predictive accuracy, highlighting its adaptability and reliability for binding affinity prediction in structure-based drug discovery.
<div id='section'>Paperid: <span id='pid'>1018, <a href='https://arxiv.org/pdf/2509.12976.pdf' target='_blank'>https://arxiv.org/pdf/2509.12976.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taher Yacoub, Camille Depenveiller, Atsushi Tatsuma, Tin Barisin, Eugen Rusakov, Udo Gobel, Yuxu Peng, Shiqiang Deng, Yuki Kagaya, Joon Hong Park, Daisuke Kihara, Marco Guerra, Giorgio Palmieri, Andrea Ranieri, Ulderico Fugacci, Silvia Biasotti, Ruiwen He, Halim Benhabiles, Adnane Cabani, Karim Hammoudi, Haotian Li, Hao Huang, Chunyan Li, Alireza Tehrani, Fanwang Meng, Farnaz Heidar-Zadeh, Tuan-Anh Yang, Matthieu Montes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12976">SHREC 2025: Protein surface shape retrieval including electrostatic potential</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This SHREC 2025 track dedicated to protein surface shape retrieval involved 9 participating teams. We evaluated the performance in retrieval of 15 proposed methods on a large dataset of 11,555 protein surfaces with calculated electrostatic potential (a key molecular surface descriptor). The performance in retrieval of the proposed methods was evaluated through different metrics (Accuracy, Balanced accuracy, F1 score, Precision and Recall). The best retrieval performance was achieved by the proposed methods that used the electrostatic potential complementary to molecular surface shape. This observation was also valid for classes with limited data which highlights the importance of taking into account additional molecular surface descriptors.
<div id='section'>Paperid: <span id='pid'>1019, <a href='https://arxiv.org/pdf/2509.11046.pdf' target='_blank'>https://arxiv.org/pdf/2509.11046.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seon-Geun Jeong, Kyeong-Hwan Moon, Won-Joo Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11046">Hybrid Quantum Neural Networks for Efficient Protein-Ligand Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-ligand binding affinity is critical in drug discovery, but experimentally determining it is time-consuming and expensive. Artificial intelligence (AI) has been used to predict binding affinity, significantly accelerating this process. However, the high-performance requirements and vast datasets involved in affinity prediction demand increasingly large AI models, requiring substantial computational resources and training time. Quantum machine learning has emerged as a promising solution to these challenges. In particular, hybrid quantum-classical models can reduce the number of parameters while maintaining or improving performance compared to classical counterparts. Despite these advantages, challenges persist: why hybrid quantum models achieve these benefits, whether quantum neural networks (QNNs) can replace classical neural networks, and whether such models are feasible on noisy intermediate-scale quantum (NISQ) devices. This study addresses these challenges by proposing a hybrid quantum neural network (HQNN) that empirically demonstrates the capability to approximate non-linear functions in the latent feature space derived from classical embedding. The primary goal of this study is to achieve a parameter-efficient model in binding affinity prediction while ensuring feasibility on NISQ devices. Numerical results indicate that HQNN achieves comparable or superior performance and parameter efficiency compared to classical neural networks, underscoring its potential as a viable replacement. This study highlights the potential of hybrid QML in computational drug discovery, offering insights into its applicability and advantages in addressing the computational challenges of protein-ligand binding affinity prediction.
<div id='section'>Paperid: <span id='pid'>1020, <a href='https://arxiv.org/pdf/2509.07204.pdf' target='_blank'>https://arxiv.org/pdf/2509.07204.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adrien Couetoux, Thomas Devenyns, Lise Diagne, David Champagne, Pierre-Yves Mousset, Chris Anagnostopoulos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07204">Predicting effect of novel treatments using molecular pathways and real-world data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In pharmaceutical R&D, predicting the efficacy of a pharmaceutical in treating a particular disease prior to clinical testing or any real-world use has been challenging. In this paper, we propose a flexible and modular machine learning-based approach for predicting the efficacy of an untested pharmaceutical for treating a disease. We train a machine learning model using sets of pharmaceutical-pathway weight impact scores and patient data, which can include patient characteristics and observed clinical outcomes. The resulting model then analyses weighted impact scores of an untested pharmaceutical across human biological molecule-protein pathways to generate a predicted efficacy value. We demonstrate how the method works on a real-world dataset with patient treatments and outcomes, with two different weight impact score algorithms We include methods for evaluating the generalisation performance on unseen treatments, and to characterise conditions under which the approach can be expected to be most predictive. We discuss specific ways in which our approach can be iterated on, making it an initial framework to support future work on predicting the effect of untested drugs, leveraging RWD clinical data and drug embeddings.
<div id='section'>Paperid: <span id='pid'>1021, <a href='https://arxiv.org/pdf/2509.03084.pdf' target='_blank'>https://arxiv.org/pdf/2509.03084.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Derek Jones, Yue Yang, Felice C. Lightstone, Niema Moshiri, Jonathan E. Allen, Tajana S. Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03084">SurGBSA: Learning Representations From Molecular Dynamics Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised pretraining from static structures of drug-like compounds and proteins enable powerful learned feature representations. Learned features demonstrate state of the art performance on a range of predictive tasks including molecular properties, structure generation, and protein-ligand interactions. The majority of approaches are limited by their use of static structures and it remains an open question, how best to use atomistic molecular dynamics (MD) simulations to develop more generalized models to improve prediction accuracy for novel molecular structures. We present SURrogate mmGBSA (SurGBSA) as a new modeling approach for MD-based representation learning, which learns a surrogate function of the Molecular Mechanics Generalized Born Surface Area (MMGBSA). We show for the first time the benefits of physics-informed pre-training to train a surrogate MMGBSA model on a collection of over 1.4 million 3D trajectories collected from MD simulations of the CASF-2016 benchmark. SurGBSA demonstrates a dramatic 27,927x speedup versus a traditional physics-based single-point MMGBSA calculation while nearly matching single-point MMGBSA accuracy on the challenging pose ranking problem for identification of the correct top pose (-0.4% difference). Our work advances the development of molecular foundation models by showing model improvements when training on MD simulations. Models, code and training data are made publicly available.
<div id='section'>Paperid: <span id='pid'>1022, <a href='https://arxiv.org/pdf/2509.02196.pdf' target='_blank'>https://arxiv.org/pdf/2509.02196.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aditya Sengar, Jiying Zhang, Pierre Vandergheynst, Patrick Barth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02196">Beyond Ensembles: Simulating All-Atom Protein Dynamics in a Learned Latent Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulating the long-timescale dynamics of biomolecules is a central challenge in computational science. While enhanced sampling methods can accelerate these simulations, they rely on pre-defined collective variables that are often difficult to identify. A recent generative model, LD-FPG, demonstrated that this problem could be bypassed by learning to sample the static equilibrium ensemble as all-atom deformations from a reference structure, establishing a powerful method for all-atom ensemble generation. However, while this approach successfully captures a system's probable conformations, it does not model the temporal evolution between them. We introduce the Graph Latent Dynamics Propagator (GLDP), a modular component for simulating dynamics within the learned latent space of LD-FPG. We then compare three classes of propagators: (i) score-guided Langevin dynamics, (ii) Koopman-based linear operators, and (iii) autoregressive neural networks. Within a unified encoder-propagator-decoder framework, we evaluate long-horizon stability, backbone and side-chain ensemble fidelity, and functional free-energy landscapes. Autoregressive neural networks deliver the most robust long rollouts; score-guided Langevin best recovers side-chain thermodynamics when the score is well learned; and Koopman provides an interpretable, lightweight baseline that tends to damp fluctuations. These results clarify the trade-offs among propagators and offer practical guidance for latent-space simulators of all-atom protein dynamics.
<div id='section'>Paperid: <span id='pid'>1023, <a href='https://arxiv.org/pdf/2508.14844.pdf' target='_blank'>https://arxiv.org/pdf/2508.14844.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Murat Isik, Mandeep Kaur Saggi, Humaira Gowher, Sabre Kais
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14844">Multimodal Quantum Vision Transformer for Enzyme Commission Classification from Biochemical Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting enzyme functionality remains one of the major challenges in computational biology, particularly for enzymes with limited structural annotations or sequence homology. We present a novel multimodal Quantum Machine Learning (QML) framework that enhances Enzyme Commission (EC) classification by integrating four complementary biochemical modalities: protein sequence embeddings, quantum-derived electronic descriptors, molecular graph structures, and 2D molecular image representations. Quantum Vision Transformer (QVT) backbone equipped with modality-specific encoders and a unified cross-attention fusion module. By integrating graph features and spatial patterns, our method captures key stereoelectronic interactions behind enzyme function. Experimental results demonstrate that our multimodal QVT model achieves a top-1 accuracy of 85.1%, outperforming sequence-only baselines by a substantial margin and achieving better performance results compared to other QML models.
<div id='section'>Paperid: <span id='pid'>1024, <a href='https://arxiv.org/pdf/2508.02834.pdf' target='_blank'>https://arxiv.org/pdf/2508.02834.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanqi Feng, Peng Qiu, Mengchun Zhang, Yiran Tao, You Fan, Jingtao Xu, Barnabas Poczos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02834">Learning from B Cell Evolution: Adaptive Multi-Expert Diffusion for Antibody Design via Online Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in diffusion models have shown remarkable potential for antibody design, yet existing approaches apply uniform generation strategies that cannot adapt to each antigen's unique requirements. Inspired by B cell affinity maturation, where antibodies evolve through multi-objective optimization balancing affinity, stability, and self-avoidance, we propose the first biologically-motivated framework that leverages physics-based domain knowledge within an online meta-learning system. Our method employs multiple specialized experts (van der Waals, molecular recognition, energy balance, and interface geometry) whose parameters evolve during generation based on iterative feedback, mimicking natural antibody refinement cycles. Instead of fixed protocols, this adaptive guidance discovers personalized optimization strategies for each target. Our experiments demonstrate that this approach: (1) discovers optimal SE(3)-equivariant guidance strategies for different antigen classes without pre-training, preserving molecular symmetries throughout optimization; (2) significantly enhances hotspot coverage and interface quality through target-specific adaptation, achieving balanced multi-objective optimization characteristic of therapeutic antibodies; (3) establishes a paradigm for iterative refinement where each antibody-antigen system learns its unique optimization profile through online evaluation; (4) generalizes effectively across diverse design challenges, from small epitopes to large protein interfaces, enabling precision-focused campaigns for individual targets.
<div id='section'>Paperid: <span id='pid'>1025, <a href='https://arxiv.org/pdf/2507.20426.pdf' target='_blank'>https://arxiv.org/pdf/2507.20426.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samiul Based Shuvo, Tasnia Binte Mamun, U Rajendra Acharya
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.20426">ResCap-DBP: A Lightweight Residual-Capsule Network for Accurate DNA-Binding Protein Prediction Using Global ProteinBERT Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>DNA-binding proteins (DBPs) are integral to gene regulation and cellular processes, making their accurate identification essential for understanding biological functions and disease mechanisms. Experimental methods for DBP identification are time-consuming and costly, driving the need for efficient computational prediction techniques. In this study, we propose a novel deep learning framework, ResCap-DBP, that combines a residual learning-based encoder with a one-dimensional Capsule Network (1D-CapsNet) to predict DBPs directly from raw protein sequences. Our architecture incorporates dilated convolutions within residual blocks to mitigate vanishing gradient issues and extract rich sequence features, while capsule layers with dynamic routing capture hierarchical and spatial relationships within the learned feature space. We conducted comprehensive ablation studies comparing global and local embeddings from ProteinBERT and conventional one-hot encoding. Results show that ProteinBERT embeddings substantially outperform other representations on large datasets. Although one-hot encoding showed marginal advantages on smaller datasets, such as PDB186, it struggled to scale effectively. Extensive evaluations on four pairs of publicly available benchmark datasets demonstrate that our model consistently outperforms current state-of-the-art methods. It achieved AUC scores of 98.0% and 89.5% on PDB14189andPDB1075, respectively. On independent test sets PDB2272 and PDB186, the model attained top AUCs of 83.2% and 83.3%, while maintaining competitive performance on larger datasets such as PDB20000. Notably, the model maintains a well balanced sensitivity and specificity across datasets. These results demonstrate the efficacy and generalizability of integrating global protein representations with advanced deep learning architectures for reliable and scalable DBP prediction in diverse genomic contexts.
<div id='section'>Paperid: <span id='pid'>1026, <a href='https://arxiv.org/pdf/2507.19805.pdf' target='_blank'>https://arxiv.org/pdf/2507.19805.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>FranÃ§ois Charih, James R. Green, Kyle K. Biggar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19805">Sequence-based protein-protein interaction prediction and its applications in drug discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Aberrant protein-protein interactions (PPIs) underpin a plethora of human diseases, and disruption of these harmful interactions constitute a compelling treatment avenue. Advances in computational approaches to PPI prediction have closely followed progress in deep learning and natural language processing. In this review, we outline the state-of the-art for sequence-based PPI prediction methods and explore their impact on target identification and drug discovery. We begin with an overview of commonly used training data sources and techniques used to curate these data to enhance the quality of the training set. Subsequently, we survey various PPI predictor types, including traditional similarity-based approaches, and deep learning-based approaches with a particular emphasis on the transformer architecture. Finally, we provide examples of PPI prediction in systems-level proteomics analyses, target identification, and design of therapeutic peptides and antibodies. We also take the opportunity to showcase the potential of PPI-aware drug discovery models in accelerating therapeutic development.
<div id='section'>Paperid: <span id='pid'>1027, <a href='https://arxiv.org/pdf/2507.12574.pdf' target='_blank'>https://arxiv.org/pdf/2507.12574.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Deng, Spencer S. Ericksen, Anthony Gitter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.12574">Assay2Mol: large language model-based drug design using BioAssay context</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific databases aggregate vast amounts of quantitative data alongside descriptive text. In biochemistry, molecule screening assays evaluate candidate molecules' functional responses against disease targets. Unstructured text that describes the biological mechanisms through which these targets operate, experimental screening protocols, and other attributes of assays offer rich information for drug discovery campaigns but has been untapped because of that unstructured format. We present Assay2Mol, a large language model-based workflow that can capitalize on the vast existing biochemical screening assays for early-stage drug discovery. Assay2Mol retrieves existing assay records involving targets similar to the new target and generates candidate molecules using in-context learning with the retrieved assay screening data. Assay2Mol outperforms recent machine learning approaches that generate candidate ligand molecules for target protein structures, while also promoting more synthesizable molecule generation.
<div id='section'>Paperid: <span id='pid'>1028, <a href='https://arxiv.org/pdf/2507.10953.pdf' target='_blank'>https://arxiv.org/pdf/2507.10953.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Balu Bhasuran, Sabenabanu Abdulkadhar, Jeyakumar Natarajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10953">Unraveling the Biomarker Prospects of High-Altitude Diseases: Insights from Biomolecular Event Network Constructed using Text Mining</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-altitude diseases (HAD), encompassing acute mountain sickness (AMS), high-altitude cerebral edema (HACE), and high-altitude pulmonary edema (HAPE), are triggered by hypobaric hypoxia at elevations above 2,500 meters. These conditions pose significant health risks, yet the molecular mechanisms remain insufficiently understood. In this study, we developed a biomolecular event extraction pipeline integrating supervised machine learning with feature-based and multiscale Laplacian graph kernels to analyze 7,847 curated HAD-related abstracts from PubMed. We extracted over 150 unique biomolecular events including gene expression, regulation, binding, and localization and constructed a weighted, undirected biomolecular event network comprising 97 nodes and 153 edges. Using the PageRank algorithm, we prioritized key biomolecules based on their centrality within the event network. The top-ranked proteins included Erythropoietin (EPO) (0.0163), Vascular endothelial growth factor (VEGF) (0.0148), Hypoxia-inducible factor 1 (HIF-1) alpha (0.0136), Endothelial PAS Domain Protein 1 (EPAS1) and Angiotensin-Converting Enzyme (ACE) (0.0119), Egl nine homolog 1 (EGLN1), Endothelin 1 (ET-1), and 70 kilodalton heat shock protein (Hsp70)(0.0118), all of which play crucial roles in oxygen sensing, vascular remodeling, erythropoiesis, and blood pressure regulation. Subnetwork analysis revealed three major functional clusters centered on hypoxia response, inflammation, and stress adaptation pathways. Our integrative approach demonstrates the utility of large-scale text mining and graph-based analysis to uncover mechanistic insights and prioritize potential biomarkers for high-altitude disease.
<div id='section'>Paperid: <span id='pid'>1029, <a href='https://arxiv.org/pdf/2507.08966.pdf' target='_blank'>https://arxiv.org/pdf/2507.08966.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meng Liu, Karl Leswing, Simon K. S. Chu, Farhad Ramezanghorbani, Griffin Young, Gabriel Marques, Prerna Das, Anjali Panikar, Esther Jamir, Mohammed Sulaiman Shamsudeen, K. Shawn Watts, Ananya Sen, Hari Priya Devannagari, Edward B. Miller, Muyun Lihan, Howook Hwang, Janet Paulsen, Xin Yu, Kyle Gion, Timur Rvachov, Emine Kucukbenli, Saee Gopal Paliwal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08966">ToxBench: A Binding Affinity Prediction Benchmark with AB-FEP-Calculated Labels for Human Estrogen Receptor Alpha</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-ligand binding affinity prediction is essential for drug discovery and toxicity assessment. While machine learning (ML) promises fast and accurate predictions, its progress is constrained by the availability of reliable data. In contrast, physics-based methods such as absolute binding free energy perturbation (AB-FEP) deliver high accuracy but are computationally prohibitive for high-throughput applications. To bridge this gap, we introduce ToxBench, the first large-scale AB-FEP dataset designed for ML development and focused on a single pharmaceutically critical target, Human Estrogen Receptor Alpha (ER$Î±$). ToxBench contains 8,770 ER$Î±$-ligand complex structures with binding free energies computed via AB-FEP with a subset validated against experimental affinities at 1.75 kcal/mol RMSE, along with non-overlapping ligand splits to assess model generalizability. Using ToxBench, we further benchmark state-of-the-art ML methods, and notably, our proposed DualBind model, which employs a dual-loss framework to effectively learn the binding energy function. The benchmark results demonstrate the superior performance of DualBind and the potential of ML to approximate AB-FEP at a fraction of the computational cost.
<div id='section'>Paperid: <span id='pid'>1030, <a href='https://arxiv.org/pdf/2506.20043.pdf' target='_blank'>https://arxiv.org/pdf/2506.20043.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmet Sarigun, Bora Uyar, Vedran Franke, Altuna Akalin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.20043">PocketVina Enables Scalable and Highly Accurate Physically Valid Docking through Multi-Pocket Conditioning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sampling physically valid ligand-binding poses remains a major challenge in molecular docking, particularly for unseen or structurally diverse targets. We introduce PocketVina, a fast and memory-efficient, search-based docking framework that combines pocket prediction with systematic multi-pocket exploration. We evaluate PocketVina across four established benchmarks--PDBbind2020 (timesplit and unseen), DockGen, Astex, and PoseBusters--and observe consistently strong performance in sampling physically valid docking poses. PocketVina achieves state-of-the-art performance when jointly considering ligand RMSD and physical validity (PB-valid), while remaining competitive with deep learning-based approaches in terms of RMSD alone, particularly on structurally diverse and previously unseen targets. PocketVina also maintains state-of-the-art physically valid docking accuracy across ligands with varying degrees of flexibility. We further introduce TargetDock-AI, a benchmarking dataset we curated, consisting of over 500000 protein-ligand pairs, and a partition of the dataset labeled with PubChem activity annotations. On this large-scale dataset, PocketVina successfully discriminates active from inactive targets, outperforming a deep learning baseline while requiring significantly less GPU memory and runtime. PocketVina offers a robust and scalable docking strategy that requires no task-specific training and runs efficiently on standard GPUs, making it well-suited for high-throughput virtual screening and structure-based drug discovery.
<div id='section'>Paperid: <span id='pid'>1031, <a href='https://arxiv.org/pdf/2506.17857.pdf' target='_blank'>https://arxiv.org/pdf/2506.17857.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chunan Liu, Aurelien Pelissier, Yanjun Shao, Lilian Denzler, Andrew C. R. Martin, Brooks Paige, MarÃ­a RodrÃ­guez MartÃ­nez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17857">AbRank: A Benchmark Dataset and Metric-Learning Framework for Antibody-Antigen Affinity Ranking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of antibody-antigen (Ab-Ag) binding affinity is essential for therapeutic design and vaccine development, yet the performance of current models is limited by noisy experimental labels, heterogeneous assay conditions, and poor generalization across the vast antibody and antigen sequence space. We introduce AbRank, a large-scale benchmark and evaluation framework that reframes affinity prediction as a pairwise ranking problem. AbRank aggregates over 380,000 binding assays from nine heterogeneous sources, spanning diverse antibodies, antigens, and experimental conditions, and introduces standardized data splits that systematically increase distribution shift, from local perturbations such as point mutations to broad generalization across novel antigens and antibodies. To ensure robust supervision, AbRank defines an m-confident ranking framework by filtering out comparisons with marginal affinity differences, focusing training on pairs with at least an m-fold difference in measured binding strength. As a baseline for the benchmark, we introduce WALLE-Affinity, a graph-based approach that integrates protein language model embeddings with structural information to predict pairwise binding preferences. Our benchmarks reveal significant limitations in current methods under realistic generalization settings and demonstrate that ranking-based training improves robustness and transferability. In summary, AbRank offers a robust foundation for machine learning models to generalize across the antibody-antigen space, with direct relevance for scalable, structure-aware antibody therapeutic design.
<div id='section'>Paperid: <span id='pid'>1032, <a href='https://arxiv.org/pdf/2506.17064.pdf' target='_blank'>https://arxiv.org/pdf/2506.17064.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aditya Sengar, Ali Hariri, Daniel Probst, Patrick Barth, Pierre Vandergheynst
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17064">Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generating diverse, all-atom conformational ensembles of dynamic proteins such as G-protein-coupled receptors (GPCRs) is critical for understanding their function, yet most generative models simplify atomic detail or ignore conformational diversity altogether. We present latent diffusion for full protein generation (LD-FPG), a framework that constructs complete all-atom protein structures, including every side-chain heavy atom, directly from molecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neural network (ChebNet) to obtain low-dimensional latent embeddings of protein conformations, which are processed using three pooling strategies: blind, sequential and residue-based. A diffusion model trained on these latent representations generates new samples that a decoder, optionally regularized by dihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a 2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptor in a membrane environment, the sequential and residue-based pooling strategy reproduces the reference ensemble with high structural fidelity (all-atom lDDT of approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backbone and side-chain dihedral-angle distributions with a Jensen-Shannon divergence of less than 0.03 compared to the MD data. LD-FPG thereby offers a practical route to system-specific, all-atom ensemble generation for large proteins, providing a promising tool for structure-based therapeutic design on complex, dynamic targets. The D2R-MD dataset and our implementation are freely available to facilitate further research.
<div id='section'>Paperid: <span id='pid'>1033, <a href='https://arxiv.org/pdf/2506.10015.pdf' target='_blank'>https://arxiv.org/pdf/2506.10015.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuqiao Zhang, Sarath Chandra Dantu, Debarghya Mitra, Dalia Chakrabarty
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10015">Identifying critical residues of a protein using meaningfully-thresholded Random Geometric Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identification of critical residues of a protein is actively pursued, since such residues are essential for protein function. We present three ways of recognising critical residues of an example protein, the evolution of which is tracked via molecular dynamical simulations. Our methods are based on learning a Random Geometric Graph (RGG) variable, where the state variable of each of 156 residues, is attached to a node of this graph, with the RGG learnt using the matrix of correlations between state variables of each residue-pair. Given the categorical nature of the state variable, correlation between a residue pair is computed using Cramer's V. We advance an organic thresholding to learn an RGG, and compare results against extant thresholding techniques, when parametrising criticality as the nodal degree in the learnt RGG. Secondly, we develop a criticality measure by ranking the computed differences between the posterior probability of the full graph variable defined on all 156 residues, and that of the graph with all but one residue omitted. A third parametrisation of criticality informs on the dynamical variation of nodal degrees as the protein evolves during the simulation. Finally, we compare results obtained with the three distinct criticality parameters, against experimentally-ascertained critical residues.
<div id='section'>Paperid: <span id='pid'>1034, <a href='https://arxiv.org/pdf/2506.05443.pdf' target='_blank'>https://arxiv.org/pdf/2506.05443.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiyu Lin, Yan Wang, You Zhou, Xinye Ni, Jiahui Wu, Sen Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.05443">UniPTMs: The First Unified Multi-type PTM Site Prediction Model via Master-Slave Architecture-Based Multi-Stage Fusion Strategy and Hierarchical Contrastive Loss</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a core mechanism of epigenetic regulation in eukaryotes, protein post-translational modifications (PTMs) require precise prediction to decipher dynamic life activity networks. To address the limitations of existing deep learning models in cross-modal feature fusion, domain generalization, and architectural optimization, this study proposes UniPTMs: the first unified framework for multi-type PTM prediction. The framework innovatively establishes a "Master-Slave" dual-path collaborative architecture: The master path dynamically integrates high-dimensional representations of protein sequences, structures, and evolutionary information through a Bidirectional Gated Cross-Attention (BGCA) module, while the slave path optimizes feature discrepancies and recalibration between structural and traditional features using a Low-Dimensional Fusion Network (LDFN). Complemented by a Multi-scale Adaptive convolutional Pyramid (MACP) for capturing local feature patterns and a Bidirectional Hierarchical Gated Fusion Network (BHGFN) enabling multi-level feature integration across paths, the framework employs a Hierarchical Dynamic Weighting Fusion (HDWF) mechanism to intelligently aggregate multimodal features. Enhanced by a novel Hierarchical Contrastive loss function for feature consistency optimization, UniPTMs demonstrates significant performance improvements (3.2%-11.4% MCC and 4.2%-14.3% AP increases) over state-of-the-art models across five modification types and transcends the Single-Type Prediction Paradigm. To strike a balance between model complexity and performance, we have also developed a lightweight variant named UniPTMs-mini.
<div id='section'>Paperid: <span id='pid'>1035, <a href='https://arxiv.org/pdf/2505.21241.pdf' target='_blank'>https://arxiv.org/pdf/2505.21241.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Divya Nori, Anisha Parsan, Caroline Uhler, Wengong Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21241">BindEnergyCraft: Casting Protein Structure Predictors as Energy-Based Models for Binder Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein binder design has been transformed by hallucination-based methods that optimize structure prediction confidence metrics, such as the interface predicted TM-score (ipTM), via backpropagation. However, these metrics do not reflect the statistical likelihood of a binder-target complex under the learned distribution and yield sparse gradients for optimization. In this work, we propose a method to extract such likelihoods from structure predictors by reinterpreting their confidence outputs as an energy-based model (EBM). By leveraging the Joint Energy-based Modeling (JEM) framework, we introduce pTMEnergy, a statistical energy function derived from predicted inter-residue error distributions. We incorporate pTMEnergy into BindEnergyCraft (BECraft), a design pipeline that maintains the same optimization framework as BindCraft but replaces ipTM with our energy-based objective. BECraft outperforms BindCraft, RFDiffusion, and ESM3 across multiple challenging targets, achieving higher in silico binder success rates while reducing structural clashes. Furthermore, pTMEnergy establishes a new state-of-the-art in structure-based virtual screening tasks for miniprotein and RNA aptamer binders.
<div id='section'>Paperid: <span id='pid'>1036, <a href='https://arxiv.org/pdf/2505.20098.pdf' target='_blank'>https://arxiv.org/pdf/2505.20098.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaowen Ling, Zhiqiang Li, Yanbin Wang, Zhuhong You
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20098">Transformers in Protein: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As protein informatics advances rapidly, the demand for enhanced predictive accuracy, structural analysis, and functional understanding has intensified. Transformer models, as powerful deep learning architectures, have demonstrated unprecedented potential in addressing diverse challenges across protein research. However, a comprehensive review of Transformer applications in this field remains lacking. This paper bridges this gap by surveying over 100 studies, offering an in-depth analysis of practical implementations and research progress of Transformers in protein-related tasks. Our review systematically covers critical domains, including protein structure prediction, function prediction, protein-protein interaction analysis, functional annotation, and drug discovery/target identification. To contextualize these advancements across various protein domains, we adopt a domain-oriented classification system. We first introduce foundational concepts: the Transformer architecture and attention mechanisms, categorize Transformer variants tailored for protein science, and summarize essential protein knowledge. For each research domain, we outline its objectives and background, critically evaluate prior methods and their limitations, and highlight transformative contributions enabled by Transformer models. We also curate and summarize pivotal datasets and open-source code resources to facilitate reproducibility and benchmarking. Finally, we discuss persistent challenges in applying Transformers to protein informatics and propose future research directions. This review aims to provide a consolidated foundation for the synergistic integration of Transformer and protein informatics, fostering further innovation and expanded applications in the field.
<div id='section'>Paperid: <span id='pid'>1037, <a href='https://arxiv.org/pdf/2505.16896.pdf' target='_blank'>https://arxiv.org/pdf/2505.16896.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Chen, David Heurtel-Depeiges, Robert M. Vernon, Christopher James Langmead, Yoshua Bengio, Quentin Fournier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16896">Structure-Aligned Protein Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models (pLMs) pre-trained on vast protein sequence databases excel at various downstream tasks but lack the structural knowledge essential for many biological applications. To address this, we integrate structural insights from pre-trained protein graph neural networks (pGNNs) into pLMs through a latent-level contrastive learning task. This task aligns residue representations from pLMs with those from pGNNs across multiple proteins, enriching pLMs with inter-protein structural knowledge. Additionally, we incorporate a physical-level task that infuses intra-protein structural knowledge by optimizing pLMs to predict structural tokens. The proposed dual-task framework effectively incorporates both inter-protein and intra-protein structural knowledge into pLMs. Given the variability in the quality of protein structures in PDB, we further introduce a residue loss selection module, which uses a small model trained on high-quality structures to select reliable yet challenging residue losses for the pLM to learn. Applying our structure alignment method to the state-of-the-art ESM2 and AMPLIFY results in notable performance gains across a wide range of tasks, including a 12.7% increase in ESM2 contact prediction. The data, code, and resulting SaESM2 and SaAMPLIFY models will be released on Hugging Face.
<div id='section'>Paperid: <span id='pid'>1038, <a href='https://arxiv.org/pdf/2505.16032.pdf' target='_blank'>https://arxiv.org/pdf/2505.16032.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kathryn Linehan, Radu Balan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16032">CUR Matrix Approximation through Convex Optimization for Feature Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The singular value decomposition (SVD) is commonly used in applications requiring a low rank matrix approximation. However, the singular vectors cannot be interpreted in terms of the original data. For applications requiring this type of interpretation, e.g., selection of important data matrix columns or rows, the approximate CUR matrix factorization can be used. Work on the CUR matrix approximation has generally focused on algorithm development, theoretical guarantees, and applications. In this work, we present a novel deterministic CUR formulation and algorithm with theoretical convergence guarantees. The algorithm utilizes convex optimization, finds important columns and rows separately, and allows the user to control the number of important columns and rows selected from the original data matrix. We present numerical results and demonstrate the effectiveness of our CUR algorithm as a feature selection method on gene expression data. These results are compared to those using the SVD and other CUR algorithms as the feature selection method. Lastly, we present a novel application of CUR as a feature selection method to determine discriminant proteins when clustering protein expression data in a self-organizing map (SOM), and compare the performance of multiple CUR algorithms in this application.
<div id='section'>Paperid: <span id='pid'>1039, <a href='https://arxiv.org/pdf/2505.15831.pdf' target='_blank'>https://arxiv.org/pdf/2505.15831.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashley Wang, Peter Chin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15831">Ricci Matrix Comparison for Graph Alignment: A DMC Variation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The graph alignment problem explores the concept of node correspondence and its optimality. In this paper, we focus on purely geometric graph alignment methods, namely our newly proposed Ricci Matrix Comparison (RMC) and its original form, Degree Matrix Comparison (DMC). To formulate a Ricci-curvature-based graph alignment situation, we start with discussing different ideas of constructing one of the most typical and important topological objects, the torus, and then move on to introducing the RMC based on DMC with theoretical motivations. Lastly, we will present to the reader experimental results on a torus and a complex protein-protein interaction network that indicate the potential of applying a differential-geometric view to graph alignment. Results show that a direct variation of DMC using Ricci curvature can help with identifying holes in tori and aligning line graphs of a complex network at 80-90+% accuracy. This paper contributes a new perspective to the field of graph alignment and partially shows the validity of the previous DMC method.
<div id='section'>Paperid: <span id='pid'>1040, <a href='https://arxiv.org/pdf/2505.12913.pdf' target='_blank'>https://arxiv.org/pdf/2505.12913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tom George Grigg, Mason Burlage, Oliver Brook Scott, Adam Taouil, Dominique Sydow, Liam Wilbraham
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12913">Active Learning on Synthons for Molecular Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Exhaustive virtual screening is highly informative but often intractable against the expensive objective functions involved in modern drug discovery. This problem is exacerbated in combinatorial contexts such as multi-vector expansion, where molecular spaces can quickly become ultra-large. Here, we introduce Scalable Active Learning via Synthon Acquisition (SALSA): a simple algorithm applicable to multi-vector expansion which extends pool-based active learning to non-enumerable spaces by factoring modeling and acquisition over synthon or fragment choices. Through experiments on ligand- and structure-based objectives, we highlight SALSA's sample efficiency, and its ability to scale to spaces of trillions of compounds. Further, we demonstrate application toward multi-parameter objective design tasks on three protein targets - finding SALSA-generated molecules have comparable chemical property profiles to known bioactives, and exhibit greater diversity and higher scores over an industry-leading generative approach.
<div id='section'>Paperid: <span id='pid'>1041, <a href='https://arxiv.org/pdf/2505.10545.pdf' target='_blank'>https://arxiv.org/pdf/2505.10545.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amira Alakhdar, Barnabas Poczos, Newell Washburn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.10545">Pharmacophore-Conditioned Diffusion Model for Ligand-Based De Novo Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing bioactive molecules remains a central, time- and cost-heavy challenge in drug discovery, particularly for novel targets lacking structural or functional data. Pharmacophore modeling presents an alternative for capturing the key features required for molecular bioactivity against a biological target. In this work, we present PharmaDiff, a pharmacophore-conditioned diffusion model for 3D molecular generation. PharmaDiff employs a transformer-based architecture to integrate an atom-based representation of the 3D pharmacophore into the generative process, enabling the precise generation of 3D molecular graphs that align with predefined pharmacophore hypotheses. Through comprehensive testing, PharmaDiff demonstrates superior performance in matching 3D pharmacophore constraints compared to ligand-based drug design methods. Additionally, it achieves higher docking scores across a range of proteins in structure-based drug design, without the need for target protein structures. By integrating pharmacophore modeling with 3D generative techniques, PharmaDiff offers a powerful and flexible framework for rational drug design.
<div id='section'>Paperid: <span id='pid'>1042, <a href='https://arxiv.org/pdf/2505.04823.pdf' target='_blank'>https://arxiv.org/pdf/2505.04823.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junhao Xiong, Hunter Nisonoff, Maria Lukarska, Ishan Gaur, Luke M. Oltrogge, David F. Savage, Jennifer Listgarten
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04823">Guide your favorite protein sequence generative model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative machine learning models on sequences are transforming protein engineering. However, no principled framework exists for conditioning these models on auxiliary information, such as experimental data, in a plug-and-play manner. Herein, we present ProteinGuide -- a principled and general method for conditioning -- by unifying a broad class of protein generative models under a single framework. We demonstrate the applicability of ProteinGuide by guiding two protein generative models, ProteinMPNN and ESM3, to generate amino acid and structure token sequences, conditioned on several user-specified properties such as enhanced stability, enzyme classes, and CATH-labeled folds. We also used ProteinGuide with inverse folding models and our own experimental assay to design adenine base editor sequences for high activity.
<div id='section'>Paperid: <span id='pid'>1043, <a href='https://arxiv.org/pdf/2504.20102.pdf' target='_blank'>https://arxiv.org/pdf/2504.20102.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingzhi Yu, Shuai Yan, Wenfeng Dai, Xiang Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.20102">HyboWaveNet: Hyperbolic Graph Neural Networks with Multi-Scale Wavelet Transform for Protein-Protein Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interactions (PPIs) are fundamental for deciphering cellular functions,disease pathways,and drug discovery.Although existing neural networks and machine learning methods have achieved high accuracy in PPI prediction,their black-box nature leads to a lack of causal interpretation of the prediction results and difficulty in capturing hierarchical geometries and multi-scale dynamic interaction patterns among proteins.To address these challenges, we propose HyboWaveNet,a novel deep learning framework that collaborates with hyperbolic graphical neural networks (HGNNs) and multiscale graphical wavelet transform for robust PPI prediction. Mapping protein features to Lorentz space simulates hierarchical topological relationships among biomolecules via a hyperbolic distance metric,enabling node feature representations that better fit biological a priori.HyboWaveNet inherently simulates hierarchical and scale-free biological relationships, while the integration of wavelet transforms enables adaptive extraction of local and global interaction features across different resolutions. Our framework generates node feature representations via a graph neural network under the Lorenz model and generates pairs of positive samples under multiple different views for comparative learning, followed by further feature extraction via multi-scale graph wavelet transforms to predict potential PPIs. Experiments on public datasets show that HyboWaveNet improves over both existing state-of-the-art methods. We also demonstrate through ablation experimental studies that the multi-scale graph wavelet transform module improves the predictive performance and generalization ability of HyboWaveNet. This work links geometric deep learning and signal processing to advance PPI prediction, providing a principled approach for analyzing complex biological systems
<div id='section'>Paperid: <span id='pid'>1044, <a href='https://arxiv.org/pdf/2504.14274.pdf' target='_blank'>https://arxiv.org/pdf/2504.14274.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhengxi Lu, Shizhuo Cheng, Yuru Jiang, Yan Zhang, Min Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.14274">ProtPainter: Draw or Drag Protein via Topology-guided Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in protein backbone generation have achieved promising results under structural, functional, or physical constraints. However, existing methods lack the flexibility for precise topology control, limiting navigation of the backbone space. We present ProtPainter, a diffusion-based approach for generating protein backbones conditioned on 3D curves. ProtPainter follows a two-stage process: curve-based sketching and sketch-guided backbone generation. For the first stage, we propose CurveEncoder, which predicts secondary structure annotations from a curve to parametrize sketch generation. For the second stage, the sketch guides the generative process in Denoising Diffusion Probabilistic Modeling (DDPM) to generate backbones. During this process, we further introduce a fusion scheduling scheme, Helix-Gating, to control the scaling factors. To evaluate, we propose the first benchmark for topology-conditioned protein generation, introducing Protein Restoration Task and a new metric, self-consistency Topology Fitness (scTF). Experiments demonstrate ProtPainter's ability to generate topology-fit (scTF > 0.8) and designable (scTM > 0.5) backbones, with drawing and dragging tasks showcasing its flexibility and versatility.
<div id='section'>Paperid: <span id='pid'>1045, <a href='https://arxiv.org/pdf/2504.13853.pdf' target='_blank'>https://arxiv.org/pdf/2504.13853.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pingfei Zhu, Chenyang Zhao, Haishi Zhao, Bo Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13853">GenShin:geometry-enhanced structural graph embodies binding pose can better predicting compound-protein interaction affinity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI-powered drug discovery typically relies on the successful prediction of compound-protein interactions, which are pivotal for the evaluation of designed compound molecules in structure-based drug design and represent a core challenge in the field.
  However, accurately predicting compound-protein affinity via regression models usually requires adequate-binding pose, which are derived from costly and complex experimental methods or time-consuming simulations with docking software. In response, we have introduced the GenShin model, which constructs a geometry-enhanced structural graph module that separately extracts additional features from proteins and compounds. Consequently, it attains an accuracy on par with mainstream models in predicting compound-protein affinities, while eliminating the need for adequate-binding pose as input. Our experimental findings demonstrate that the GenShin model vastly outperforms other models that rely on non-input docking conformations, achieving, or in some cases even exceeding, the performance of those requiring adequate-binding pose. Further experiments indicate that our GenShin model is more robust to inadequate-binding pose, affirming its higher suitability for real-world drug discovery scenarios. We hope our work will inspire more endeavors to bridge the gap between AI models and practical drug discovery challenges.
<div id='section'>Paperid: <span id='pid'>1046, <a href='https://arxiv.org/pdf/2504.08328.pdf' target='_blank'>https://arxiv.org/pdf/2504.08328.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alice Driessen, Benedek Harsanyi, Marianna Rapsomaniki, Jannis Born
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08328">Towards generalizable single-cell perturbation modeling via the Conditional Monge Gap</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning the response of single-cells to various treatments offers great potential to enable targeted therapies. In this context, neural optimal transport (OT) has emerged as a principled methodological framework because it inherently accommodates the challenges of unpaired data induced by cell destruction during data acquisition. However, most existing OT approaches are incapable of conditioning on different treatment contexts (e.g., time, drug treatment, drug dosage, or cell type) and we still lack methods that unanimously show promising generalization performance to unseen treatments. Here, we propose the Conditional Monge Gap which learns OT maps conditionally on arbitrary covariates. We demonstrate its value in predicting single-cell perturbation responses conditional to one or multiple drugs, a drug dosage, or combinations thereof. We find that our conditional models achieve results comparable and sometimes even superior to the condition-specific state-of-the-art on scRNA-seq as well as multiplexed protein imaging data. Notably, by aggregating data across conditions we perform cross-task learning which unlocks remarkable generalization abilities to unseen drugs or drug dosages, widely outperforming other conditional models in capturing heterogeneity (i.e., higher moments) in the perturbed population. Finally, by scaling to hundreds of conditions and testing on unseen drugs, we narrow the gap between structure-based and effect-based drug representations, suggesting a promising path to the successful prediction of perturbation effects for unseen treatments.
<div id='section'>Paperid: <span id='pid'>1047, <a href='https://arxiv.org/pdf/2504.07156.pdf' target='_blank'>https://arxiv.org/pdf/2504.07156.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan van Eck, Dea Gogishvili, Wilson Silva, Sanne Abeln
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07156">PLM-eXplain: Divide and Conquer the Protein Embedding Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models (PLMs) have revolutionised computational biology through their ability to generate powerful sequence representations for diverse prediction tasks. However, their black-box nature limits biological interpretation and translation to actionable insights. We present an explainable adapter layer - PLM-eXplain (PLM-X), that bridges this gap by factoring PLM embeddings into two components: an interpretable subspace based on established biochemical features, and a residual subspace that preserves the model's predictive power. Using embeddings from ESM2, our adapter incorporates well-established properties, including secondary structure and hydropathy while maintaining high performance. We demonstrate the effectiveness of our approach across three protein-level classification tasks: prediction of extracellular vesicle association, identification of transmembrane helices, and prediction of aggregation propensity. PLM-X enables biological interpretation of model decisions without sacrificing accuracy, offering a generalisable solution for enhancing PLM interpretability across various downstream applications. This work addresses a critical need in computational biology by providing a bridge between powerful deep learning models and actionable biological insights.
<div id='section'>Paperid: <span id='pid'>1048, <a href='https://arxiv.org/pdf/2504.02698.pdf' target='_blank'>https://arxiv.org/pdf/2504.02698.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengrui XU, Tianchi Lu, Zikun Wang, Jixiu Zhai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02698">SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interaction (PPI) prediction plays a pivotal role in deciphering cellular functions and disease mechanisms. To address the limitations of traditional experimental methods and existing computational approaches in cross-modal feature fusion and false-negative suppression, we propose SCMPPI-a novel supervised contrastive multimodal framework. By effectively integrating sequence-based features (AAC, DPC, ESMC-CKSAAP) with network topology (Node2Vec embeddings) and incorporating an enhanced contrastive learning strategy with negative sample filtering, SCMPPI achieves superior prediction performance. Extensive experiments on eight benchmark datasets demonstrate its state-of-the-art accuracy(98.13%) and AUC(99.69%), along with excellent cross-species generalization (AUC>99%). Successful applications in CD9 networks, Wnt pathway analysis, and cancer-specific networks further highlight its potential for disease target discovery, establishing SCMPPI as a powerful tool for multimodal biological data analysis.
<div id='section'>Paperid: <span id='pid'>1049, <a href='https://arxiv.org/pdf/2503.13329.pdf' target='_blank'>https://arxiv.org/pdf/2503.13329.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Beatriz Costa-Gomes, Joel Greer, Nikolai Juraschko, James Parkhurst, Jola Mirecka, Marjan Famili, Camila Rangel-Smith, Oliver Strickson, Alan Lowe, Mark Basham, Tom Burnley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13329">PERC: a suite of software tools for the curation of cryoEM data with application to simulation, modelling and machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ease of access to data, tools and models expedites scientific research. In structural biology there are now numerous open repositories of experimental and simulated datasets. Being able to easily access and utilise these is crucial for allowing researchers to make optimal use of their research effort. The tools presented here are useful for collating existing public cryoEM datasets and/or creating new synthetic cryoEM datasets to aid the development of novel data processing and interpretation algorithms. In recent years, structural biology has seen the development of a multitude of machine-learning based algorithms for aiding numerous steps in the processing and reconstruction of experimental datasets and the use of these approaches has become widespread. Developing such techniques in structural biology requires access to large datasets which can be cumbersome to curate and unwieldy to make use of. In this paper we present a suite of Python software packages which we collectively refer to as PERC (profet, EMPIARreader and CAKED). These are designed to reduce the burden which data curation places upon structural biology research. The protein structure fetcher (profet) package allows users to conveniently download and cleave sequences or structures from the Protein Data Bank or Alphafold databases. EMPIARreader allows lazy loading of Electron Microscopy Public Image Archive datasets in a machine-learning compatible structure. The Class Aggregator for Key Electron-microscopy Data (CAKED) package is designed to seamlessly facilitate the training of machine learning models on electron microscopy data, including electron-cryo-microscopy-specific data augmentation and labelling. These packages may be utilised independently or as building blocks in workflows. All are available in open source repositories and designed to be easily extensible to facilitate more advanced workflows if required.
<div id='section'>Paperid: <span id='pid'>1050, <a href='https://arxiv.org/pdf/2503.08838.pdf' target='_blank'>https://arxiv.org/pdf/2503.08838.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Burak Suyunu, Ãzdeniz Dolu, Arzucan ÃzgÃ¼r
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08838">evoBPE: Evolutionary Protein Sequence Tokenization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in computational biology have drawn compelling parallels between protein sequences and linguistic structures, highlighting the need for sophisticated tokenization methods that capture the intricate evolutionary dynamics of protein sequences. Current subword tokenization techniques, primarily developed for natural language processing, often fail to represent protein sequences' complex structural and functional properties adequately. This study introduces evoBPE, a novel tokenization approach that integrates evolutionary mutation patterns into sequence segmentation, addressing critical limitations in existing methods. By leveraging established substitution matrices, evoBPE transcends traditional frequency-based tokenization strategies. The method generates candidate token pairs through biologically informed mutations, evaluating them based on pairwise alignment scores and frequency thresholds. Extensive experiments on human protein sequences show that evoBPE performs better across multiple dimensions. Domain conservation analysis reveals that evoBPE consistently outperforms standard Byte-Pair Encoding, particularly as vocabulary size increases. Furthermore, embedding similarity analysis using ESM-2 suggests that mutation-based token replacements preserve biological sequence properties more effectively than arbitrary substitutions. The research contributes to protein sequence representation by introducing a mutation-aware tokenization method that better captures evolutionary nuances. By bridging computational linguistics and molecular biology, evoBPE opens new possibilities for machine learning applications in protein function prediction, structural modeling, and evolutionary analysis.
<div id='section'>Paperid: <span id='pid'>1051, <a href='https://arxiv.org/pdf/2503.05560.pdf' target='_blank'>https://arxiv.org/pdf/2503.05560.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mirja Granfors, JesÃºs Pineda, Blanca Zufiria GerbolÃ©s, Joana B. Pereira, Carlo Manzo, Giovanni Volpe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05560">Global graph features unveiled by unsupervised geometric deep learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graphs provide a powerful framework for modeling complex systems, but their structural variability poses significant challenges for analysis and classification. To address these challenges, we introduce GAUDI (Graph Autoencoder Uncovering Descriptive Information), a novel unsupervised geometric deep learning framework designed to capture both local details and global structure. GAUDI employs an innovative hourglass architecture with hierarchical pooling and upsampling layers linked through skip connections, which preserve essential connectivity information throughout the encoding-decoding process. Even though identical or highly similar underlying parameters describing a system's state can lead to significant variability in graph realizations, GAUDI consistently maps them into nearby regions of a structured and continuous latent space, effectively disentangling invariant process-level features from stochastic noise. We demonstrate GAUDI's versatility across multiple applications, including small-world networks modeling, characterization of protein assemblies from super-resolution microscopy, analysis of collective motion in the Vicsek model, and identification of age-related changes in brain connectivity. Comparison with related approaches highlights GAUDI's superior performance in analyzing complex graphs, providing new insights into emergent phenomena across diverse scientific domains.
<div id='section'>Paperid: <span id='pid'>1052, <a href='https://arxiv.org/pdf/2503.03360.pdf' target='_blank'>https://arxiv.org/pdf/2503.03360.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Afnan Sultan, Max Rausch-Dupont, Shahrukh Khan, Olga Kalinina, Dietrich Klakow, Andrea Volkamer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.03360">Transformers for molecular property prediction: Domain adaptation efficiently improves performance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over the past six years, molecular transformer models have become key tools in drug discovery. Most existing models are pre-trained on large, unlabeled datasets such as ZINC or ChEMBL. However, the extent to which large-scale pre-training improves molecular property prediction remains unclear. This study evaluates transformer models for this task while addressing their limitations. We explore how pre-training dataset size and chemically informed objectives impact performance. Our results show that increasing the dataset beyond approximately 400K to 800K molecules from large-scale unlabeled databases does not enhance performance across seven datasets covering five ADME endpoints: lipophilicity, permeability, solubility (two datasets), microsomal stability (two datasets), and plasma protein binding. In contrast, domain adaptation on a small, domain-specific dataset (less than or equal 4K molecules) using multi-task regression of physicochemical properties significantly boosts performance (P-value less than 0.001). A model pre-trained on 400K molecules and adapted with domain-specific data outperforms larger models such as MolFormer and performs comparably to MolBERT. Benchmarks against Random Forest (RF) baselines using descriptors and Morgan fingerprints show that chemically and physically informed features consistently yield better performance across model types. While RF remains a strong baseline, we identify concrete practices to enhance transformer performance. Aligning pre-training and adaptation with chemically meaningful tasks and domain-relevant data presents a promising direction for molecular property prediction. Our models are available on HuggingFace for easy use and adaptation.
<div id='section'>Paperid: <span id='pid'>1053, <a href='https://arxiv.org/pdf/2503.00143.pdf' target='_blank'>https://arxiv.org/pdf/2503.00143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tom Pan, Evan Dramko, Mitchell D. Miller, George N. Phillips, Anastasios Kyrillidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00143">RecCrysFormer: Refined Protein Structural Prediction from 3D Patterson Maps via Recycling Training Runs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Determining protein structures at an atomic level remains a significant challenge in structural biology. We introduce $\texttt{RecCrysFormer}$, a hybrid model that exploits the strengths of transformers with the aim of integrating experimental and ML approaches to protein structure determination from crystallographic data. $\texttt{RecCrysFormer}$ leverages Patterson maps and incorporates known standardized partial structures of amino acid residues to directly predict electron density maps, which are essential for constructing detailed atomic models through crystallographic refinement processes. $\texttt{RecCrysFormer}$ benefits from a ``recycling'' training regimen that iteratively incorporates results from crystallographic refinements and previous training runs as additional inputs in the form of template maps. Using a preliminary dataset of synthetic peptide fragments based on Protein Data Bank, $\texttt{RecCrysFormer}$ achieves good accuracy in structural predictions and shows robustness against variations in crystal parameters, such as unit cell dimensions and angles.
<div id='section'>Paperid: <span id='pid'>1054, <a href='https://arxiv.org/pdf/2502.20632.pdf' target='_blank'>https://arxiv.org/pdf/2502.20632.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shoummo Ahsan Khandoker, Estelle M. Inack, Mohamed Hibat-Allah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.20632">Lattice Protein Folding with Variational Annealing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the principles of protein folding is a cornerstone of computational biology, with implications for drug design, bioengineering, and the understanding of fundamental biological processes. Lattice protein folding models offer a simplified yet powerful framework for studying the complexities of protein folding, enabling the exploration of energetically optimal folds under constrained conditions. However, finding these optimal folds is a computationally challenging combinatorial optimization problem. In this work, we introduce a novel upper-bound training scheme that employs masking to identify the lowest-energy folds in two-dimensional Hydrophobic-Polar (HP) lattice protein folding. By leveraging Dilated Recurrent Neural Networks (RNNs) integrated with an annealing process driven by temperature-like fluctuations, our method accurately predicts optimal folds for benchmark systems of up to 60 beads. Our approach also effectively masks invalid folds from being sampled without compromising the autoregressive sampling properties of RNNs. This scheme is generalizable to three spatial dimensions and can be extended to lattice protein models with larger alphabets. Our findings emphasize the potential of advanced machine learning techniques in tackling complex protein folding problems and a broader class of constrained combinatorial optimization challenges.
<div id='section'>Paperid: <span id='pid'>1055, <a href='https://arxiv.org/pdf/2502.12565.pdf' target='_blank'>https://arxiv.org/pdf/2502.12565.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hikaru Asano, Tadashi Kozuno, Yukino Baba
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12565">Self Iterative Label Refinement via Robust Unlabeled Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in large language models (LLMs) have yielded impressive performance on various tasks, yet they often depend on high-quality feedback that can be costly. Self-refinement methods attempt to leverage LLMs' internal evaluation mechanisms with minimal human supervision; however, these approaches frequently suffer from inherent biases and overconfidence, especially in domains where the models lack sufficient internal knowledge, resulting in performance degradation. As an initial step toward enhancing self-refinement for broader applications, we introduce an iterative refinement pipeline that employs the Unlabeled-Unlabeled learning framework to improve LLM-generated pseudo-labels for classification tasks. By exploiting two unlabeled datasets with differing positive class ratios, our approach iteratively denoises and refines the initial pseudo-labels, thereby mitigating the adverse effects of internal biases with minimal human supervision. Evaluations on diverse datasets, including low-resource language corpora, patent classifications, and protein structure categorizations, demonstrate that our method consistently outperforms both initial LLM's classification performance and the self-refinement approaches by cutting-edge models (e.g., GPT-4o and DeepSeek-R1).
<div id='section'>Paperid: <span id='pid'>1056, <a href='https://arxiv.org/pdf/2502.10828.pdf' target='_blank'>https://arxiv.org/pdf/2502.10828.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amey P. Pasarkar, Adji Bousso Dieng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.10828">The Vendiscope: An Algorithmic Microscope For Data Collections</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The evolution of microscopy, beginning with its invention in the late 16th century, has continuously enhanced our ability to explore and understand the microscopic world, enabling increasingly detailed observations of structures and phenomena. In parallel, the rise of data-driven science has underscored the need for sophisticated methods to explore and understand the composition of complex data collections. This paper introduces the Vendiscope, the first algorithmic microscope designed to extend traditional microscopy to computational analysis. The Vendiscope leverages the Vendi scores -- a family of differentiable diversity metrics rooted in ecology and quantum mechanics -- and assigns weights to data points based on their contribution to the overall diversity of the collection. These weights enable high-resolution data analysis at scale. We demonstrate this across biology, materials science, and machine learning (ML). We analyzed the $250$ million protein sequences in the protein universe, discovering that over $200$ million are near-duplicates and that AlphaFold fails on proteins with Gene Ontology (GO) functions that contribute most to diversity. Applying the Vendiscope to the Materials Project database led to similar findings: more than $85\%$ of the crystals with formation energy data are near-duplicates and ML models perform poorly on materials that enhance diversity. Additionally, the Vendiscope can be used to study phenomena such as memorization in generative models. We used the Vendiscope to identify memorized training samples from $13$ different generative models and found that the best-performing ones often memorize the training samples that contribute least to diversity. Our findings demonstrate that the Vendiscope can serve as a powerful tool for data-driven science.
<div id='section'>Paperid: <span id='pid'>1057, <a href='https://arxiv.org/pdf/2502.01461.pdf' target='_blank'>https://arxiv.org/pdf/2502.01461.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amitay Sicherman, Kira Radinsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01461">Docking-Aware Attention: Dynamic Protein Representations through Molecular Context Integration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational prediction of enzymatic reactions represents a crucial challenge in sustainable chemical synthesis across various scientific domains, ranging from drug discovery to materials science and green chemistry. These syntheses rely on proteins that selectively catalyze complex molecular transformations. These protein catalysts exhibit remarkable substrate adaptability, with the same protein often catalyzing different chemical transformations depending on its molecular partners. Current approaches to protein representation in reaction prediction either ignore protein structure entirely or rely on static embeddings, failing to capture how proteins dynamically adapt their behavior to different substrates. We present Docking-Aware Attention (DAA), a novel architecture that generates dynamic, context-dependent protein representations by incorporating molecular docking information into the attention mechanism. DAA combines physical interaction scores from docking predictions with learned attention patterns to focus on protein regions most relevant to specific molecular interactions. We evaluate our method on enzymatic reaction prediction, where it outperforms previous state-of-the-art methods, achieving 62.2\% accuracy versus 56.79\% on complex molecules and 55.54\% versus 49.45\% on innovative reactions. Through detailed ablation studies and visualizations, we demonstrate how DAA generates interpretable attention patterns that adapt to different molecular contexts. Our approach represents a general framework for context-aware protein representation in biocatalysis prediction, with potential applications across enzymatic synthesis planning. We open-source our implementation and pre-trained models to facilitate further research.
<div id='section'>Paperid: <span id='pid'>1058, <a href='https://arxiv.org/pdf/2501.18223.pdf' target='_blank'>https://arxiv.org/pdf/2501.18223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manuel F. Mollon, Joaquin Gonzalez-Rodriguez, Alicia Lozano-Diez, Daniel Ramos, Doroteo T. Toledano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18223">Exploring Large Protein Language Models in Constrained Evaluation Scenarios within the FLIP Benchmark</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we expand upon the FLIP benchmark-designed for evaluating protein fitness prediction models in small, specialized prediction tasks-by assessing the performance of state-of-the-art large protein language models, including ESM-2 and SaProt on the FLIP dataset. Unlike larger, more diverse benchmarks such as ProteinGym, which cover a broad spectrum of tasks, FLIP focuses on constrained settings where data availability is limited. This makes it an ideal framework to evaluate model performance in scenarios with scarce task-specific data. We investigate whether recent advances in protein language models lead to significant improvements in such settings. Our findings provide valuable insights into the performance of large-scale models in specialized protein prediction tasks.
<div id='section'>Paperid: <span id='pid'>1059, <a href='https://arxiv.org/pdf/2501.09571.pdf' target='_blank'>https://arxiv.org/pdf/2501.09571.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Laird, Circe Hsu, Asilata Bapat, Robin Walters
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.09571">MatrixNet: Learning over symmetry groups using learned group representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Group theory has been used in machine learning to provide a theoretically grounded approach for incorporating known symmetry transformations in tasks from robotics to protein modeling. In these applications, equivariant neural networks use known symmetry groups with predefined representations to learn over geometric input data. We propose MatrixNet, a neural network architecture that learns matrix representations of group element inputs instead of using predefined representations. MatrixNet achieves higher sample efficiency and generalization over several standard baselines in prediction tasks over the several finite groups and the Artin braid group. We also show that MatrixNet respects group relations allowing generalization to group elements of greater word length than in the training set.
<div id='section'>Paperid: <span id='pid'>1060, <a href='https://arxiv.org/pdf/2501.07747.pdf' target='_blank'>https://arxiv.org/pdf/2501.07747.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Bianchin de Oliveira, Helio Pedrini, Zanoni Dias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.07747">Scaling Up ESM2 Architectures for Long Protein Sequences Analysis: Long and Quantized Approaches</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Various approaches utilizing Transformer architectures have achieved state-of-the-art results in Natural Language Processing (NLP). Based on this success, numerous architectures have been proposed for other types of data, such as in biology, particularly for protein sequences. Notably among these are the ESM2 architectures, pre-trained on billions of proteins, which form the basis of various state-of-the-art approaches in the field. However, the ESM2 architectures have a limitation regarding input size, restricting it to 1,022 amino acids, which necessitates the use of preprocessing techniques to handle sequences longer than this limit. In this paper, we present the long and quantized versions of the ESM2 architectures, doubling the input size limit to 2,048 amino acids.
<div id='section'>Paperid: <span id='pid'>1061, <a href='https://arxiv.org/pdf/2501.02824.pdf' target='_blank'>https://arxiv.org/pdf/2501.02824.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Jiang, Long Chen, Yueying Zhu, Yazhou Shi, Huahai Qiu, Bengong Zhang, Tianshou Zhou, Guo-Wei Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.02824">Proteomic Learning of Gamma-Aminobutyric Acid (GABA) Receptor-Mediated Anesthesia</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anesthetics are crucial in surgical procedures and therapeutic interventions, but they come with side effects and varying levels of effectiveness, calling for novel anesthetic agents that offer more precise and controllable effects. Targeting Gamma-aminobutyric acid (GABA) receptors, the primary inhibitory receptors in the central nervous system, could enhance their inhibitory action, potentially reducing side effects while improving the potency of anesthetics. In this study, we introduce a proteomic learning of GABA receptor-mediated anesthesia based on 24 GABA receptor subtypes by considering over 4000 proteins in protein-protein interaction (PPI) networks and over 1.5 millions known binding compounds. We develop a corresponding drug-target interaction network to identify potential lead compounds for novel anesthetic design. To ensure robust proteomic learning predictions, we curated a dataset comprising 136 targets from a pool of 980 targets within the PPI networks. We employed three machine learning algorithms, integrating advanced natural language processing (NLP) models such as pretrained transformer and autoencoder embeddings. Through a comprehensive screening process, we evaluated the side effects and repurposing potential of over 180,000 drug candidates targeting the GABRA5 receptor. Additionally, we assessed the ADMET (absorption, distribution, metabolism, excretion, and toxicity) properties of these candidates to identify those with near-optimal characteristics. This approach also involved optimizing the structures of existing anesthetics. Our work presents an innovative strategy for the development of new anesthetic drugs, optimization of anesthetic use, and deeper understanding of potential anesthesia-related side effects.
<div id='section'>Paperid: <span id='pid'>1062, <a href='https://arxiv.org/pdf/2501.02680.pdf' target='_blank'>https://arxiv.org/pdf/2501.02680.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wen-ran Li, Xavier F. Cadet, David Medina-Ortiz, Mehdi D. Davari, Ramanathan Sowdhamini, Cedric Damour, Yu Li, Alain Miranville, Frederic Cadet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.02680">From thermodynamics to protein design: Diffusion models for biomolecule generation towards autonomous protein engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein design with desirable properties has been a significant challenge for many decades. Generative artificial intelligence is a promising approach and has achieved great success in various protein generation tasks. Notably, diffusion models stand out for their robust mathematical foundations and impressive generative capabilities, offering unique advantages in certain applications such as protein design. In this review, we first give the definition and characteristics of diffusion models and then focus on two strategies: Denoising Diffusion Probabilistic Models and Score-based Generative Models, where DDPM is the discrete form of SGM. Furthermore, we discuss their applications in protein design, peptide generation, drug discovery, and protein-ligand interaction. Finally, we outline the future perspectives of diffusion models to advance autonomous protein design and engineering. The E(3) group consists of all rotations, reflections, and translations in three-dimensions. The equivariance on the E(3) group can keep the physical stability of the frame of each amino acid as much as possible, and we reflect on how to keep the diffusion model E(3) equivariant for protein generation.
<div id='section'>Paperid: <span id='pid'>1063, <a href='https://arxiv.org/pdf/2412.19812.pdf' target='_blank'>https://arxiv.org/pdf/2412.19812.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Conghao Wang, Jagath C. Rajapakse
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.19812">Pharmacophore-guided de novo drug design with diffusion bridge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>De novo design of bioactive drug molecules with potential to treat desired biological targets is a profound task in the drug discovery process. Existing approaches tend to leverage the pocket structure of the target protein to condition the molecule generation. However, even the pocket area of the target protein may contain redundant information since not all atoms in the pocket is responsible for the interaction with the ligand. In this work, we propose PharmacoBridge, a phamacophore-guided de novo design approach to generate drug candidates inducing desired bioactivity via diffusion bridge. Our method adapts the diffusion bridge to effectively convert pharmacophore arrangements in the spatial space into molecular structures under the manner of SE(3)-equivariant transformation, providing sophisticated control over optimal biochemical feature arrangements on the generated molecules. PharmacoBridge is demonstrated to generate hit candidates that exhibit high binding affinity with potential protein targets.
<div id='section'>Paperid: <span id='pid'>1064, <a href='https://arxiv.org/pdf/2412.18633.pdf' target='_blank'>https://arxiv.org/pdf/2412.18633.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars L. Schaaf, Ilyes Batatia, Christoph Brunken, Thomas D. Barrett, Jules Tilly
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.18633">BoostMD: Accelerating molecular sampling by leveraging ML force field features from previous time-steps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulating atomic-scale processes, such as protein dynamics and catalytic reactions, is crucial for advancements in biology, chemistry, and materials science. Machine learning force fields (MLFFs) have emerged as powerful tools that achieve near quantum mechanical accuracy, with promising generalization capabilities. However, their practical use is often limited by long inference times compared to classical force fields, especially when running extensive molecular dynamics (MD) simulations required for many biological applications. In this study, we introduce BoostMD, a surrogate model architecture designed to accelerate MD simulations. BoostMD leverages node features computed at previous time steps to predict energies and forces based on positional changes. This approach reduces the complexity of the learning task, allowing BoostMD to be both smaller and significantly faster than conventional MLFFs. During simulations, the computationally intensive reference MLFF is evaluated only every $N$ steps, while the lightweight BoostMD model handles the intermediate steps at a fraction of the computational cost. Our experiments demonstrate that BoostMD achieves an eight-fold speedup compared to the reference model and generalizes to unseen dipeptides. Furthermore, we find that BoostMD accurately samples the ground-truth Boltzmann distribution when running molecular dynamics. By combining efficient feature reuse with a streamlined architecture, BoostMD offers a robust solution for conducting large-scale, long-timescale molecular simulations, making high-accuracy ML-driven modeling more accessible and practical.
<div id='section'>Paperid: <span id='pid'>1065, <a href='https://arxiv.org/pdf/2412.17240.pdf' target='_blank'>https://arxiv.org/pdf/2412.17240.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yilong Zang, Lingfei Ren, Yue Li, Zhikang Wang, David Antony Selby, Zheng Wang, Sebastian Josef Vollmer, Hongzhi Yin, Jiangning Song, Junhang Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.17240">Rethinking Cancer Gene Identification through Graph Anomaly Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph neural networks (GNNs) have shown promise in integrating protein-protein interaction (PPI) networks for identifying cancer genes in recent studies. However, due to the insufficient modeling of the biological information in PPI networks, more faithfully depiction of complex protein interaction patterns for cancer genes within the graph structure remains largely unexplored. This study takes a pioneering step toward bridging biological anomalies in protein interactions caused by cancer genes to statistical graph anomaly. We find a unique graph anomaly exhibited by cancer genes, namely weight heterogeneity, which manifests as significantly higher variance in edge weights of cancer gene nodes within the graph. Additionally, from the spectral perspective, we demonstrate that the weight heterogeneity could lead to the "flattening out" of spectral energy, with a concentration towards the extremes of the spectrum. Building on these insights, we propose the HIerarchical-Perspective Graph Neural Network (HIPGNN) that not only determines spectral energy distribution variations on the spectral perspective, but also perceives detailed protein interaction context on the spatial perspective. Extensive experiments are conducted on two reprocessed datasets STRINGdb and CPDB, and the experimental results demonstrate the superiority of HIPGNN.
<div id='section'>Paperid: <span id='pid'>1066, <a href='https://arxiv.org/pdf/2412.12101.pdf' target='_blank'>https://arxiv.org/pdf/2412.12101.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elana Simon, James Zou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12101">InterPLM: Discovering Interpretable Features in Protein Language Models via Sparse Autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models (PLMs) have demonstrated remarkable success in protein modeling and design, yet their internal mechanisms for predicting structure and function remain poorly understood. Here we present a systematic approach to extract and analyze interpretable features from PLMs using sparse autoencoders (SAEs). By training SAEs on embeddings from the PLM ESM-2, we identify up to 2,548 human-interpretable latent features per layer that strongly correlate with up to 143 known biological concepts such as binding sites, structural motifs, and functional domains. In contrast, examining individual neurons in ESM-2 reveals up to 46 neurons per layer with clear conceptual alignment across 15 known concepts, suggesting that PLMs represent most concepts in superposition. Beyond capturing known annotations, we show that ESM-2 learns coherent concepts that do not map onto existing annotations and propose a pipeline using language models to automatically interpret novel latent features learned by the SAEs. As practical applications, we demonstrate how these latent features can fill in missing annotations in protein databases and enable targeted steering of protein sequence generation. Our results demonstrate that PLMs encode rich, interpretable representations of protein biology and we propose a systematic framework to extract and analyze these latent features. In the process, we recover both known biology and potentially new protein motifs. As community resources, we introduce InterPLM (interPLM.ai), an interactive visualization platform for exploring and analyzing learned PLM features, and release code for training and analysis at github.com/ElanaPearl/interPLM.
<div id='section'>Paperid: <span id='pid'>1067, <a href='https://arxiv.org/pdf/2412.05776.pdf' target='_blank'>https://arxiv.org/pdf/2412.05776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Azwad Tamir, Jiann-Shiun Yuan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05776">ProtGO: A Transformer based Fusion Model for accurately predicting Gene Ontology (GO) Terms from full scale Protein Sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent developments in next generation sequencing technology have led to the creation of extensive, open-source protein databases consisting of hundreds of millions of sequences. To render these sequences applicable in biomedical applications, they must be meticulously annotated by wet lab testing or extracting them from existing literature. Over the last few years, researchers have developed numerous automatic annotation systems, particularly deep learning models based on machine learning and artificial intelligence, to address this issue. In this work, we propose a transformer-based fusion model capable of predicting Gene Ontology (GO) terms from full-scale protein sequences, achieving state-of-the-art accuracy compared to other contemporary machine learning annotation systems. The approach performs particularly well on clustered split datasets, which comprise training and testing samples originating from distinct distributions that are structurally diverse. This demonstrates that the model is able to understand both short and long term dependencies within the enzyme's structure and can precisely identify the motifs associated with the various GO terms. Furthermore, the technique is lightweight and less computationally expensive compared to the benchmark methods, while at the same time not unaffected by sequence length, rendering it appropriate for diverse applications with varying sequence lengths.
<div id='section'>Paperid: <span id='pid'>1068, <a href='https://arxiv.org/pdf/2411.17669.pdf' target='_blank'>https://arxiv.org/pdf/2411.17669.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Burak Suyunu, Enes Taylan, Arzucan ÃzgÃ¼r
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17669">Linguistic Laws Meet Protein Sequences: A Comparative Analysis of Subword Tokenization Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tokenization is a crucial step in processing protein sequences for machine learning models, as proteins are complex sequences of amino acids that require meaningful segmentation to capture their functional and structural properties. However, existing subword tokenization methods, developed primarily for human language, may be inadequate for protein sequences, which have unique patterns and constraints. This study evaluates three prominent tokenization approaches, Byte-Pair Encoding (BPE), WordPiece, and SentencePiece, across varying vocabulary sizes (400-6400), analyzing their effectiveness in protein sequence representation, domain boundary preservation, and adherence to established linguistic laws. Our comprehensive analysis reveals distinct behavioral patterns among these tokenizers, with vocabulary size significantly influencing their performance. BPE demonstrates better contextual specialization and marginally better domain boundary preservation at smaller vocabularies, while SentencePiece achieves better encoding efficiency, leading to lower fertility scores. WordPiece offers a balanced compromise between these characteristics. However, all tokenizers show limitations in maintaining protein domain integrity, particularly as vocabulary size increases. Analysis of linguistic law adherence shows partial compliance with Zipf's and Brevity laws but notable deviations from Menzerath's law, suggesting that protein sequences may follow distinct organizational principles from natural languages. These findings highlight the limitations of applying traditional NLP tokenization methods to protein sequences and emphasize the need for developing specialized tokenization strategies that better account for the unique characteristics of proteins.
<div id='section'>Paperid: <span id='pid'>1069, <a href='https://arxiv.org/pdf/2411.15618.pdf' target='_blank'>https://arxiv.org/pdf/2411.15618.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Florian B. Hinz, Matthew R. Masters, Julia N. Kieu, Amr H. Mahmoud, Markus A. Lill
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15618">Accelerated Hydration Site Localization and Thermodynamic Profiling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Water plays a fundamental role in the structure and function of proteins and other biomolecules. The thermodynamic profile of water molecules surrounding a protein are critical for ligand binding and recognition. Therefore, identifying the location and thermodynamic behavior of relevant water molecules is important for generating and optimizing lead compounds for affinity and selectivity to a given target. Computational methods have been developed to identify these hydration sites, but are largely limited to simplified models that fail to capture multi-body interactions, or dynamics-based methods that rely on extensive sampling. Here we present a method for fast and accurate localization and thermodynamic profiling of hydration sites for protein structures. The method is based on a geometric deep neural network trained on a large, novel dataset of explicit water molecular dynamics simulations. We confirm the accuracy and robustness of our model on experimental data and demonstrate it's utility on several case studies.
<div id='section'>Paperid: <span id='pid'>1070, <a href='https://arxiv.org/pdf/2411.14157.pdf' target='_blank'>https://arxiv.org/pdf/2411.14157.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahsa Sheikholeslami, Navid Mazrouei, Yousof Gheisari, Afshin Fasihi, Matin Irajpour, Ali Motahharynia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14157">DrugGen: Advancing Drug Discovery with Large Language Models and Reinforcement Learning Feedback</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional drug design faces significant challenges due to inherent chemical and biological complexities, often resulting in high failure rates in clinical trials. Deep learning advancements, particularly generative models, offer potential solutions to these challenges. One promising algorithm is DrugGPT, a transformer-based model, that generates small molecules for input protein sequences. Although promising, it generates both chemically valid and invalid structures and does not incorporate the features of approved drugs, resulting in time-consuming and inefficient drug discovery. To address these issues, we introduce DrugGen, an enhanced model based on the DrugGPT structure. DrugGen is fine-tuned on approved drug-target interactions and optimized with proximal policy optimization. By giving reward feedback from protein-ligand binding affinity prediction using pre-trained transformers (PLAPT) and a customized invalid structure assessor, DrugGen significantly improves performance. Evaluation across multiple targets demonstrated that DrugGen achieves 100% valid structure generation compared to 95.5% with DrugGPT and produced molecules with higher predicted binding affinities (7.22 [6.30-8.07]) compared to DrugGPT (5.81 [4.97-6.63]) while maintaining diversity and novelty. Docking simulations further validate its ability to generate molecules targeting binding sites effectively. For example, in the case of fatty acid-binding protein 5 (FABP5), DrugGen generated molecules with superior docking scores (FABP5/11, -9.537 and FABP5/5, -8.399) compared to the reference molecule (Palmitic acid, -6.177). Beyond lead compound generation, DrugGen also shows potential for drug repositioning and creating novel pharmacophores for existing targets. By producing high-quality small molecules, DrugGen provides a high-performance medium for advancing pharmaceutical research and drug discovery.
<div id='section'>Paperid: <span id='pid'>1071, <a href='https://arxiv.org/pdf/2411.04775.pdf' target='_blank'>https://arxiv.org/pdf/2411.04775.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Tabish, Neil K. Chada, Stefan Klus
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04775">Learning dynamical systems from data: Gradient-based dictionary optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Koopman operator plays a crucial role in analyzing the global behavior of dynamical systems. Existing data-driven methods for approximating the Koopman operator or discovering the governing equations of the underlying system typically require a fixed set of basis functions, also called dictionary. The optimal choice of basis functions is highly problem-dependent and often requires domain knowledge. We present a novel gradient descent-based optimization framework for learning suitable and interpretable basis functions from data and show how it can be used in combination with EDMD, SINDy, and PDE-FIND. We illustrate the efficacy of the proposed approach with the aid of various benchmark problems such as the Ornstein-Uhlenbeck process, Chua's circuit, a nonlinear heat equation, as well as protein-folding data.
<div id='section'>Paperid: <span id='pid'>1072, <a href='https://arxiv.org/pdf/2410.21335.pdf' target='_blank'>https://arxiv.org/pdf/2410.21335.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Po-Yu Liang, Jun Bai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21335">E(3)-invariant diffusion model for pocket-aware peptide generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biologists frequently desire protein inhibitors for a variety of reasons, including use as research tools for understanding biological processes and application to societal problems in agriculture, healthcare, etc. Immunotherapy, for instance, relies on immune checkpoint inhibitors to block checkpoint proteins, preventing their binding with partner proteins and boosting immune cell function against abnormal cells. Inhibitor discovery has long been a tedious process, which in recent years has been accelerated by computational approaches. Advances in artificial intelligence now provide an opportunity to make inhibitor discovery smarter than ever before. While extensive research has been conducted on computer-aided inhibitor discovery, it has mainly focused on either sequence-to-structure mapping, reverse mapping, or bio-activity prediction, making it unrealistic for biologists to utilize such tools. Instead, our work proposes a new method of computer-assisted inhibitor discovery: de novo pocket-aware peptide structure and sequence generation network. Our approach consists of two sequential diffusion models for end-to-end structure generation and sequence prediction. By leveraging angle and dihedral relationships between backbone atoms, we ensure an E(3)-invariant representation of peptide structures. Our results demonstrate that our method achieves comparable performance to state-of-the-art models, highlighting its potential in pocket-aware peptide design. This work offers a new approach for precise drug discovery using receptor-specific peptide generation.
<div id='section'>Paperid: <span id='pid'>1073, <a href='https://arxiv.org/pdf/2410.21069.pdf' target='_blank'>https://arxiv.org/pdf/2410.21069.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoqi Ling, Cheng Cai, Demin Kong, Zhisheng Wei, Jing Wu, Lei Wang, Zhaohong Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21069">EMOCPD: Efficient Attention-based Models for Computational Protein Design Using Amino Acid Microenvironment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational protein design (CPD) refers to the use of computational methods to design proteins. Traditional methods relying on energy functions and heuristic algorithms for sequence design are inefficient and do not meet the demands of the big data era in biomolecules, with their accuracy limited by the energy functions and search algorithms. Existing deep learning methods are constrained by the learning capabilities of the networks, failing to extract effective information from sparse protein structures, which limits the accuracy of protein design. To address these shortcomings, we developed an Efficient attention-based Models for Computational Protein Design using amino acid microenvironment (EMOCPD). It aims to predict the category of each amino acid in a protein by analyzing the three-dimensional atomic environment surrounding the amino acids, and optimize the protein based on the predicted high-probability potential amino acid categories. EMOCPD employs a multi-head attention mechanism to focus on important features in the sparse protein microenvironment and utilizes an inverse residual structure to optimize the network architecture. The proposed EMOCPD achieves over 80% accuracy on the training set and 68.33% and 62.32% accuracy on two independent test sets, respectively, surpassing the best comparative methods by over 10%. In protein design, the thermal stability and protein expression of the predicted mutants from EMOCPD show significant improvements compared to the wild type, effectively validating EMOCPD's potential in designing superior proteins. Furthermore, the predictions of EMOCPD are influenced positively, negatively, or have minimal impact based on the content of the 20 amino acids, categorizing amino acids as positive, negative, or neutral. Research findings indicate that EMOCPD is more suitable for designing proteins with lower contents of negative amino acids.
<div id='section'>Paperid: <span id='pid'>1074, <a href='https://arxiv.org/pdf/2410.20182.pdf' target='_blank'>https://arxiv.org/pdf/2410.20182.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Deng, Spencer S. Ericksen, Anthony Gitter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20182">Chemical Language Model Linker: blending text and molecules with modular adapters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The development of large language models and multi-modal models has enabled the appealing idea of generating novel molecules from text descriptions. Generative modeling would shift the paradigm from relying on large-scale chemical screening to find molecules with desired properties to directly generating those molecules. However, multi-modal models combining text and molecules are often trained from scratch, without leveraging existing high-quality pretrained models. Training from scratch consumes more computational resources and prohibits model scaling. In contrast, we propose a lightweight adapter-based strategy named Chemical Language Model Linker (ChemLML). ChemLML blends the two single domain models and obtains conditional molecular generation from text descriptions while still operating in the specialized embedding spaces of the molecular domain. ChemLML can tailor diverse pretrained text models for molecule generation by training relatively few adapter parameters. We find that the choice of molecular representation used within ChemLML, SMILES versus SELFIES, has a strong influence on conditional molecular generation performance. SMILES is often preferable despite not guaranteeing valid molecules. We raise issues in using the entire PubChem dataset of molecules and their associated descriptions for evaluating molecule generation and provide a filtered version of the dataset as a generation test set. To demonstrate how ChemLML could be used in practice, we generate candidate protein inhibitors and use docking to assess their quality and also generate candidate membrane permeable molecules.
<div id='section'>Paperid: <span id='pid'>1075, <a href='https://arxiv.org/pdf/2410.18101.pdf' target='_blank'>https://arxiv.org/pdf/2410.18101.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuzhi Xu, Haowei Ni, Qinhui Gao, Chia-Hua Chang, Yanran Huo, Fanyu Zhao, Shiyu Hu, Wei Xia, Yike Zhang, Radu Grovu, Min He, John. Z. H. Zhang, Yuanqing Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.18101">Molecular Dynamics and Machine Learning Unlock Possibilities in Beauty Design -- A Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational molecular design -- the endeavor to design molecules, with various missions, aided by machine learning and molecular dynamics approaches, has been widely applied to create valuable new molecular entities, from small molecule therapeutics to protein biologics. In the small data regime, physics-based approaches model the interaction between the molecule being designed and proteins of key physiological functions, providing structural insights into the mechanism. When abundant data has been collected, a quantitative structure-activity relationship (QSAR) can be more directly constructed from experimental data, from which machine learning can distill key insights to guide the design of the next round of experiment design. Machine learning methodologies can also facilitate physical modeling, from improving the accuracy of force fields and extending them to unseen chemical spaces, to more directly enhancing the sampling on the conformational spaces. We argue that these techniques are mature enough to be applied to not just extend the longevity of life, but the beauty it manifests. In this perspective, we review the current frontiers in the research \& development of skin care products, as well as the statistical and physical toolbox applicable to addressing the challenges in this industry. Feasible interdisciplinary research projects are proposed to harness the power of machine learning tools to design innovative, effective, and inexpensive skin care products.
<div id='section'>Paperid: <span id='pid'>1076, <a href='https://arxiv.org/pdf/2410.15128.pdf' target='_blank'>https://arxiv.org/pdf/2410.15128.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haibo Wang, Yuxuan Qiu, Yanze Wang, Rob Brekelmans, Yuanqi Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15128">Generalized Flow Matching for Transition Dynamics Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulating transition dynamics between metastable states is a fundamental challenge in dynamical systems and stochastic processes with wide real-world applications in understanding protein folding, chemical reactions and neural activities. However, the computational challenge often lies on sampling exponentially many paths in which only a small fraction ends in the target metastable state due to existence of high energy barriers. To amortize the cost, we propose a data-driven approach to warm-up the simulation by learning nonlinear interpolations from local dynamics. Specifically, we infer a potential energy function from local dynamics data. To find plausible paths between two metastable states, we formulate a generalized flow matching framework that learns a vector field to sample propable paths between the two marginal densities under the learned energy function. Furthermore, we iteratively refine the model by assigning importance weights to the sampled paths and buffering more likely paths for training. We validate the effectiveness of the proposed method to sample probable paths on both synthetic and real-world molecular systems.
<div id='section'>Paperid: <span id='pid'>1077, <a href='https://arxiv.org/pdf/2410.13264.pdf' target='_blank'>https://arxiv.org/pdf/2410.13264.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xu Han, Yuancheng Sun, Kai Chen, Kang Liu, Qiwei Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13264">The Latent Road to Atoms: Backmapping Coarse-grained Protein Structures with Latent Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Coarse-grained(CG) molecular dynamics simulations offer computational efficiency for exploring protein conformational ensembles and thermodynamic properties. Though coarse representations enable large-scale simulations across extended temporal and spatial ranges, the sacrifice of atomic-level details limits their utility in tasks such as ligand docking and protein-protein interaction prediction. Backmapping, the process of reconstructing all-atom structures from coarse-grained representations, is crucial for recovering these fine details. While recent machine learning methods have made strides in protein structure generation, challenges persist in reconstructing diverse atomistic conformations that maintain geometric accuracy and chemical validity. In this paper, we present Latent Diffusion Backmapping (LDB), a novel approach leveraging denoising diffusion within latent space to address these challenges. By combining discrete latent encoding with diffusion, LDB bypasses the need for equivariant and internal coordinate manipulation, significantly simplifying the training and sampling processes as well as facilitating better and wider exploration in configuration space. We evaluate LDB's state-of-the-art performance on three distinct protein datasets, demonstrating its ability to efficiently reconstruct structures with high structural accuracy and chemical validity. Moreover, LDB shows exceptional versatility in capturing diverse protein ensembles, highlighting its capability to explore intricate conformational spaces. Our results position LDB as a powerful and scalable approach for backmapping, effectively bridging the gap between CG simulations and atomic-level analyses in computational biology.
<div id='section'>Paperid: <span id='pid'>1078, <a href='https://arxiv.org/pdf/2410.08203.pdf' target='_blank'>https://arxiv.org/pdf/2410.08203.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Olga Anosova, Alexey Gorelov, William Jeffcott, Ziqiu Jiang, Vitaliy Kurlin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08203">Complete and bi-continuous invariant of protein backbones under rigid motion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are large biomolecules that regulate all living organisms and consist of one or several chains. The primary structure of a protein chain is a sequence of amino acid residues whose three main atoms (alpha-carbon, nitrogen, and carbonyl carbon) form a protein backbone. The tertiary structure is the rigid shape of a protein chain represented by atomic positions in 3-dimensional space. Because different geometric structures often have distinct functional properties, it is important to continuously quantify differences in rigid shapes of protein backbones. Unfortunately, many widely used similarities of proteins fail axioms of a distance metric and discontinuously change under tiny perturbations of atoms.
  This paper develops a complete invariant that identifies any protein backbone in 3-dimensional space, uniquely under rigid motion. This invariant is Lipschitz bi-continuous in the sense that it changes up to a constant multiple of a maximum perturbation of atoms, and vice versa. The new invariant has been used to detect thousands of (near-)duplicates in the Protein Data Bank, whose presence inevitably skews machine learning predictions. The resulting invariant space allows low-dimensional maps with analytically defined coordinates that reveal substantial variability in the protein universe.
<div id='section'>Paperid: <span id='pid'>1079, <a href='https://arxiv.org/pdf/2410.03634.pdf' target='_blank'>https://arxiv.org/pdf/2410.03634.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jason Yang, Aadyot Bhatnagar, Jeffrey A. Ruffolo, Ali Madani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.03634">Function-Guided Conditional Generation Using Protein Language Models with Adapters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The conditional generation of proteins with desired functions is a key goal for generative models. Existing methods based on prompting of protein language models (PLMs) can generate proteins conditioned on a target functionality, such as a desired enzyme family. However, these methods are limited to simple, tokenized conditioning and have not been shown to generalize to unseen functions. In this study, we propose ProCALM (Protein Conditionally Adapted Language Model), an approach for the conditional generation of proteins using adapters to PLMs. While previous methods have used adapters for structure-conditioned generation from PLMs, our implementation of ProCALM involves finetuning ProGen2 to condition generation based on versatile representations of protein function-e.g. enzyme family, taxonomy, or natural language descriptions. ProCALM matches or exceeds the performance of existing methods at conditional sequence generation from target functions. Impressively, it can also generalize to rare and unseen functions. Overall, ProCALM is a flexible and computationally efficient approach, and we expect that it can be extended to a wide range of generative language models.
<div id='section'>Paperid: <span id='pid'>1080, <a href='https://arxiv.org/pdf/2410.00833.pdf' target='_blank'>https://arxiv.org/pdf/2410.00833.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erik Jansson, Jonathan Krook, Klas Modin, Ozan Ãktem
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00833">Geometric shape matching for recovering protein conformations from single-particle Cryo-EM data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We address recovery of the three-dimensional backbone structure of single polypeptide proteins from single-particle cryo-electron microscopy (Cryo-SPA) data. Cryo-SPA produces noisy tomographic projections of electrostatic potentials of macromolecules. From these projections, we use methods from shape analysis to recover the three-dimensional backbone structure. Thus, we view the reconstruction problem as an indirect matching problem, where a point cloud representation of the protein backbone is deformed to match 2D tomography data. The deformations are obtained via the action of a matrix Lie group. By selecting a deformation energy, the optimality conditions are obtained, which lead to computational algorithms for optimal deformations. We showcase our approach on synthetic data, for which we recover the three-dimensional structure of the backbone.
<div id='section'>Paperid: <span id='pid'>1081, <a href='https://arxiv.org/pdf/2410.00523.pdf' target='_blank'>https://arxiv.org/pdf/2410.00523.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bernd Ulmann, Shrish Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00523">Building a simple oscillator based Ising machine for research and education</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Oscillator based Ising machines are non-von-Neumann machines ideally suited for solving combinatorial problems otherwise intractable on classic stored-program digital computers due to their run-time complexity. Possible future applications are manifold ranging from quantum simulations to protein folding and are of high academic and commercial interest as well. Described in the following is a very simple such machine aimed at educational and research applications.
<div id='section'>Paperid: <span id='pid'>1082, <a href='https://arxiv.org/pdf/2409.13057.pdf' target='_blank'>https://arxiv.org/pdf/2409.13057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>James Michels, Ramya Bandarupalli, Amin Ahangar Akbari, Thai Le, Hong Xiao, Jing Li, Erik F. Y. Hom
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13057">Natural Language Processing Methods for the Study of Protein-Ligand Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in Natural Language Processing (NLP) have ignited interest in developing effective methods for predicting protein-ligand interactions (PLIs) given their relevance to drug discovery and protein engineering efforts and the ever-growing volume of biochemical sequence and structural data available. The parallels between human languages and the "languages" used to represent proteins and ligands have enabled the use of NLP machine learning approaches to advance PLI studies. In this review, we explain where and how such approaches have been applied in the recent literature and discuss useful mechanisms such as long short-term memory, transformers, and attention. We conclude with a discussion of the current limitations of NLP methods for the study of PLIs as well as key challenges that need to be addressed in future work.
<div id='section'>Paperid: <span id='pid'>1083, <a href='https://arxiv.org/pdf/2409.07189.pdf' target='_blank'>https://arxiv.org/pdf/2409.07189.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamed Dhouioui, Jonathan Barnoud, Rhoslyn Roebuck Williams, Harry J. Stroud, Phil Bates, David R. Glowacki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.07189">A Perspective on AI-Guided Molecular Simulations in VR: Exploring Strategies for Imitation Learning in Hyperdimensional Molecular Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular dynamics simulations are a crucial computational tool for researchers to understand and engineer molecular structure and function in areas such as drug discovery, protein engineering, and material design. Despite their utility, MD simulations are expensive, owing to the high dimensionality of molecular systems. Interactive molecular dynamics in virtual reality (iMD-VR) has recently been developed as a 'human-in-the-loop' strategy, which leverages high-performance computing to accelerate the researcher's ability to solve the hyperdimensional sampling problem. By providing an immersive 3D environment that enables visualization and manipulation of real-time molecular motion, iMD-VR enables researchers and students to efficiently and intuitively explore and navigate these complex, high-dimensional systems. iMD-VR platforms offer a unique opportunity to quickly generate rich datasets that capture human experts' spatial insight regarding molecular structure and function. This paper explores the possibility of employing user-generated iMD-VR datasets to train AI agents via imitation learning (IL). IL is an important technique in robotics that enables agents to mimic complex behaviors from expert demonstrations, thus circumventing the need for explicit programming or intricate reward design. We review the utilization of IL for manipulation tasks in robotics and discuss how iMD-VR recordings could be used to train IL models for solving specific molecular 'tasks'. We then investigate how such approaches could be applied to the data captured from iMD-VR recordings. Finally, we outline the future research directions and potential challenges of using AI agents to augment human expertise to efficiently navigate conformational spaces, highlighting how this approach could provide valuable insight across domains such as materials science, protein engineering, and computer-aided drug design.
<div id='section'>Paperid: <span id='pid'>1084, <a href='https://arxiv.org/pdf/2408.08341.pdf' target='_blank'>https://arxiv.org/pdf/2408.08341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Po-Yu Liang, Xueting Huang, Tibo Duran, Andrew J. Wiemer, Jun Bai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.08341">Exploring Latent Space for Generating Peptide Analogs Using Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generating peptides with desired properties is crucial for drug discovery and biotechnology. Traditional sequence-based and structure-based methods often require extensive datasets, which limits their effectiveness. In this study, we proposed a novel method that utilized autoencoder shaped models to explore the protein embedding space, and generate novel peptide analogs by leveraging protein language models. The proposed method requires only a single sequence of interest, avoiding the need for large datasets. Our results show significant improvements over baseline models in similarity indicators of peptide structures, descriptors and bioactivities. The proposed method validated through Molecular Dynamics simulations on TIGIT inhibitors, demonstrates that our method produces peptide analogs with similar yet distinct properties, highlighting its potential to enhance peptide screening processes.
<div id='section'>Paperid: <span id='pid'>1085, <a href='https://arxiv.org/pdf/2408.06402.pdf' target='_blank'>https://arxiv.org/pdf/2408.06402.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaojiao Guan, Yongxin Ji, Cheng Peng, Wei Zou, Xubo Tang, Jiayu Shang, Yanni Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.06402">PhaGO: Protein function annotation for bacteriophages by integrating the genomic context</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bacteriophages are viruses that target bacteria, playing a crucial role in microbial ecology. Phage proteins are important in understanding phage biology, such as virus infection, replication, and evolution. Although a large number of new phages have been identified via metagenomic sequencing, many of them have limited protein function annotation. Accurate function annotation of phage proteins presents several challenges, including their inherent diversity and the scarcity of annotated ones. Existing tools have yet to fully leverage the unique properties of phages in annotating protein functions. In this work, we propose a new protein function annotation tool for phages by leveraging the modular genomic structure of phage genomes. By employing embeddings from the latest protein foundation models and Transformer to capture contextual information between proteins in phage genomes, PhaGO surpasses state-of-the-art methods in annotating diverged proteins and proteins with uncommon functions by 6.78% and 13.05% improvement, respectively. PhaGO can annotate proteins lacking homology search results, which is critical for characterizing the rapidly accumulating phage genomes. We demonstrate the utility of PhaGO by identifying 688 potential holins in phages, which exhibit high structural conservation with known holins. The results show the potential of PhaGO to extend our understanding of newly discovered phages.
<div id='section'>Paperid: <span id='pid'>1086, <a href='https://arxiv.org/pdf/2408.00220.pdf' target='_blank'>https://arxiv.org/pdf/2408.00220.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Su, Yiying Tong, Guo-Wei Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00220">Persistent de Rham-Hodge Laplacians in Eulerian representation for manifold topological learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, topological data analysis has become a trending topic in data science and engineering. However, the key technique of topological data analysis, i.e., persistent homology, is defined on point cloud data, which does not work directly for data on manifolds. Although earlier evolutionary de Rham-Hodge theory deals with data on manifolds, it is inconvenient for machine learning applications because of the numerical inconsistency caused by remeshing the involving manifolds in the Lagrangian representation. In this work, we introduce persistent de Rham-Hodge Laplacian, or persistent Hodge Laplacian (PHL) as an abbreviation, for manifold topological learning. Our PHLs are constructed in the Eulerian representation via structure-persevering Cartesian grids, avoiding the numerical inconsistency over the multiscale manifolds. To facilitate the manifold topological learning, we propose a persistent Hodge Laplacian learning algorithm for data on manifolds or volumetric data. As a proof-of-principle application of the proposed manifold topological learning model, we consider the prediction of protein-ligand binding affinities with two benchmark datasets. Our numerical experiments highlight the power and promise of the proposed method.
<div id='section'>Paperid: <span id='pid'>1087, <a href='https://arxiv.org/pdf/2408.00057.pdf' target='_blank'>https://arxiv.org/pdf/2408.00057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dan Kalifa, Uriel Singer, Kira Radinsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00057">GOProteinGNN: Leveraging Protein Knowledge Graphs for Protein Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins play a vital role in biological processes and are indispensable for living organisms. Accurate representation of proteins is crucial, especially in drug development. Recently, there has been a notable increase in interest in utilizing machine learning and deep learning techniques for unsupervised learning of protein representations. However, these approaches often focus solely on the amino acid sequence of proteins and lack factual knowledge about proteins and their interactions, thus limiting their performance. In this study, we present GOProteinGNN, a novel architecture that enhances protein language models by integrating protein knowledge graph information during the creation of amino acid level representations. Our approach allows for the integration of information at both the individual amino acid level and the entire protein level, enabling a comprehensive and effective learning process through graph-based learning. By doing so, we can capture complex relationships and dependencies between proteins and their functional annotations, resulting in more robust and contextually enriched protein representations. Unlike previous methods, GOProteinGNN uniquely learns the entire protein knowledge graph during training, which allows it to capture broader relational nuances and dependencies beyond mere triplets as done in previous work. We perform a comprehensive evaluation on several downstream tasks demonstrating that GOProteinGNN consistently outperforms previous methods, showcasing its effectiveness and establishing it as a state-of-the-art solution for protein representation learning.
<div id='section'>Paperid: <span id='pid'>1088, <a href='https://arxiv.org/pdf/2407.13780.pdf' target='_blank'>https://arxiv.org/pdf/2407.13780.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ulrich A. Mbou Sob, Qiulin Li, Miguel ArbesÃº, Oliver Bent, Andries P. Smit, Arnu Pretorius
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13780">Generative Model for Small Molecules with Latent Space RL Fine-Tuning to Protein Targets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A specific challenge with deep learning approaches for molecule generation is generating both syntactically valid and chemically plausible molecular string representations. To address this, we propose a novel generative latent-variable transformer model for small molecules that leverages a recently proposed molecular string representation called SAFE. We introduce a modification to SAFE to reduce the number of invalid fragmented molecules generated during training and use this to train our model. Our experiments show that our model can generate novel molecules with a validity rate > 90% and a fragmentation rate < 1% by sampling from a latent space. By fine-tuning the model using reinforcement learning to improve molecular docking, we significantly increase the number of hit candidates for five specific protein targets compared to the pre-trained model, nearly doubling this number for certain targets. Additionally, our top 5% mean docking scores are comparable to the current state-of-the-art (SOTA), and we marginally outperform SOTA on three of the five targets.
<div id='section'>Paperid: <span id='pid'>1089, <a href='https://arxiv.org/pdf/2407.00002.pdf' target='_blank'>https://arxiv.org/pdf/2407.00002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peter MÃ¸rch Groth, Mads Herbert Kerrn, Lars Olsen, Jesper Salomon, Wouter Boomsma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.00002">Kermut: Composite kernel regression for protein variant effects</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable prediction of protein variant effects is crucial for both protein optimization and for advancing biological understanding. For practical use in protein engineering, it is important that we can also provide reliable uncertainty estimates for our predictions, and while prediction accuracy has seen much progress in recent years, uncertainty metrics are rarely reported. We here provide a Gaussian process regression model, Kermut, with a novel composite kernel for modeling mutation similarity, which obtains state-of-the-art performance for supervised protein variant effect prediction while also offering estimates of uncertainty through its posterior. An analysis of the quality of the uncertainty estimates demonstrates that our model provides meaningful levels of overall calibration, but that instance-specific uncertainty calibration remains more challenging.
<div id='section'>Paperid: <span id='pid'>1090, <a href='https://arxiv.org/pdf/2406.16995.pdf' target='_blank'>https://arxiv.org/pdf/2406.16995.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xing Fang, Chenpeng Yu, Shiye Tian, Hui Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16995">tcrLM: a lightweight protein language model for predicting T cell receptor and epitope binding specificity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The anti-cancer immune response relies on the bindings between T-cell receptors (TCRs) and antigens, which elicits adaptive immunity to eliminate tumor cells. This ability of the immune system to respond to novel various neoantigens arises from the immense diversity of TCR repository. However, TCR diversity poses a significant challenge on accurately predicting antigen-TCR bindings. In this study, we introduce a lightweight masked language model, termed tcrLM, to address this challenge. Our approach involves randomly masking segments of TCR sequences and training tcrLM to infer the masked segments, thereby enabling the extraction of expressive features from TCR sequences. To further enhance robustness, we incorporate virtual adversarial training into tcrLM. We construct the largest TCR CDR3 sequence set with more than 100 million distinct sequences, and pretrain tcrLM on these sequences. The pre-trained encoder is subsequently applied to predict TCR-antigen binding specificity. We evaluate model performance on three test datasets: independent, external, and COVID-19 test set. The results demonstrate that tcrLM not only surpasses existing TCR-antigen binding prediction methods, but also outperforms other mainstream protein language models. More interestingly, tcrLM effectively captures the biochemical properties and positional preference of amino acids within TCR sequences. Additionally, the predicted TCR-neoantigen binding scores indicates the immunotherapy responses and clinical outcomes in a melanoma cohort. These findings demonstrate the potential of tcrLM in predicting TCR-antigen binding specificity, with significant implications for advancing immunotherapy and personalized medicine.
<div id='section'>Paperid: <span id='pid'>1091, <a href='https://arxiv.org/pdf/2406.16821.pdf' target='_blank'>https://arxiv.org/pdf/2406.16821.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Jian, Curtis Wu, Danny Reidenbach, Aditi S. Krishnapriyan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16821">General Binding Affinity Guidance for Diffusion Models in Structure-Based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-Based Drug Design (SBDD) focuses on generating valid ligands that strongly and specifically bind to a designated protein pocket. Several methods use machine learning for SBDD to generate these ligands in 3D space, conditioned on the structure of a desired protein pocket. Recently, diffusion models have shown success here by modeling the underlying distributions of atomic positions and types. While these methods are effective in considering the structural details of the protein pocket, they often fail to explicitly consider the binding affinity. Binding affinity characterizes how tightly the ligand binds to the protein pocket, and is measured by the change in free energy associated with the binding process. It is one of the most crucial metrics for benchmarking the effectiveness of the interaction between a ligand and protein pocket. To address this, we propose BADGER: Binding Affinity Diffusion Guidance with Enhanced Refinement. BADGER is a general guidance method to steer the diffusion sampling process towards improved protein-ligand binding, allowing us to adjust the distribution of the binding affinity between ligands and proteins. Our method is enabled by using a neural network (NN) to model the energy function, which is commonly approximated by AutoDock Vina (ADV). ADV's energy function is non-differentiable, and estimates the affinity based on the interactions between a ligand and target protein receptor. By using a NN as a differentiable energy function proxy, we utilize the gradient of our learned energy function as a guidance method on top of any trained diffusion model. We show that our method improves the binding affinity of generated ligands to their protein receptors by up to 60\%, significantly surpassing previous machine learning methods. We also show that our guidance method is flexible and can be easily applied to other diffusion-based SBDD frameworks.
<div id='section'>Paperid: <span id='pid'>1092, <a href='https://arxiv.org/pdf/2406.08511.pdf' target='_blank'>https://arxiv.org/pdf/2406.08511.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amira Alakhdar, Barnabas Poczos, Newell Washburn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.08511">Diffusion Models in $\textit{De Novo}$ Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have emerged as powerful tools for molecular generation, particularly in the context of 3D molecular structures. Inspired by non-equilibrium statistical physics, these models can generate 3D molecular structures with specific properties or requirements crucial to drug discovery. Diffusion models were particularly successful at learning 3D molecular geometries' complex probability distributions and their corresponding chemical and physical properties through forward and reverse diffusion processes. This review focuses on the technical implementation of diffusion models tailored for 3D molecular generation. It compares the performance, evaluation methods, and implementation details of various diffusion models used for molecular generation tasks. We cover strategies for atom and bond representation, architectures of reverse diffusion denoising networks, and challenges associated with generating stable 3D molecular structures. This review also explores the applications of diffusion models in $\textit{de novo}$ drug design and related areas of computational chemistry, such as structure-based drug design, including target-specific molecular generation, molecular docking, and molecular dynamics of protein-ligand complexes. We also cover conditional generation on physical properties, conformation generation, and fragment-based drug design. By summarizing the state-of-the-art diffusion models for 3D molecular generation, this review sheds light on their role in advancing drug discovery as well as their current limitations.
<div id='section'>Paperid: <span id='pid'>1093, <a href='https://arxiv.org/pdf/2406.07770.pdf' target='_blank'>https://arxiv.org/pdf/2406.07770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meng Liu, Saee Gopal Paliwal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.07770">DualBind: A Dual-Loss Framework for Protein-Ligand Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of protein-ligand binding affinities is crucial for drug development. Recent advances in machine learning show promising results on this task. However, these methods typically rely heavily on labeled data, which can be scarce or unreliable, or they rely on assumptions like Boltzmann-distributed data that may not hold true in practice. Here, we present DualBind, a novel framework that integrates supervised mean squared error (MSE) with unsupervised denoising score matching (DSM) to accurately learn the binding energy function. DualBind not only addresses the limitations of DSM-only models by providing more accurate absolute affinity predictions but also improves generalizability and reduces reliance on labeled data compared to MSE-only models. Our experimental results demonstrate that DualBind excels in predicting binding affinities and can effectively utilize both labeled and unlabeled data to enhance performance.
<div id='section'>Paperid: <span id='pid'>1094, <a href='https://arxiv.org/pdf/2406.05738.pdf' target='_blank'>https://arxiv.org/pdf/2406.05738.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thomas Le Menestrel, Manuel Rivas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.05738">Smiles2Dock: an open large-scale multi-task dataset for ML-based molecular docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Docking is a crucial component in drug discovery aimed at predicting the binding conformation and affinity between small molecules and target proteins. ML-based docking has recently emerged as a prominent approach, outpacing traditional methods like DOCK and AutoDock Vina in handling the growing scale and complexity of molecular libraries. However, the availability of comprehensive and user-friendly datasets for training and benchmarking ML-based docking algorithms remains limited. We introduce Smiles2Dock, an open large-scale multi-task dataset for molecular docking. We created a framework combining P2Rank and AutoDock Vina to dock 1.7 million ligands from the ChEMBL database against 15 AlphaFold proteins, giving us more than 25 million protein-ligand binding scores. The dataset leverages a wide range of high-accuracy AlphaFold protein models, encompasses a diverse set of biologically relevant compounds and enables researchers to benchmark all major approaches for ML-based docking such as Graph, Transformer and CNN-based methods. We also introduce a novel Transformer-based architecture for docking scores prediction and set it as an initial benchmark for our dataset. Our dataset and code are publicly available to support the development of novel ML-based methods for molecular docking to advance scientific research in this field.
<div id='section'>Paperid: <span id='pid'>1095, <a href='https://arxiv.org/pdf/2406.04929.pdf' target='_blank'>https://arxiv.org/pdf/2406.04929.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Oscar Lao, Konstantinos Zacharopoulos, Apostolos Fournaris, Rossano Schifanella, Ioannis Arapakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04929">Protein pathways as a catalyst to directed evolution of the topology of artificial neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the present article, we propose a paradigm shift on evolving Artificial Neural Networks (ANNs) towards a new bio-inspired design that is grounded on the structural properties, interactions, and dynamics of protein networks (PNs): the Artificial Protein Network (APN). This introduces several advantages previously unrealized by state-of-the-art approaches in NE: (1) We can draw inspiration from how nature, thanks to millions of years of evolution, efficiently encodes protein interactions in the DNA to translate our APN to silicon DNA. This helps bridge the gap between syntax and semantics observed in current NE approaches. (2) We can learn from how nature builds networks in our genes, allowing us to design new and smarter networks through EA evolution. (3) We can perform EA crossover/mutation operations and evolution steps, replicating the operations observed in nature directly on the genotype of networks, thus exploring and exploiting the phenotypic space, such that we avoid getting trapped in sub-optimal solutions. (4) Our novel definition of APN opens new ways to leverage our knowledge about different living things and processes from biology. (5) Using biologically inspired encodings, we can model more complex demographic and ecological relationships (e.g., virus-host or predator-prey interactions), allowing us to optimise for multiple, often conflicting objectives.
<div id='section'>Paperid: <span id='pid'>1096, <a href='https://arxiv.org/pdf/2406.01572.pdf' target='_blank'>https://arxiv.org/pdf/2406.01572.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hunter Nisonoff, Junhao Xiong, Stephan Allenspach, Jennifer Listgarten
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01572">Unlocking Guidance for Discrete State-Space Diffusion and Flow Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative models on discrete state-spaces have a wide range of potential applications, particularly in the domain of natural sciences. In continuous state-spaces, controllable and flexible generation of samples with desired properties has been realized using guidance on diffusion and flow models. However, these guidance approaches are not readily amenable to discrete state-space models. Consequently, we introduce a general and principled method for applying guidance on such models. Our method depends on leveraging continuous-time Markov processes on discrete state-spaces, which unlocks computational tractability for sampling from a desired guided distribution. We demonstrate the utility of our approach, Discrete Guidance, on a range of applications including guided generation of small-molecules, DNA sequences and protein sequences.
<div id='section'>Paperid: <span id='pid'>1097, <a href='https://arxiv.org/pdf/2405.18768.pdf' target='_blank'>https://arxiv.org/pdf/2405.18768.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Divya Nori, Wengong Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18768">RNAFlow: RNA Structure & Sequence Design via Inverse Folding-Based Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing significance of RNA engineering in diverse biological applications has spurred interest in developing AI methods for structure-based RNA design. While diffusion models have excelled in protein design, adapting them for RNA presents new challenges due to RNA's conformational flexibility and the computational cost of fine-tuning large structure prediction models. To this end, we propose RNAFlow, a flow matching model for protein-conditioned RNA sequence-structure design. Its denoising network integrates an RNA inverse folding model and a pre-trained RosettaFold2NA network for generation of RNA sequences and structures. The integration of inverse folding in the structure denoising process allows us to simplify training by fixing the structure prediction network. We further enhance the inverse folding model by conditioning it on inferred conformational ensembles to model dynamic RNA conformations. Evaluation on protein-conditioned RNA structure and sequence generation tasks demonstrates RNAFlow's advantage over existing RNA design methods.
<div id='section'>Paperid: <span id='pid'>1098, <a href='https://arxiv.org/pdf/2405.18749.pdf' target='_blank'>https://arxiv.org/pdf/2405.18749.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hirofumi Tsuruta, Hiroyuki Yamazaki, Ryota Maeda, Ryotaro Tamura, Akihiro Imura
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18749">A SARS-CoV-2 Interaction Dataset and VHH Sequence Corpus for Antibody Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibodies are crucial proteins produced by the immune system to eliminate harmful foreign substances and have become pivotal therapeutic agents for treating human diseases. To accelerate the discovery of antibody therapeutics, there is growing interest in constructing language models using antibody sequences. However, the applicability of pre-trained language models for antibody discovery has not been thoroughly evaluated due to the scarcity of labeled datasets. To overcome these limitations, we introduce AVIDa-SARS-CoV-2, a dataset featuring the antigen-variable domain of heavy chain of heavy chain antibody (VHH) interactions obtained from two alpacas immunized with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) spike proteins. AVIDa-SARS-CoV-2 includes binary labels indicating the binding or non-binding of diverse VHH sequences to 12 SARS-CoV-2 mutants, such as the Delta and Omicron variants. Furthermore, we release VHHCorpus-2M, a pre-training dataset for antibody language models, containing over two million VHH sequences. We report benchmark results for predicting SARS-CoV-2-VHH binding using VHHBERT pre-trained on VHHCorpus-2M and existing general protein and antibody-specific pre-trained language models. These results confirm that AVIDa-SARS-CoV-2 provides valuable benchmarks for evaluating the representation capabilities of antibody language models for binding prediction, thereby facilitating the development of AI-driven antibody discovery. The datasets are available at https://datasets.cognanous.com.
<div id='section'>Paperid: <span id='pid'>1099, <a href='https://arxiv.org/pdf/2405.16861.pdf' target='_blank'>https://arxiv.org/pdf/2405.16861.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joongwon Lee, Wonho Zhung, Jisu Seo, Woo Youn Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16861">BInD: Bond and Interaction-generating Diffusion Model for Multi-objective Structure-based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A remarkable advance in geometric deep generative models with accumulated structural data enables structure-based drug design (SBDD) with target protein information only. However, most existing models struggle to address multi-objectives simultaneously while performing well only in their specialized tasks. Here, we present BInD, a diffusion model with knowledge-based guidance for multi-objective SBDD. BInD is designed to co-generate molecules and their interactions with a target protein to consider all key objectives equally well, including target-specific interactions, molecular properties, and local geometry. Comprehensive evaluations show that BInD achieves robust performance for all objectives while outperforming or matching state-of-the-art methods for each. Finally, we propose a train-free optimization method empowered by retrieving target-specific interactions, highlighting the role of non-covalent interactions in achieving higher selectivity and binding affinities to a target protein.
<div id='section'>Paperid: <span id='pid'>1100, <a href='https://arxiv.org/pdf/2405.16796.pdf' target='_blank'>https://arxiv.org/pdf/2405.16796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mostofa Rafid Uddin, Min Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16796">DualContrast: Unsupervised Disentangling of Content and Transformations with Implicit Parameterization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised disentanglement of content and transformation is significantly important for analyzing shape-focused scientific image datasets, given their efficacy in solving downstream image-based shape-analyses tasks. The existing relevant works address the problem by explicitly parameterizing the transformation latent codes in a generative model, significantly reducing their expressiveness. Moreover, they are not applicable in cases where transformations can not be readily parametrized. An alternative to such explicit approaches is contrastive methods with data augmentation, which implicitly disentangles transformations and content. However, the existing contrastive strategies are insufficient to this end. Therefore, we developed a novel contrastive method with generative modeling, DualContrast, specifically for unsupervised disentanglement of content and transformations in shape-focused image datasets. DualContrast creates positive and negative pairs for content and transformation from data and latent spaces. Our extensive experiments showcase the efficacy of DualContrast over existing self-supervised and explicit parameterization approaches. With DualContrast, we disentangled protein composition and conformations in cellular 3D protein images, which was unattainable with existing disentanglement approaches
<div id='section'>Paperid: <span id='pid'>1101, <a href='https://arxiv.org/pdf/2405.15928.pdf' target='_blank'>https://arxiv.org/pdf/2405.15928.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dea Gogishvili, Emmanuel Minois-Genin, Jan van Eck, Sanne Abeln
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15928">PatchProt: Hydrophobic patch prediction using protein foundation models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hydrophobic patches on protein surfaces play important functional roles in protein-protein and protein-ligand interactions. Large hydrophobic surfaces are also involved in the progression of aggregation diseases. Predicting exposed hydrophobic patches from a protein sequence has been shown to be a difficult task. Fine-tuning foundation models allows for adapting a model to the specific nuances of a new task using a much smaller dataset. Additionally, multi-task deep learning offers a promising solution for addressing data gaps, simultaneously outperforming single-task methods. In this study, we harnessed a recently released leading large language model ESM-2. Efficient fine-tuning of ESM-2 was achieved by leveraging a recently developed parameter-efficient fine-tuning method. This approach enabled comprehensive training of model layers without excessive parameters and without the need to include a computationally expensive multiple sequence analysis. We explored several related tasks, at local (residue) and global (protein) levels, to improve the representation of the model. As a result, our fine-tuned ESM-2 model, PatchProt, cannot only predict hydrophobic patch areas but also outperforms existing methods at predicting primary tasks, including secondary structure and surface accessibility predictions. Importantly, our analysis shows that including related local tasks can improve predictions on more difficult global tasks. This research sets a new standard for sequence-based protein property prediction and highlights the remarkable potential of fine-tuning foundation models enriching the model representation by training over related tasks.
<div id='section'>Paperid: <span id='pid'>1102, <a href='https://arxiv.org/pdf/2405.15840.pdf' target='_blank'>https://arxiv.org/pdf/2405.15840.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Benoit Gaujac, JÃ©rÃ©mie DonÃ, Liviu Copoiu, Timothy Atkinson, Thomas Pierrot, Thomas D. Barrett
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15840">Learning the Language of Protein Structure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Representation learning and \emph{de novo} generation of proteins are pivotal computational biology tasks. Whilst natural language processing (NLP) techniques have proven highly effective for protein sequence modelling, structure modelling presents a complex challenge, primarily due to its continuous and three-dimensional nature. Motivated by this discrepancy, we introduce an approach using a vector-quantized autoencoder that effectively tokenizes protein structures into discrete representations. This method transforms the continuous, complex space of protein structures into a manageable, discrete format with a codebook ranging from 4096 to 64000 tokens, achieving high-fidelity reconstructions with backbone root mean square deviations (RMSD) of approximately 1-5 Ã. To demonstrate the efficacy of our learned representations, we show that a simple GPT model trained on our codebooks can generate novel, diverse, and designable protein structures. Our approach not only provides representations of protein structure, but also mitigates the challenges of disparate modal representations and sets a foundation for seamless, multi-modal integration, enhancing the capabilities of computational methods in protein design.
<div id='section'>Paperid: <span id='pid'>1103, <a href='https://arxiv.org/pdf/2405.12961.pdf' target='_blank'>https://arxiv.org/pdf/2405.12961.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shriram Chennakesavalu, Frank Hu, Sebastian Ibarraran, Grant M. Rotskoff
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12961">Aligning Transformers with Continuous Feedback via Energy Rank Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Searching through chemical space is an exceptionally challenging problem because the number of possible molecules grows combinatorially with the number of atoms. Large, autoregressive models trained on databases of chemical compounds have yielded powerful generators, but we still lack robust strategies for generating molecules with desired properties. This molecular search problem closely resembles the "alignment" problem for large language models, though for many chemical tasks we have a specific and easily evaluable reward function. Here, we introduce an algorithm called energy rank alignment (ERA) that leverages an explicit reward function to produce a gradient-based objective that we use to optimize autoregressive policies. We show theoretically that this algorithm is closely related to proximal policy optimization (PPO) and direct preference optimization (DPO), but has a minimizer that converges to an ideal Gibbs-Boltzmann distribution with the reward playing the role of an energy function. Furthermore, this algorithm is highly scalable, does not require reinforcement learning, and performs well relative to DPO when the number of preference observations per pairing is small. We deploy this approach to align molecular transformers and protein language models to generate molecules and protein sequences, respectively, with externally specified properties and find that it does so robustly, searching through diverse parts of chemical space.
<div id='section'>Paperid: <span id='pid'>1104, <a href='https://arxiv.org/pdf/2405.08031.pdf' target='_blank'>https://arxiv.org/pdf/2405.08031.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Gharizadeh, Karim Abbasi, Amin Ghareyazi, Mohammad R. K. Mofrad, Hamid R. Rabiee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08031">HGTDR: Advancing Drug Repurposing with Heterogeneous Graph Transformers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motivation: Drug repurposing is a viable solution for reducing the time and cost associated with drug development. However, thus far, the proposed drug repurposing approaches still need to meet expectations. Therefore, it is crucial to offer a systematic approach for drug repurposing to achieve cost savings and enhance human lives. In recent years, using biological network-based methods for drug repurposing has generated promising results. Nevertheless, these methods have limitations. Primarily, the scope of these methods is generally limited concerning the size and variety of data they can effectively handle. Another issue arises from the treatment of heterogeneous data, which needs to be addressed or converted into homogeneous data, leading to a loss of information. A significant drawback is that most of these approaches lack end-to-end functionality, necessitating manual implementation and expert knowledge in certain stages. Results: We propose a new solution, HGTDR (Heterogeneous Graph Transformer for Drug Repurposing), to address the challenges associated with drug repurposing. HGTDR is a three-step approach for knowledge graph-based drug re-purposing: 1) constructing a heterogeneous knowledge graph, 2) utilizing a heterogeneous graph transformer network, and 3) computing relationship scores using a fully connected network. By leveraging HGTDR, users gain the ability to manipulate input graphs, extract information from diverse entities, and obtain their desired output. In the evaluation step, we demonstrate that HGTDR performs comparably to previous methods. Furthermore, we review medical studies to validate our method's top ten drug repurposing suggestions, which have exhibited promising results. We also demon-strated HGTDR's capability to predict other types of relations through numerical and experimental validation, such as drug-protein and disease-protein inter-relations.
<div id='section'>Paperid: <span id='pid'>1105, <a href='https://arxiv.org/pdf/2405.07452.pdf' target='_blank'>https://arxiv.org/pdf/2405.07452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karim Abbasi, Parvin Razzaghi, Amin Ghareyazi, Hamid R. Rabiee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.07452">PLA-SGCN: Protein-Ligand Binding Affinity Prediction by Integrating Similar Pairs and Semi-supervised Graph Convolutional Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The protein-ligand binding affinity (PLA) prediction goal is to predict whether or not the ligand could bind to a protein sequence. Recently, in PLA prediction, deep learning has received much attention. Two steps are involved in deep learning-based approaches: feature extraction and task prediction step. Many deep learning-based approaches concentrate on introducing new feature extraction networks or integrating auxiliary knowledge like protein-protein interaction networks or gene ontology knowledge. Then, a task prediction network is designed simply using some fully connected layers. This paper aims to integrate retrieved similar hard protein-ligand pairs in PLA prediction (i.e., task prediction step) using a semi-supervised graph convolutional network (GCN). Hard protein-ligand pairs are retrieved for each input query sample based on the manifold smoothness constraint. Then, a graph is learned automatically in which each node is a protein-ligand pair, and each edge represents the similarity between pairs. In other words, an end-to-end framework is proposed that simultaneously retrieves hard similar samples, learns protein-ligand descriptor, learns the graph topology of the input sample with retrieved similar hard samples (learn adjacency matrix), and learns a semi-supervised GCN to predict the binding affinity (as task predictor). The training step adjusts the parameter values, and in the inference step, the learned model is fine-tuned for each input sample. To evaluate the proposed approach, it is applied to the four well-known PDBbind, Davis, KIBA, and BindingDB datasets. The results show that the proposed method significantly performs better than the comparable approaches.
<div id='section'>Paperid: <span id='pid'>1106, <a href='https://arxiv.org/pdf/2405.06729.pdf' target='_blank'>https://arxiv.org/pdf/2405.06729.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aleix Lafita, Ferran Gonzalez, Mahmoud Hossam, Paul Smyth, Jacob Deasy, Ari Allyn-Feuer, Daniel Seaton, Stephen Young
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06729">Fine-tuning Protein Language Models with Deep Mutational Scanning improves Variant Effect Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein Language Models (PLMs) have emerged as performant and scalable tools for predicting the functional impact and clinical significance of protein-coding variants, but they still lag experimental accuracy. Here, we present a novel fine-tuning approach to improve the performance of PLMs with experimental maps of variant effects from Deep Mutational Scanning (DMS) assays using a Normalised Log-odds Ratio (NLR) head. We find consistent improvements in a held-out protein test set, and on independent DMS and clinical variant annotation benchmarks from ProteinGym and ClinVar. These findings demonstrate that DMS is a promising source of sequence diversity and supervised training data for improving the performance of PLMs for variant effect prediction.
<div id='section'>Paperid: <span id='pid'>1107, <a href='https://arxiv.org/pdf/2405.06654.pdf' target='_blank'>https://arxiv.org/pdf/2405.06654.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Qiang, Wenxian Shi, Yuxuan Song, Menghua Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06654">PROflow: An iterative refinement model for PROTAC-induced structure prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteolysis targeting chimeras (PROTACs) are small molecules that trigger the breakdown of traditionally ``undruggable'' proteins by binding simultaneously to their targets and degradation-associated proteins. A key challenge in their rational design is understanding their structural basis of activity. Due to the lack of crystal structures (18 in the PDB), existing PROTAC docking methods have been forced to simplify the problem into a distance-constrained protein-protein docking task. To address the data issue, we develop a novel pseudo-data generation scheme that requires only binary protein-protein complexes. This new dataset enables PROflow, an iterative refinement model for PROTAC-induced structure prediction that models the full PROTAC flexibility during constrained protein-protein docking. PROflow outperforms the state-of-the-art across docking metrics and runtime. Its inference speed enables the large-scale screening of PROTAC designs, and computed properties of predicted structures achieve statistically significant correlations with published degradation activities.
<div id='section'>Paperid: <span id='pid'>1108, <a href='https://arxiv.org/pdf/2405.06301.pdf' target='_blank'>https://arxiv.org/pdf/2405.06301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Lindsay, Sian Lindsay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06301">Learning from String Sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Universal Similarity Metric (USM) has been demonstrated to give practically useful measures of "similarity" between sequence data. Here we have used the USM as an alternative distance metric in a K-Nearest Neighbours (K-NN) learner to allow effective pattern recognition of variable length sequence data. We compare this USM approach with the commonly used string-to-word vector approach. Our experiments have used two data sets of divergent domains: (1) spam email filtering and (2) protein subcellular localization. Our results with this data reveal that the USM-based K-NN learner (1) gives predictions with higher classification accuracy than those output by techniques that use the string-to-word vector approach, and (2) can be used to generate reliable probability forecasts.
<div id='section'>Paperid: <span id='pid'>1109, <a href='https://arxiv.org/pdf/2404.17144.pdf' target='_blank'>https://arxiv.org/pdf/2404.17144.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon J. Ward, Muhamed Baljevic, Sharon M. Weiss
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17144">Sensor Response-Time Reduction using Long-Short Term Memory Network Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The response time of a biosensor is a crucial metric in safety-critical applications such as medical diagnostics where an earlier diagnosis can markedly improve patient outcomes. However, the speed at which a biosensor reaches a final equilibrium state can be limited by poor mass transport and long molecular diffusion times that increase the time it takes target molecules to reach the active sensing region of a biosensor. While optimization of system and sensor design can promote molecules reaching the sensing element faster, a simpler and complementary approach for response time reduction that is widely applicable across all sensor platforms is to use time-series forecasting to predict the ultimate steady-state sensor response. In this work, we show that ensembles of long short-term memory (LSTM) networks can accurately predict equilibrium biosensor response from a small quantity of initial time-dependent biosensor measurements, allowing for significant reduction in response time by a mean and median factor of improvement of 18.6 and 5.1 respectively. The ensemble of models simultaneously estimates uncertainty, which is vital for ensuring confidence in the predictions and subsequent safety-related decisions that are made. This approach is demonstrated on real-time experimental data collected by exposing porous silicon biosensors to buffered protein solutions using a multi-channel fluidic cell that enables the automated measurement of 100 porous silicon biosensors in parallel. The dramatic improvement in sensor response time achieved using LSTM network ensembles and associated uncertainty quantification opens the door to trustworthy and faster responding biosensors, enabling more rapid medical diagnostics for faster clinical decision making that can lead to improved patient outcomes and healthcare access, as well as quicker identification of toxins in food and the environment.
<div id='section'>Paperid: <span id='pid'>1110, <a href='https://arxiv.org/pdf/2404.10178.pdf' target='_blank'>https://arxiv.org/pdf/2404.10178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chentianye Xu, Xueying Zhan, Min Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10178">CryoMAE: Few-Shot Cryo-EM Particle Picking with Masked Autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryo-electron microscopy (cryo-EM) emerges as a pivotal technology for determining the architecture of cells, viruses, and protein assemblies at near-atomic resolution. Traditional particle picking, a key step in cryo-EM, struggles with manual effort and automated methods' sensitivity to low signal-to-noise ratio (SNR) and varied particle orientations. Furthermore, existing neural network (NN)-based approaches often require extensive labeled datasets, limiting their practicality. To overcome these obstacles, we introduce cryoMAE, a novel approach based on few-shot learning that harnesses the capabilities of Masked Autoencoders (MAE) to enable efficient selection of single particles in cryo-EM images. Contrary to conventional NN-based techniques, cryoMAE requires only a minimal set of positive particle images for training yet demonstrates high performance in particle detection. Furthermore, the implementation of a self-cross similarity loss ensures distinct features for particle and background regions, thereby enhancing the discrimination capability of cryoMAE. Experiments on large-scale cryo-EM datasets show that cryoMAE outperforms existing state-of-the-art (SOTA) methods, improving 3D reconstruction resolution by up to 22.4%.
<div id='section'>Paperid: <span id='pid'>1111, <a href='https://arxiv.org/pdf/2404.02003.pdf' target='_blank'>https://arxiv.org/pdf/2404.02003.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinze Li, Penglei Wang, Tianfan Fu, Wenhao Gao, Chengtao Li, Leilei Shi, Junhong Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.02003">AUTODIFF: Autoregressive Diffusion Modeling for Structure-based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structure-based drug design (SBDD), which aims to generate molecules that can bind tightly to the target protein, is an essential problem in drug discovery, and previous approaches have achieved initial success. However, most existing methods still suffer from invalid local structure or unrealistic conformation issues, which are mainly due to the poor leaning of bond angles or torsional angles. To alleviate these problems, we propose AUTODIFF, a diffusion-based fragment-wise autoregressive generation model. Specifically, we design a novel molecule assembly strategy named conformal motif that preserves the conformation of local structures of molecules first, then we encode the interaction of the protein-ligand complex with an SE(3)-equivariant convolutional network and generate molecules motif-by-motif with diffusion modeling. In addition, we also improve the evaluation framework of SBDD by constraining the molecular weights of the generated molecules in the same range, together with some new metrics, which make the evaluation more fair and practical. Extensive experiments on CrossDocked2020 demonstrate that our approach outperforms the existing models in generating realistic molecules with valid structures and conformations while maintaining high binding affinity.
<div id='section'>Paperid: <span id='pid'>1112, <a href='https://arxiv.org/pdf/2404.00766.pdf' target='_blank'>https://arxiv.org/pdf/2404.00766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Puneet Mehrotra, Vaastav Anand, Daniel Margo, Milad Rezaei Hajidehi, Margo Seltzer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00766">SoK: The Faults in our Graph Benchmarks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph-structured data is prevalent in domains such as social networks, financial transactions, brain networks, and protein interactions. As a result, the research community has produced new databases and analytics engines to process such data. Unfortunately, there is not yet widespread benchmark standardization in graph processing, and the heterogeneity of evaluations found in the literature can lead researchers astray. Evaluations frequently ignore datasets' statistical idiosyncrasies, which significantly affect system performance. Scalability studies often use datasets that fit easily in memory on a modest desktop. Some studies rely on synthetic graph generators, but these generators produce graphs with unnatural characteristics that also affect performance, producing misleading results. Currently, the community has no consistent and principled manner with which to compare systems and provide guidance to developers who wish to select the system most suited to their application.
  We provide three different systematizations of benchmarking practices. First, we present a 12-year literary review of graph processing benchmarking, including a summary of the prevalence of specific datasets and benchmarks used in these papers. Second, we demonstrate the impact of two statistical properties of datasets that drastically affect benchmark performance. We show how different assignments of IDs to vertices, called vertex orderings, dramatically alter benchmark performance due to the caching behavior they induce. We also show the impact of zero-degree vertices on the runtime of benchmarks such as breadth-first search and single-source shortest path. We show that these issues can cause performance to change by as much as 38% on several popular graph processing systems. Finally, we suggest best practices to account for these issues when evaluating graph systems.
<div id='section'>Paperid: <span id='pid'>1113, <a href='https://arxiv.org/pdf/2403.04106.pdf' target='_blank'>https://arxiv.org/pdf/2403.04106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elsa Lawrence, Adham El-Shazly, Srijit Seal, Chaitanya K Joshi, Pietro LiÃ², Shantanu Singh, Andreas Bender, Pietro Sormanni, Matthew Greenig
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.04106">Understanding Biology in the Age of Artificial Intelligence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern life sciences research is increasingly relying on artificial intelligence approaches to model biological systems, primarily centered around the use of machine learning (ML) models. Although ML is undeniably useful for identifying patterns in large, complex data sets, its widespread application in biological sciences represents a significant deviation from traditional methods of scientific inquiry. As such, the interplay between these models and scientific understanding in biology is a topic with important implications for the future of scientific research, yet it is a subject that has received little attention. Here, we draw from an epistemological toolkit to contextualize recent applications of ML in biological sciences under modern philosophical theories of understanding, identifying general principles that can guide the design and application of ML systems to model biological phenomena and advance scientific knowledge. We propose that conceptions of scientific understanding as information compression, qualitative intelligibility, and dependency relation modelling provide a useful framework for interpreting ML-mediated understanding of biological systems. Through a detailed analysis of two key application areas of ML in modern biological research - protein structure prediction and single cell RNA-sequencing - we explore how these features have thus far enabled ML systems to advance scientific understanding of their target phenomena, how they may guide the development of future ML models, and the key obstacles that remain in preventing ML from achieving its potential as a tool for biological discovery. Consideration of the epistemological features of ML applications in biology will improve the prospects of these methods to solve important problems and advance scientific understanding of living systems.
<div id='section'>Paperid: <span id='pid'>1114, <a href='https://arxiv.org/pdf/2402.19095.pdf' target='_blank'>https://arxiv.org/pdf/2402.19095.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanlin Zhou, Kai Tan, Xinyu Shen, Zheng He, Haotian Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.19095">A Protein Structure Prediction Approach Leveraging Transformer and CNN Integration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are essential for life, and their structure determines their function. The protein secondary structure is formed by the folding of the protein primary structure, and the protein tertiary structure is formed by the bending and folding of the secondary structure. Therefore, the study of protein secondary structure is very helpful to the overall understanding of protein structure. Although the accuracy of protein secondary structure prediction has continuously improved with the development of machine learning and deep learning, progress in the field of protein structure prediction, unfortunately, remains insufficient to meet the large demand for protein information. Therefore, based on the advantages of deep learning-based methods in feature extraction and learning ability, this paper adopts a two-dimensional fusion deep neural network model, DstruCCN, which uses Convolutional Neural Networks (CCN) and a supervised Transformer protein language model for single-sequence protein structure prediction. The training features of the two are combined to predict the protein Transformer binding site matrix, and then the three-dimensional structure is reconstructed using energy minimization.
<div id='section'>Paperid: <span id='pid'>1115, <a href='https://arxiv.org/pdf/2402.10291.pdf' target='_blank'>https://arxiv.org/pdf/2402.10291.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vijayalakshmi Saravanan, Perry Siehien, Shinjae Yoo, Hubertus Van Dam, Thomas Flynn, Christopher Kelly, Khaled Z Ibrahim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10291">An Evaluation of Real-time Adaptive Sampling Change Point Detection Algorithm using KCUSUM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting abrupt changes in real-time data streams from scientific simulations presents a challenging task, demanding the deployment of accurate and efficient algorithms. Identifying change points in live data stream involves continuous scrutiny of incoming observations for deviations in their statistical characteristics, particularly in high-volume data scenarios. Maintaining a balance between sudden change detection and minimizing false alarms is vital. Many existing algorithms for this purpose rely on known probability distributions, limiting their feasibility. In this study, we introduce the Kernel-based Cumulative Sum (KCUSUM) algorithm, a non-parametric extension of the traditional Cumulative Sum (CUSUM) method, which has gained prominence for its efficacy in online change point detection under less restrictive conditions. KCUSUM splits itself by comparing incoming samples directly with reference samples and computes a statistic grounded in the Maximum Mean Discrepancy (MMD) non-parametric framework. This approach extends KCUSUM's pertinence to scenarios where only reference samples are available, such as atomic trajectories of proteins in vacuum, facilitating the detection of deviations from the reference sample without prior knowledge of the data's underlying distribution. Furthermore, by harnessing MMD's inherent random-walk structure, we can theoretically analyze KCUSUM's performance across various use cases, including metrics like expected delay and mean runtime to false alarms. Finally, we discuss real-world use cases from scientific simulations such as NWChem CODAR and protein folding data, demonstrating KCUSUM's practical effectiveness in online change point detection.
<div id='section'>Paperid: <span id='pid'>1116, <a href='https://arxiv.org/pdf/2402.01481.pdf' target='_blank'>https://arxiv.org/pdf/2402.01481.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiale Zhao, Wanru Zhuang, Jia Song, Yaqi Li, Shuqi Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01481">Pre-Training Protein Bi-level Representation Through Span Mask Strategy On 3D Protein Chains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, there has been a surge in the development of 3D structure-based pre-trained protein models, representing a significant advancement over pre-trained protein language models in various downstream tasks. However, most existing structure-based pre-trained models primarily focus on the residue level, i.e., alpha carbon atoms, while ignoring other atoms like side chain atoms. We argue that modeling proteins at both residue and atom levels is important since the side chain atoms can also be crucial for numerous downstream tasks, for example, molecular docking. Nevertheless, we find that naively combining residue and atom information during pre-training typically fails. We identify a key reason is the information leakage caused by the inclusion of atom structure in the input, which renders residue-level pre-training tasks trivial and results in insufficiently expressive residue representations. To address this issue, we introduce a span mask pre-training strategy on 3D protein chains to learn meaningful representations of both residues and atoms. This leads to a simple yet effective approach to learning protein representation suitable for diverse downstream tasks. Extensive experimental results on binding site prediction and function prediction tasks demonstrate our proposed pre-training approach significantly outperforms other methods. Our code will be made public.
<div id='section'>Paperid: <span id='pid'>1117, <a href='https://arxiv.org/pdf/2401.06936.pdf' target='_blank'>https://arxiv.org/pdf/2401.06936.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinru Hua, Rasool Ahmad, Jose Blanchet, Wei Cai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.06936">Accelerated Sampling of Rare Events using a Neural Network Bias Potential</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of computational physics and material science, the efficient sampling of rare events occurring at atomic scale is crucial. It aids in understanding mechanisms behind a wide range of important phenomena, including protein folding, conformal changes, chemical reactions and materials diffusion and deformation. Traditional simulation methods, such as Molecular Dynamics and Monte Carlo, often prove inefficient in capturing the timescale of these rare events by brute force. In this paper, we introduce a practical approach by combining the idea of importance sampling with deep neural networks (DNNs) that enhance the sampling of these rare events. In particular, we approximate the variance-free bias potential function with DNNs which is trained to maximize the probability of rare event transition under the importance potential function. This method is easily scalable to high-dimensional problems and provides robust statistical guarantees on the accuracy of the estimated probability of rare event transition. Furthermore, our algorithm can actively generate and learn from any successful samples, which is a novel improvement over existing methods. Using a 2D system as a test bed, we provide comparisons between results obtained from different training strategies, traditional Monte Carlo sampling and numerically solved optimal bias potential function under different temperatures. Our numerical results demonstrate the efficacy of the DNN-based importance sampling of rare events.
<div id='section'>Paperid: <span id='pid'>1118, <a href='https://arxiv.org/pdf/2401.02124.pdf' target='_blank'>https://arxiv.org/pdf/2401.02124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeynep Hilal Kilimci, Mustafa Yalcin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02124">ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anticancer peptides (ACPs) are a class of molecules that have gained significant attention in the field of cancer research and therapy. ACPs are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. One of the key advantages of ACPs is their ability to selectively target cancer cells while sparing healthy cells to a greater extent. This selectivity is often attributed to differences in the surface properties of cancer cells compared to normal cells. That is why ACPs are being investigated as potential candidates for cancer therapy. ACPs may be used alone or in combination with other treatment modalities like chemotherapy and radiation therapy. While ACPs hold promise as a novel approach to cancer treatment, there are challenges to overcome, including optimizing their stability, improving selectivity, and enhancing their delivery to cancer cells, continuous increasing in number of peptide sequences, developing a reliable and precise prediction model. In this work, we propose an efficient transformer-based framework to identify anticancer peptides for by performing accurate a reliable and precise prediction model. For this purpose, four different transformer models, namely ESM, ProtBert, BioBERT, and SciBERT are employed to detect anticancer peptides from amino acid sequences. To demonstrate the contribution of the proposed framework, extensive experiments are carried on widely-used datasets in the literature, two versions of AntiCp2, cACP-DeepGram, ACP-740. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed framework, ESM, exhibits 96.45 of accuracy for AntiCp2 dataset, 97.66 of accuracy for cACP-DeepGram dataset, and 88.51 of accuracy for ACP-740 dataset, thence determining new state-of-the-art.
<div id='section'>Paperid: <span id='pid'>1119, <a href='https://arxiv.org/pdf/2312.03773.pdf' target='_blank'>https://arxiv.org/pdf/2312.03773.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoyue Wang, Li Pan, Bo Yang, Junqiang Jiang, Wenbin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.03773">A multi-layer refined network model for the identification of essential proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The identification of essential proteins in protein-protein interaction networks (PINs) can help to discover drug targets and prevent disease. In order to improve the accuracy of the identification of essential proteins, researchers attempted to obtain a refined PIN by combining multiple biological information to filter out some unreliable interactions in the PIN. Unfortunately, such approaches drastically reduce the number of nodes in the PIN after multiple refinements and result in a sparser PIN. It makes a considerable portion of essential proteins unidentifiable. In this paper, we propose a multi-layer refined network (MR-PIN) that addresses this problem. Firstly, four refined networks are constructed by respectively integrating different biological information into the static PIN to form a multi-layer heterogeneous network. Then scores of proteins in each network layer are calculated by the existing node ranking method, and the importance score of a protein in the MR-PIN is evaluated in terms of the geometric mean of its scores in all layers. Finally, all nodes are sorted by their importance scores to determine their essentiality. To evaluate the effectiveness of the multi-layer refined network model, we apply 16 node ranking methods on the MR-PIN, and compare the results with those on the SPIN, DPIN and RDPIN. Then the predictive performances of these ranking methods are validated in terms of the identification number of essential protein at top100 - top600, sensitivity, specificity, positive predictive value, negative predictive value, F-measure, accuracy, Jackknife, ROCAUC and PRAUC. The experimental results show that the MR-PIN is superior to the existing refined PINs in the identification accuracy of essential proteins.
<div id='section'>Paperid: <span id='pid'>1120, <a href='https://arxiv.org/pdf/2311.16140.pdf' target='_blank'>https://arxiv.org/pdf/2311.16140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fei He, Zhiyuan Yang, Mingyue Gao, Biplab Poudel, Newgin Sam Ebin Sam Dhas, Rajan Gyawali, Ashwin Dhakal, Jianlin Cheng, Dong Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16140">Adapting Segment Anything Model (SAM) through Prompt-based Learning for Enhanced Protein Identification in Cryo-EM Micrographs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryo-electron microscopy (cryo-EM) remains pivotal in structural biology, yet the task of protein particle picking, integral for 3D protein structure construction, is laden with manual inefficiencies. While recent AI tools such as Topaz and crYOLO are advancing the field, they do not fully address the challenges of cryo-EM images, including low contrast, complex shapes, and heterogeneous conformations. This study explored prompt-based learning to adapt the state-of-the-art image segmentation foundation model Segment Anything Model (SAM) for cryo-EM. This focus was driven by the desire to optimize model performance with a small number of labeled data without altering pre-trained parameters, aiming for a balance between adaptability and foundational knowledge retention. Through trials with three prompt-based learning strategies, namely head prompt, prefix prompt, and encoder prompt, we observed enhanced performance and reduced computational requirements compared to the fine-tuning approach. This work not only highlights the potential of prompting SAM in protein identification from cryo-EM micrographs but also suggests its broader promise in biomedical image segmentation and object detection.
<div id='section'>Paperid: <span id='pid'>1121, <a href='https://arxiv.org/pdf/2311.05642.pdf' target='_blank'>https://arxiv.org/pdf/2311.05642.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Li Pan, Haoyue Wang, Jing Sun, Bin Li, Bo Yang, Wenbin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.05642">A protein network refinement method based on module discovery and biological information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The identification of essential proteins can help in understanding the minimum requirements for cell survival and development. Network-based centrality approaches are commonly used to identify essential proteins from protein-protein interaction networks (PINs). Unfortunately, these approaches are limited by the poor quality of the underlying PIN data. To overcome this problem, researchers have focused on the prediction of essential proteins by combining PINs with other biological data. In this paper, we proposed a network refinement method based on module discovery and biological information to obtain a higher quality PIN. First, to extract the maximal connected subgraph in the PIN and to divide it into different modules by using Fast-unfolding algorithm; then, to detect critical modules based on the homology information, subcellular localization information and topology information within each module, and to construct a more refined network (CM-PIN). To evaluate the effectiveness of the proposed method, we used 10 typical network-based centrality methods (LAC, DC, DMNC, NC, TP, LID, CC, BC, PR, LR) to compare the overall performance of the CM-PIN with those the refined dynamic protein network (RD-PIN). The experimental results showed that the CM-PIN was optimal in terms of precision-recall curve, jackknife curve and other criteria, and can help to identify essential proteins more accurately.
<div id='section'>Paperid: <span id='pid'>1122, <a href='https://arxiv.org/pdf/2311.05486.pdf' target='_blank'>https://arxiv.org/pdf/2311.05486.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harto Saarinen, Mark Goldsmith, Rui-Sheng Wang, Joseph Loscalzo, Sabrina Maniscalco
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.05486">Disease Gene Prioritization With Quantum Walks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Disease gene prioritization assigns scores to genes or proteins according to their likely relevance for a given disease based on a provided set of seed genes. Here, we describe a new algorithm for disease gene prioritization based on continuous-time quantum walks using the adjacency matrix of a protein-protein interaction (PPI) network. Our algorithm can be seen as a quantum version of a previous method known as the diffusion kernel, but, importantly, has higher performance in predicting disease genes, and also permits the encoding of seed node self-loops into the underlying Hamiltonian, which offers yet another boost in performance. We demonstrate the success of our proposed method by comparing it to several well-known gene prioritization methods on three disease sets, across seven different PPI networks. In order to compare these methods, we use cross-validation and examine the mean reciprocal ranks and recall values. We further validate our method by performing an enrichment analysis of the predicted genes for coronary artery disease. We also investigate the impact of adding self-loops to the seeds, and argue that they allow the quantum walker to remain more local to low-degree seed nodes.
<div id='section'>Paperid: <span id='pid'>1123, <a href='https://arxiv.org/pdf/2310.13806.pdf' target='_blank'>https://arxiv.org/pdf/2310.13806.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarah Coffland, Katie Christensen, Filip Jagodzinski, Brian Hutchinson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.13806">RoseNet: Predicting Energy Metrics of Double InDel Mutants Using Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An amino acid insertion or deletion, or InDel, can have profound and varying functional impacts on a protein's structure. InDel mutations in the transmembrane conductor regulator protein for example give rise to cystic fibrosis. Unfortunately performing InDel mutations on physical proteins and studying their effects is a time prohibitive process. Consequently, modeling InDels computationally can supplement and inform wet lab experiments. In this work, we make use of our data sets of exhaustive double InDel mutations for three proteins which we computationally generated using a robotics inspired inverse kinematics approach available in Rosetta. We develop and train a neural network, RoseNet, on several structural and energetic metrics output by Rosetta during the mutant generation process. We explore and present how RoseNet is able to emulate the exhaustive data set using deep learning methods, and show to what extent it can predict Rosetta metrics for unseen mutant sequences with two InDels. RoseNet achieves a Pearson correlation coefficient median accuracy of 0.775 over all Rosetta scores for the largest protein. Furthermore, a sensitivity analysis is performed to determine the necessary quantity of data required to accurately emulate the structural scores for computationally generated mutants. We show that the model can be trained on minimal data (<50%) and still retain a high level of accuracy.
<div id='section'>Paperid: <span id='pid'>1124, <a href='https://arxiv.org/pdf/2310.10598.pdf' target='_blank'>https://arxiv.org/pdf/2310.10598.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jenna C. Fromer, David E. Graff, Connor W. Coley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.10598">Pareto Optimization to Accelerate Multi-Objective Virtual Screening</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The discovery of therapeutic molecules is fundamentally a multi-objective optimization problem. One formulation of the problem is to identify molecules that simultaneously exhibit strong binding affinity for a target protein, minimal off-target interactions, and suitable pharmacokinetic properties. Inspired by prior work that uses active learning to accelerate the identification of strong binders, we implement multi-objective Bayesian optimization to reduce the computational cost of multi-property virtual screening and apply it to the identification of ligands predicted to be selective based on docking scores to on- and off-targets. We demonstrate the superiority of Pareto optimization over scalarization across three case studies. Further, we use the developed optimization tool to search a virtual library of over 4M molecules for those predicted to be selective dual inhibitors of EGFR and IGF1R, acquiring 100% of the molecules that form the library's Pareto front after exploring only 8% of the library. This workflow and associated open source software can reduce the screening burden of molecular design projects and is complementary to research aiming to improve the accuracy of binding predictions and other molecular properties.
<div id='section'>Paperid: <span id='pid'>1125, <a href='https://arxiv.org/pdf/2310.06881.pdf' target='_blank'>https://arxiv.org/pdf/2310.06881.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Damiano Piovesan, Davide Zago, Parnal Joshi, M. Clara De Paolis Kaluza, Mahta Mehdiabadi, Rashika Ramola, Alexander Miguel Monzon, Walter Reade, Iddo Friedberg, Predrag Radivojac, Silvio C. E. Tosatto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06881">CAFA-evaluator: A Python Tool for Benchmarking Ontological Classification Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present CAFA-evaluator, a powerful Python program designed to evaluate the performance of prediction methods on targets with hierarchical concept dependencies. It generalizes multi-label evaluation to modern ontologies where the prediction targets are drawn from a directed acyclic graph and achieves high efficiency by leveraging matrix computation and topological sorting. The program requirements include a small number of standard Python libraries, making CAFA-evaluator easy to maintain. The code replicates the Critical Assessment of protein Function Annotation (CAFA) benchmarking, which evaluates predictions of the consistent subgraphs in Gene Ontology. Owing to its reliability and accuracy, the organizers have selected CAFA-evaluator as the official CAFA evaluation software.
<div id='section'>Paperid: <span id='pid'>1126, <a href='https://arxiv.org/pdf/2310.01768.pdf' target='_blank'>https://arxiv.org/pdf/2310.01768.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yikai Liu, Ming Chen, Guang Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.01768">Backdiff: a diffusion model for generalized transferable protein backmapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Coarse-grained (CG) models play a crucial role in the study of protein structures, protein thermodynamic properties, and protein conformation dynamics. Due to the information loss in the coarse-graining process, backmapping from CG to all-atom configurations is essential in many protein design and drug discovery applications when detailed atomic representations are needed for in-depth studies. Despite recent progress in data-driven backmapping approaches, devising a backmapping method that can be universally applied across various CG models and proteins remains unresolved. In this work, we propose BackDiff, a new generative model designed to achieve generalization and reliability in the protein backmapping problem. BackDiff leverages the conditional score-based diffusion model with geometric representations. Since different CG models can contain different coarse-grained sites which include selected atoms (CG atoms) and simple CG auxiliary functions of atomistic coordinates (CG auxiliary variables), we design a self-supervised training framework to adapt to different CG atoms, and constrain the diffusion sampling paths with arbitrary CG auxiliary variables as conditions. Our method facilitates end-to-end training and allows efficient sampling across different proteins and diverse CG models without the need for retraining. Comprehensive experiments over multiple popular CG models demonstrate BackDiff's superior performance to existing state-of-the-art approaches, and generalization and flexibility that these approaches cannot achieve. A pretrained BackDiff model can offer a convenient yet reliable plug-and-play solution for protein researchers, enabling them to investigate further from their own CG models.
<div id='section'>Paperid: <span id='pid'>1127, <a href='https://arxiv.org/pdf/2310.00795.pdf' target='_blank'>https://arxiv.org/pdf/2310.00795.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yasin Shokrollahi, Jose Colmenarez, Wenxi Liu, Sahar Yarmohammadtoosky, Matthew M. Nikahd, Pengfei Dong, Xianqi Li, Linxia Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.00795">Recent Advances in Generative AI for Healthcare Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid advancement of Artificial Intelligence (AI) has catalyzed revolutionary changes across various sectors, notably in healthcare. In particular, generative AI-led by diffusion models and transformer architectures-has enabled significant breakthroughs in medical imaging (including image reconstruction, image-to-image translation, generation, and classification), protein structure prediction, clinical documentation, diagnostic assistance, radiology interpretation, clinical decision support, medical coding, and billing, as well as drug design and molecular representation. These innovations have enhanced clinical diagnosis, data reconstruction, and drug synthesis. This review paper aims to offer a comprehensive synthesis of recent advances in healthcare applications of generative AI, with an emphasis on diffusion and transformer models. Moreover, we discuss current capabilities, highlight existing limitations, and outline promising research directions to address emerging challenges. Serving as both a reference for researchers and a guide for practitioners, this work offers an integrated view of the state of the art, its impact on healthcare, and its future potential.
<div id='section'>Paperid: <span id='pid'>1128, <a href='https://arxiv.org/pdf/2309.16439.pdf' target='_blank'>https://arxiv.org/pdf/2309.16439.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Trevor Norton, Jie Xu, Brian Choi, Mark Kon, Julio Enrique CastrillÃ³n-CandÃ¡s
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16439">Uncertainty quantification and complex analyticity of the nonlinear Poisson-Boltzmann equation for the interface problem with random domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The nonlinear Poisson-Boltzmann equation (NPBE) is an elliptic partial differential equation used in applications such as protein interactions and biophysical chemistry (among many others). It describes the nonlinear electrostatic potential of charged bodies submerged in an ionic solution. The kinetic presence of the solvent molecules introduces randomness to the shape of a protein, and thus a more accurate model that incorporates these random perturbations of the domain is analyzed to compute the statistics of quantities of interest of the solution. When the parameterization of the random perturbations is high-dimensional, this calculation is intractable as it is subject to the curse of dimensionality. However, if the solution of the NPBE varies analytically with respect to the random parameters, the problem becomes amenable to techniques such as sparse grids and deep neural networks. In this paper, we show analyticity of the solution of the NPBE with respect to analytic perturbations of the domain by using the analytic implicit function theorem and the domain mapping method. Previous works have shown analyticity of solutions to linear elliptic equations but not for nonlinear problems. We further show how to derive \emph{a priori} bounds on the size of the region of analyticity. This method is applied to the trypsin molecule to demonstrate that the convergence rates of the quantity of interest are consistent with the analyticity result. Furthermore, the approach developed here is sufficiently general enough to be applied to other nonlinear problems in uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>1129, <a href='https://arxiv.org/pdf/2309.04503.pdf' target='_blank'>https://arxiv.org/pdf/2309.04503.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaofan Li, Prasenjit Mitra, Rui Zhou, Wolfgang Nejdl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.04503">Quantum Algorithm for Maximum Biclique Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying a biclique with the maximum number of edges bears considerable implications for numerous fields of application, such as detecting anomalies in E-commerce transactions, discerning protein-protein interactions in biology, and refining the efficacy of social network recommendation algorithms. However, the inherent NP-hardness of this problem significantly complicates the matter. The prohibitive time complexity of existing algorithms is the primary bottleneck constraining the application scenarios. Aiming to address this challenge, we present an unprecedented exploration of a quantum computing approach. Efficient quantum algorithms, as a crucial future direction for handling NP-hard problems, are presently under intensive investigation, of which the potential has already been proven in practical arenas such as cybersecurity. However, in the field of quantum algorithms for graph databases, little work has been done due to the challenges presented by the quantum representation of complex graph topologies. In this study, we delve into the intricacies of encoding a bipartite graph on a quantum computer. Given a bipartite graph with n vertices, we propose a ground-breaking algorithm qMBS with time complexity O^*(2^(n/2)), illustrating a quadratic speed-up in terms of complexity compared to the state-of-the-art. Furthermore, we detail two variants tailored for the maximum vertex biclique problem and the maximum balanced biclique problem. To corroborate the practical performance and efficacy of our proposed algorithms, we have conducted proof-of-principle experiments utilizing IBM quantum simulators, of which the results provide a substantial validation of our approach to the extent possible to date.
<div id='section'>Paperid: <span id='pid'>1130, <a href='https://arxiv.org/pdf/2309.03919.pdf' target='_blank'>https://arxiv.org/pdf/2309.03919.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>L. Domingo, M. Chehimi, S. Banerjee, S. He Yuxun, S. Konakanchi, L. Ogunfowora, S. Roy, S. Selvaras, M. Djukic, C. Johnson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.03919">A hybrid quantum-classical fusion neural network to improve protein-ligand binding affinity predictions for drug discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The field of drug discovery hinges on the accurate prediction of binding affinity between prospective drug molecules and target proteins, especially when such proteins directly influence disease progression. However, estimating binding affinity demands significant financial and computational resources. While state-of-the-art methodologies employ classical machine learning (ML) techniques, emerging hybrid quantum machine learning (QML) models have shown promise for enhanced performance, owing to their inherent parallelism and capacity to manage exponential increases in data dimensionality. Despite these advances, existing models encounter issues related to convergence stability and prediction accuracy. This paper introduces a novel hybrid quantum-classical deep learning model tailored for binding affinity prediction in drug discovery. Specifically, the proposed model synergistically integrates 3D and spatial graph convolutional neural networks within an optimized quantum architecture. Simulation results demonstrate a 6% improvement in prediction accuracy relative to existing classical models, as well as a significantly more stable convergence performance compared to previous classical approaches.
<div id='section'>Paperid: <span id='pid'>1131, <a href='https://arxiv.org/pdf/2309.01122.pdf' target='_blank'>https://arxiv.org/pdf/2309.01122.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bruna Moreira da Silva, David B. Ascher, Nicholas Geard, Douglas E. V. Pires
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.01122">AI driven B-cell Immunotherapy Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibodies, a prominent class of approved biologics, play a crucial role in detecting foreign antigens. The effectiveness of antigen neutralisation and elimination hinges upon the strength, sensitivity, and specificity of the paratope-epitope interaction, which demands resource-intensive experimental techniques for characterisation. In recent years, artificial intelligence and machine learning methods have made significant strides, revolutionising the prediction of protein structures and their complexes. The past decade has also witnessed the evolution of computational approaches aiming to support immunotherapy design. This review focuses on the progress of machine learning-based tools and their frameworks in the domain of B-cell immunotherapy design, encompassing linear and conformational epitope prediction, paratope prediction, and antibody design. We mapped the most commonly used data sources, evaluation metrics, and method availability and thoroughly assessed their significance and limitations, discussing the main challenges ahead.
<div id='section'>Paperid: <span id='pid'>1132, <a href='https://arxiv.org/pdf/2308.10275.pdf' target='_blank'>https://arxiv.org/pdf/2308.10275.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizheng Wang, Yixiao Zhai, Yijie Ding, Quan Zou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10275">SBSM-Pro: Support Bio-sequence Machine for Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins play a pivotal role in biological systems. The use of machine learning algorithms for protein classification can assist and even guide biological experiments, offering crucial insights for biotechnological applications. We introduce the Support Bio-Sequence Machine for Proteins (SBSM-Pro), a model purpose-built for the classification of biological sequences. This model starts with raw sequences and groups amino acids based on their physicochemical properties. It incorporates sequence alignment to measure the similarities between proteins and uses a novel multiple kernel learning (MKL) approach to integrate various types of information, utilizing support vector machines for classification prediction. The results indicate that our model demonstrates commendable performance across ten datasets in terms of the identification of protein function and posttranslational modification. This research not only exemplifies state-of-the-art work in protein classification but also paves avenues for new directions in this domain, representing a beneficial endeavor in the development of platforms tailored for the classification of biological sequences. SBSM-Pro is available for access at http://lab.malab.cn/soft/SBSM-Pro/.
<div id='section'>Paperid: <span id='pid'>1133, <a href='https://arxiv.org/pdf/2308.10077.pdf' target='_blank'>https://arxiv.org/pdf/2308.10077.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Asif Khan, Amos Storkey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10077">Contrastive Learning for Non-Local Graphs with Multi-Resolution Structural Views</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning node-level representations of heterophilic graphs is crucial for various applications, including fraudster detection and protein function prediction. In such graphs, nodes share structural similarity identified by the equivalence of their connectivity which is implicitly encoded in the form of higher-order hierarchical information in the graphs. The contrastive methods are popular choices for learning the representation of nodes in a graph. However, existing contrastive methods struggle to capture higher-order graph structures. To address this limitation, we propose a novel multiview contrastive learning approach that integrates diffusion filters on graphs. By incorporating multiple graph views as augmentations, our method captures the structural equivalence in heterophilic graphs, enabling the discovery of hidden relationships and similarities not apparent in traditional node representations. Our approach outperforms baselines on synthetic and real structural datasets, surpassing the best baseline by $16.06\%$ on Cornell, $3.27\%$ on Texas, and $8.04\%$ on Wisconsin. Additionally, it consistently achieves superior performance on proximal tasks, demonstrating its effectiveness in uncovering structural information and improving downstream applications.
<div id='section'>Paperid: <span id='pid'>1134, <a href='https://arxiv.org/pdf/2308.07136.pdf' target='_blank'>https://arxiv.org/pdf/2308.07136.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Umberto Lupo, Damiano Sgarbossa, Anne-Florence Bitbol
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07136">Pairing interacting protein sequences using masked language modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting which proteins interact together from amino-acid sequences is an important task. We develop a method to pair interacting protein sequences which leverages the power of protein language models trained on multiple sequence alignments, such as MSA Transformer and the EvoFormer module of AlphaFold. We formulate the problem of pairing interacting partners among the paralogs of two protein families in a differentiable way. We introduce a method called DiffPALM that solves it by exploiting the ability of MSA Transformer to fill in masked amino acids in multiple sequence alignments using the surrounding context. MSA Transformer encodes coevolution between functionally or structurally coupled amino acids. We show that it captures inter-chain coevolution, while it was trained on single-chain data, which means that it can be used out-of-distribution. Relying on MSA Transformer without fine-tuning, DiffPALM outperforms existing coevolution-based pairing methods on difficult benchmarks of shallow multiple sequence alignments extracted from ubiquitous prokaryotic protein datasets. It also outperforms an alternative method based on a state-of-the-art protein language model trained on single sequences. Paired alignments of interacting protein sequences are a crucial ingredient of supervised deep learning methods to predict the three-dimensional structure of protein complexes. DiffPALM substantially improves the structure prediction of some eukaryotic protein complexes by AlphaFold-Multimer, without significantly deteriorating any of those we tested. It also achieves competitive performance with using orthology-based pairing.
<div id='section'>Paperid: <span id='pid'>1135, <a href='https://arxiv.org/pdf/2308.06292.pdf' target='_blank'>https://arxiv.org/pdf/2308.06292.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sandun Rajapaksa, Lloyd Allison, Peter J. Stuckey, Maria Garcia de la Banda, Arun S. Konagurthu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06292">The divergence time of protein structures modelled by Markov matrices and its relation to the divergence of sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A complete time-parameterized statistical model quantifying the divergent evolution of protein structures in terms of the patterns of conservation of their secondary structures is inferred from a large collection of protein 3D structure alignments. This provides a better alternative to time-parameterized sequence-based models of protein relatedness, that have clear limitations dealing with twilight and midnight zones of sequence relationships. Since protein structures are far more conserved due to the selection pressure directly placed on their function, divergence time estimates can be more accurate when inferred from structures. We use the Bayesian and information-theoretic framework of Minimum Message Length to infer a time-parameterized stochastic matrix (accounting for perturbed structural states of related residues) and associated Dirichlet models (accounting for insertions and deletions during the evolution of protein domains). These are used in concert to estimate the Markov time of divergence of tertiary structures, a task previously only possible using proxies (like RMSD). By analyzing one million pairs of homologous structures, we yield a relationship between the Markov divergence time of structures and of sequences. Using these inferred models and the relationship between the divergence of sequences and structures, we demonstrate a competitive performance in secondary structure prediction against neural network architectures commonly employed for this task. The source code and supplementary information are downloadable from \url{http://lcb.infotech.monash.edu.au/sstsum}.
<div id='section'>Paperid: <span id='pid'>1136, <a href='https://arxiv.org/pdf/2308.03654.pdf' target='_blank'>https://arxiv.org/pdf/2308.03654.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijie Chen, Xinyan Wang, Yuhang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.03654">FFF: Fragments-Guided Flexible Fitting for Building Complete Protein Structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryo-electron microscopy (cryo-EM) is a technique for reconstructing the 3-dimensional (3D) structure of biomolecules (especially large protein complexes and molecular assemblies). As the resolution increases to the near-atomic scale, building protein structures de novo from cryo-EM maps becomes possible. Recently, recognition-based de novo building methods have shown the potential to streamline this process. However, it cannot build a complete structure due to the low signal-to-noise ratio (SNR) problem. At the same time, AlphaFold has led to a great breakthrough in predicting protein structures. This has inspired us to combine fragment recognition and structure prediction methods to build a complete structure. In this paper, we propose a new method named FFF that bridges protein structure prediction and protein structure recognition with flexible fitting. First, a multi-level recognition network is used to capture various structural features from the input 3D cryo-EM map. Next, protein structural fragments are generated using pseudo peptide vectors and a protein sequence alignment method based on these extracted features. Finally, a complete structural model is constructed using the predicted protein fragments via flexible fitting. Based on our benchmark tests, FFF outperforms the baseline methods for building complete protein structures.
<div id='section'>Paperid: <span id='pid'>1137, <a href='https://arxiv.org/pdf/2307.16037.pdf' target='_blank'>https://arxiv.org/pdf/2307.16037.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Colin Zhang, Yang Ha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.16037">Developing novel ligands with enhanced binding affinity for the sphingosine 1-phosphate receptor 1 using machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiple sclerosis (MS) is a debilitating neurological disease affecting nearly one million people in the United States. Sphingosine-1-phosphate receptor 1, or S1PR1, is a protein target for MS. Siponimod, a ligand of S1PR1, was approved by the FDA in 2019 for MS treatment, but there is a demonstrated need for better therapies. To this end, we finetuned an autoencoder machine learning model that converts chemical formulas into mathematical vectors and generated over 500 molecular variants based on siponimod, out of which 25 compounds had higher predicted binding affinity to S1PR1. The model was able to generate these ligands in just under one hour. Filtering these compounds led to the discovery of six promising candidates with good drug-like properties and ease of synthesis. Furthermore, by analyzing the binding interactions for these ligands, we uncovered several chemical properties that contribute to high binding affinity to S1PR1. This study demonstrates that machine learning can accelerate the drug discovery process and reveal new insights into protein-drug interactions.
<div id='section'>Paperid: <span id='pid'>1138, <a href='https://arxiv.org/pdf/2307.05439.pdf' target='_blank'>https://arxiv.org/pdf/2307.05439.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nic Fishman, Leo Klarner, Emile Mathieu, Michael Hutchinson, Valentin de Bortoli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.05439">Metropolis Sampling for Constrained Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Denoising diffusion models have recently emerged as the predominant paradigm for generative modelling on image domains. In addition, their extension to Riemannian manifolds has facilitated a range of applications across the natural sciences. While many of these problems stand to benefit from the ability to specify arbitrary, domain-informed constraints, this setting is not covered by the existing (Riemannian) diffusion model methodology. Recent work has attempted to address this issue by constructing novel noising processes based on the reflected Brownian motion and logarithmic barrier methods. However, the associated samplers are either computationally burdensome or only apply to convex subsets of Euclidean space. In this paper, we introduce an alternative, simple noising scheme based on Metropolis sampling that affords substantial gains in computational efficiency and empirical performance compared to the earlier samplers. Of independent interest, we prove that this new process corresponds to a valid discretisation of the reflected Brownian motion. We demonstrate the scalability and flexibility of our approach on a range of problem settings with convex and non-convex constraints, including applications from geospatial modelling, robotics and protein design.
<div id='section'>Paperid: <span id='pid'>1139, <a href='https://arxiv.org/pdf/2306.14852.pdf' target='_blank'>https://arxiv.org/pdf/2306.14852.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danny Reidenbach, Aditi S. Krishnapriyan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.14852">CoarsenConf: Equivariant Coarsening with Aggregated Attention for Molecular Conformer Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular conformer generation (MCG) is an important task in cheminformatics and drug discovery. The ability to efficiently generate low-energy 3D structures can avoid expensive quantum mechanical simulations, leading to accelerated virtual screenings and enhanced structural exploration. Several generative models have been developed for MCG, but many struggle to consistently produce high-quality conformers. To address these issues, we introduce CoarsenConf, which coarse-grains molecular graphs based on torsional angles and integrates them into an SE(3)-equivariant hierarchical variational autoencoder. Through equivariant coarse-graining, we aggregate the fine-grained atomic coordinates of subgraphs connected via rotatable bonds, creating a variable-length coarse-grained latent representation. Our model uses a novel aggregated attention mechanism to restore fine-grained coordinates from the coarse-grained latent representation, enabling efficient generation of accurate conformers. Furthermore, we evaluate the chemical and biochemical quality of our generated conformers on multiple downstream applications, including property prediction and oracle-based protein docking. Overall, CoarsenConf generates more accurate conformer ensembles compared to prior generative models.
<div id='section'>Paperid: <span id='pid'>1140, <a href='https://arxiv.org/pdf/2306.08907.pdf' target='_blank'>https://arxiv.org/pdf/2306.08907.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Li Zhang, Wenhao Li, Haotian Guan, Zhiquan He, Mingjun Cheng, Han Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.08907">MCPI: Integrating Multimodal Data for Enhanced Prediction of Compound Protein Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The identification of compound-protein interactions (CPI) plays a critical role in drug screening, drug repurposing, and combination therapy studies. The effectiveness of CPI prediction relies heavily on the features extracted from both compounds and target proteins. While various prediction methods employ different feature combinations, both molecular-based and network-based models encounter the common obstacle of incomplete feature representations. Thus, a promising solution to this issue is to fully integrate all relevant CPI features. This study proposed a novel model named MCPI, which is designed to improve the prediction performance of CPI by integrating multiple sources of information, including the PPI network, CCI network, and structural features of CPI. The results of the study indicate that the MCPI model outperformed other existing methods for predicting CPI on public datasets. Furthermore, the study has practical implications for drug development, as the model was applied to search for potential inhibitors among FDA-approved drugs in response to the SARS-CoV-2 pandemic. The prediction results were then validated through the literature, suggesting that the MCPI model could be a useful tool for identifying potential drug candidates. Overall, this study has the potential to advance our understanding of CPI and guide drug development efforts.
<div id='section'>Paperid: <span id='pid'>1141, <a href='https://arxiv.org/pdf/2306.04667.pdf' target='_blank'>https://arxiv.org/pdf/2306.04667.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francesco Ceccarelli, Lorenzo Giusti, Sean B. Holden, Pietro LiÃ²
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.04667">Neural Embeddings for Protein Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins perform much of the work in living organisms, and consequently the development of efficient computational methods for protein representation is essential for advancing large-scale biological research. Most current approaches struggle to efficiently integrate the wealth of information contained in the protein sequence and structure. In this paper, we propose a novel framework for embedding protein graphs in geometric vector spaces, by learning an encoder function that preserves the structural distance between protein graphs. Utilizing Graph Neural Networks (GNNs) and Large Language Models (LLMs), the proposed framework generates structure- and sequence-aware protein representations. We demonstrate that our embeddings are successful in the task of comparing protein structures, while providing a significant speed-up compared to traditional approaches based on structural alignment. Our framework achieves remarkable results in the task of protein structure classification; in particular, when compared to other work, the proposed method shows an average F1-Score improvement of 26% on out-of-distribution (OOD) samples and of 32% when tested on samples coming from the same distribution as the training data. Our approach finds applications in areas such as drug prioritization, drug re-purposing, disease sub-type analysis and elsewhere.
<div id='section'>Paperid: <span id='pid'>1142, <a href='https://arxiv.org/pdf/2306.03329.pdf' target='_blank'>https://arxiv.org/pdf/2306.03329.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hirofumi Tsuruta, Hiroyuki Yamazaki, Ryota Maeda, Ryotaro Tamura, Jennifer N. Wei, Zelda Mariet, Poomarin Phloyphisut, Hidetoshi Shimokawa, Joseph R. Ledsam, Lucy Colwell, Akihiro Imura
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03329">AVIDa-hIL6: A Large-Scale VHH Dataset Produced from an Immunized Alpaca for Predicting Antigen-Antibody Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antibodies have become an important class of therapeutic agents to treat human diseases. To accelerate therapeutic antibody discovery, computational methods, especially machine learning, have attracted considerable interest for predicting specific interactions between antibody candidates and target antigens such as viruses and bacteria. However, the publicly available datasets in existing works have notable limitations, such as small sizes and the lack of non-binding samples and exact amino acid sequences. To overcome these limitations, we have developed AVIDa-hIL6, a large-scale dataset for predicting antigen-antibody interactions in the variable domain of heavy chain of heavy chain antibodies (VHHs), produced from an alpaca immunized with the human interleukin-6 (IL-6) protein, as antigens. By leveraging the simple structure of VHHs, which facilitates identification of full-length amino acid sequences by DNA sequencing technology, AVIDa-hIL6 contains 573,891 antigen-VHH pairs with amino acid sequences. All the antigen-VHH pairs have reliable labels for binding or non-binding, as generated by a novel labeling method. Furthermore, via introduction of artificial mutations, AVIDa-hIL6 contains 30 different mutants in addition to wild-type IL-6 protein. This characteristic provides opportunities to develop machine learning models for predicting changes in antibody binding by antigen mutations. We report experimental benchmark results on AVIDa-hIL6 by using machine learning models. The results indicate that the existing models have potential, but further research is needed to generalize them to predict effective antibodies against unknown mutants. The dataset is available at https://avida-hil6.cognanous.com.
<div id='section'>Paperid: <span id='pid'>1143, <a href='https://arxiv.org/pdf/2306.00557.pdf' target='_blank'>https://arxiv.org/pdf/2306.00557.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Justin Diamond, Markus Lill
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.00557">Improving Protein-peptide Interface Predictions in the Low Data Regime</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel approach for predicting protein-peptide interactions using a bi-modal transformer architecture that learns an inter-facial joint distribution of residual contacts. The current data sets for crystallized protein-peptide complexes are limited, making it difficult to accurately predict interactions between proteins and peptides. To address this issue, we propose augmenting the existing data from PepBDB with pseudo protein-peptide complexes derived from the PDB. The augmented data set acts as a method to transfer physics-based contextdependent intra-residue (within a domain) interactions to the inter-residual (between) domains. We show that the distributions of inter-facial residue-residue interactions share overlap with inter residue-residue interactions, enough to increase predictive power of our bi-modal transformer architecture. In addition, this dataaugmentation allows us to leverage the vast amount of protein-only data available in the PDB to train neural networks, in contrast to template-based modeling that acts as a prior
<div id='section'>Paperid: <span id='pid'>1144, <a href='https://arxiv.org/pdf/2305.07877.pdf' target='_blank'>https://arxiv.org/pdf/2305.07877.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gregor GunÄar, MatjaÅ¾ Kukar, Tim Smole, SaÅ¡o MoÅ¡kon, TomaÅ¾ Vovko, Simon Podnar, Peter ÄernelÄ, Miran Brvar, Mateja Notar, Manca KÃ¶ster, Marjeta TuÅ¡ek Jelenc, Marko Notar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.07877">Differentiating Viral and Bacterial Infections: A Machine Learning Model Based on Routine Blood Test Values</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing threat of antibiotic resistance necessitates accurate differentiation between bacterial and viral infections for proper antibiotic administration. In this study, a Virus vs. Bacteria machine learning model was developed to distinguish between these infection types using 16 routine blood test results, C-reactive protein concentration (CRP), biological sex, and age. With a dataset of 44,120 cases from a single medical center, the model achieved an accuracy of 82.2 %, a sensitivity of 79.7 %, a specificity of 84.5 %, a Brier score of 0.129, and an area under the ROC curve (AUC) of 0.905, outperforming a CRP-based decision rule. Notably, the machine learning model enhanced accuracy within the CRP range of 10-40 mg/L, a range where CRP alone is less informative. These results highlight the advantage of integrating multiple blood parameters in diagnostics. The "Virus vs. Bacteria" model paves the way for advanced diagnostic tools, leveraging machine learning to optimize infection management.
<div id='section'>Paperid: <span id='pid'>1145, <a href='https://arxiv.org/pdf/2305.07617.pdf' target='_blank'>https://arxiv.org/pdf/2305.07617.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marianne Defresne, Sophie Barbe, Thomas Schiex
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.07617">Scalable Coupling of Deep Learning with Logical Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the ongoing quest for hybridizing discrete reasoning with neural nets, there is an increasing interest in neural architectures that can learn how to solve discrete reasoning or optimization problems from natural inputs. In this paper, we introduce a scalable neural architecture and loss function dedicated to learning the constraints and criteria of NP-hard reasoning problems expressed as discrete Graphical Models. Our loss function solves one of the main limitations of Besag's pseudo-loglikelihood, enabling learning of high energies. We empirically show it is able to efficiently learn how to solve NP-hard reasoning problems from natural inputs as the symbolic, visual or many-solutions Sudoku problems as well as the energy optimization formulation of the protein design problem, providing data efficiency, interpretability, and \textit{a posteriori} control over predictions.
<div id='section'>Paperid: <span id='pid'>1146, <a href='https://arxiv.org/pdf/2303.16452.pdf' target='_blank'>https://arxiv.org/pdf/2303.16452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youhan Lee, Hasun Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.16452">ProtFIM: Fill-in-Middle Protein Sequence Design via Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models (pLMs), pre-trained via causal language modeling on protein sequences, have been a promising tool for protein sequence design. In real-world protein engineering, there are many cases where the amino acids in the middle of a protein sequence are optimized while maintaining other residues. Unfortunately, because of the left-to-right nature of pLMs, existing pLMs modify suffix residues by prompting prefix residues, which are insufficient for the infilling task that considers the whole surrounding context. To find the more effective pLMs for protein engineering, we design a new benchmark, Secondary structureE InFilling rEcoveRy, SEIFER, which approximates infilling sequence design scenarios. With the evaluation of existing models on the benchmark, we reveal the weakness of existing language models and show that language models trained via fill-in-middle transformation, called ProtFIM, are more appropriate for protein engineering. Also, we prove that ProtFIM generates protein sequences with decent protein representations through exhaustive experiments and visualizations.
<div id='section'>Paperid: <span id='pid'>1147, <a href='https://arxiv.org/pdf/2303.11494.pdf' target='_blank'>https://arxiv.org/pdf/2303.11494.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Patricia Suriana, Joseph M. Paggi, Ron O. Dror
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.11494">FlexVDW: A machine learning approach to account for protein flexibility in ligand docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most widely used ligand docking methods assume a rigid protein structure. This leads to problems when the structure of the target protein deforms upon ligand binding. In particular, the ligand's true binding pose is often scored very unfavorably due to apparent clashes between ligand and protein atoms, which lead to extremely high values of the calculated van der Waals energy term. Traditionally, this problem has been addressed by explicitly searching for receptor conformations to account for the flexibility of the receptor in ligand binding. Here we present a deep learning model trained to take receptor flexibility into account implicitly when predicting van der Waals energy. We show that incorporating this machine-learned energy term into a state-of-the-art physics-based scoring function improves small molecule ligand pose prediction results in cases with substantial protein deformation, without degrading performance in cases with minimal protein deformation. This work demonstrates the feasibility of learning effects of protein flexibility on ligand binding without explicitly modeling changes in protein structure.
<div id='section'>Paperid: <span id='pid'>1148, <a href='https://arxiv.org/pdf/2303.00176.pdf' target='_blank'>https://arxiv.org/pdf/2303.00176.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew S. Schmitt, Jonathan Colen, Stefano Sala, John Devany, Shailaja Seetharaman, Margaret L. Gardel, Patrick W. Oakes, Vincenzo Vitelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.00176">Zyxin is all you need: machine learning adherent cell mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cellular form and function emerge from complex mechanochemical systems within the cytoplasm. No systematic strategy currently exists to infer large-scale physical properties of a cell from its many molecular components. This is a significant obstacle to understanding biophysical processes such as cell adhesion and migration. Here, we develop a data-driven biophysical modeling approach to learn the mechanical behavior of adherent cells. We first train neural networks to predict forces generated by adherent cells from images of cytoskeletal proteins. Strikingly, experimental images of a single focal adhesion protein, such as zyxin, are sufficient to predict forces and generalize to unseen biological regimes. This protein field alone contains enough information to yield accurate predictions even if forces themselves are generated by many interacting proteins. We next develop two approaches - one explicitly constrained by physics, the other more agnostic - that help construct data-driven continuum models of cellular forces using this single focal adhesion field. Both strategies consistently reveal that cellular forces are encoded by two different length scales in adhesion protein distributions. Beyond adherent cell mechanics, our work serves as a case study for how to integrate neural networks in the construction of predictive phenomenological models in cell biology, even when little knowledge of the underlying microscopic mechanisms exist.
<div id='section'>Paperid: <span id='pid'>1149, <a href='https://arxiv.org/pdf/2303.00170.pdf' target='_blank'>https://arxiv.org/pdf/2303.00170.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai-Lang Yao, Wu-Jun Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.00170">Asymmetric Learning for Graph Neural Network based Link Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Link prediction is a fundamental problem in many graph based applications, such as protein-protein interaction prediction. Graph neural network (GNN) has recently been widely used for link prediction. However, existing GNN based link prediction (GNN-LP) methods suffer from scalability problem during training for large-scale graphs, which has received little attention by researchers. In this paper, we first give computation complexity analysis of existing GNN-LP methods, which reveals that the scalability problem stems from their symmetric learning strategy adopting the same class of GNN models to learn representation for both head and tail nodes. Then we propose a novel method, called asymmetric learning (AML), for GNN-LP. The main idea of AML is to adopt a GNN model for learning head node representation while using a multi-layer perceptron (MLP) model for learning tail node representation. Furthermore, AML proposes a row-wise sampling strategy to generate mini-batch for training, which is a necessary component to make the asymmetric learning strategy work for training speedup. To the best of our knowledge, AML is the first GNN-LP method adopting an asymmetric learning strategy for node representation learning. Experiments on three real large-scale datasets show that AML is 1.7X~7.3X faster in training than baselines with a symmetric learning strategy, while having almost no accuracy loss.
<div id='section'>Paperid: <span id='pid'>1150, <a href='https://arxiv.org/pdf/2302.10952.pdf' target='_blank'>https://arxiv.org/pdf/2302.10952.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Hu, Hsu Kiang Ooi, Mohammad Sajjad Ghaemi, Anguang Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10952">Machine learning for the prediction of safe and biologically active organophosphorus molecules</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drug discovery is a complex process with a large molecular space to be considered. By constraining the search space, the fragment-based drug design is an approach that can effectively sample the chemical space of interest. Here we propose a framework of Recurrent Neural Networks (RNN) with an attention model to sample the chemical space of organophosphorus molecules using the fragment-based approach. The framework is trained with a ZINC dataset that is screened for high druglikeness scores. The goal is to predict molecules with similar biological action modes as organophosphorus pesticides or chemical warfare agents yet less toxic to humans. The generated molecules contain a starting fragment of PO2F but have a bulky hydrocarbon side chain limiting its binding effectiveness to the targeted protein.
<div id='section'>Paperid: <span id='pid'>1151, <a href='https://arxiv.org/pdf/2302.10348.pdf' target='_blank'>https://arxiv.org/pdf/2302.10348.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pablo Herrera-Nieto, AdriÃ  PÃ©rez, Gianni De Fabritiis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10348">Binding-and-folding recognition of an intrinsically disordered protein using online learning molecular dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Intrinsically disordered proteins participate in many biological processes by folding upon binding with other proteins. However, coupled folding and binding processes are not well understood from an atomistic point of view. One of the main questions is whether folding occurs prior to or after binding. Here we use a novel unbiased high-throughput adaptive sampling approach to reconstruct the binding and folding between the disordered transactivation domain of \mbox{c-Myb} and the KIX domain of the CREB-binding protein. The reconstructed long-term dynamical process highlights the binding of a short stretch of amino acids on \mbox{c-Myb} as a folded $Î±$-helix. Leucine residues, specially Leu298 to Leu302, establish initial native contacts that prime the binding and folding of the rest of the peptide, with a mixture of conformational selection on the N-terminal region with an induced fit of the C-terminal.
<div id='section'>Paperid: <span id='pid'>1152, <a href='https://arxiv.org/pdf/2302.07868.pdf' target='_blank'>https://arxiv.org/pdf/2302.07868.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Atabey ÃnlÃ¼, Elif Ãevrim, Melih GÃ¶kay YiÄit, Ahmet SarÄ±gÃ¼n, Hayriye Ãelikbilek, Osman Bayram, Deniz Cansen Kahraman, Abdurrahman OlÄaÃ§, Ahmet Sureyya RifaioÄlu, Erden BanoÄlu, Tunca DoÄan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.07868">Target Specific De Novo Design of Drug Candidate Molecules with Graph Transformer-based Generative Adversarial Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discovering novel drug candidate molecules is one of the most fundamental and critical steps in drug development. Generative deep learning models, which create synthetic data given a probability distribution, offer a high potential for designing de novo molecules. However, to be utilisable in real life drug development pipelines, these models should be able to design drug like and target centric molecules. In this study, we propose an end to end generative system, DrugGEN, for the de novo design of drug candidate molecules that interact with intended target proteins. The proposed method represents molecules as graphs and processes them via a generative adversarial network comprising graph transformer layers. The system is trained using a large dataset of drug like compounds and target specific bioactive molecules to design effective inhibitory molecules against the AKT1 protein, which is critically important in developing treatments for various types of cancer. We conducted molecular docking and dynamics to assess the target centric generation performance of the model, as well as attention score visualisation to examine model interpretability. In parallel, selected compounds were chemically synthesised and evaluated in the context of in vitro enzymatic assays, which identified two bioactive molecules that inhibited AKT1 at low micromolar concentrations. These results indicate that DrugGEN's de novo molecules have a high potential for interacting with the AKT1 protein at the level of its native ligands. Using the open access DrugGEN codebase, it is possible to easily train models for other druggable proteins, given a dataset of experimentally known bioactive molecules.
<div id='section'>Paperid: <span id='pid'>1153, <a href='https://arxiv.org/pdf/2301.10814.pdf' target='_blank'>https://arxiv.org/pdf/2301.10814.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wengong Jin, Siranush Sarkizova, Xun Chen, Nir Hacohen, Caroline Uhler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.10814">Unsupervised Protein-Ligand Binding Energy Prediction via Neural Euler's Rotation Equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-ligand binding prediction is a fundamental problem in AI-driven drug discovery. Prior work focused on supervised learning methods using a large set of binding affinity data for small molecules, but it is hard to apply the same strategy to other drug classes like antibodies as labelled data is limited. In this paper, we explore unsupervised approaches and reformulate binding energy prediction as a generative modeling task. Specifically, we train an energy-based model on a set of unlabelled protein-ligand complexes using SE(3) denoising score matching and interpret its log-likelihood as binding affinity. Our key contribution is a new equivariant rotation prediction network called Neural Euler's Rotation Equations (NERE) for SE(3) score matching. It predicts a rotation by modeling the force and torque between protein and ligand atoms, where the force is defined as the gradient of an energy function with respect to atom coordinates. We evaluate NERE on protein-ligand and antibody-antigen binding affinity prediction benchmarks. Our model outperforms all unsupervised baselines (physics-based and statistical potentials) and matches supervised learning methods in the antibody case.
<div id='section'>Paperid: <span id='pid'>1154, <a href='https://arxiv.org/pdf/2301.09533.pdf' target='_blank'>https://arxiv.org/pdf/2301.09533.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Milo Roucairol, Tristan Cazenave
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.09533">Solving the HP model with Nested Monte Carlo Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper we present a new Monte Carlo Search (MCS) algorithm for finding the ground state energy of proteins in the HP-model. We also compare it briefly to other MCS algorithms not usually used on the HP-model and provide an overview of the algorithms used on HP-model. The algorithm presented in this paper does not beat state of the art algorithms, see PERM (Hsu and Grassberger 2011), REMC (Thachuk, Shmygelska, and Hoos 2007) or WLRE (WÃ¼st and Landau 2012) for better results.
  Hsu, H.-P.; and Grassberger, P. 2011. A review of Monte Carlo simulations of polymers with PERM. Journal of Statistical Physics, 144 (3): 597 to 637.
  Thachuk, C.; Shmygelska, A.; and Hoos, H. H. 2007. A replica exchange Monte Carlo algorithm for protein folding in the HP model. BMC Bioinformatics, 8(1): 342.
  WÃ¼st, T.; and Landau, D. P. 2012. Optimized Wang-Landau sampling of lattice polymers: Ground state search and folding thermodynamics of HP model proteins. The Journal of Chemical Physics, 137(6): 064903.
<div id='section'>Paperid: <span id='pid'>1155, <a href='https://arxiv.org/pdf/2301.06331.pdf' target='_blank'>https://arxiv.org/pdf/2301.06331.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>L. Domingo, M. Djukic, C. Johnson, F. Borondo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.06331">Hybrid quantum-classical convolutional neural networks to improve molecular protein binding affinity predictions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One of the main challenges in drug discovery is to find molecules that bind specifically and strongly to their target protein while having minimal binding to other proteins. By predicting binding affinity, it is possible to identify the most promising candidates from a large pool of potential compounds, reducing the number of compounds that need to be tested experimentally. Recently, deep learning methods have shown superior performance than traditional computational methods for making accurate predictions on large datasets. However, the complexity and time-consuming nature of these methods have limited their usage and development. Quantum machine learning is an emerging technology that has the potential to improve many classical machine learning algorithms. In this work we present a hybrid quantum-classical convolutional neural network, which is able to reduce by 20% the complexity of the classical network while maintaining optimal performance in the predictions. Additionally, it results in a significant time savings of up to 40% in the training process, which means a meaningful speed up of the drug discovery process.
<div id='section'>Paperid: <span id='pid'>1156, <a href='https://arxiv.org/pdf/2301.06194.pdf' target='_blank'>https://arxiv.org/pdf/2301.06194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Md Masud Rana, Duc Duy Nguyen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.06194">Geometric Graph Learning with Extended Atom-Types Features for Protein-Ligand Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding and accurately predicting protein-ligand binding affinity are essential in the drug design and discovery process. At present, machine learning-based methodologies are gaining popularity as a means of predicting binding affinity due to their efficiency and accuracy, as well as the increasing availability of structural and binding affinity data for protein-ligand complexes. In biomolecular studies, graph theory has been widely applied since graphs can be used to model molecules or molecular complexes in a natural manner. In the present work, we upgrade the graph-based learners for the study of protein-ligand interactions by integrating extensive atom types such as SYBYL and extended connectivity interactive features (ECIF) into multiscale weighted colored graphs (MWCG). By pairing with the gradient boosting decision tree (GBDT) machine learning algorithm, our approach results in two different methods, namely $^\text{sybyl}\text{GGL}$-Score and $^\text{ecif}\text{GGL}$-Score. Both of our models are extensively validated in their scoring power using three commonly used benchmark datasets in the drug design area, namely CASF-2007, CASF-2013, and CASF-2016. The performance of our best model $^\text{sybyl}\text{GGL}$-Score is compared with other state-of-the-art models in the binding affinity prediction for each benchmark. While both of our models achieve state-of-the-art results, the SYBYL atom-type model $^\text{sybyl}\text{GGL}$-Score outperforms other methods by a wide margin in all benchmarks.
<div id='section'>Paperid: <span id='pid'>1157, <a href='https://arxiv.org/pdf/2212.10946.pdf' target='_blank'>https://arxiv.org/pdf/2212.10946.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steven Sachio, Cleo Kontoravdi, Maria M. Papathanasiou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.10946">A model-based approach towards accelerated process development: A case study on chromatography</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Process development is typically associated with lengthy wet-lab experiments for the identification of good candidate setups and operating conditions. In this paper, we present the key features of a model-based approach for the identification and assessment of process design space (DSp), integrating the analysis of process performance and flexibility. The presented approach comprises three main steps: (1) model development & problem formulation, (2) DSp identification, and (3) DSp analysis. We demonstrate how such an approach can be used for the identification of acceptable operating spaces that enable the assessment of different operating points and quantification of process flexibility. The above steps are demonstrated on Protein A chromatographic purification of antibody-based therapeutics used in biopharmaceutical manufacturing.
<div id='section'>Paperid: <span id='pid'>1158, <a href='https://arxiv.org/pdf/2212.08989.pdf' target='_blank'>https://arxiv.org/pdf/2212.08989.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Loc Vu-Quoc, Alexander Humer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.08989">Deep learning applied to computational mechanics: A comprehensive review, state of the art, and the classics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Three recent breakthroughs due to AI in arts and science serve as motivation: An award winning digital image, protein folding, fast matrix multiplication. Many recent developments in artificial neural networks, particularly deep learning (DL), applied and relevant to computational mechanics (solid, fluids, finite-element technology) are reviewed in detail. Both hybrid and pure machine learning (ML) methods are discussed. Hybrid methods combine traditional PDE discretizations with ML methods either (1) to help model complex nonlinear constitutive relations, (2) to nonlinearly reduce the model order for efficient simulation (turbulence), or (3) to accelerate the simulation by predicting certain components in the traditional integration methods. Here, methods (1) and (2) relied on Long-Short-Term Memory (LSTM) architecture, with method (3) relying on convolutional neural networks. Pure ML methods to solve (nonlinear) PDEs are represented by Physics-Informed Neural network (PINN) methods, which could be combined with attention mechanism to address discontinuous solutions. Both LSTM and attention architectures, together with modern and generalized classic optimizers to include stochasticity for DL networks, are extensively reviewed. Kernel machines, including Gaussian processes, are provided to sufficient depth for more advanced works such as shallow networks with infinite width. Not only addressing experts, readers are assumed familiar with computational mechanics, but not with DL, whose concepts and applications are built up from the basics, aiming at bringing first-time learners quickly to the forefront of research. History and limitations of AI are recounted and discussed, with particular attention at pointing out misstatements or misconceptions of the classics, even in well-known references. Positioning and pointing control of a large-deformable beam is given as an example.
<div id='section'>Paperid: <span id='pid'>1159, <a href='https://arxiv.org/pdf/2211.09240.pdf' target='_blank'>https://arxiv.org/pdf/2211.09240.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Agata Dziwulska-Hunek, Agnieszka Niemczynowicz, RadosÅaw A. Kycia, Arkadiusz Matwijczuk, Krzysztof KornarzyÅski, Joanna Stadnik, Mariusz Szymanek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.09240">Stimulation of soy seeds using environmentally friendly magnetic and electric fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The study analyzes the impact of constant and alternating magnetic fields and alternating electric fields on various growth parameters of soy plants: the germination energy and capacity, plants emergence and number, the Yield(II) of the fresh mass of seedlings, protein content, and photosynthetic parameters. Four cultivars were used: MAVKA, MERLIN, VIOLETTA, and ANUSZKA. Moreover, the advanced Machine Learning processing pipeline was proposed to distinguish the impact of physical factors on photosynthetic parameters. It is possible to distinguish exposition on different physical factors for the first three cultivars; therefore, it indicates that the EM factors have some observable effect on soy plants. Moreover, some influence of physical factors on growth parameters was observed. The use of ELM (Electromagnetic) fields had a positive impact on the germination rate in Merlin plants. The highest values were recorded for the constant magnetic field (CMF) - Merlin, and the lowest for the alternating electric field (AEF) - Violetta. An increase in terms of emergence and number of plants after seed stimulation was observed for the Mavka cultivar, except for the AEF treatment (number of plants after 30 days) (...)
<div id='section'>Paperid: <span id='pid'>1160, <a href='https://arxiv.org/pdf/2210.00006.pdf' target='_blank'>https://arxiv.org/pdf/2210.00006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kiarash Jamali, Dari Kimanius, Sjors H. W. Scheres
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.00006">A Graph Neural Network Approach to Automated Model Building in Cryo-EM Maps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electron cryo-microscopy (cryo-EM) produces three-dimensional (3D) maps of the electrostatic potential of biological macromolecules, including proteins. Along with knowledge about the imaged molecules, cryo-EM maps allow de novo atomic modelling, which is typically done through a laborious manual process. Taking inspiration from recent advances in machine learning applications to protein structure prediction, we propose a graph neural network (GNN) approach for automated model building of proteins in cryo-EM maps. The GNN acts on a graph with nodes assigned to individual amino acids and edges representing the protein chain. Combining information from the voxel-based cryo-EM data, the amino acid sequence data and prior knowledge about protein geometries, the GNN refines the geometry of the protein chain and classifies the amino acids for each of its nodes. Application to 28 test cases shows that our approach outperforms the state-of-the-art and approximates manual building for cryo-EM maps with resolutions better than 3.5 Ã.
<div id='section'>Paperid: <span id='pid'>1161, <a href='https://arxiv.org/pdf/2209.08171.pdf' target='_blank'>https://arxiv.org/pdf/2209.08171.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nabin Giri, Raj S. Roy, Jianlin Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.08171">Deep learning for reconstructing protein structures from cryo-EM density maps: recent advances and future directions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryo-Electron Microscopy (cryo-EM) has emerged as a key technology to determine the structure of proteins, particularly large protein complexes and assemblies in recent years. A key challenge in cryo-EM data analysis is to automatically reconstruct accurate protein structures from cryo-EM density maps. In this review, we briefly overview various deep learning methods for building protein structures from cryo-EM density maps, analyze their impact, and discuss the challenges of preparing high-quality data sets for training deep learning models. Looking into the future, more advanced deep learning models of effectively integrating cryo-EM data with other sources of complementary data such as protein sequences and AlphaFold-predicted structures need to be developed to further advance the field.
<div id='section'>Paperid: <span id='pid'>1162, <a href='https://arxiv.org/pdf/2209.04517.pdf' target='_blank'>https://arxiv.org/pdf/2209.04517.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marjan Famili, Jola Mirecka, Camila Rangel Smith, Anna KotaÅska, Nikolai Juraschko, Beatriz Costa-Gomes, Colin M. Palmer, Jeyan Thiyagalingam, Tom Burnley, Mark Basham, Alan R. Lowe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.04517">Affinity-VAE: incorporating prior knowledge in representation learning from scientific images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning compact and interpretable representations of data is a critical challenge in scientific image analysis. Here, we introduce Affinity-VAE, a generative model that enables us to impose our scientific intuition about the similarity of instances in the dataset on the learned representation during training. We demonstrate the utility of the approach in the scientific domain of cryo-electron tomography (cryo-ET) where a significant current challenge is to identify similar molecules within a noisy and low contrast tomographic image volume. This task is distinct from classification in that, at inference time, it is unknown whether an instance is part of the training set or not. We trained affinity-VAE using prior knowledge of protein structure to inform the latent space. Our model is able to create rotationally-invariant, morphologically homogeneous clusters in the latent representation, with improved cluster separation compared to other approaches. It achieves competitive performance on protein classification with the added benefit of disentangling object pose, structural similarity and an interpretable latent representation. In the context of cryo-ET data, affinity-VAE captures the orientation of identified proteins in 3D which can be used as a prior for subsequent scientific experiments. Extracting physical principles from a trained network is of significant importance in scientific imaging where a ground truth training set is not always feasible.
<div id='section'>Paperid: <span id='pid'>1163, <a href='https://arxiv.org/pdf/2208.11030.pdf' target='_blank'>https://arxiv.org/pdf/2208.11030.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mark Goldsmith, Guillermo GarcÃ­a-PÃ©rez, Joonas Malmi, Matteo A. C. Rossi, Harto Saarinen, Sabrina Maniscalco
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.11030">Link prediction with continuous-time classical and quantum walks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interaction (PPI) networks consist of the physical and/or functional interactions between the proteins of an organism. Since the biophysical and high-throughput methods used to form PPI networks are expensive, time-consuming, and often contain inaccuracies, the resulting networks are usually incomplete. In order to infer missing interactions in these networks, we propose a novel class of link prediction methods based on continuous-time classical and quantum random walks. In the case of quantum walks, we examine the usage of both the network adjacency and Laplacian matrices for controlling the walk dynamics. We define a score function based on the corresponding transition probabilities and perform tests on four real-world PPI datasets. Our results show that continuous-time classical random walks and quantum walks using the network adjacency matrix can successfully predict missing protein-protein interactions, with performance rivalling the state of the art.
<div id='section'>Paperid: <span id='pid'>1164, <a href='https://arxiv.org/pdf/2207.09827.pdf' target='_blank'>https://arxiv.org/pdf/2207.09827.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Miguel E. P. Silva, Robert E. Gaunt, Luis Ospina-Forero, Caroline Jay, Thomas House
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.09827">Comparing directed networks via denoising graphlet distributions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Network comparison is a widely-used tool for analyzing complex systems, with applications in varied domains including comparison of protein interactions or highlighting changes in structure of trade networks. In recent years, a number of network comparison methodologies based on the distribution of graphlets (small connected network subgraphs) have been introduced. In particular, NetEmd has recently achieved state of the art performance in undirected networks. In this work, we propose an extension of NetEmd to directed networks and deal with the significant increase in complexity of graphlet structure in the directed case by denoising through linear projections. Simulation results show that our framework is able to improve on the performance of a simple translation of the undirected NetEmd algorithm to the directed case, especially when networks differ in size and density.
<div id='section'>Paperid: <span id='pid'>1165, <a href='https://arxiv.org/pdf/2207.02149.pdf' target='_blank'>https://arxiv.org/pdf/2207.02149.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars Holdijk, Yuanqi Du, Ferry Hooft, Priyank Jaini, Bernd Ensing, Max Welling
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.02149">Stochastic Optimal Control for Collective Variable Free Sampling of Molecular Transition Paths</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the problem of sampling transition paths between two given metastable states of a molecular system, e.g. a folded and unfolded protein or products and reactants of a chemical reaction. Due to the existence of high energy barriers separating the states, these transition paths are unlikely to be sampled with standard Molecular Dynamics (MD) simulation. Traditional methods to augment MD with a bias potential to increase the probability of the transition rely on a dimensionality reduction step based on Collective Variables (CVs). Unfortunately, selecting appropriate CVs requires chemical intuition and traditional methods are therefore not always applicable to larger systems. Additionally, when incorrect CVs are used, the bias potential might not be minimal and bias the system along dimensions irrelevant to the transition. Showing a formal relation between the problem of sampling molecular transition paths, the SchrÃ¶dinger bridge problem and stochastic optimal control with neural network policies, we propose a machine learning method for sampling said transitions. Unlike previous non-machine learning approaches our method, named PIPS, does not depend on CVs. We show that our method successful generates low energy transitions for Alanine Dipeptide as well as the larger Polyproline and Chignolin proteins.
<div id='section'>Paperid: <span id='pid'>1166, <a href='https://arxiv.org/pdf/2205.04652.pdf' target='_blank'>https://arxiv.org/pdf/2205.04652.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohaddeseh Bastan, Nishant Shankar, Mihai Surdeanu, Niranjan Balasubramanian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.04652">SuMe: A Dataset Towards Summarizing Biomedical Mechanisms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Can language models read biomedical texts and explain the biomedical mechanisms discussed? In this work we introduce a biomedical mechanism summarization task. Biomedical studies often investigate the mechanisms behind how one entity (e.g., a protein or a chemical) affects another in a biological context. The abstracts of these publications often include a focused set of sentences that present relevant supporting statements regarding such relationships, associated experimental evidence, and a concluding sentence that summarizes the mechanism underlying the relationship. We leverage this structure and create a summarization task, where the input is a collection of sentences and the main entities in an abstract, and the output includes the relationship and a sentence that summarizes the mechanism. Using a small amount of manually labeled mechanism sentences, we train a mechanism sentence classifier to filter a large biomedical abstract collection and create a summarization dataset with 22k instances. We also introduce conclusion sentence generation as a pretraining task with 611k instances. We benchmark the performance of large bio-domain language models. We find that while the pretraining task help improves performance, the best model produces acceptable mechanism outputs in only 32% of the instances, which shows the task presents significant challenges in biomedical language understanding and summarization.
<div id='section'>Paperid: <span id='pid'>1167, <a href='https://arxiv.org/pdf/2204.07110.pdf' target='_blank'>https://arxiv.org/pdf/2204.07110.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Damiano Sgarbossa, Umberto Lupo, Anne-Florence Bitbol
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.07110">Generative power of a protein language model trained on multiple sequence alignments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational models starting from large ensembles of evolutionarily related protein sequences capture a representation of protein families and learn constraints associated to protein structure and function. They thus open the possibility for generating novel sequences belonging to protein families. Protein language models trained on multiple sequence alignments, such as MSA Transformer, are highly attractive candidates to this end. We propose and test an iterative method that directly employs the masked language modeling objective to generate sequences using MSA Transformer. We demonstrate that the resulting sequences score as well as natural sequences, for homology, coevolution and structure-based measures. For large protein families, our synthetic sequences have similar or better properties compared to sequences generated by Potts models, including experimentally-validated ones. Moreover, for small protein families, our generation method based on MSA Transformer outperforms Potts models. Our method also more accurately reproduces the higher-order statistics and the distribution of sequences in sequence space of natural data than Potts models. MSA Transformer is thus a strong candidate for protein sequence generation and protein design.
<div id='section'>Paperid: <span id='pid'>1168, <a href='https://arxiv.org/pdf/2202.04801.pdf' target='_blank'>https://arxiv.org/pdf/2202.04801.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shubhayu Bhattacharyay, Ioan Milosevic, Lindsay Wilson, David K. Menon, Robert D. Stevens, Ewout W. Steyerberg, David W. Nelson, Ari Ercole, the CENTER-TBI investigators/participants
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.04801">The leap to ordinal: detailed functional prognosis after traumatic brain injury with a flexible modelling approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When a patient is admitted to the intensive care unit (ICU) after a traumatic brain injury (TBI), an early prognosis is essential for baseline risk adjustment and shared decision making. TBI outcomes are commonly categorised by the Glasgow Outcome Scale-Extended (GOSE) into 8, ordered levels of functional recovery at 6 months after injury. Existing ICU prognostic models predict binary outcomes at a certain threshold of GOSE (e.g., prediction of survival [GOSE>1] or functional independence [GOSE>4]). We aimed to develop ordinal prediction models that concurrently predict probabilities of each GOSE score. From a prospective cohort (n=1,550, 65 centres) in the ICU stratum of the Collaborative European NeuroTrauma Effectiveness Research in TBI (CENTER-TBI) patient dataset, we extracted all clinical information within 24 hours of ICU admission (1,151 predictors) and 6-month GOSE scores. We analysed the effect of 2 design elements on ordinal model performance: (1) the baseline predictor set, ranging from a concise set of 10 validated predictors to a token-embedded representation of all possible predictors, and (2) the modelling strategy, from ordinal logistic regression to multinomial deep learning. With repeated k-fold cross-validation, we found that expanding the baseline predictor set significantly improved ordinal prediction performance while increasing analytical complexity did not. Half of these gains could be achieved with the addition of 8 high-impact predictors (2 demographic variables, 4 protein biomarkers, and 2 severity assessments) to the concise set. At best, ordinal models achieved 0.76 (95% CI: 0.74-0.77) ordinal discrimination ability (ordinal c-index) and 57% (95% CI: 54%-60%) explanation of ordinal variation in 6-month GOSE (Somers' D). Our results motivate the search for informative predictors for higher GOSE and the development of ordinal dynamic prediction models.
<div id='section'>Paperid: <span id='pid'>1169, <a href='https://arxiv.org/pdf/2201.01018.pdf' target='_blank'>https://arxiv.org/pdf/2201.01018.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiayu Shang, Yanni Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.01018">CHERRY: a Computational metHod for accuratE pRediction of virus-pRokarYotic interactions using a graph encoder-decoder model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prokaryotic viruses, which infect bacteria and archaea, are key players in microbial communities. Predicting the hosts of prokaryotic viruses helps decipher the dynamic relationship between microbes. Experimental methods for host prediction cannot keep pace with the fast accumulation of sequenced phages. Thus, there is a need for computational host prediction. Despite some promising results, computational host prediction remains a challenge because of the limited known interactions and the sheer amount of sequenced phages by high-throughput sequencing technologies. The state-of-the-art methods can only achieve 43\% accuracy at the species level. In this work, we formulate host prediction as link prediction in a knowledge graph that integrates multiple protein and DNA-based sequence features. Our implementation named CHERRY can be applied to predict hosts for newly discovered viruses and to identify viruses infecting targeted bacteria. We demonstrated the utility of CHERRY for both applications and compared its performance with 11 popular host prediction methods. To our best knowledge, CHERRY has the highest accuracy in identifying virus-prokaryote interactions. It outperforms all the existing methods at the species level with an accuracy increase of 37\%. In addition, CHERRY's performance on short contigs is more stable than other tools.
<div id='section'>Paperid: <span id='pid'>1170, <a href='https://arxiv.org/pdf/2110.14746.pdf' target='_blank'>https://arxiv.org/pdf/2110.14746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Theodore Jiang, Li Fang, Kai Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.14746">Deciphering the Language of Nature: A transformer-based language model for deleterious mutations in proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Various machine-learning models, including deep neural network models, have already been developed to predict deleteriousness of missense (non-synonymous) mutations. Potential improvements to the current state of the art, however, may still benefit from a fresh look at the biological problem using more sophisticated self-adaptive machine-learning approaches. Recent advances in the natural language processing field show transformer models-a type of deep neural network-to be particularly powerful at modeling sequence information with context dependence. In this study, we introduce MutFormer, a transformer-based model for the prediction of deleterious missense mutations, which uses reference and mutated protein sequences from the human genome as the primary features. MutFormer takes advantage of a combination of self-attention layers and convolutional layers to learn both long-range and short-range dependencies between amino acid mutations in a protein sequence. In this study, we first pre-trained MutFormer on reference protein sequences and mutated protein sequences resulting from common genetic variants observed in human populations. We next examined different fine-tuning methods to successfully apply the model to deleteriousness prediction of missense mutations. Finally, we evaluated MutFormer's performance on multiple testing data sets. We found that MutFormer showed similar or improved performance over a variety of existing tools, including those that used conventional machine-learning approaches. We conclude that MutFormer successfully considers sequence features that are not explored in previous studies and could potentially complement existing computational predictions or empirically generated functional scores to improve our understanding of disease variants.
<div id='section'>Paperid: <span id='pid'>1171, <a href='https://arxiv.org/pdf/2003.06665.pdf' target='_blank'>https://arxiv.org/pdf/2003.06665.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Budel, Maksim Kitsak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2003.06665">Complementarity in Complex Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many networks, including networks of protein-protein interactions, interdisciplinary collaboration networks, and semantic networks, connections are established between nodes with complementary rather than similar properties. While complementarity is abundant in networks, we lack mathematical intuition and quantitative methods to study complementarity mechanisms in these systems. In this work, we close this gap by providing a rigorous definition of complementarity and developing geometric complementarity frameworks for modeling and inference tasks on networks. We demonstrate the utility of complementarity frameworks by learning geometric representations of several real systems. Complementarity not only offers novel practical analysis methods but also enhances our intuition about formation mechanisms in networks on a broader scale and calls for a careful re-evaluation of existing similarity-inspired methods.
<div id='section'>Paperid: <span id='pid'>1172, <a href='https://arxiv.org/pdf/2001.04794.pdf' target='_blank'>https://arxiv.org/pdf/2001.04794.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francesco Bardozzo, Pietro Lio', Roberto Tagliaferri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2001.04794">A machine learning approach to investigate regulatory control circuits in bacterial metabolic pathways</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, a machine learning approach for identifying the multi-omics metabolic regulatory control circuits inside the pathways is described. Therefore, the identification of bacterial metabolic pathways that are more regulated than others in term of their multi-omics follows from the analysis of these circuits . This is a consequence of the alternation of the omic values of codon usage and protein abundance along with the circuits. In this work, the E.Coli's Glycolysis and its multi-omic circuit features are shown as an example.
<div id='section'>Paperid: <span id='pid'>1173, <a href='https://arxiv.org/pdf/2509.20542.pdf' target='_blank'>https://arxiv.org/pdf/2509.20542.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rujie Yin, Yang Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.20542">A Hierarchical Adaptive Diffusion Model for Flexible Protein-Protein Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structural prediction of protein-protein interactions is important to understand the molecular basis of cellular interactions, but it still faces major challenges when significant conformational changes are present. We propose a generative framework of hierarchical adaptive diffusion to improve accuracy and efficiency in such cases. It is hierarchical in separating global inter-protein rigid-body motions and local intra-protein flexibility in diffusion processes, and the distinct local and global noise schedules are designed to mimic the induced-fit effect. It is adaptive in conditioning the local flexibility schedule on predicted levels of conformational change, allowing faster flexing for larger anticipated conformational changes. Furthermore, it couples the local and global diffusion processes through a common score and confidence network with sequence, evolution, structure, and dynamics features as inputs, and maintains rotational or translational invariance or equivariance in outputs. It builds on our newly curated DIPS-AF dataset of nearly 39,000 examples for pre-training. Experiments on the independent docking benchmark dataset DB5.5 show that our model outperforms an AlphaFold2-like iterative transformer (GeoDock) and a diffusion model (DiffDock-PP) in both rigid and flexible cases, with larger improvements in more flexible cases. Ablation studies prove the importance of adaptive schedules, dynamics features, and pre-training. Additional analyses and case studies reveal remaining gaps in sampling, scoring, and conformational resolution.
<div id='section'>Paperid: <span id='pid'>1174, <a href='https://arxiv.org/pdf/2509.17937.pdf' target='_blank'>https://arxiv.org/pdf/2509.17937.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jayashrita Debnath, Gerhard Hummer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17937">Random functions as data compressors for machine learning of molecular processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) is rapidly transforming the way molecular dynamics simulations are performed and analyzed, from materials modeling to studies of protein folding and function. ML algorithms are often employed to learn low-dimensional representations of conformational landscapes and to cluster trajectories into relevant metastable states. Most of these algorithms require selecting a small number of features that describe the problem of interest. Although deep neural networks can tackle large numbers of input features, the training costs increase with input size, which makes the selection of a subset of features mandatory for most problems of practical interest. Here, we show that random nonlinear projections can be used to compress large feature spaces and make computations faster without substantial loss of information. We describe an efficient way to produce random projections and then exemplify the general procedure for protein folding. For our test cases NTL9 and the double-norleucin variant of the villin headpiece, we find that random compression retains the core static and dynamic information of the original high dimensional feature space and makes trajectory analysis more robust.
<div id='section'>Paperid: <span id='pid'>1175, <a href='https://arxiv.org/pdf/2509.05541.pdf' target='_blank'>https://arxiv.org/pdf/2509.05541.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Diego Sanchez Espinosa, Erik H Thiede, Yunan Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05541">Cryo-EM as a Stochastic Inverse Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryo-electron microscopy (Cryo-EM) enables high-resolution imaging of biomolecules, but structural heterogeneity remains a major challenge in 3D reconstruction. Traditional methods assume a discrete set of conformations, limiting their ability to recover continuous structural variability. In this work, we formulate cryo-EM reconstruction as a stochastic inverse problem (SIP) over probability measures, where the observed images are modeled as the push-forward of an unknown distribution over molecular structures via a random forward operator. We pose the reconstruction problem as the minimization of a variational discrepancy between observed and simulated image distributions, using statistical distances such as the KL divergence and the Maximum Mean Discrepancy. The resulting optimization is performed over the space of probability measures via a Wasserstein gradient flow, which we numerically solve using particles to represent and evolve conformational ensembles. We validate our approach using synthetic examples, including a realistic protein model, which demonstrates its ability to recover continuous distributions over structural states. We analyze the connection between our formulation and Maximum A Posteriori (MAP) approaches, which can be interpreted as instances of the discretize-then-optimize (DTO) framework. We further provide a consistency analysis, establishing conditions under which DTO methods, such as MAP estimation, converge to the solution of the underlying infinite-dimensional continuous problem. Beyond cryo-EM, the framework provides a general methodology for solving SIPs involving random forward operators.
<div id='section'>Paperid: <span id='pid'>1176, <a href='https://arxiv.org/pdf/2509.05302.pdf' target='_blank'>https://arxiv.org/pdf/2509.05302.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Raúl Miñán, Carles Perez-Lopez, Javier Iglesias, Álvaro Ciudad, Alexis Molina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05302">Sesame: Opening the door to protein pockets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking is a cornerstone of drug discovery, relying on high-resolution ligand-bound structures to achieve accurate predictions. However, obtaining these structures is often costly and time-intensive, limiting their availability. In contrast, ligand-free structures are more accessible but suffer from reduced docking performance due to pocket geometries being less suited for ligand accommodation in apo structures. Traditional methods for artificially inducing these conformations, such as molecular dynamics simulations, are computationally expensive. In this work, we introduce Sesame, a generative model designed to predict this conformational change efficiently. By generating geometries better suited for ligand accommodation at a fraction of the computational cost, Sesame aims to provide a scalable solution for improving virtual screening workflows.
<div id='section'>Paperid: <span id='pid'>1177, <a href='https://arxiv.org/pdf/2509.04998.pdf' target='_blank'>https://arxiv.org/pdf/2509.04998.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matouš Soldát, Jiří Kléma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.04998">Directed Evolution of Proteins via Bayesian Optimization in Embedding Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Directed evolution is an iterative laboratory process of designing proteins with improved function by iteratively synthesizing new protein variants and evaluating their desired property with expensive and time-consuming biochemical screening. Machine learning methods can help select informative or promising variants for screening to increase their quality and reduce the amount of necessary screening. In this paper, we present a novel method for machine-learning-assisted directed evolution of proteins which combines Bayesian optimization with informative representation of protein variants extracted from a pre-trained protein language model. We demonstrate that the new representation based on the sequence embeddings significantly improves the performance of Bayesian optimization yielding better results with the same number of conducted screening in total. At the same time, our method outperforms the state-of-the-art machine-learning-assisted directed evolution methods with regression objective.
<div id='section'>Paperid: <span id='pid'>1178, <a href='https://arxiv.org/pdf/2509.03885.pdf' target='_blank'>https://arxiv.org/pdf/2509.03885.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyu Wang, Arian Jamasb, Mustafa Hajij, Alex Morehead, Luke Braithwaite, Pietro Liò
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03885">Topotein: Topological Deep Learning for Protein Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein representation learning (PRL) is crucial for understanding structure-function relationships, yet current sequence- and graph-based methods fail to capture the hierarchical organization inherent in protein structures. We introduce Topotein, a comprehensive framework that applies topological deep learning to PRL through the novel Protein Combinatorial Complex (PCC) and Topology-Complete Perceptron Network (TCPNet). Our PCC represents proteins at multiple hierarchical levels -- from residues to secondary structures to complete proteins -- while preserving geometric information at each level. TCPNet employs SE(3)-equivariant message passing across these hierarchical structures, enabling more effective capture of multi-scale structural patterns. Through extensive experiments on four PRL tasks, TCPNet consistently outperforms state-of-the-art geometric graph neural networks. Our approach demonstrates particular strength in tasks such as fold classification which require understanding of secondary structure arrangements, validating the importance of hierarchical topological features for protein analysis.
<div id='section'>Paperid: <span id='pid'>1179, <a href='https://arxiv.org/pdf/2509.03351.pdf' target='_blank'>https://arxiv.org/pdf/2509.03351.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Natalia Flechas Manrique, Alberto Martínez, Elena López-Martínez, Luc Andrea, Román Orus, Aitor Manteca, Aitziber L. Cortajarena, Llorenç Espinosa-Portalés
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03351">epiGPTope: A machine learning-based epitope generator and classifier</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Epitopes are short antigenic peptide sequences which are recognized by antibodies or immune cell receptors. These are central to the development of immunotherapies, vaccines, and diagnostics. However, the rational design of synthetic epitope libraries is challenging due to the large combinatorial sequence space, $20^n$ combinations for linear epitopes of n amino acids, making screening and testing unfeasible, even with high throughput experimental techniques. In this study, we present a large language model, epiGPTope, pre-trained on protein data and specifically fine-tuned on linear epitopes, which for the first time can directly generate novel epitope-like sequences, which are found to possess statistical properties analogous to the ones of known epitopes. This generative approach can be used to prepare libraries of epitope candidate sequences. We further train statistical classifiers to predict whether an epitope sequence is of bacterial or viral origin, thus narrowing the candidate library and increasing the likelihood of identifying specific epitopes. We propose that such combination of generative and predictive models can be of assistance in epitope discovery. The approach uses only primary amino acid sequences of linear epitopes, bypassing the need for a geometric framework or hand-crafted features of the sequences. By developing a method to create biologically feasible sequences, we anticipate faster and more cost-effective generation and screening of synthetic epitopes, with relevant applications in the development of new biotechnologies.
<div id='section'>Paperid: <span id='pid'>1180, <a href='https://arxiv.org/pdf/2509.02610.pdf' target='_blank'>https://arxiv.org/pdf/2509.02610.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan Feldman, Tal Feldman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02610">Resilient Biosecurity in the Era of AI-Enabled Bioweapons</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in generative biology have enabled the design of novel proteins, creating significant opportunities for drug discovery while also introducing new risks, including the potential development of synthetic bioweapons. Existing biosafety measures primarily rely on inference-time filters such as sequence alignment and protein-protein interaction (PPI) prediction to detect dangerous outputs. In this study, we evaluate the performance of three leading PPI prediction tools: AlphaFold 3, AF3Complex, and SpatialPPIv2. These models were tested on well-characterized viral-host interactions, such as those involving Hepatitis B and SARS-CoV-2. Despite being trained on many of the same viruses, the models fail to detect a substantial number of known interactions. Strikingly, none of the tools successfully identify any of the four experimentally validated SARS-CoV-2 mutants with confirmed binding. These findings suggest that current predictive filters are inadequate for reliably flagging even known biological threats and are even more unlikely to detect novel ones. We argue for a shift toward response-oriented infrastructure, including rapid experimental validation, adaptable biomanufacturing, and regulatory frameworks capable of operating at the speed of AI-driven developments.
<div id='section'>Paperid: <span id='pid'>1181, <a href='https://arxiv.org/pdf/2508.18891.pdf' target='_blank'>https://arxiv.org/pdf/2508.18891.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhijin Wang, Senzhen Wu, Yue Hu, Xiufeng Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18891">pyFAST: A Modular PyTorch Framework for Time Series Modeling with Multi-source and Sparse Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern time series analysis demands frameworks that are flexible, efficient, and extensible. However, many existing Python libraries exhibit limitations in modularity and in their native support for irregular, multi-source, or sparse data. We introduce pyFAST, a research-oriented PyTorch framework that explicitly decouples data processing from model computation, fostering a cleaner separation of concerns and facilitating rapid experimentation. Its data engine is engineered for complex scenarios, supporting multi-source loading, protein sequence handling, efficient sequence- and patch-level padding, dynamic normalization, and mask-based modeling for both imputation and forecasting. pyFAST integrates LLM-inspired architectures for the alignment-free fusion of sparse data sources and offers native sparse metrics, specialized loss functions, and flexible exogenous data fusion. Training utilities include batch-based streaming aggregation for evaluation and device synergy to maximize computational efficiency. A comprehensive suite of classical and deep learning models (Linears, CNNs, RNNs, Transformers, and GNNs) is provided within a modular architecture that encourages extension. Released under the MIT license at GitHub, pyFAST provides a compact yet powerful platform for advancing time series research and applications.
<div id='section'>Paperid: <span id='pid'>1182, <a href='https://arxiv.org/pdf/2508.18693.pdf' target='_blank'>https://arxiv.org/pdf/2508.18693.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhitong Cheng, Yiran Jiang, Yulong Ge, Yufeng Li, Zhongheng Qin, Rongzhi Lin, Jianwei Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18693">Feature-Space Planes Searcher: A Universal Domain Adaptation Framework for Interpretability and Computational Efficiency</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain shift, characterized by degraded model performance during transition from labeled source domains to unlabeled target domains, poses a persistent challenge for deploying deep learning systems. Current unsupervised domain adaptation (UDA) methods predominantly rely on fine-tuning feature extractors - an approach limited by inefficiency, reduced interpretability, and poor scalability to modern architectures.
  Our analysis reveals that models pretrained on large-scale data exhibit domain-invariant geometric patterns in their feature space, characterized by intra-class clustering and inter-class separation, thereby preserving transferable discriminative structures. These findings indicate that domain shifts primarily manifest as boundary misalignment rather than feature degradation.
  Unlike fine-tuning entire pre-trained models - which risks introducing unpredictable feature distortions - we propose the Feature-space Planes Searcher (FPS): a novel domain adaptation framework that optimizes decision boundaries by leveraging these geometric patterns while keeping the feature encoder frozen. This streamlined approach enables interpretative analysis of adaptation while substantially reducing memory and computational costs through offline feature extraction, permitting full-dataset optimization in a single computation cycle.
  Evaluations on public benchmarks demonstrate that FPS achieves competitive or superior performance to state-of-the-art methods. FPS scales efficiently with multimodal large models and shows versatility across diverse domains including protein structure prediction, remote sensing classification, and earthquake detection. We anticipate FPS will provide a simple, effective, and generalizable paradigm for transfer learning, particularly in domain adaptation tasks. .
<div id='section'>Paperid: <span id='pid'>1183, <a href='https://arxiv.org/pdf/2508.18446.pdf' target='_blank'>https://arxiv.org/pdf/2508.18446.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Abbaszadeh, Armita Shahlaee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18446">From Prediction to Simulation: AlphaFold 3 as a Differentiable Framework for Structural Biology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AlphaFold 3 represents a transformative advancement in computational biology, enhancing protein structure prediction through novel multi-scale transformer architectures, biologically informed cross-attention mechanisms, and geometry-aware optimization strategies. These innovations dramatically improve predictive accuracy and generalization across diverse protein families, surpassing previous methods. Crucially, AlphaFold 3 embodies a paradigm shift toward differentiable simulation, bridging traditional static structural modeling with dynamic molecular simulations. By reframing protein folding predictions as a differentiable process, AlphaFold 3 serves as a foundational framework for integrating deep learning with physics-based molecular
<div id='section'>Paperid: <span id='pid'>1184, <a href='https://arxiv.org/pdf/2508.16587.pdf' target='_blank'>https://arxiv.org/pdf/2508.16587.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rakesh Thakur, Riya Gupta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16587">HemePLM-Diffuse: A Scalable Generative Framework for Protein-Ligand Dynamics in Large Biomolecular System</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Comprehending the long-timescale dynamics of protein-ligand complexes is very important for drug discovery and structural biology, but it continues to be computationally challenging for large biomolecular systems. We introduce HemePLM-Diffuse, an innovative generative transformer model that is designed for accurate simulation of protein-ligand trajectories, inpaints the missing ligand fragments, and sample transition paths in systems with more than 10,000 atoms. HemePLM-Diffuse has features of SE(3)-Invariant tokenization approach for proteins and ligands, that utilizes time-aware cross-attentional diffusion to effectively capture atomic motion. We also demonstrate its capabilities using the 3CQV HEME system, showing enhanced accuracy and scalability compared to leading models such as TorchMD-Net, MDGEN, and Uni-Mol.
<div id='section'>Paperid: <span id='pid'>1185, <a href='https://arxiv.org/pdf/2508.13421.pdf' target='_blank'>https://arxiv.org/pdf/2508.13421.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabrielle Wehr, Reuben Rideaux, Amaya J. Fox, David R. Lightfoot, Jason Tangen, Jason B. Mattingley, Shane E. Ehrhardt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13421">Virtuous Machines: Towards Artificial General Science</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence systems are transforming scientific discovery by accelerating specific research tasks, from protein structure prediction to materials design, yet remain confined to narrow domains requiring substantial human oversight. The exponential growth of scientific literature and increasing domain specialisation constrain researchers' capacity to synthesise knowledge across disciplines and develop unifying theories, motivating exploration of more general-purpose AI systems for science. Here we show that a domain-agnostic, agentic AI system can independently navigate the scientific workflow - from hypothesis generation through data collection to manuscript preparation. The system autonomously designed and executed three psychological studies on visual working memory, mental rotation, and imagery vividness, executed one new online data collection with 288 participants, developed analysis pipelines through 8-hour+ continuous coding sessions, and produced completed manuscripts. The results demonstrate the capability of AI scientific discovery pipelines to conduct non-trivial research with theoretical reasoning and methodological rigour comparable to experienced researchers, though with limitations in conceptual nuance and theoretical interpretation. This is a step toward embodied AI that can test hypotheses through real-world experiments, accelerating discovery by autonomously exploring regions of scientific space that human cognitive and resource constraints might otherwise leave unexplored. It raises important questions about the nature of scientific understanding and the attribution of scientific credit.
<div id='section'>Paperid: <span id='pid'>1186, <a href='https://arxiv.org/pdf/2508.13255.pdf' target='_blank'>https://arxiv.org/pdf/2508.13255.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahi Navelkar, Andrea Cosolo, Bogdan Bintu, Yubao Cheng, Vincent Gardeux, Silvia Gutnik, Taihei Fujimori, Antonina Hafner, Atishay Jay, Bojing Blair Jia, Adam Paul Jussila, Gerard Llimos, Antonios Lioutas, Nuno MC Martins, William J Moore, Yodai Takei, Frances Wong, Kaifu Yang, Huaiying Zhang, Quan Zhu, Magda Bienko, Lacramioara Bintu, Long Cai, Bart Deplancke, Marcelo Nollmann, Susan E Mango, Bing Ren, Peter J Park, Ahilya N Sawh, Andrew Schroeder, Jason R Swedlow, Golnaz Vahedi, Chao-Ting Wu, Sarah Aufmkolk, Alistair N Boettiger, Irene Farabella, Caterina Strambio-De-Castillia, Siyuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13255">FAIR sharing of Chromatin Tracing datasets using the newly developed 4DN FISH Omics Format</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A key output of the NIH Common Fund 4D Nucleome (4DN) project is the open publication of datasets on the structure of the human cell nucleus and genome. In recent years, multiplexed Fluorescence In Situ Hybridization (FISH) and FISH-omics methods have rapidly expanded, enabling quantification of chromatin organization in single cells, sometimes alongside RNA and protein measurements. These approaches have deepened our understanding of how 3D chromosome architecture relates to transcriptional activity and cell development in health and disease. However, results from Chromatin Tracing FISH-omics experiments remain difficult to share, reuse, and analyze due to the absence of standardized data-exchange specifications. Building on the recent release of microscopy metadata standards, we introduce the 4DN FISH Omics Format-Chromatin Tracing (FOF-CT), a community-developed standard for processed results from diverse imaging techniques. Current studies generally use one of two representations: ball-and-stick, where genomic segments appear as individual fluorescence spots, or volumetric, representing them as clouds of single-molecule localizations. This manuscript focuses on ball-and-stick methods, including those from the pioneering study of Wang et al. (2016) and related techniques. We describe the FOF-CT structure and present newly deposited datasets in the 4DN Data Portal and the OME Image Data Resource (IDR), highlighting their potential for reuse, integration, and modeling. We also outline example analysis pipelines and illustrate biological insights enabled by standardized, FAIR-compliant Chromatin Tracing datasets.
<div id='section'>Paperid: <span id='pid'>1187, <a href='https://arxiv.org/pdf/2508.12575.pdf' target='_blank'>https://arxiv.org/pdf/2508.12575.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zohra Yagoub, Hafida Bouziane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12575">Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The prediction of amyloidogenicity in peptides and proteins remains a focal point of ongoing bioinformatics. The crucial step in this field is to apply advanced computational methodologies. Many recent approaches to predicting amyloidogenicity within proteins are highly based on evolutionary motifs and the individual properties of amino acids. It is becoming increasingly evident that the sequence information-based features show high predictive performance. Consequently, our study evaluated the contextual features of protein sequences obtained from a pretrained protein large language model leveraging bidirectional LSTM and GRU to predict amyloidogenic regions in peptide and protein sequences. Our method achieved an accuracy of 84.5% on 10-fold cross-validation and an accuracy of 83% in the test dataset. Our results demonstrate competitive performance, highlighting the potential of LLMs in enhancing the accuracy of amyloid prediction.
<div id='section'>Paperid: <span id='pid'>1188, <a href='https://arxiv.org/pdf/2508.10541.pdf' target='_blank'>https://arxiv.org/pdf/2508.10541.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Brian Shing-Hei Wong, Joshua Mincheol Kim, Sin-Hang Fung, Qing Xiong, Kelvin Fu-Kiu Ao, Junkang Wei, Ran Wang, Dan Michelle Wang, Jingying Zhou, Bo Feng, Alfred Sze-Lok Cheng, Kevin Y. Yip, Stephen Kwok-Wing Tsui, Qin Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10541">Driving Accurate Allergen Prediction with Protein Language Models and Generalization-Focused Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Allergens, typically proteins capable of triggering adverse immune responses, represent a significant public health challenge. To accurately identify allergen proteins, we introduce Applm (Allergen Prediction with Protein Language Models), a computational framework that leverages the 100-billion parameter xTrimoPGLM protein language model. We show that Applm consistently outperforms seven state-of-the-art methods in a diverse set of tasks that closely resemble difficult real-world scenarios. These include identifying novel allergens that lack similar examples in the training set, differentiating between allergens and non-allergens among homologs with high sequence similarity, and assessing functional consequences of mutations that create few changes to the protein sequences. Our analysis confirms that xTrimoPGLM, originally trained on one trillion tokens to capture general protein sequence characteristics, is crucial for Applm's performance by detecting important differences among protein sequences. In addition to providing Applm as open-source software, we also provide our carefully curated benchmark datasets to facilitate future research.
<div id='section'>Paperid: <span id='pid'>1189, <a href='https://arxiv.org/pdf/2508.10117.pdf' target='_blank'>https://arxiv.org/pdf/2508.10117.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nguyen Manh Son, Pham Huu Vang, Nguyen Thi Dung, Nguyen Manh Ha. Ta Thi Thao, Tran Thi Thu Thuy, Phan Minh Giang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10117">In silico study on the cytotoxicity against Hela cancer cells of xanthones bioactive compounds from Garcinia cowa: QSAR based on Graph Deep Learning, Network Pharmacology, and Molecular Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cancer is recognized as a complex group of diseases, contributing to the highest global mortality rates, with increasing prevalence and a trend toward affecting younger populations. It is characterized by uncontrolled proliferation of abnormal cells, invasion of adjacent tissues, and metastasis to distant organs. Garcinia cowa, a traditional medicinal plant widely used in Southeast Asia, including Vietnam, is employed to treat fever, cough, indigestion, as a laxative, and for parasitic diseases. Numerous xanthone compounds isolated from this species exhibit a broad spectrum of biological activities, with some showing promise as anti cancer and antimalarial agents. Network pharmacology analysis successfully identified key bioactive compounds Rubraxanthone, Garcinone D, Norcowanin, Cowanol, and Cowaxanthone alongside their primary protein targets (TNF, CTNNB1, SRC, NFKB1, and MTOR), providing critical insights into the molecular mechanisms underlying their anti-cancer effects. The Graph Attention Network algorithm demonstrated superior predictive performance, achieving an R2 of 0.98 and an RMSE of 0.02 after data augmentation, highlighting its accuracy in predicting pIC50 values for xanthone based compounds. Additionally, molecular docking revealed MTOR as a potential target for inducing cytotoxicity in HeLa cancer cells from Garcinia cowa.
<div id='section'>Paperid: <span id='pid'>1190, <a href='https://arxiv.org/pdf/2508.09659.pdf' target='_blank'>https://arxiv.org/pdf/2508.09659.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Johannes F. Hevler, Shivam Verma, Mirat Soijtra, Carolyn R. Bertozzi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.09659">Thermal Tracks: A Gaussian process-based framework for universal melting curve analysis enabling unconstrained hit identification in thermal proteome profiling experiments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Thermal Tracks is a Python-based statistical framework for analyzing protein thermal stability data that overcomes key limitations of existing thermal proteome profiling (TPP) work-flows. Unlike standard approaches that assume sigmoidal melting curves and are constrained by empirical null distributions (limiting significant hits to approximately 5 % of data), Thermal Tracks uses Gaussian Process (GP) models with squared-exponential kernels to flexibly model any melting curve shape while generating unbiased null distributions through kernel priors. This framework is particularly valuable for analyzing proteome-wide perturbations that significantly alter protein thermal stability, such as pathway inhibitions, genetic modifications, or environmental stresses, where conventional TPP methods may miss biologically relevant changes due to their statistical constraints. Furthermore, Thermal Tracks excels at analyzing proteins with un-conventional melting profiles, including phase-separating proteins and membrane proteins, which often exhibit complex, non-sigmoidal thermal stability behaviors. Thermal Tracks is freely available from GitHub and is implemented in Python, providing an accessible and flexible tool for proteome-wide thermal profiling studies.
<div id='section'>Paperid: <span id='pid'>1191, <a href='https://arxiv.org/pdf/2508.07887.pdf' target='_blank'>https://arxiv.org/pdf/2508.07887.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabrina Namazova, Alessandra Brondetta, Younes Strittmatter, Matthew Nassar, Sebastian Musslick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07887">Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulators have revolutionized scientific practice across the natural sciences. By generating data that reliably approximate real-world phenomena, they enable scientists to accelerate hypothesis testing and optimize experimental designs. This is perhaps best illustrated by AlphaFold, a Nobel-prize winning simulator in chemistry that predicts protein structures from amino acid sequences, enabling rapid prototyping of molecular interactions, drug targets, and protein functions. In the behavioral sciences, a reliable participant simulator - a system capable of producing human-like behavior across cognitive tasks - would represent a similarly transformative advance. Recently, Binz et al. introduced Centaur, a large language model (LLM) fine-tuned on human data from 160 experiments, proposing its use not only as a model of cognition but also as a participant simulator for "in silico prototyping of experimental studies", e.g., to advance automated cognitive science. Here, we review the core criteria for a participant simulator and assess how well Centaur meets them. Although Centaur demonstrates strong predictive accuracy, its generative behavior - a critical criterion for a participant simulator - systematically diverges from human data. This suggests that, while Centaur is a significant step toward predicting human behavior, it does not yet meet the standards of a reliable participant simulator or an accurate model of cognition.
<div id='section'>Paperid: <span id='pid'>1192, <a href='https://arxiv.org/pdf/2508.07345.pdf' target='_blank'>https://arxiv.org/pdf/2508.07345.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samiha Afaf Neha, Abir Ahammed Bhuiyan, Md. Ishrak Khan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07345">ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>\textbf{Introduction:} Accurate prediction of Phage Virion Proteins (PVP) is essential for genomic studies due to their crucial role as structural elements in bacteriophages. Computational tools, particularly machine learning, have emerged for annotating phage protein sequences from high-throughput sequencing. However, effective annotation requires specialized sequence encodings. Our paper introduces ProteoKnight, a new image-based encoding method that addresses spatial constraints in existing techniques, yielding competitive performance in PVP classification using pre-trained convolutional neural networks. Additionally, our study evaluates prediction uncertainty in binary PVP classification through Monte Carlo Dropout (MCD). \textbf{Methods:} ProteoKnight adapts the classical DNA-Walk algorithm for protein sequences, incorporating pixel colors and adjusting walk distances to capture intricate protein features. Encoded sequences were classified using multiple pre-trained CNNs. Variance and entropy measures assessed prediction uncertainty across proteins of various classes and lengths. \textbf{Results:} Our experiments achieved 90.8% accuracy in binary classification, comparable to state-of-the-art methods. Multi-class classification accuracy remains suboptimal. Our uncertainty analysis unveils variability in prediction confidence influenced by protein class and sequence length. \textbf{Conclusions:} Our study surpasses frequency chaos game representation (FCGR) by introducing novel image encoding that mitigates spatial information loss limitations. Our classification technique yields accurate and robust PVP predictions while identifying low-confidence predictions.
<div id='section'>Paperid: <span id='pid'>1193, <a href='https://arxiv.org/pdf/2508.07326.pdf' target='_blank'>https://arxiv.org/pdf/2508.07326.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Polina V. Banushkina, Sergei V. Krivov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07326">Nonparametric Reaction Coordinate Optimization with Histories: A Framework for Rare Event Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rare but critical events in complex systems, such as protein folding, chemical reactions, disease progression, and extreme weather or climate phenomena, are governed by complex, high-dimensional, stochastic dynamics. Identifying an optimal reaction coordinate (RC) that accurately captures the progress of these dynamics is crucial for understanding and simulating such processes. This work introduces a nonparametric RC optimization framework that incorporates trajectory histories, enabling robust analysis even for irregular or incomplete data. The power of the method is demonstrated through increasingly challenging analyses of protein folding dynamics, where it provides accurate committor estimates that pass a stringent validation test and yield high-resolution free energy profiles. Its generality is further illustrated through applications to dynamics in phase space, a conceptual ocean circulation model, and a longitudinal clinical dataset. These results demonstrate that rare event dynamics can be accurately characterized without exhaustive sampling of the configuration space, establishing a general, flexible, and robust framework for analyzing complex dynamical systems and longitudinal datasets.
<div id='section'>Paperid: <span id='pid'>1194, <a href='https://arxiv.org/pdf/2508.04724.pdf' target='_blank'>https://arxiv.org/pdf/2508.04724.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Timothy Fei Truong, Tristan Bepler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.04724">Understanding protein function with a multimodal retrieval-augmented foundation model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models (PLMs) learn probability distributions over natural protein sequences. By learning from hundreds of millions of natural protein sequences, protein understanding and design capabilities emerge. Recent works have shown that scaling these models improves structure prediction, but does not seem to improve mutation understanding and representation quality for protein function prediction. We introduce PoET-2, a multimodal, retrieval-augmented protein foundation model that incorporates in-context learning of family-specific evolutionary constraints with optional structure conditioning to learn generative distributions over protein sequences. PoET-2 uses a hierarchical transformer encoder that is equivariant to sequence context ordering and a dual decoder architecture with both causal and masked language modeling objectives, allowing PoET-2 to operate in both fully generative and bidirectional representation learning modes. PoET-2 achieves state-of-the-art performance on zero-shot variant effect prediction, excelling at scoring variants with multiple mutations and challenging indel mutations. In supervised settings, PoET-2 embeddings outperform previous methods for learning sequence-function relationships, especially with small datasets. This work highlights the benefits of combining retrieval augmentation with multimodal, family-centric modeling for advancing protein foundation models.
<div id='section'>Paperid: <span id='pid'>1195, <a href='https://arxiv.org/pdf/2508.03709.pdf' target='_blank'>https://arxiv.org/pdf/2508.03709.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mhd Hussein Murtada, Z. Faidon Brotzakis, Michele Vendruscolo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03709">MD-LLM-1: A Large Language Model for Molecular Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular dynamics (MD) is a powerful approach for modelling molecular systems, but it remains computationally intensive on spatial and time scales of many macromolecular systems of biological interest. To explore the opportunities offered by deep learning to address this problem, we introduce a Molecular Dynamics Large Language Model (MD-LLM) framework to illustrate how LLMs can be leveraged to learn protein dynamics and discover states not seen in training. By applying MD-LLM-1, the first implementation of this approach, obtained by fine-tuning Mistral 7B, to the T4 lysozyme and Mad2 protein systems, we show that training on one conformational state enables the prediction of other conformational states. These results indicate that MD-LLM-1 can learn the principles for the exploration of the conformational landscapes of proteins, although it is not yet modeling explicitly their thermodynamics and kinetics.
<div id='section'>Paperid: <span id='pid'>1196, <a href='https://arxiv.org/pdf/2508.03446.pdf' target='_blank'>https://arxiv.org/pdf/2508.03446.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erico Souza Teixeira, Lucas Barros Fernandes, Yara Rodrigues InÃ¡cio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03446">Quantum Neural Network applications to Protein Binding Affinity Predictions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Binding energy is a fundamental thermodynamic property that governs molecular interactions, playing a crucial role in fields such as healthcare and the natural sciences. It is particularly relevant in drug development, vaccine design, and other biomedical applications. Over the years, various methods have been developed to estimate protein binding energy, ranging from experimental techniques to computational approaches, with machine learning making significant contributions to this field. Although classical computing has demonstrated strong results in constructing predictive models, the variation of quantum computing for machine learning has emerged as a promising alternative. Quantum neural networks (QNNs) have gained traction as a research focus, raising the question of their potential advantages in predicting binding energies. To investigate this potential, this study explored the feasibility of QNNs for this task by proposing thirty variations of multilayer perceptron-based quantum neural networks. These variations span three distinct architectures, each incorporating ten different quantum circuits to configure their quantum layers. The performance of these quantum models was compared with that of a state-of-the-art classical multilayer perceptron-based artificial neural network, evaluating both accuracy and training time. A primary dataset was used for training, while two additional datasets containing entirely unseen samples were employed for testing. Results indicate that the quantum models achieved approximately 20% higher accuracy on one unseen dataset, although their accuracy was lower on the other datasets. Notably, quantum models exhibited training times several orders of magnitude shorter than their classical counterparts, highlighting their potential for efficient protein binding energy prediction.
<div id='section'>Paperid: <span id='pid'>1197, <a href='https://arxiv.org/pdf/2508.03444.pdf' target='_blank'>https://arxiv.org/pdf/2508.03444.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Atabey ÃnlÃ¼, Phil Rohr, Ahmet Celebi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03444">An Auditable Agent Platform For Automated Molecular Optimisation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drug discovery frequently loses momentum when data, expertise, and tools are scattered, slowing design cycles. To shorten this loop we built a hierarchical, tool using agent framework that automates molecular optimisation. A Principal Researcher defines each objective, a Database agent retrieves target information, an AI Expert generates de novo scaffolds with a sequence to molecule deep learning model, a Medicinal Chemist edits them while invoking a docking tool, a Ranking agent scores the candidates, and a Scientific Critic polices the logic. Each tool call is summarised and stored causing the full reasoning path to remain inspectable. The agents communicate through concise provenance records that capture molecular lineage, to build auditable, molecule centered reasoning trajectories and reuse successful transformations via in context learning. Three cycle research loops were run against AKT1 protein using five large language models. After ranking the models by mean docking score, we ran 20 independent scale ups on the two top performers. We then compared the leading LLMs' binding affinity results across three configurations, LLM only, single agent, and multi agent. Our results reveal an architectural trade off, the multi agent setting excelled at focused binding optimization, improving average predicted binding affinity by 31%. In contrast, single agent runs generated molecules with superior drug like properties at the cost of less potent binding scores. Unguided LLM runs finished fastest, yet their lack of transparent tool signals left the validity of their reasoning paths unverified. These results show that test time scaling, focused feedback loops and provenance convert general purpose LLMs into auditable systems for molecular design, and suggest that extending the toolset to ADMET and selectivity predictors could push research workflows further along the discovery pipeline.
<div id='section'>Paperid: <span id='pid'>1198, <a href='https://arxiv.org/pdf/2507.22186.pdf' target='_blank'>https://arxiv.org/pdf/2507.22186.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ambarish Singh, Romila Pradhan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.22186">SourceSplice: Source Selection for Machine Learning Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data quality plays a pivotal role in the predictive performance of machine learning (ML) tasks - a challenge amplified by the deluge of data sources available in modern organizations. Prior work in data discovery largely focus on metadata matching, semantic similarity or identifying tables that should be joined to answer a particular query, but do not consider source quality for high performance of the downstream ML task. This paper addresses the problem of determining the best subset of data sources that must be combined to construct the underlying training dataset for a given ML task. We propose SourceGrasp and SourceSplice, frameworks designed to efficiently select a suitable subset of sources that maximizes the utility of the downstream ML model. Both the algorithms rely on the core idea that sources (or their combinations) contribute differently to the task utility, and must be judiciously chosen. While SourceGrasp utilizes a metaheuristic based on a greediness criterion and randomization, the SourceSplice framework presents a source selection mechanism inspired from gene splicing - a core concept used in protein synthesis. We empirically evaluate our algorithms on three real-world datasets and synthetic datasets and show that, with significantly fewer subset explorations, SourceSplice effectively identifies subsets of data sources leading to high task utility. We also conduct studies reporting the sensitivity of SourceSplice to the decision choices under several settings.
<div id='section'>Paperid: <span id='pid'>1199, <a href='https://arxiv.org/pdf/2507.21938.pdf' target='_blank'>https://arxiv.org/pdf/2507.21938.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Abrudan, Sebastian Pujalte Ojeda, Chaitanya K. Joshi, Matthew Greenig, Felipe Engelberger, Alena Khmelinskaia, Jens Meiler, Michele Vendruscolo, Tuomas P. J. Knowles
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21938">Multi-state Protein Design with DynamicMPNN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structural biology has long been dominated by the one sequence, one structure, one function paradigm, yet many critical biological processes - from enzyme catalysis to membrane transport - depend on proteins that adopt multiple conformational states. Existing multi-state design approaches rely on post-hoc aggregation of single-state predictions, achieving poor experimental success rates compared to single-state design. We introduce DynamicMPNN, an inverse folding model explicitly trained to generate sequences compatible with multiple conformations through joint learning across conformational ensembles. Trained on 46,033 conformational pairs covering 75% of CATH superfamilies and evaluated using AlphaFold initial guess, DynamicMPNN outperforms ProteinMPNN by up to 13% on structure-normalized RMSD across our challenging multi-state protein benchmark.
<div id='section'>Paperid: <span id='pid'>1200, <a href='https://arxiv.org/pdf/2507.20520.pdf' target='_blank'>https://arxiv.org/pdf/2507.20520.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Praneeth Narisetty, Uday Kumar Reddy Kattamanchi, Lohit Akshant Nimma, Sri Ram Kaushik Karnati, Shiva Nagendra Babu Kore, Mounika Golamari, Tejashree Nageshreddy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.20520">AQUA: A Large Language Model for Aquaculture & Fisheries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Aquaculture plays a vital role in global food security and coastal economies by providing sustainable protein sources. As the industry expands to meet rising demand, it faces growing challenges such as disease outbreaks, inefficient feeding practices, rising labor costs, logistical inefficiencies, and critical hatchery issues, including high mortality rates and poor water quality control. Although artificial intelligence has made significant progress, existing machine learning methods fall short of addressing the domain-specific complexities of aquaculture. To bridge this gap, we introduce AQUA, the first large language model (LLM) tailored for aquaculture, designed to support farmers, researchers, and industry practitioners. Central to this effort is AQUADAPT (Data Acquisition, Processing and Tuning), an Agentic Framework for generating and refining high-quality synthetic data using a combination of expert knowledge, largescale language models, and automated evaluation techniques. Our work lays the foundation for LLM-driven innovations in aquaculture research, advisory systems, and decision-making tools.
<div id='section'>Paperid: <span id='pid'>1201, <a href='https://arxiv.org/pdf/2507.16915.pdf' target='_blank'>https://arxiv.org/pdf/2507.16915.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>April Herwig, Matthew J. Colbrook, Oliver Junge, PÃ©ter Koltai, Julia Slipantschuk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16915">Avoiding spectral pollution for transfer operators using residuals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Koopman operator theory enables linear analysis of nonlinear dynamical systems by lifting their evolution to infinite-dimensional function spaces. However, finite-dimensional approximations of Koopman and transfer (Frobenius--Perron) operators are prone to spectral pollution, introducing spurious eigenvalues that can compromise spectral computations. While recent advances have yielded provably convergent methods for Koopman operators, analogous tools for general transfer operators remain limited. In this paper, we present algorithms for computing spectral properties of transfer operators without spectral pollution, including extensions to the Hardy-Hilbert space. Case studies--ranging from families of Blaschke maps with known spectrum to a molecular dynamics model of protein folding--demonstrate the accuracy and flexibility of our approach. Notably, we demonstrate that spectral features can arise even when the corresponding eigenfunctions lie outside the chosen space, highlighting the functional-analytic subtleties in defining the "true" Koopman spectrum. Our methods offer robust tools for spectral estimation across a broad range of applications.
<div id='section'>Paperid: <span id='pid'>1202, <a href='https://arxiv.org/pdf/2507.16801.pdf' target='_blank'>https://arxiv.org/pdf/2507.16801.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxi Lin, Yaxue Fang, Zehong Zhang, Zhouwu Liu, Siyun Zhong, Fulong Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16801">Decoding Translation-Related Functional Sequences in 5'UTRs Using Interpretable Deep Learning Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding how 5' untranslated regions (5'UTRs) regulate mRNA translation is critical for controlling protein expression and designing effective therapeutic mRNAs. While recent deep learning models have shown promise in predicting translational efficiency from 5'UTR sequences, most are constrained by fixed input lengths and limited interpretability. We introduce UTR-STCNet, a Transformer-based architecture for flexible and biologically grounded modeling of variable-length 5'UTRs. UTR-STCNet integrates a Saliency-Aware Token Clustering (SATC) module that iteratively aggregates nucleotide tokens into multi-scale, semantically meaningful units based on saliency scores. A Saliency-Guided Transformer (SGT) block then captures both local and distal regulatory dependencies using a lightweight attention mechanism. This combined architecture achieves efficient and interpretable modeling without input truncation or increased computational cost. Evaluated across three benchmark datasets, UTR-STCNet consistently outperforms state-of-the-art baselines in predicting mean ribosome load (MRL), a key proxy for translational efficiency. Moreover, the model recovers known functional elements such as upstream AUGs and Kozak motifs, highlighting its potential for mechanistic insight into translation regulation.
<div id='section'>Paperid: <span id='pid'>1203, <a href='https://arxiv.org/pdf/2507.14639.pdf' target='_blank'>https://arxiv.org/pdf/2507.14639.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saleh Alwer, Ronan Fleming
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14639">KinForm: Kinetics Informed Feature Optimised Representation Models for Enzyme $k_{cat}$ and $K_{M}$ Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kinetic parameters such as the turnover number ($k_{cat}$) and Michaelis constant ($K_{\mathrm{M}}$) are essential for modelling enzymatic activity but experimental data remains limited in scale and diversity. Previous methods for predicting enzyme kinetics typically use mean-pooled residue embeddings from a single protein language model to represent the protein. We present KinForm, a machine learning framework designed to improve predictive accuracy and generalisation for kinetic parameters by optimising protein feature representations. KinForm combines several residue-level embeddings (Evolutionary Scale Modeling Cambrian, Evolutionary Scale Modeling 2, and ProtT5-XL-UniRef50), taken from empirically selected intermediate transformer layers and applies weighted pooling based on per-residue binding-site probability. To counter the resulting high dimensionality, we apply dimensionality reduction using principal--component analysis (PCA) on concatenated protein features, and rebalance the training data via a similarity-based oversampling strategy. KinForm outperforms baseline methods on two benchmark datasets. Improvements are most pronounced in low sequence similarity bins. We observe improvements from binding-site probability pooling, intermediate-layer selection, PCA, and oversampling of low-identity proteins. We also find that removing sequence overlap between folds provides a more realistic evaluation of generalisation and should be the standard over random splitting when benchmarking kinetic prediction models.
<div id='section'>Paperid: <span id='pid'>1204, <a href='https://arxiv.org/pdf/2507.13950.pdf' target='_blank'>https://arxiv.org/pdf/2507.13950.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingbo Liang, Bruna Jacobson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.13950">MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Extensively exploring protein conformational landscapes remains a major challenge in computational biology due to the high computational cost involved in dynamic physics-based simulations. In this work, we propose a novel pipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and generative adversarial networks (GANs) to explore protein conformational spaces. MoDyGAN contains a generator that maps Gaussian distributions into MD-derived protein trajectories, and a refinement module that combines ensemble learning with a dual-discriminator to further improve the plausibility of generated conformations. Central to our approach is an innovative representation technique that reversibly transforms 3D protein structures into 2D matrices, enabling the use of advanced image-based GAN architectures. We use three rigid proteins to demonstrate that MoDyGAN can generate plausible new conformations. We also use deca-alanine as a case study to show that interpolations within the latent space closely align with trajectories obtained from steered molecular dynamics (SMD) simulations. Our results suggest that representing proteins as image-like data unlocks new possibilities for applying advanced deep learning techniques to biomolecular simulation, leading to an efficient sampling of conformational states. Additionally, the proposed framework holds strong potential for extension to other complex 3D structures.
<div id='section'>Paperid: <span id='pid'>1205, <a href='https://arxiv.org/pdf/2507.11950.pdf' target='_blank'>https://arxiv.org/pdf/2507.11950.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lauren Lui, Torben Nielsen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11950">RNAMunin: A Deep Machine Learning Model for Non-coding RNA Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Functional annotation of microbial genomes is often biased toward protein-coding genes, leaving a vast, unexplored landscape of non-coding RNAs (ncRNAs) that are critical for regulating bacterial and archaeal physiology, stress response and metabolism. Identifying ncRNAs directly from genomic sequence is a paramount challenge in bioinformatics and biology, essential for understanding the complete regulatory potential of an organism. This paper presents RNAMunin, a machine learning (ML) model that is capable of finding ncRNAs using genomic sequence alone. It is also computationally viable for large sequence datasets such as long read metagenomic assemblies with contigs totaling multiple Gbp. RNAMunin is trained on Rfam sequences extracted from approximately 60 Gbp of long read metagenomes from 16 San Francisco Estuary samples. We know of no other model that can detect ncRNAs based solely on genomic sequence at this scale. Since RNAMunin only requires genomic sequence as input, we do not need for an ncRNA to be transcribed to find it, i.e., we do not need transcriptomics data. We wrote this manuscript in a narrative style in order to best convey how RNAMunin was developed and how it works in detail. Unlike almost all current ML models, at approximately 1M parameters, RNAMunin is very small and very fast.
<div id='section'>Paperid: <span id='pid'>1206, <a href='https://arxiv.org/pdf/2507.11757.pdf' target='_blank'>https://arxiv.org/pdf/2507.11757.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuehua Song, Yong Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11757">A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting drug-target interactions (DTIs) is pivotal for advancing drug discovery and target validation techniques. While machine learning approaches including those that are based on Graph Neural Networks (GNN) have achieved notable success in DTI prediction, many of them have difficulties in effectively integrating the diverse features of drugs, targets and their interactions. To address this limitation, we introduce a novel framework to take advantage of the power of both transductive learning and inductive learning so that features at molecular level and drug-target interaction network level can be exploited. Within this framework is a GNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and target molecular structures as meta-nodes in a drug-target interaction graph, enabling a detailed exploration of their intricate relationships. To evaluate the proposed model, we have compiled a special benchmark comprising drug SMILES, protein sequences, and their interaction data, which is interesting in its own right. Our experimental results demonstrate that the GiG model significantly outperforms existing approaches across all evaluation metrics, highlighting the benefits of integrating different learning paradigms and interaction data.
<div id='section'>Paperid: <span id='pid'>1207, <a href='https://arxiv.org/pdf/2507.11176.pdf' target='_blank'>https://arxiv.org/pdf/2507.11176.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoran Li, Xingye Cheng, Ziyang Huang, Jingyuan Luo, Qianqian Xu, Qiguang Zhao, Tianchen Guo, Yumeng Zhang, Linda Lidan Zhong, Zhaoxiang Bian, Leihan Tang, Aiping Lyu, Liang Tian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11176">An Interpretable AI framework Quantifying Traditional Chinese Medicine Principles Towards Enhancing and Integrating with Modern Biomedicine</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional Chinese Medicine diagnosis and treatment principles, established through centuries of trial-and-error clinical practice, directly maps patient-specific symptom patterns to personalised herbal therapies. These empirical holistic mapping principles offer valuable strategies to address remaining challenges of reductionism methodologies in modern biomedicine. However, the lack of a quantitative framework and molecular-level evidence has limited their interpretability and reliability. Here, we present an AI framework trained on ancient and classical TCM formula records to quantify the symptom pattern-herbal therapy mappings. Interestingly, we find that empirical TCM diagnosis and treatment are consistent with the encoding-decoding processes in the AI model. This enables us to construct an interpretable TCM embedding space (TCM-ES) using the model's quantitative representation of TCM principles. Validated through broad and extensive TCM patient data, the TCM-ES offers universal quantification of the TCM practice and therapeutic efficacy. We further map biomedical entities into the TCM-ES through correspondence alignment. We find that the principal directions of the TCM-ES are significantly associated with key biological functions (such as metabolism, immune, and homeostasis), and that the disease and herb embedding proximity aligns with their genetic relationships in the human protein interactome, which demonstrate the biological significance of TCM principles. Moreover, the TCM-ES uncovers latent disease relationships, and provides alternative metric to assess clinical efficacy for modern disease-drug pairs. Finally, we construct a comprehensive and integrative TCM knowledge graph, which predicts potential associations between diseases and targets, drugs, herbal compounds, and herbal therapies, providing TCM-informed opportunities for disease analysis and drug development.
<div id='section'>Paperid: <span id='pid'>1208, <a href='https://arxiv.org/pdf/2507.10273.pdf' target='_blank'>https://arxiv.org/pdf/2507.10273.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lu Zhu, Emmanuel Noutahi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10273">Conditional Chemical Language Models are Versatile Tools in Drug Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative chemical language models (CLMs) have demonstrated strong capabilities in molecular design, yet their impact in drug discovery remains limited by the absence of reliable reward signals and the lack of interpretability in their outputs. We present SAFE-T, a generalist chemical modeling framework that conditions on biological context -- such as protein targets or mechanisms of action -- to prioritize and design molecules without relying on structural information or engineered scoring functions. SAFE-T models the conditional likelihood of fragment-based molecular sequences given a biological prompt, enabling principled scoring of molecules across tasks such as virtual screening, drug-target interaction prediction, and activity cliff detection. Moreover, it supports goal-directed generation by sampling from this learned distribution, aligning molecular design with biological objectives. In comprehensive zero-shot evaluations across predictive (LIT-PCBA, DAVIS, KIBA, ACNet) and generative (DRUG, PMO) benchmarks, SAFE-T consistently achieves performance comparable to or better than existing approaches while being significantly faster. Fragment-level attribution further reveals that SAFE-T captures known structure-activity relationships, supporting interpretable and biologically grounded design. Together with its computational efficiency, these results demonstrate that conditional generative CLMs can unify scoring and generation to accelerate early-stage drug discovery.
<div id='section'>Paperid: <span id='pid'>1209, <a href='https://arxiv.org/pdf/2507.06458.pdf' target='_blank'>https://arxiv.org/pdf/2507.06458.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arjun Banerjee, David Martinez, Camille Dang, Ethan Tam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06458">Automated Neuron Labelling Enables Generative Steering and Interpretability in Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models (PLMs) encode rich biological information, yet their internal neuron representations are poorly understood. We introduce the first automated framework for labeling every neuron in a PLM with biologically grounded natural language descriptions. Unlike prior approaches relying on sparse autoencoders or manual annotation, our method scales to hundreds of thousands of neurons, revealing individual neurons are selectively sensitive to diverse biochemical and structural properties. We then develop a novel neuron activation-guided steering method to generate proteins with desired traits, enabling convergence to target biochemical properties like molecular weight and instability index as well as secondary and tertiary structural motifs, including alpha helices and canonical Zinc Fingers. We finally show that analysis of labeled neurons in different model sizes reveals PLM scaling laws and a structured neuron space distribution.
<div id='section'>Paperid: <span id='pid'>1210, <a href='https://arxiv.org/pdf/2507.05540.pdf' target='_blank'>https://arxiv.org/pdf/2507.05540.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chunhui Gu, Mohammad Sadegh Nasr, James P. Long, Kim-Anh Do, Ehsan Irajizad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05540">Robust Learning on Noisy Graphs via Latent Space Constraints with External Knowledge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) often struggle with noisy edges. We propose Latent Space Constrained Graph Neural Networks (LSC-GNN) to incorporate external "clean" links and guide embeddings of a noisy target graph. We train two encoders--one on the full graph (target plus external edges) and another on a regularization graph excluding the target's potentially noisy links--then penalize discrepancies between their latent representations. This constraint steers the model away from overfitting spurious edges. Experiments on benchmark datasets show LSC-GNN outperforms standard and noise-resilient GNNs in graphs subjected to moderate noise. We extend LSC-GNN to heterogeneous graphs and validate it on a small protein-metabolite network, where metabolite-protein interactions reduce noise in protein co-occurrence data. Our results highlight LSC-GNN's potential to boost predictive performance and interpretability in settings with noisy relational structures.
<div id='section'>Paperid: <span id='pid'>1211, <a href='https://arxiv.org/pdf/2507.02902.pdf' target='_blank'>https://arxiv.org/pdf/2507.02902.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoran Zhang, Mingyuan Zhou, Wesley Tansey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02902">Controllable diffusion-based generation for multi-channel biological data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spatial profiling technologies in biology, such as imaging mass cytometry (IMC) and spatial transcriptomics (ST), generate high-dimensional, multi-channel data with strong spatial alignment and complex inter-channel relationships. Generative modeling of such data requires jointly capturing intra- and inter-channel structure, while also generalizing across arbitrary combinations of observed and missing channels for practical application. Existing diffusion-based models generally assume low-dimensional inputs (e.g., RGB images) and rely on simple conditioning mechanisms that break spatial correspondence and ignore inter-channel dependencies. This work proposes a unified diffusion framework for controllable generation over structured and spatial biological data. Our model contains two key innovations: (1) a hierarchical feature injection mechanism that enables multi-resolution conditioning on spatially aligned channels, and (2) a combination of latent-space and output-space channel-wise attention to capture inter-channel relationships. To support flexible conditioning and generalization to arbitrary subsets of observed channels, we train the model using a random masking strategy, enabling it to reconstruct missing channels from any combination of inputs. We demonstrate state-of-the-art performance across both spatial and non-spatial prediction tasks, including protein imputation in IMC and gene-to-protein prediction in single-cell datasets, and show strong generalization to unseen conditional configurations.
<div id='section'>Paperid: <span id='pid'>1212, <a href='https://arxiv.org/pdf/2507.02624.pdf' target='_blank'>https://arxiv.org/pdf/2507.02624.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Antoine HonorÃ©, Borja RodrÃ­guez GÃ¡lvez, Yoomi Park, Yitian Zhou, Volker M. Lauschke, Ming Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02624">A Matrix Variational Auto-Encoder for Variant Effect Prediction in Pharmacogenes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Variant effect predictors (VEPs) aim to assess the functional impact of protein variants, traditionally relying on multiple sequence alignments (MSAs). This approach assumes that naturally occurring variants are fit, an assumption challenged by pharmacogenomics, where some pharmacogenes experience low evolutionary pressure. Deep mutational scanning (DMS) datasets provide an alternative by offering quantitative fitness scores for variants. In this work, we propose a transformer-based matrix variational auto-encoder (matVAE) with a structured prior and evaluate its performance on 33 DMS datasets corresponding to 26 drug target and ADME proteins from the ProteinGym benchmark. Our model trained on MSAs (matVAE-MSA) outperforms the state-of-the-art DeepSequence model in zero-shot prediction on DMS datasets, despite using an order of magnitude fewer parameters and requiring less computation at inference time. We also compare matVAE-MSA to matENC-DMS, a model of similar capacity trained on DMS data, and find that the latter performs better on supervised prediction tasks. Additionally, incorporating AlphaFold-generated structures into our transformer model further improves performance, achieving results comparable to DeepSequence trained on MSAs and finetuned on DMS. These findings highlight the potential of DMS datasets to replace MSAs without significant loss in predictive performance, motivating further development of DMS datasets and exploration of their relationships to enhance variant effect prediction.
<div id='section'>Paperid: <span id='pid'>1213, <a href='https://arxiv.org/pdf/2506.13006.pdf' target='_blank'>https://arxiv.org/pdf/2506.13006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eunna Huh, Hyeonsu Lee, Hyunjin Shin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13006">Antibody Foundational Model : Ab-RoBERTa</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the growing prominence of antibody-based therapeutics, antibody engineering has gained increasing attention as a critical area of research and development. Recent progress in transformer-based protein large language models (LLMs) has demonstrated promising applications in protein sequence design and structural prediction. Moreover, the availability of large-scale antibody datasets such as the Observed Antibody Space (OAS) database has opened new avenues for the development of LLMs specialized for processing antibody sequences. Among these, RoBERTa has demonstrated improved performance relative to BERT, while maintaining a smaller parameter count (125M) compared to the BERT-based protein model, ProtBERT (420M). This reduced model size enables more efficient deployment in antibody-related applications. However, despite the numerous advantages of the RoBERTa architecture, antibody-specific foundational models built upon it have remained inaccessible to the research community. In this study, we introduce Ab-RoBERTa, a RoBERTa-based antibody-specific LLM, which is publicly available at https://huggingface.co/mogam-ai/Ab-RoBERTa. This resource is intended to support a wide range of antibody-related research applications including paratope prediction or humanness assessment.
<div id='section'>Paperid: <span id='pid'>1214, <a href='https://arxiv.org/pdf/2506.12455.pdf' target='_blank'>https://arxiv.org/pdf/2506.12455.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongqin Qiu, Xinyu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.12455">A Transfer Learning Framework for Multilayer Networks via Model Averaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Link prediction in multilayer networks is a key challenge in applications such as recommendation systems and protein-protein interaction prediction. While many techniques have been developed, most rely on assumptions about shared structures and require access to raw auxiliary data, limiting their practicality. To address these issues, we propose a novel transfer learning framework for multilayer networks using a bi-level model averaging method. A $K$-fold cross-validation criterion based on edges is used to automatically weight inter-layer and intra-layer candidate models. This enables the transfer of information from auxiliary layers while mitigating model uncertainty, even without prior knowledge of shared structures. Theoretically, we prove the optimality and weight convergence of our method under mild conditions. Computationally, our framework is efficient and privacy-preserving, as it avoids raw data sharing and supports parallel processing across multiple servers. Simulations show our method outperforms others in predictive accuracy and robustness. We further demonstrate its practical value through two real-world recommendation system applications.
<div id='section'>Paperid: <span id='pid'>1215, <a href='https://arxiv.org/pdf/2506.06305.pdf' target='_blank'>https://arxiv.org/pdf/2506.06305.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>NoÃ©mie Bergues, Arthur CarrÃ©, Paul Join-Lambert, Brice Hoffmann, Arnaud Blondel, Hamza Tajmouati
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06305">Template-Guided 3D Molecular Pose Generation via Flow Matching and Differentiable Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the 3D conformation of small molecules within protein binding sites is a key challenge in drug design. When a crystallized reference ligand (template) is available, it provides geometric priors that can guide 3D pose prediction. We present a two-stage method for ligand conformation generation guided by such templates. In the first stage, we introduce a molecular alignment approach based on flow-matching to generate 3D coordinates for the ligand, using the template structure as a reference. In the second stage, a differentiable pose optimization procedure refines this conformation based on shape and pharmacophore similarities, internal energy, and, optionally, the protein binding pocket. We evaluate our approach on a new benchmark of ligand pairs co-crystallized with the same target and show that it outperforms standard docking tools and open-access alignment methods, especially in cases involving low similarity to the template or high ligand flexibility.
<div id='section'>Paperid: <span id='pid'>1216, <a href='https://arxiv.org/pdf/2506.02212.pdf' target='_blank'>https://arxiv.org/pdf/2506.02212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ella Rannon, David Burstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02212">Leveraging Natural Language Processing to Unravel the Mystery of Life: A Review of NLP Approaches in Genomics, Transcriptomics, and Proteomics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Natural Language Processing (NLP) has transformed various fields beyond linguistics by applying techniques originally developed for human language to the analysis of biological sequences. This review explores the application of NLP methods to biological sequence data, focusing on genomics, transcriptomics, and proteomics. We examine how various NLP methods, from classic approaches like word2vec to advanced models employing transformers and hyena operators, are being adapted to analyze DNA, RNA, protein sequences, and entire genomes. The review also examines tokenization strategies and model architectures, evaluating their strengths, limitations, and suitability for different biological tasks. We further cover recent advances in NLP applications for biological data, such as structure prediction, gene expression, and evolutionary analysis, highlighting the potential of these methods for extracting meaningful insights from large-scale genomic data. As language models continue to advance, their integration into bioinformatics holds immense promise for advancing our understanding of biological processes in all domains of life.
<div id='section'>Paperid: <span id='pid'>1217, <a href='https://arxiv.org/pdf/2505.23879.pdf' target='_blank'>https://arxiv.org/pdf/2505.23879.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Caio Cheohen, VinnÃ­cius M. S. Gomes, Manuela L. da Silva
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23879">CNN-LSTM Hybrid Model for AI-Driven Prediction of COVID-19 Severity from Spike Sequences and Clinical Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The COVID-19 pandemic, caused by SARS-CoV-2, highlighted the critical need for accurate prediction of disease severity to optimize healthcare resource allocation and patient management. The spike protein, which facilitates viral entry into host cells, exhibits high mutation rates, particularly in the receptor-binding domain, influencing viral pathogenicity. Artificial intelligence approaches, such as deep learning, offer promising solutions for leveraging genomic and clinical data to predict disease outcomes. Objective: This study aimed to develop a hybrid CNN-LSTM deep learning model to predict COVID-19 severity using spike protein sequences and associated clinical metadata from South American patients. Methods: We retrieved 9,570 spike protein sequences from the GISAID database, of which 3,467 met inclusion criteria after standardization. The dataset included 2,313 severe and 1,154 mild cases. A feature engineering pipeline extracted features from sequences, while demographic and clinical variables were one-hot encoded. A hybrid CNN-LSTM architecture was trained, combining CNN layers for local pattern extraction and an LSTM layer for long-term dependency modeling. Results: The model achieved an F1 score of 82.92%, ROC-AUC of 0.9084, precision of 83.56%, and recall of 82.85%, demonstrating robust classification performance. Training stabilized at 85% accuracy with minimal overfitting. The most prevalent lineages (P.1, AY.99.2) and clades (GR, GK) aligned with regional epidemiological trends, suggesting potential associations between viral genetics and clinical outcomes. Conclusion: The CNN-LSTM hybrid model effectively predicted COVID-19 severity using spike protein sequences and clinical data, highlighting the utility of AI in genomic surveillance and precision public health. Despite limitations, this approach provides a framework for early severity prediction in future outbreaks.
<div id='section'>Paperid: <span id='pid'>1218, <a href='https://arxiv.org/pdf/2505.22926.pdf' target='_blank'>https://arxiv.org/pdf/2505.22926.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sylvey Lin, Zhi-Yi Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22926">Leveraging Diffusion Models for Synthetic Data Augmentation in Protein Subcellular Localization Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate whether synthetic images generated by diffusion models can enhance multi-label classification of protein subcellular localization. Specifically, we implement a simplified class-conditional denoising diffusion probabilistic model (DDPM) to produce label-consistent samples and explore their integration with real data via two hybrid training strategies: Mix Loss and Mix Representation. While these approaches yield promising validation performance, our proposed MixModel exhibits poor generalization to unseen test data, underscoring the challenges of leveraging synthetic data effectively. In contrast, baseline classifiers built on ResNet backbones with conventional loss functions demonstrate greater stability and test-time performance. Our findings highlight the importance of realistic data generation and robust supervision when incorporating generative augmentation into biomedical image classification.
<div id='section'>Paperid: <span id='pid'>1219, <a href='https://arxiv.org/pdf/2505.22494.pdf' target='_blank'>https://arxiv.org/pdf/2505.22494.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michal Kmicikiewicz, Vincent Fortuin, Ewa Szczurek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22494">ProSpero: Active Learning for Robust Protein Design Beyond Wild-Type Neighborhoods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing protein sequences of both high fitness and novelty is a challenging task in data-efficient protein engineering. Exploration beyond wild-type neighborhoods often leads to biologically implausible sequences or relies on surrogate models that lose fidelity in novel regions. Here, we propose ProSpero, an active learning framework in which a frozen pre-trained generative model is guided by a surrogate updated from oracle feedback. By integrating fitness-relevant residue selection with biologically-constrained Sequential Monte Carlo sampling, our approach enables exploration beyond wild-type neighborhoods while preserving biological plausibility. We show that our framework remains effective even when the surrogate is misspecified. ProSpero consistently outperforms or matches existing methods across diverse protein engineering tasks, retrieving sequences of both high fitness and novelty.
<div id='section'>Paperid: <span id='pid'>1220, <a href='https://arxiv.org/pdf/2505.19763.pdf' target='_blank'>https://arxiv.org/pdf/2505.19763.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thomas Hamelryck, Kanti V. Mardia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19763">Unfolding AlphaFold's Bayesian Roots in Probability Kinematics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel theoretical interpretation of AlphaFold1 that reveals the potential of generalized Bayesian updating for probabilistic deep learning. The seminal breakthrough of AlphaFold1 in protein structure prediction by deep learning relied on a learned potential energy function, in contrast to the later end-to-end architectures of AlphaFold2 and AlphaFold3. While this potential was originally justified by referring to physical potentials of mean force (PMFs), we reinterpret AlphaFold1's potential as an instance of {\em probability kinematics} -- also known as {\em Jeffrey conditioning} -- a principled but under-recognised generalization of conventional Bayesian updating. Probability kinematics accommodates uncertain or {\em soft} evidence in the form of updated probabilities over a partition. This perspective reveals AlphaFold1's potential as a form of generalized Bayesian updating, rather than a thermodynamic potential. To confirm our probabilistic framework's scope and precision, we analyze a synthetic 2D model in which an angular random walk prior is updated with evidence on distances via probability kinematics, mirroring AlphaFold1's approach. This theoretical contribution connects AlphaFold1 to a broader class of well-justified Bayesian methods, allowing precise quantification, surpassing merely qualitative heuristics based on PMFs. Our contribution is theoretical: we replace AlphaFold1's heuristic analogy with a principled probabilistic framework, tested in a controlled synthetic setting where correctness can be assessed. More broadly, our results point to the considerable promise of probability kinematics for probabilistic deep learning, by allowing the formulation of complex models from a few simpler components.
<div id='section'>Paperid: <span id='pid'>1221, <a href='https://arxiv.org/pdf/2505.15747.pdf' target='_blank'>https://arxiv.org/pdf/2505.15747.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kanan Kiguchi, Yunhao Tu, Katsuhiro Ajito, Fady Alnajjar, Kazuyuki Murase
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15747">Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel framework for integrating fragmented multi-modal data in Alzheimer's disease (AD) research using large language models (LLMs) and knowledge graphs. While traditional multimodal analysis requires matched patient IDs across datasets, our approach demonstrates population-level integration of MRI, gene expression, biomarkers, EEG, and clinical indicators from independent cohorts. Statistical analysis identified significant features in each modality, which were connected as nodes in a knowledge graph. LLMs then analyzed the graph to extract potential correlations and generate hypotheses in natural language. This approach revealed several novel relationships, including a potential pathway linking metabolic risk factors to tau protein abnormalities via neuroinflammation (r>0.6, p<0.001), and unexpected correlations between frontal EEG channels and specific gene expression profiles (r=0.42-0.58, p<0.01). Cross-validation with independent datasets confirmed the robustness of major findings, with consistent effect sizes across cohorts (variance <15%). The reproducibility of these findings was further supported by expert review (Cohen's k=0.82) and computational validation. Our framework enables cross modal integration at a conceptual level without requiring patient ID matching, offering new possibilities for understanding AD pathology through fragmented data reuse and generating testable hypotheses for future research.
<div id='section'>Paperid: <span id='pid'>1222, <a href='https://arxiv.org/pdf/2505.11610.pdf' target='_blank'>https://arxiv.org/pdf/2505.11610.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Asher Moldwin, Amarda Shehu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11610">Foundation Models for AI-Enabled Biological Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper surveys foundation models for AI-enabled biological design, focusing on recent developments in applying large-scale, self-supervised models to tasks such as protein engineering, small molecule design, and genomic sequence design. Though this domain is evolving rapidly, this survey presents and discusses a taxonomy of current models and methods. The focus is on challenges and solutions in adapting these models for biological applications, including biological sequence modeling architectures, controllability in generation, and multi-modal integration. The survey concludes with a discussion of open problems and future directions, offering concrete next-steps to improve the quality of biological sequence generation.
<div id='section'>Paperid: <span id='pid'>1223, <a href='https://arxiv.org/pdf/2505.11529.pdf' target='_blank'>https://arxiv.org/pdf/2505.11529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dan Luo, Jinyu Zhou, Le Xu, Sisi Yuan, Xuan Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11529">DynamicDTA: Drug-Target Binding Affinity Prediction Using Dynamic Descriptors and Graph Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting drug-target binding affinity (DTA) is essential for identifying potential therapeutic candidates in drug discovery. However, most existing models rely heavily on static protein structures, often overlooking the dynamic nature of proteins, which is crucial for capturing conformational flexibility that will be beneficial for protein binding interactions. We introduce DynamicDTA, an innovative deep learning framework that incorporates static and dynamic protein features to enhance DTA prediction. The proposed DynamicDTA takes three types of inputs, including drug sequence, protein sequence, and dynamic descriptors. A molecular graph representation of the drug sequence is generated and subsequently processed through graph convolutional network, while the protein sequence is encoded using dilated convolutions. Dynamic descriptors, such as root mean square fluctuation, are processed through a multi-layer perceptron. These embedding features are fused with static protein features using cross-attention, and a tensor fusion network integrates all three modalities for DTA prediction. Extensive experiments on three datasets demonstrate that DynamicDTA achieves by at least 3.4% improvement in RMSE score with comparison to seven state-of-the-art baseline methods. Additionally, predicting novel drugs for Human Immunodeficiency Virus Type 1 and visualizing the docking complexes further demonstrates the reliability and biological relevance of DynamicDTA.
<div id='section'>Paperid: <span id='pid'>1224, <a href='https://arxiv.org/pdf/2505.10848.pdf' target='_blank'>https://arxiv.org/pdf/2505.10848.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Justin Sanders, Melih Yilmaz, Jacob H. Russell, Wout Bittremieux, William E. Fondrie, Nicholas M. Riley, Sewoong Oh, William Stafford Noble
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.10848">Foundation model for mass spectrometry proteomics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mass spectrometry is the dominant technology in the field of proteomics, enabling high-throughput analysis of the protein content of complex biological samples. Due to the complexity of the instrumentation and resulting data, sophisticated computational methods are required for the processing and interpretation of acquired mass spectra. Machine learning has shown great promise to improve the analysis of mass spectrometry data, with numerous purpose-built methods for improving specific steps in the data acquisition and analysis pipeline reaching widespread adoption. Here, we propose unifying various spectrum prediction tasks under a single foundation model for mass spectra. To this end, we pre-train a spectrum encoder using de novo sequencing as a pre-training task. We then show that using these pre-trained spectrum representations improves our performance on the four downstream tasks of spectrum quality prediction, chimericity prediction, phosphorylation prediction, and glycosylation status prediction. Finally, we perform multi-task fine-tuning and find that this approach improves the performance on each task individually. Overall, our work demonstrates that a foundation model for tandem mass spectrometry proteomics trained on de novo sequencing learns generalizable representations of spectra, improves performance on downstream tasks where training data is limited, and can ultimately enhance data acquisition and analysis in proteomics experiments.
<div id='section'>Paperid: <span id='pid'>1225, <a href='https://arxiv.org/pdf/2505.10711.pdf' target='_blank'>https://arxiv.org/pdf/2505.10711.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>SebestyÃ©n Kamp, Giovanni Stracquadanio, T. Ian Simpson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.10711">GNN-Suite: a Graph Neural Network Benchmarking Framework for Biomedical Informatics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present GNN-Suite, a robust modular framework for constructing and benchmarking Graph Neural Network (GNN) architectures in computational biology. GNN-Suite standardises experimentation and reproducibility using the Nextflow workflow to evaluate GNN performance. We demonstrate its utility in identifying cancer-driver genes by constructing molecular networks from protein-protein interaction (PPI) data from STRING and BioGRID and annotating nodes with features from the PCAWG, PID, and COSMIC-CGC repositories.
  Our design enables fair comparisons among diverse GNN architectures including GAT, GAT3H, GCN, GCN2, GIN, GTN, HGCN, PHGCN, and GraphSAGE and a baseline Logistic Regression (LR) model. All GNNs were configured as standardised two-layer models and trained with uniform hyperparameters (dropout = 0.2; Adam optimiser with learning rate = 0.01; and an adjusted binary cross-entropy loss to address class imbalance) over an 80/20 train-test split for 300 epochs. Each model was evaluated over 10 independent runs with different random seeds to yield statistically robust performance metrics, with balanced accuracy (BACC) as the primary measure. Notably, GCN2 achieved the highest BACC (0.807 +/- 0.035) on a STRING-based network, although all GNN types outperformed the LR baseline, highlighting the advantage of network-based learning over feature-only approaches.
  Our results show that a common framework for implementing and evaluating GNN architectures aids in identifying not only the best model but also the most effective means of incorporating complementary data. By making GNN-Suite publicly available, we aim to foster reproducible research and promote improved benchmarking standards in computational biology. Future work will explore additional omics datasets and further refine network architectures to enhance predictive accuracy and interpretability in biomedical applications.
<div id='section'>Paperid: <span id='pid'>1226, <a href='https://arxiv.org/pdf/2505.09087.pdf' target='_blank'>https://arxiv.org/pdf/2505.09087.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>He Wang, Yikun Zhang, Jie Chen, Jian Zhan, Yaoqi Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.09087">A Comparative Review of RNA Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given usefulness of protein language models (LMs) in structure and functional inference, RNA LMs have received increased attentions in the last few years. However, these RNA models are often not compared against the same standard. Here, we divided RNA LMs into three classes (pretrained on multiple RNA types (especially noncoding RNAs), specific-purpose RNAs, and LMs that unify RNA with DNA or proteins or both) and compared 13 RNA LMs along with 3 DNA and 1 protein LMs as controls in zero-shot prediction of RNA secondary structure and functional classification. Results shows that the models doing well on secondary structure prediction often perform worse in function classification or vice versa, suggesting that more balanced unsupervised training is needed.
<div id='section'>Paperid: <span id='pid'>1227, <a href='https://arxiv.org/pdf/2505.06753.pdf' target='_blank'>https://arxiv.org/pdf/2505.06753.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhamed Amin, Bernard R. Brooks
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06753">Boltzmann Classifier: A Thermodynamic-Inspired Approach to Supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present the Boltzmann classifier, a novel distance based probabilistic classification algorithm inspired by the Boltzmann distribution. Unlike traditional classifiers that produce hard decisions or uncalibrated probabilities, the Boltzmann classifier assigns class probabilities based on the average distance to the nearest neighbors within each class, providing interpretable, physically meaningful outputs. We evaluate the performance of the method across three application domains: molecular activity prediction, oxidation state classification of transition metal complexes, and breast cancer diagnosis. In the molecular activity task, the classifier achieved the highest accuracy in predicting active compounds against two protein targets, with strong correlations observed between the predicted probabilities and experimental pIC50 values. For metal complexes, the classifier accurately distinguished between oxidation states II and III for Fe, Mn, and Co, using only metal-ligand bond lengths extracted from crystallographic data, and demonstrated high consistency with known chemical trends. In the breast cancer dataset, the classifier achieved 97% accuracy, with low confidence predictions concentrated in inherently ambiguous cases. Across all tasks, the Boltzmann classifier performed competitively or better than standard models such as logistic regression, support vector machines, random forests, and k-nearest neighbors. Its probabilistic outputs were found to correlate with continuous physical or biological properties, highlighting its potential utility in both classification and regression contexts. The results suggest that the Boltzmann classifier is a robust and interpretable alternative to conventional machine learning approaches, particularly in scientific domains where underlying structure property relationships are important.
<div id='section'>Paperid: <span id='pid'>1228, <a href='https://arxiv.org/pdf/2505.02022.pdf' target='_blank'>https://arxiv.org/pdf/2505.02022.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiming Zhang, Koji Tsuda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02022">NbBench: Benchmarking Language Models for Comprehensive Nanobody Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nanobodies -- single-domain antibody fragments derived from camelid heavy-chain-only antibodies -- exhibit unique advantages such as compact size, high stability, and strong binding affinity, making them valuable tools in therapeutics and diagnostics. While recent advances in pretrained protein and antibody language models (PPLMs and PALMs) have greatly enhanced biomolecular understanding, nanobody-specific modeling remains underexplored and lacks a unified benchmark. To address this gap, we introduce NbBench, the first comprehensive benchmark suite for nanobody representation learning. Spanning eight biologically meaningful tasks across nine curated datasets, NbBench encompasses structure annotation, binding prediction, and developability assessment. We systematically evaluate eleven representative models -- including general-purpose protein LMs, antibody-specific LMs, and nanobody-specific LMs -- in a frozen setting. Our analysis reveals that antibody language models excel in antigen-related tasks, while performance on regression tasks such as thermostability and affinity remains challenging across all models. Notably, no single model consistently outperforms others across all tasks. By standardizing datasets, task definitions, and evaluation protocols, NbBench offers a reproducible foundation for assessing and advancing nanobody modeling.
<div id='section'>Paperid: <span id='pid'>1229, <a href='https://arxiv.org/pdf/2504.19034.pdf' target='_blank'>https://arxiv.org/pdf/2504.19034.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samantha Petti, Carlos MartÃ­-GÃ³mez, Justin B. Kinney, Juannan Zhou, David M. McCandlish
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.19034">On learning functions over biological sequence space: relating Gaussian process priors, regularization, and gauge fixing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mappings from biological sequences (DNA, RNA, protein) to quantitative measures of sequence functionality play an important role in contemporary biology. We are interested in the related tasks of (i) inferring predictive sequence-to-function maps and (ii) decomposing sequence-function maps to elucidate the contributions of individual subsequences. Because each sequence-function map can be written as a weighted sum over subsequences in multiple ways, meaningfully interpreting these weights requires ``gauge-fixing,'' i.e., defining a unique representation for each map. Recent work has established that most existing gauge-fixed representations arise as the unique solutions to $L_2$-regularized regression in an overparameterized ``weight space'' where the choice of regularizer defines the gauge. Here, we establish the relationship between regularized regression in overparameterized weight space and Gaussian process approaches that operate in ``function space,'' i.e.~the space of all real-valued functions on a finite set of sequences. We disentangle how weight space regularizers both impose an implicit prior on the learned function and restrict the optimal weights to a particular gauge. We show how to construct regularizers that correspond to arbitrary explicit Gaussian process priors combined with a wide variety of gauges and characterize the implicit function space priors associated with the most common weight space regularizers. Finally, we derive the posterior distribution of a broad class of sequence-to-function statistics, including gauge-fixed weights and multiple systems for expressing higher-order epistatic coefficients. We show that such distributions can be efficiently computed for product-kernel priors using a kernel trick.
<div id='section'>Paperid: <span id='pid'>1230, <a href='https://arxiv.org/pdf/2504.17162.pdf' target='_blank'>https://arxiv.org/pdf/2504.17162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cece Zhang, Xuehuan Zhu, Nick Peterson, Jieqiong Wang, Shibiao Wan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.17162">A Comprehensive Review on RNA Subcellular Localization Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The subcellular localization of RNAs, including long non-coding RNAs (lncRNAs), messenger RNAs (mRNAs), microRNAs (miRNAs) and other smaller RNAs, plays a critical role in determining their biological functions. For instance, lncRNAs are predominantly associated with chromatin and act as regulators of gene transcription and chromatin structure, while mRNAs are distributed across the nucleus and cytoplasm, facilitating the transport of genetic information for protein synthesis. Understanding RNA localization sheds light on processes like gene expression regulation with spatial and temporal precision. However, traditional wet lab methods for determining RNA localization, such as in situ hybridization, are often time-consuming, resource-demanding, and costly. To overcome these challenges, computational methods leveraging artificial intelligence (AI) and machine learning (ML) have emerged as powerful alternatives, enabling large-scale prediction of RNA subcellular localization. This paper provides a comprehensive review of the latest advancements in AI-based approaches for RNA subcellular localization prediction, covering various RNA types and focusing on sequence-based, image-based, and hybrid methodologies that combine both data types. We highlight the potential of these methods to accelerate RNA research, uncover molecular pathways, and guide targeted disease treatments. Furthermore, we critically discuss the challenges in AI/ML approaches for RNA subcellular localization, such as data scarcity and lack of benchmarks, and opportunities to address them. This review aims to serve as a valuable resource for researchers seeking to develop innovative solutions in the field of RNA subcellular localization and beyond.
<div id='section'>Paperid: <span id='pid'>1231, <a href='https://arxiv.org/pdf/2504.17068.pdf' target='_blank'>https://arxiv.org/pdf/2504.17068.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pranav Kantroo, GÃ¼nter P. Wagner, Benjamin B. Machta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.17068">In-Context Learning can distort the relationship between sequence likelihoods and biological fitness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Language models have emerged as powerful predictors of the viability of biological sequences. During training these models learn the rules of the grammar obeyed by sequences of amino acids or nucleotides. Once trained, these models can take a sequence as input and produce a likelihood score as an output; a higher likelihood implies adherence to the learned grammar and correlates with experimental fitness measurements. Here we show that in-context learning can distort the relationship between fitness and likelihood scores of sequences. This phenomenon most prominently manifests as anomalously high likelihood scores for sequences that contain repeated motifs. We use protein language models with different architectures trained on the masked language modeling objective for our experiments, and find transformer-based models to be particularly vulnerable to this effect. This behavior is mediated by a look-up operation where the model seeks the identity of the masked position by using the other copy of the repeated motif as a reference. This retrieval behavior can override the model's learned priors. This phenomenon persists for imperfectly repeated sequences, and extends to other kinds of biologically relevant features such as reversed complement motifs in RNA sequences that fold into hairpin structures.
<div id='section'>Paperid: <span id='pid'>1232, <a href='https://arxiv.org/pdf/2504.16886.pdf' target='_blank'>https://arxiv.org/pdf/2504.16886.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arnav Sharma, Anthony Gitter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16886">Exploring zero-shot structure-based protein fitness prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to make zero-shot predictions about the fitness consequences of protein sequence changes with pre-trained machine learning models enables many practical applications. Such models can be applied for downstream tasks like genetic variant interpretation and protein engineering without additional labeled data. The advent of capable protein structure prediction tools has led to the availability of orders of magnitude more precomputed predicted structures, giving rise to powerful structure-based fitness prediction models. Through our experiments, we assess several modeling choices for structure-based models and their effects on downstream fitness prediction. Zero-shot fitness prediction models can struggle to assess the fitness landscape within disordered regions of proteins, those that lack a fixed 3D structure. We confirm the importance of matching protein structures to fitness assays and find that predicted structures for disordered regions can be misleading and affect predictive performance. Lastly, we evaluate an additional structure-based model on the ProteinGym substitution benchmark and show that simple multi-modal ensembles are strong baselines.
<div id='section'>Paperid: <span id='pid'>1233, <a href='https://arxiv.org/pdf/2504.16479.pdf' target='_blank'>https://arxiv.org/pdf/2504.16479.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yujie Qin, Ming He, Changyong Yu, Ming Ni, Xian Liu, Xiaochen Bo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16479">The Dance of Atoms-De Novo Protein Design with Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The de novo design of proteins refers to creating proteins with specific structures and functions that do not naturally exist. In recent years, the accumulation of high-quality protein structure and sequence data and technological advancements have paved the way for the successful application of generative artificial intelligence (AI) models in protein design. These models have surpassed traditional approaches that rely on fragments and bioinformatics. They have significantly enhanced the success rate of de novo protein design, and reduced experimental costs, leading to breakthroughs in the field. Among various generative AI models, diffusion models have yielded the most promising results in protein design. In the past two to three years, more than ten protein design models based on diffusion models have emerged. Among them, the representative model, RFDiffusion, has demonstrated success rates in 25 protein design tasks that far exceed those of traditional methods, and other AI-based approaches like RFjoint and hallucination. This review will systematically examine the application of diffusion models in generating protein backbones and sequences. We will explore the strengths and limitations of different models, summarize successful cases of protein design using diffusion models, and discuss future development directions.
<div id='section'>Paperid: <span id='pid'>1234, <a href='https://arxiv.org/pdf/2504.16261.pdf' target='_blank'>https://arxiv.org/pdf/2504.16261.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Krinos Li, Xianglu Xiao, Zijun Zhong, Guang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16261">Accurate and generalizable protein-ligand binding affinity prediction with geometric deep learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-ligand binding complexes are ubiquitous and essential to life. Protein-ligand binding affinity prediction (PLA) quantifies the binding strength between ligands and proteins, providing crucial insights for discovering and designing potential candidate ligands. While recent advances have been made in predicting protein-ligand complex structures, existing algorithms for interaction and affinity prediction suffer from a sharp decline in performance when handling ligands bound with novel unseen proteins. We propose IPBind, a geometric deep learning-based computational method, enabling robust predictions by leveraging interatomic potential between complex's bound and unbound status. Experimental results on widely used binding affinity prediction benchmarks demonstrate the effectiveness and universality of IPBind. Meanwhile, it provides atom-level insights into prediction. This work highlights the advantage of leveraging machine learning interatomic potential for predicting protein-ligand binding affinity.
<div id='section'>Paperid: <span id='pid'>1235, <a href='https://arxiv.org/pdf/2504.15634.pdf' target='_blank'>https://arxiv.org/pdf/2504.15634.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peizheng Liu, Hitoshi Iba
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15634">Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar Protein Folding Model with Attention-based layers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformer-based architectures have recently propelled advances in sequence modeling across domains, but their application to the hydrophobic-hydrophilic (H-P) model for protein folding remains relatively unexplored. In this work, we adapt a Deep Q-Network (DQN) integrated with attention mechanisms (Transformers) to address the 3D H-P protein folding problem. Our system formulates folding decisions as a self-avoiding walk in a reinforced environment, and employs a specialized reward function based on favorable hydrophobic interactions. To improve performance, the method incorporates validity check including symmetry-breaking constraints, dueling and double Q-learning, and prioritized replay to focus learning on critical transitions. Experimental evaluations on standard benchmark sequences demonstrate that our approach achieves several known best solutions for shorter sequences, and obtains near-optimal results for longer chains. This study underscores the promise of attention-based reinforcement learning for protein folding, and created a prototype of Transformer-based Q-network structure for 3-dimensional lattice models.
<div id='section'>Paperid: <span id='pid'>1236, <a href='https://arxiv.org/pdf/2504.13978.pdf' target='_blank'>https://arxiv.org/pdf/2504.13978.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuqing Liu, Meng Zhao, Guanlan Hu, Yuchen Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13978">Association between nutritional factors, inflammatory biomarkers and cancer types: an analysis of NHANES data using machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background. Diet and inflammation are critical factors influencing cancer risk. However, the combined impact of nutritional status and inflammatory biomarkers on cancer status and type, using machine learning (ML), remains underexplored.
  Objectives. This study investigates the association between nutritional factors, inflammatory biomarkers, and cancer status, and whether these relationships differ across cancer types using National Health and Nutrition Examination Survey (NHANES) data.
  Methods. We analyzed 24 macro- and micronutrients, C-reactive protein (CRP), and the advanced lung cancer inflammation index (ALI) in 26,409 NHANES participants (2,120 with cancer). Multivariable logistic regression assessed associations with cancer prevalence. We also examined whether these features differed across the five most common cancer types. To evaluate predictive value, we applied three ML models - Logistic Regression, Random Forest, and XGBoost - on the full feature set.
  Results. The cohort's mean age was 49.1 years; 34.7% were obese. Comorbidities such as anemia and liver conditions, along with nutritional factors like protein and several vitamins, were key predictors of cancer status. Among the models, Random Forest performed best, achieving an accuracy of 0.72.
  Conclusions. Higher-quality nutritional intake and lower levels of inflammation may offer protective effects against cancer. These findings highlight the potential of combining nutritional and inflammatory markers with ML to inform cancer prevention strategies.
<div id='section'>Paperid: <span id='pid'>1237, <a href='https://arxiv.org/pdf/2504.13863.pdf' target='_blank'>https://arxiv.org/pdf/2504.13863.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Snigdha Tiwari, Sahil Sharma, Arvind Bagga, Aditi Sinha, Deepak Sharma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13863">Utsarjan: A smartphone App for providing kidney care and real-time assistance to children with nephrotic syndrome</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background Telemedicine has the potential to provide secure and cost-effective healthcare at the touch of a button. Nephrotic syndrome is a chronic childhood illness involving frequent relapses and demands long/complex treatment. Hence, developing a remote means of doctor-patient interface will ensure the provision of quality healthcare to patients. Methods The Utsarjan mobile App framework was built with Flutter that enables cross-platform development (Android, iOS, Windows) with speed, smoothness, and open-source benefits. The frontend uses Dart for user interaction, while the backend employs Node.js, Express, and NGINX for APIs, load balancing and high performance. MongoDB ensures a flexible database, Bcrypt secures passwords, PM2 handles deployment, uptime and logs, while Firebase Cloud Messaging powers free push notifications. Results Utsarjan (means excretion) is a multi-functional smartphone application for giving nephrotic care and real-time assistance to all patients (especially those in rural regions and/or who do not have access to specialists). It helps patients and doctors by ensuring opportune visits, recording each clinical test/parameter and improving medication adherence. It gives a graphical visualization of relapses, medicine dosage as well as different anthropometric parameters (urine protein, BP, height and weight). This is the first nephrotic care App that enables prompt access to doctor's advice. Conclusions Utsarjan is a mobile App to provide kidney care and real-time assistance to children with nephrotic syndrome. It gives a graphical overview of changes in a patient's health over the long course of treatment. This will assist doctors in appropriately modifying the treatment regimen. Consequently, it will (hopefully) lead to the prevention of relapses and/or complications.
<div id='section'>Paperid: <span id='pid'>1238, <a href='https://arxiv.org/pdf/2504.10388.pdf' target='_blank'>https://arxiv.org/pdf/2504.10388.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Krishna Rijal, Caroline M. Holmes, Samantha Petti, Gautam Reddy, Michael M. Desai, Pankaj Mehta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.10388">Inferring genotype-phenotype maps using attention models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting phenotype from genotype is a central challenge in genetics. Traditional approaches in quantitative genetics typically analyze this problem using methods based on linear regression. These methods generally assume that the genetic architecture of complex traits can be parameterized in terms of an additive model, where the effects of loci are independent, plus (in some cases) pairwise epistatic interactions between loci. However, these models struggle to analyze more complex patterns of epistasis or subtle gene-environment interactions. Recent advances in machine learning, particularly attention-based models, offer a promising alternative. Initially developed for natural language processing, attention-based models excel at capturing context-dependent interactions and have shown exceptional performance in predicting protein structure and function. Here, we apply attention-based models to quantitative genetics. We analyze the performance of this attention-based approach in predicting phenotype from genotype using simulated data across a range of models with increasing epistatic complexity, and using experimental data from a recent quantitative trait locus mapping study in budding yeast. We find that our model demonstrates superior out-of-sample predictions in epistatic regimes compared to standard methods. We also explore a more general multi-environment attention-based model to jointly analyze genotype-phenotype maps across multiple environments and show that such architectures can be used for "transfer learning" - predicting phenotypes in novel environments with limited training data.
<div id='section'>Paperid: <span id='pid'>1239, <a href='https://arxiv.org/pdf/2504.08437.pdf' target='_blank'>https://arxiv.org/pdf/2504.08437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Neeru Dubey, Elin Karlsson, Miguel Angel Redondo, Johan ReimegÃ¥rd, Anna Rising, Hedvig KjellstrÃ¶m
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08437">Customizing Spider Silk: Generative Models with Mechanical Property Conditioning for Protein Engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The remarkable mechanical properties of spider silk, including its tensile strength and extensibility, are primarily governed by the repetitive regions of the proteins that constitute the fiber, the major ampullate spidroins (MaSps). However, establishing correlations between mechanical characteristics and repeat sequences is challenging due to the intricate sequence-structure-function relationships of MaSps and the limited availability of annotated datasets. In this study, we present a novel computational framework for designing MaSp repeat sequences with customizable mechanical properties. To achieve this, we developed a lightweight GPT-based generative model by distilling the pre-trained ProtGPT2 protein language model. The distilled model was subjected to multilevel fine-tuning using curated subsets of the Spider Silkome dataset. Specifically, we adapt the model for MaSp repeat generation using 6,000 MaSp repeat sequences and further refine it with 572 repeats associated with experimentally determined fiber-level mechanical properties. Our model generates biologically plausible MaSp repeat regions tailored to specific mechanical properties while also predicting those properties for given sequences. Validation includes sequence-level analysis, assessing physicochemical attributes and expected distribution of key motifs as well as secondary structure compositions. A correlation study using BLAST on the Spider Silkome dataset and a test set of MaSp repeats with known mechanical properties further confirmed the predictive accuracy of the model. This framework advances the rational design of spider silk-inspired biomaterials, offering a versatile tool for engineering protein sequences with tailored mechanical attributes.
<div id='section'>Paperid: <span id='pid'>1240, <a href='https://arxiv.org/pdf/2504.06282.pdf' target='_blank'>https://arxiv.org/pdf/2504.06282.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jakub VaÅ¡Ã­Äek, Dafni Skiadopoulou, Ksenia G. Kuznetsova, Lukas KÃ¤ll, Marc Vaudel, Stefan Bruckner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.06282">ProHap Explorer: Visualizing Haplotypes in Proteogenomic Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In mass spectrometry-based proteomics, experts usually project data onto a single set of reference sequences, overlooking the influence of common haplotypes (combinations of genetic variants inherited together from a parent). We recently introduced ProHap, a tool for generating customized protein haplotype databases. Here, we present ProHap Explorer, a visualization interface designed to investigate the influence of common haplotypes on the human proteome. It enables users to explore haplotypes, their effects on protein sequences, and the identification of non-canonical peptides in public mass spectrometry datasets. The design builds on well-established representations in biological sequence analysis, ensuring familiarity for domain experts while integrating novel interactive elements tailored to proteogenomic data exploration. User interviews with proteomics experts confirmed the tool's utility, highlighting its ability to reveal whether haplotypes affect proteins of interest. By facilitating the intuitive exploration of proteogenomic variation, ProHap Explorer supports research in personalized medicine and the development of targeted therapies.
<div id='section'>Paperid: <span id='pid'>1241, <a href='https://arxiv.org/pdf/2504.02839.pdf' target='_blank'>https://arxiv.org/pdf/2504.02839.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Valentin Lombard, Sergei Grudinin, Elodie Laine
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02839">PETIMOT: A Novel Framework for Inferring Protein Motions from Sparse Data Using SE(3)-Equivariant Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins move and deform to ensure their biological functions. Despite significant progress in protein structure prediction, approximating conformational ensembles at physiological conditions remains a fundamental open problem. This paper presents a novel perspective on the problem by directly targeting continuous compact representations of protein motions inferred from sparse experimental observations. We develop a task-specific loss function enforcing data symmetries, including scaling and permutation operations. Our method PETIMOT (Protein sEquence and sTructure-based Inference of MOTions) leverages transfer learning from pre-trained protein language models through an SE(3)-equivariant graph neural network. When trained and evaluated on the Protein Data Bank, PETIMOT shows superior performance in time and accuracy, capturing protein dynamics, particularly large/slow conformational changes, compared to state-of-the-art flow-matching approaches and traditional physics-based models.
<div id='section'>Paperid: <span id='pid'>1242, <a href='https://arxiv.org/pdf/2504.02014.pdf' target='_blank'>https://arxiv.org/pdf/2504.02014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiannuo Li, Lan Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02014">HCAF-DTA: drug-target binding affinity prediction with cross-attention fused hypergraph neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of the binding affinity between drugs and target proteins is a core task in computer-aided drug design. Existing deep learning methods tend to ignore the information of internal sub-structural features of drug molecules and drug-target interactions, resulting in limited prediction performance. In this paper, we propose a drug-target association prediction model HCAF-DTA based on cross-attention fusion hypergraph neural network. The model innovatively introduces hypergraph representation in the feature extraction stage: drug molecule hypergraphs are constructed based on the tree decomposition algorithm, and the sub-structural and global features extracted by fusing the hypergraph neural network with the graphical neural network through hopping connections, in which the hyper edges can efficiently characterise the functional functional groups and other key chemical features; for the protein feature extraction, a weighted graph is constructed based on the residues predicted by the ESM model contact maps to construct weighted graphs, and multilayer graph neural networks were used to capture spatial dependencies. In the prediction stage, a bidirectional multi-head cross-attention mechanism is designed to model intermolecular interactions from the dual viewpoints of atoms and amino acids, and cross-modal features with correlated information are fused by attention. Experiments on benchmark datasets such as Davis and KIBA show that HCAF-DTA outperforms state of the arts in all three performance evaluation metrics, with the MSE metrics reaching 0.198 and 0.122, respectively, with an improvement of up to 4% from the optimal baseline.
<div id='section'>Paperid: <span id='pid'>1243, <a href='https://arxiv.org/pdf/2504.00146.pdf' target='_blank'>https://arxiv.org/pdf/2504.00146.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tudor-Stefan Cotet, Igor Krawczuk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.00146">Why risk matters for protein binder design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian optimization (BO) has recently become more prevalent in protein engineering applications and hence has become a fruitful target of benchmarks. However, current BO comparisons often overlook real-world considerations like risk and cost constraints. In this work, we compare 72 model combinations of encodings, surrogate models, and acquisition functions on 11 protein binder fitness landscapes, specifically from this perspective. Drawing from the portfolio optimization literature, we adopt metrics to quantify the cold-start performance relative to a random baseline, to assess the risk of an optimization campaign, and to calculate the overall budget required to reach a fitness threshold. Our results suggest the existence of Pareto-optimal models on the risk-performance axis, the shift of this preference depending on the landscape explored, and the robust correlation between landscape properties such as epistasis with the average and worst-case model performance. They also highlight that rigorous model selection requires substantial computational and statistical efforts.
<div id='section'>Paperid: <span id='pid'>1244, <a href='https://arxiv.org/pdf/2503.20767.pdf' target='_blank'>https://arxiv.org/pdf/2503.20767.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Clara Fannjiang, Ji Won Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.20767">Reliable algorithm selection for machine learning-guided design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Algorithms for machine learning-guided design, or design algorithms, use machine learning-based predictions to propose novel objects with desired property values. Given a new design task -- for example, to design novel proteins with high binding affinity to a therapeutic target -- one must choose a design algorithm and specify any hyperparameters and predictive and/or generative models involved. How can these decisions be made such that the resulting designs are successful? This paper proposes a method for design algorithm selection, which aims to select design algorithms that will produce a distribution of design labels satisfying a user-specified success criterion -- for example, that at least ten percent of designs' labels exceed a threshold. It does so by combining designs' predicted property values with held-out labeled data to reliably forecast characteristics of the label distributions produced by different design algorithms, building upon techniques from prediction-powered inference. The method is guaranteed with high probability to return design algorithms that yield successful label distributions (or the null set if none exist), if the density ratios between the design and labeled data distributions are known. We demonstrate the method's effectiveness in simulated protein and RNA design tasks, in settings with either known or estimated density ratios.
<div id='section'>Paperid: <span id='pid'>1245, <a href='https://arxiv.org/pdf/2503.18551.pdf' target='_blank'>https://arxiv.org/pdf/2503.18551.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eoin Quinn, Ghassene Jebali, Maxime Seince, Oliver Bent
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18551">Discriminative protein sequence modelling with Latent Space Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We explore a framework for protein sequence representation learning that decomposes the task between manifold learning and distributional modelling. Specifically we present a Latent Space Diffusion architecture which combines a protein sequence autoencoder with a denoising diffusion model operating on its latent space. We obtain a one-parameter family of learned representations from the diffusion model, along with the autoencoder's latent representation. We propose and evaluate two autoencoder architectures: a homogeneous model forcing amino acids of the same type to be identically distributed in the latent space, and an inhomogeneous model employing a noise-based variant of masking. As a baseline we take a latent space learned by masked language modelling, and evaluate discriminative capability on a range of protein property prediction tasks. Our finding is twofold: the diffusion models trained on both our proposed variants display higher discriminative power than the one trained on the masked language model baseline, none of the diffusion representations achieve the performance of the masked language model embeddings themselves.
<div id='section'>Paperid: <span id='pid'>1246, <a href='https://arxiv.org/pdf/2503.18213.pdf' target='_blank'>https://arxiv.org/pdf/2503.18213.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Delower Hossain, Jake Y Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18213">A Study on Neuro-Symbolic Artificial Intelligence: Healthcare Perspectives</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over the last few decades, Artificial Intelligence (AI) scientists have been conducting investigations to attain human-level performance by a machine in accomplishing a cognitive task. Within machine learning, the ultimate aspiration is to attain Artificial General Intelligence (AGI) through a machine. This pursuit has led to the exploration of two distinct AI paradigms. Symbolic AI, also known as classical or GOFAI (Good Old-Fashioned AI) and Connectionist (Sub-symbolic) AI, represented by Neural Systems, are two mutually exclusive paradigms. Symbolic AI excels in reasoning, explainability, and knowledge representation but faces challenges in processing complex real-world data with noise. Conversely, deep learning (Black-Box systems) research breakthroughs in neural networks are notable, yet they lack reasoning and interpretability. Neuro-symbolic AI (NeSy), an emerging area of AI research, attempts to bridge this gap by integrating logical reasoning into neural networks, enabling them to learn and reason with symbolic representations. While a long path, this strategy has made significant progress towards achieving common sense reasoning by systems. This article conducts an extensive review of over 977 studies from prominent scientific databases (DBLP, ACL, IEEExplore, Scopus, PubMed, ICML, ICLR), thoroughly examining the multifaceted capabilities of Neuro-Symbolic AI, with a particular focus on its healthcare applications, particularly in drug discovery, and Protein engineering research. The survey addresses vital themes, including reasoning, explainability, integration strategies, 41 healthcare-related use cases, benchmarking, datasets, current approach limitations from both healthcare and broader perspectives, and proposed novel approaches for future experiments.
<div id='section'>Paperid: <span id='pid'>1247, <a href='https://arxiv.org/pdf/2503.17430.pdf' target='_blank'>https://arxiv.org/pdf/2503.17430.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shun-Cai Zhao, Yi-Meng Huang, Yi-Fan Yang, Zi-Ran Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17430">Multi-timescale time encoding for CNN prediction of Fenna-Matthews-Olson energy-transfer dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning simulations of open quantum dynamics often rely on recursive predictors that accumulate error. We develop a non-recursive convolutional neural networks (CNNs) that maps system parameters and a redundant time encoding directly to excitation-energy-transfer populations in the Fenna-Matthews-Olson complex. The encoding-modified logistic plus $\tanh$ functions-normalizes time and resolves fast, transitional, and quasi-steady regimes, while physics-informed labels enforce population conservation and inter-site consistency. Trained only on $0\sim 7 ps$ reference trajectories generated with a Lindblad model in QuTiP, the network accurately predicts $0\sim100 ps$ dynamics across a range of reorganization energies, bath rates, and temperatures. Beyond $20 ps$, the absolute relative error remains below 0.05, demonstrating stable long-time extrapolation. By avoiding step-by-step recursion, the method suppresses error accumulation and generalizes across timescales. These results show that redundant time encoding enables data-efficient inference of long-time quantum dissipative dynamics in realistic pigment-protein complexes, and may aid the data-driven design of light-harvesting materials.
<div id='section'>Paperid: <span id='pid'>1248, <a href='https://arxiv.org/pdf/2503.16351.pdf' target='_blank'>https://arxiv.org/pdf/2503.16351.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Krithik Ramesh, Sameed M. Siddiqui, Albert Gu, Michael D. Mitzenmacher, Pardis C. Sabeti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16351">Lyra: An Efficient and Expressive Subquadratic Architecture for Modeling Biological Sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning architectures such as convolutional neural networks and Transformers have revolutionized biological sequence modeling, with recent advances driven by scaling up foundation and task-specific models. The computational resources and large datasets required, however, limit their applicability in biological contexts. We introduce Lyra, a subquadratic architecture for sequence modeling, grounded in the biological framework of epistasis for understanding sequence-to-function relationships. Mathematically, we demonstrate that state space models efficiently capture global epistatic interactions and combine them with projected gated convolutions for modeling local relationships. We demonstrate that Lyra is performant across over 100 wide-ranging biological tasks, achieving state-of-the-art (SOTA) performance in many key areas, including protein fitness landscape prediction, biophysical property prediction (e.g. disordered protein region functions) peptide engineering applications (e.g. antibody binding, cell-penetrating peptide prediction), RNA structure analysis, RNA function prediction, and CRISPR guide design. It achieves this with orders-of-magnitude improvements in inference speed and reduction in parameters (up to 120,000-fold in our tests) compared to recent biology foundation models. Using Lyra, we were able to train and run every task in this study on two or fewer GPUs in under two hours, democratizing access to biological sequence modeling at SOTA performance, with potential applications to many fields.
<div id='section'>Paperid: <span id='pid'>1249, <a href='https://arxiv.org/pdf/2503.13352.pdf' target='_blank'>https://arxiv.org/pdf/2503.13352.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ewan R. S. Wallace, Nathan C. Frey, Joshua A. Rackers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13352">Strain Problems got you in a Twist? Try StrainRelief: A Quantum-Accurate Tool for Ligand Strain Calculations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ligand strain energy, the energy difference between the bound and unbound conformations of a ligand, is an important component of structure-based small molecule drug design. A large majority of observed ligands in protein-small molecule co-crystal structures bind in low-strain conformations, making strain energy a useful filter for structure-based drug design. In this work we present a tool for calculating ligand strain with a high accuracy. StrainRelief uses a MACE Neural Network Potential (NNP), trained on a large database of Density Functional Theory (DFT) calculations to estimate ligand strain of neutral molecules with quantum accuracy. We show that this tool estimates strain energy differences relative to DFT to within 1.4 kcal/mol, more accurately than alternative NNPs. These results highlight the utility of NNPs in drug discovery, and provide a useful tool for drug discovery teams.
<div id='section'>Paperid: <span id='pid'>1250, <a href='https://arxiv.org/pdf/2503.09251.pdf' target='_blank'>https://arxiv.org/pdf/2503.09251.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yigang Chen, Xiang Ji, Ziyue Zhang, Yuming Zhou, Yang-Chi-Dung Lin, Hsi-Yuan Huang, Tao Zhang, Yi Lai, Ke Chen, Chang Su, Xingqiao Lin, Zihao Zhu, Yanggyi Zhang, Kangping Wei, Jiehui Fu, Yixian Huang, Shidong Cui, Shih-Chung Yen, Ariel Warshel, Hsien-Da Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.09251">SCOPE-DTI: Semi-Inductive Dataset Construction and Framework Optimization for Practical Usability Enhancement in Deep Learning-Based Drug Target Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based drug-target interaction (DTI) prediction methods have demonstrated strong performance; however, real-world applicability remains constrained by limited data diversity and modeling complexity. To address these challenges, we propose SCOPE-DTI, a unified framework combining a large-scale, balanced semi-inductive human DTI dataset with advanced deep learning modeling. Constructed from 13 public repositories, the SCOPE dataset expands data volume by up to 100-fold compared to common benchmarks such as the Human dataset. The SCOPE model integrates three-dimensional protein and compound representations, graph neural networks, and bilinear attention mechanisms to effectively capture cross domain interaction patterns, significantly outperforming state-of-the-art methods across various DTI prediction tasks. Additionally, SCOPE-DTI provides a user-friendly interface and database. We further validate its effectiveness by experimentally identifying anticancer targets of Ginsenoside Rh1. By offering comprehensive data, advanced modeling, and accessible tools, SCOPE-DTI accelerates drug discovery research.
<div id='section'>Paperid: <span id='pid'>1251, <a href='https://arxiv.org/pdf/2503.04239.pdf' target='_blank'>https://arxiv.org/pdf/2503.04239.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Papalitsas, Yanfei Guan, Shreyas Waghe, Athanasios Liakos, Ioannis Balatsos, Vassilios Pantazopoulos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04239">Quantum Approximate Optimization Algorithms for Molecular Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking is a critical process for drug discovery and challenging due to the complexity and size of biomolecular systems, where the optimal binding configuration of a drug to a target protein is determined. Hybrid classical-quantum computing techniques offer a novel approach to address these challenges. The Quantum Approximate Optimization Algorithm (QAOA) and its variations are hybrid classical-quantum techniques, and a promising tool for combinatorial optimization challenges. This paper presents a Digitized Counterdiabatic QAOA (DC-QAOA) approach to molecular docking. Simulated quantum runs were conducted on a GPU cluster. We examined 14 and 17 nodes instances - to the best of our knowledge the biggest published instance is 12-node at Ding et al. and we present the results. Based on computational results, we conclude that binding interactions represent the anticipated exact solution. Additionally, as the size of the examined instance increases, the computational times exhibit a significant escalation.
<div id='section'>Paperid: <span id='pid'>1252, <a href='https://arxiv.org/pdf/2502.21274.pdf' target='_blank'>https://arxiv.org/pdf/2502.21274.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Roman Klypa, Alberto Bietti, Sergei Grudinin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.21274">BAnG: Bidirectional Anchored Generation for Conditional RNA Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing RNA molecules that interact with specific proteins is a critical challenge in experimental and computational biology. Existing computational approaches require a substantial amount of previously known interacting RNA sequences for each specific protein or a detailed knowledge of RNA structure, restricting their utility in practice. To address this limitation, we develop RNA-BAnG, a deep learning-based model designed to generate RNA sequences for protein interactions without these requirements. Central to our approach is a novel generative method, Bidirectional Anchored Generation (BAnG), which leverages the observation that protein-binding RNA sequences often contain functional binding motifs embedded within broader sequence contexts. We first validate our method on generic synthetic tasks involving similar localized motifs to those appearing in RNAs, demonstrating its benefits over existing generative approaches. We then evaluate our model on biological sequences, showing its effectiveness for conditional RNA sequence design given a binding protein.
<div id='section'>Paperid: <span id='pid'>1253, <a href='https://arxiv.org/pdf/2502.18305.pdf' target='_blank'>https://arxiv.org/pdf/2502.18305.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adolfo Ruiz-SanmartÃ­n, Vicent Ribas, David SuÃ±ol, Luis Chiscano-CamÃ³n, Laura MartÃ­n, IvÃ¡n BajaÃ±a, Juliana Bastida, Nieves Larrosa, Juan JosÃ© GonzÃ¡lez, M Dolores Carrasco, NÃºria Canela, Ricard Ferrer, Juan Carlos Ruiz-RodrÃ­gue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18305">Exploring proteomic signatures in sepsis and non-infectious systemic inflammatory response syndrome</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: The search for new biomarkers that allow an early diagnosis in sepsis has become a necessity in medicine. The objective of this study is to identify potential protein biomarkers of differential expression between sepsis and non-infectious systemic inflammatory response syndrome (NISIRS).
  Methods: Prospective observational study of a cohort of septic patients activated by the Sepsis Code and patients admitted with NISIRS, during the period 2016-2017. A mass spectrometry-based approach was used to analyze the plasma proteins in the enrolled subjects. Subsequently, using recursive feature elimination (RFE) classification and cross-validation with a vector classifier, an association of these proteins in patients with sepsis compared to patients with NISIRS. The protein-protein interaction network was analyzed with String software.
  Results: A total of 277 patients (141 with sepsis and 136 with NISIRS) were included. After performing RFE, 25 proteins in the study patient cohort showed statistical significance, with an accuracy of 0.960, specificity of 0.920, sensitivity of 0.973, and an AUC of 0.985. Of these, 14 proteins (vWF, PPBP, C5, C1RL, FCN3, SAA2, ORM1, ITIH3, GSN, C1QA, CA1, CFB, C3, LBP) have a greater relationship with sepsis while 11 proteins (FN1, IGFALS, SERPINA4, APOE, APOH, C6, SERPINA3, AHSG, LUM, ITIH2, SAA1) are more expressed in NISIRS.
<div id='section'>Paperid: <span id='pid'>1254, <a href='https://arxiv.org/pdf/2502.16446.pdf' target='_blank'>https://arxiv.org/pdf/2502.16446.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haocheng Tang, Jing Long, Beihong Ji, Junmei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16446">Auxiliary Discrminator Sequence Generative Adversarial Networks (ADSeqGAN) for Few Sample Molecule Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we introduce Auxiliary Discriminator Sequence Generative Adversarial Networks (ADSeqGAN), a novel approach for molecular generation in small-sample datasets. Traditional generative models often struggle with limited training data, particularly in drug discovery, where molecular datasets for specific therapeutic targets, such as nucleic acids binders and central nervous system (CNS) drugs, are scarce. ADSeqGAN addresses this challenge by integrating an auxiliary random forest classifier as an additional discriminator into the GAN framework, significantly improves molecular generation quality and class specificity. Our method incorporates pretrained generator and Wasserstein distance to enhance training stability and diversity. We evaluate ADSeqGAN across three representative cases. First, on nucleic acid- and protein-targeting molecules, ADSeqGAN shows superior capability in generating nucleic acid binders compared to baseline models. Second, through oversampling, it markedly improves CNS drug generation, achieving higher yields than traditional de novo models. Third, in cannabinoid receptor type 1 (CB1) ligand design, ADSeqGAN generates novel druglike molecules, with 32.8\% predicted actives surpassing hit rates of CB1-focused and general-purpose libraries when assessed by a target-specific LRIP-SF scoring function. Overall, ADSeqGAN offers a versatile framework for molecular design in data-scarce scenarios, with demonstrated applications in nucleic acid binders, CNS drugs, and CB1 ligands.
<div id='section'>Paperid: <span id='pid'>1255, <a href='https://arxiv.org/pdf/2502.16324.pdf' target='_blank'>https://arxiv.org/pdf/2502.16324.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Nourbakhsh, Hoda Mohammadzade
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16324">Deep Time Warping for Multiple Time Series Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time Series Alignment is a critical task in signal processing with numerous real-world applications. In practice, signals often exhibit temporal shifts and scaling, making classification on raw data prone to errors. This paper introduces a novel approach for Multiple Time Series Alignment (MTSA) leveraging Deep Learning techniques. While most existing methods primarily address Multiple Sequence Alignment (MSA) for protein and DNA sequences, there remains a significant gap in alignment methodologies for numerical time series. Additionally, conventional approaches typically focus on pairwise alignment, whereas our proposed method aligns all signals in a multiple manner (all the signals are aligned together at once). This innovation not only enhances alignment efficiency but also significantly improves computational speed. By decomposing into piece-wise linear sections, we introduce varying levels of complexity into the warping function. Additionally, our method ensures the satisfaction of three warping constraints: boundary, monotonicity, and continuity conditions. The utilization of a deep convolutional network allows us to employ a new loss function, addressing some limitations of Dynamic Time Warping (DTW). Experimental results on the UCR Archive 2018, comprising 129 time series datasets, demonstrate that employing our approach to align signals significantly enhances classification accuracy and warping average and also reduces the run time across the majority of these datasets.
<div id='section'>Paperid: <span id='pid'>1256, <a href='https://arxiv.org/pdf/2502.15855.pdf' target='_blank'>https://arxiv.org/pdf/2502.15855.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dengdeng Huang, Shikui Tu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15855">THFlow: A Temporally Hierarchical Flow Matching Framework for 3D Peptide Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep generative models provide a promising approach to de novo 3D peptide design. Most of them jointly model the distributions of peptide's position, orientation, and conformation, attempting to simultaneously converge to the target pocket. However, in the early stage of docking, optimizing conformation-only modalities such as rotation and torsion can be physically meaningless, as the peptide is initialized far from the protein pocket and no interaction field is present. We define this problem as the multimodal temporal inconsistency problem and claim it is a key factor contributing to low binding affinity in generated peptides. To address this challenge, we propose THFlow, a novel flow matching-based multimodal generative model that explicitly models the temporal hierarchy between peptide position and conformation. It employs a polynomial based conditional flow to accelerate positional convergence early on, and later aligns it with rotation and torsion for coordinated conformation refinement under the emerging interaction field. Additionally, we incorporate interaction-related features, such as polarity, to further enhance the model's understanding of peptide-protein binding. Extensive experiments demonstrate that THFlow outperforms existing methods in generating peptides with superior stability, affinity, and diversity, offering an effective and accurate solution for advancing peptide-based therapeutic development.
<div id='section'>Paperid: <span id='pid'>1257, <a href='https://arxiv.org/pdf/2502.13484.pdf' target='_blank'>https://arxiv.org/pdf/2502.13484.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yusuke Uchida, Takaaki Fukui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.13484">2.5D U-Net with Depth Reduction for 3D CryoET Object Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryo-electron tomography (cryoET) is a crucial technique for unveiling the structure of protein complexes. Automatically analyzing tomograms captured by cryoET is an essential step toward understanding cellular structures. In this paper, we introduce the 4th place solution from the CZII - CryoET Object Identification competition, which was organized to advance the development of automated tomogram analysis techniques. Our solution adopted a heatmap-based keypoint detection approach, utilizing an ensemble of two different types of 2.5D U-Net models with depth reduction. Despite its highly unified and simple architecture, our method achieved 4th place, demonstrating its effectiveness.
<div id='section'>Paperid: <span id='pid'>1258, <a href='https://arxiv.org/pdf/2502.10848.pdf' target='_blank'>https://arxiv.org/pdf/2502.10848.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jirka Lhotka, Daniel Probst
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.10848">Implicit Neural Representations of Molecular Vector-Valued Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecules have various computational representations, including numerical descriptors, strings, graphs, point clouds, and surfaces. Each representation method enables the application of various machine learning methodologies from linear regression to graph neural networks paired with large language models. To complement existing representations, we introduce the representation of molecules through vector-valued functions, or $n$-dimensional vector fields, that are parameterized by neural networks, which we denote molecular neural fields. Unlike surface representations, molecular neural fields capture external features and the hydrophobic core of macromolecules such as proteins. Compared to discrete graph or point representations, molecular neural fields are compact, resolution independent and inherently suited for interpolation in spatial and temporal dimensions. These properties inherited by molecular neural fields lend themselves to tasks including the generation of molecules based on their desired shape, structure, and composition, and the resolution-independent interpolation between molecular conformations in space and time. Here, we provide a framework and proofs-of-concept for molecular neural fields, namely, the parametrization and superresolution reconstruction of a protein-ligand complex using an auto-decoder architecture and the embedding of molecular volumes in latent space using an auto-encoder architecture.
<div id='section'>Paperid: <span id='pid'>1259, <a href='https://arxiv.org/pdf/2502.09135.pdf' target='_blank'>https://arxiv.org/pdf/2502.09135.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edith Natalia Villegas Garcia, Alessio Ansuini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09135">Interpreting and Steering Protein Language Models through Sparse Autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid advancements in transformer-based language models have revolutionized natural language processing, yet understanding the internal mechanisms of these models remains a significant challenge. This paper explores the application of sparse autoencoders (SAE) to interpret the internal representations of protein language models, specifically focusing on the ESM-2 8M parameter model. By performing a statistical analysis on each latent component's relevance to distinct protein annotations, we identify potential interpretations linked to various protein characteristics, including transmembrane regions, binding sites, and specialized motifs.
  We then leverage these insights to guide sequence generation, shortlisting the relevant latent components that can steer the model towards desired targets such as zinc finger domains. This work contributes to the emerging field of mechanistic interpretability in biological sequence models, offering new perspectives on model steering for sequence design.
<div id='section'>Paperid: <span id='pid'>1260, <a href='https://arxiv.org/pdf/2502.02182.pdf' target='_blank'>https://arxiv.org/pdf/2502.02182.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Louis-Alexandre Leger, Maxine Leonardi, Andrea Salati, Felix Naef, Martin Weigert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.02182">Sequence models for continuous cell cycle stage prediction from brightfield images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding cell cycle dynamics is crucial for studying biological processes such as growth, development and disease progression. While fluorescent protein reporters like the Fucci system allow live monitoring of cell cycle phases, they require genetic engineering and occupy additional fluorescence channels, limiting broader applicability in complex experiments. In this study, we conduct a comprehensive evaluation of deep learning methods for predicting continuous Fucci signals using non-fluorescence brightfield imaging, a widely available label-free modality. To that end, we generated a large dataset of 1.3 M images of dividing RPE1 cells with full cell cycle trajectories to quantitatively compare the predictive performance of distinct model categories including single time-frame models, causal state space models and bidirectional transformer models. We show that both causal and transformer-based models significantly outperform single- and fixed frame approaches, enabling the prediction of visually imperceptible transitions like G1/S within 1h resolution. Our findings underscore the importance of sequence models for accurate predictions of cell cycle dynamics and highlight their potential for label-free imaging.
<div id='section'>Paperid: <span id='pid'>1261, <a href='https://arxiv.org/pdf/2501.18456.pdf' target='_blank'>https://arxiv.org/pdf/2501.18456.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lorenzo Rosset, Roberto Netti, Anna Paola Muntoni, Martin Weigt, Francesco Zamponi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18456">adabmDCA 2.0 -- a flexible but easy-to-use package for Direct Coupling Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this methods article, we provide a flexible but easy-to-use implementation of Direct Coupling Analysis (DCA) based on Boltzmann machine learning, together with a tutorial on how to use it. The package \texttt{adabmDCA 2.0} is available in different programming languages (C++, Julia, Python) usable on different architectures (single-core and multi-core CPU, GPU) using a common front-end interface. In addition to several learning protocols for dense and sparse generative DCA models, it allows to directly address common downstream tasks like residue-residue contact prediction, mutational-effect prediction, scoring of sequence libraries and generation of artificial sequences for sequence design. It is readily applicable to protein and RNA sequence data.
<div id='section'>Paperid: <span id='pid'>1262, <a href='https://arxiv.org/pdf/2501.17589.pdf' target='_blank'>https://arxiv.org/pdf/2501.17589.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiang Li, Yuan-Ting Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17589">Extracting Inter-Protein Interactions Via Multitasking Graph Structure Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying protein-protein interactions (PPI) is crucial for gaining in-depth insights into numerous biological processes within cells and holds significant guiding value in areas such as drug development and disease treatment. Currently, most PPI prediction methods focus primarily on the study of protein sequences, neglecting the critical role of the internal structure of proteins. This paper proposes a novel PPI prediction method named MgslaPPI, which utilizes graph attention to mine protein structural information and enhances the expressive power of the protein encoder through multitask learning strategy. Specifically, we decompose the end-to-end PPI prediction process into two stages: amino acid residue reconstruction (A2RR) and protein interaction prediction (PIP). In the A2RR stage, we employ a graph attention-based residue reconstruction method to explore the internal relationships and features of proteins. In the PIP stage, in addition to the basic interaction prediction task, we introduce two auxiliary tasks, i.e., protein feature reconstruction (PFR) and masked interaction prediction (MIP). The PFR task aims to reconstruct the representation of proteins in the PIP stage, while the MIP task uses partially masked protein features for PPI prediction, with both working in concert to prompt MgslaPPI to capture more useful information. Experimental results demonstrate that MgslaPPI significantly outperforms existing state-of-the-art methods under various data partitioning schemes.
<div id='section'>Paperid: <span id='pid'>1263, <a href='https://arxiv.org/pdf/2501.16391.pdf' target='_blank'>https://arxiv.org/pdf/2501.16391.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoqing Lian, Jie Zhu, Tianxu Lv, Shiyun Nie, Hang Fan, Guosheng Wu, Yunjun Ge, Lihua Li, Xiangxiang Zeng, Xiang Pan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16391">Inductive-Associative Meta-learning Pipeline with Human Cognitive Patterns for Unseen Drug-Target Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Significant differences in protein structures hinder the generalization of existing drug-target interaction (DTI) models, which often rely heavily on pre-learned binding principles or detailed annotations. In contrast, BioBridge designs an Inductive-Associative pipeline inspired by the workflow of scientists who base their accumulated expertise on drawing insights into novel drug-target pairs from weakly related references. BioBridge predicts novel drug-target interactions using limited sequence data, incorporating multi-level encoders with adversarial training to accumulate transferable binding principles. On these principles basis, BioBridge employs a dynamic prototype meta-learning framework to associate insights from weakly related annotations, enabling robust predictions for previously unseen drug-target pairs. Extensive experiments demonstrate that BioBridge surpasses existing models, especially for unseen proteins. Notably, when only homologous protein binding data is available, BioBridge proves effective for virtual screening of the epidermal growth factor receptor and adenosine receptor, underscoring its potential in drug discovery.
<div id='section'>Paperid: <span id='pid'>1264, <a href='https://arxiv.org/pdf/2501.14426.pdf' target='_blank'>https://arxiv.org/pdf/2501.14426.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Fuest, Alfredo Cuesta, Kalyan Veeramachaneni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.14426">CENTS: Generating synthetic electricity consumption time series for rare and unseen scenarios</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent breakthroughs in large-scale generative modeling have demonstrated the potential of foundation models in domains such as natural language, computer vision, and protein structure prediction. However, their application in the energy and smart grid sector remains limited due to the scarcity and heterogeneity of high-quality data. In this work, we propose a method for creating high-fidelity electricity consumption time series data for rare and unseen context variables (e.g. location, building type, photovoltaics). Our approach, Context Encoding and Normalizing Time Series Generation, or CENTS, includes three key innovations: (i) A context normalization approach that enables inverse transformation for time series context variables unseen during training, (ii) a novel context encoder to condition any state-of-the-art time-series generator on arbitrary numbers and combinations of context variables, (iii) a framework for training this context encoder jointly with a time-series generator using an auxiliary context classification loss designed to increase expressivity of context embeddings and improve model performance. We further provide a comprehensive overview of different evaluation metrics for generative time series models. Our results highlight the efficacy of the proposed method in generating realistic household-level electricity consumption data, paving the way for training larger foundation models in the energy domain on synthetic as well as real-world data.
<div id='section'>Paperid: <span id='pid'>1265, <a href='https://arxiv.org/pdf/2501.12309.pdf' target='_blank'>https://arxiv.org/pdf/2501.12309.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eugenio Borzone, Leandro Di Persia, Matias Gerard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12309">A Hybrid Supervised and Self-Supervised Graph Neural Network for Edge-Centric Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel graph-based deep learning model for tasks involving relations between two nodes (edge-centric tasks), where the focus lies on predicting relationships and interactions between pairs of nodes rather than node properties themselves. This model combines supervised and self-supervised learning, taking into account for the loss function the embeddings learned and patterns with and without ground truth. Additionally it incorporates an attention mechanism that leverages both node and edge features. The architecture, trained end-to-end, comprises two primary components: embedding generation and prediction. First, a graph neural network (GNN) transform raw node features into dense, low-dimensional embeddings, incorporating edge attributes. Then, a feedforward neural model processes the node embeddings to produce the final output. Experiments demonstrate that our model matches or exceeds existing methods for protein-protein interactions prediction and Gene Ontology (GO) terms prediction. The model also performs effectively with one-hot encoding for node features, providing a solution for the previously unsolved problem of predicting similarity between compounds with unknown structures.
<div id='section'>Paperid: <span id='pid'>1266, <a href='https://arxiv.org/pdf/2501.07731.pdf' target='_blank'>https://arxiv.org/pdf/2501.07731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sepideh Maleki, Josh Vekhter, Keshav Pingali
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.07731">HyperQuery: Beyond Binary Link Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Groups with complex set intersection relations are a natural way to model a wide array of data, from the formation of social groups to the complex protein interactions which form the basis of biological life. One approach to representing such higher order relationships is as a hypergraph. However, efforts to apply machine learning techniques to hypergraph structured datasets have been limited thus far. In this paper, we address the problem of link prediction in knowledge hypergraphs as well as simple hypergraphs and develop a novel, simple, and effective optimization architecture that addresses both tasks. Additionally, we introduce a novel feature extraction technique using node level clustering and we show how integrating data from node-level labels can improve system performance. Our self-supervised approach achieves significant improvement over state of the art baselines on several hyperedge prediction and knowledge hypergraph completion benchmarks.
<div id='section'>Paperid: <span id='pid'>1267, <a href='https://arxiv.org/pdf/2501.07405.pdf' target='_blank'>https://arxiv.org/pdf/2501.07405.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aram Ansary Ogholbake, Qiang Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.07405">PROTECT: Protein circadian time prediction using unsupervised learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Circadian rhythms regulate the physiology and behavior of humans and animals. Despite advancements in understanding these rhythms and predicting circadian phases at the transcriptional level, predicting circadian phases from proteomic data remains elusive. This challenge is largely due to the scarcity of time labels in proteomic datasets, which are often characterized by small sample sizes, high dimensionality, and significant noise. Furthermore, existing methods for predicting circadian phases from transcriptomic data typically rely on prior knowledge of known rhythmic genes, making them unsuitable for proteomic datasets. To address this gap, we developed a novel computational method using unsupervised deep learning techniques to predict circadian sample phases from proteomic data without requiring time labels or prior knowledge of proteins or genes. Our model involves a two-stage training process optimized for robust circadian phase prediction: an initial greedy one-layer-at-a-time pre-training which generates informative initial parameters followed by fine-tuning. During fine-tuning, a specialized loss function guides the model to align protein expression levels with circadian patterns, enabling it to accurately capture the underlying rhythmic structure within the data. We tested our method on both time-labeled and unlabeled proteomic data. For labeled data, we compared our predictions to the known time labels, achieving high accuracy, while for unlabeled human datasets, including postmortem brain regions and urine samples, we explored circadian disruptions. Notably, our analysis identified disruptions in rhythmic proteins between Alzheimer's disease and control subjects across these samples.
<div id='section'>Paperid: <span id='pid'>1268, <a href='https://arxiv.org/pdf/2501.07014.pdf' target='_blank'>https://arxiv.org/pdf/2501.07014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karishma Thakrar, Jiangqin Ma, Max Diamond, Akash Patel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.07014">AlgoRxplorers | Precision in Mutation: Enhancing Drug Design with Advanced Protein Stability Prediction Tools</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the impact of single-point amino acid mutations on protein stability is essential for understanding disease mechanisms and advancing drug development. Protein stability, quantified by changes in Gibbs free energy ($ÎÎG$), is influenced by these mutations. However, the scarcity of data and the complexity of model interpretation pose challenges in accurately predicting stability changes. This study proposes the application of deep neural networks, leveraging transfer learning and fusing complementary information from different models, to create a feature-rich representation of the protein stability landscape. We developed four models, with our third model, ThermoMPNN+, demonstrating the best performance in predicting $ÎÎG$ values. This approach, which integrates diverse feature sets and embeddings through latent transfusion techniques, aims to refine $ÎÎG$ predictions and contribute to a deeper understanding of protein dynamics, potentially leading to advancements in disease research and drug discovery.
<div id='section'>Paperid: <span id='pid'>1269, <a href='https://arxiv.org/pdf/2501.06615.pdf' target='_blank'>https://arxiv.org/pdf/2501.06615.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dexuan Xie, Liam Jemison, Yi Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06615">A Nonlocal size modified Poisson-Boltzmann Model and Its Finite Element Solver for Protein in Multi-Species Ionic Solution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Poisson-Boltzmann (PB) model is a widely used implicit solvent model in protein simulations. Although variants, such as the size modified PB and nonlocal modified PB models, have been developed to account for ionic size effects and nonlocal dielectric correlations, no existing PB variants simultaneously incorporate both, due to significant modeling and computational challenges. To address this gap, in this paper, a nonlocal size modified PB (NSMPB) model is introduced and solved using a finite element method for a protein with a three-dimensional molecular structure and an ionic solution containing multiple ion species. In particular, a novel solution decomposition is proposed to overcome the difficulties caused by the increased nonlinearity, nonlocality, and solution singularities of the model. It is then applied to the development of the NSMPB finite element solver, which includes an efficient modified Newton iterative method, an effective damping parameter selection strategy, and good selections of initial iterations. Moreover, the construction of the modified Newton iterative method is mathematically justified. Furthermore, an NSMPB finite element package is developed by integrating a mesh generation tool, a protein data bank file retrieval program, and the PDB2PQR package to simplify and accelerate its usage and application. Finally, numerical experiments are conducted on an ionic solution with four species, proteins with up to 11439 atoms, and irregular interface-fitted tetrahedral box meshes with up to 1188840 vertices. The numerical results confirm the fast convergence and strong robustness of the modified Newton iterative method, demonstrate the high performance of the package, and highlight the crucial roles played by the damping parameter and initial iteration selections in enhancing the method's convergence. The package will be a valuable tool in protein simulations.
<div id='section'>Paperid: <span id='pid'>1270, <a href='https://arxiv.org/pdf/2501.04387.pdf' target='_blank'>https://arxiv.org/pdf/2501.04387.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giovanni di Sarra, Barbara Bravi, Yasser Roudi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.04387">The unbearable lightness of Restricted Boltzmann Machines: Theoretical Insights and Biological Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Restricted Boltzmann Machines are simple yet powerful neural networks. They can be used for learning structure in data, and are used as a building block of more complex neural architectures. At the same time, their simplicity makes them easy to use, amenable to theoretical analysis, yielding interpretable models in applications. Here, we focus on reviewing the role that the activation functions, describing the input-output relationship of single neurons in RBM, play in the functionality of these models. We discuss recent theoretical results on the benefits and limitations of different activation functions. We also review applications to biological data analysis, namely neural data analysis, where RBM units are mostly taken to have sigmoid activation functions and binary units, to protein data analysis and immunology where non-binary units and non-sigmoid activation functions have recently been shown to yield important insights into the data. Finally, we discuss open problems addressing which can shed light on broader issues in neural network research.
<div id='section'>Paperid: <span id='pid'>1271, <a href='https://arxiv.org/pdf/2412.20329.pdf' target='_blank'>https://arxiv.org/pdf/2412.20329.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giovanny Espitia, Yui Tik Pang, James C. Gumbart
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20329">Protein Structure Prediction in the 3D HP Model Using Deep Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We address protein structure prediction in the 3D Hydrophobic-Polar lattice model through two novel deep learning architectures. For proteins under 36 residues, our hybrid reservoir-based model combines fixed random projections with trainable deep layers, achieving optimal conformations with 25% fewer training episodes. For longer sequences, we employ a long short-term memory network with multi-headed attention, matching best-known energy values. Both architectures leverage a stabilized Deep Q-Learning framework with experience replay and target networks, demonstrating consistent achievement of optimal conformations while significantly improving training efficiency compared to existing methods.
<div id='section'>Paperid: <span id='pid'>1272, <a href='https://arxiv.org/pdf/2412.19815.pdf' target='_blank'>https://arxiv.org/pdf/2412.19815.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Regina Ibragimova, Dimitrios Iliadis, Willem Waegeman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.19815">Enhancing Drug-Target Interaction Prediction through Transfer Learning from Activity Cliff Prediction Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, machine learning (ML) has gained popularity in the early stages of drug discovery. This trend is unsurprising given the increasing volume of relevant experimental data and the continuous improvement of ML algorithms. However, conventional models, which rely on the principle of molecular similarity, often fail to capture the complexities of chemical interactions, particularly those involving activity cliffs (ACs) - compounds that are structurally similar but exhibit evidently different activity behaviors. In this work, we address two distinct yet related tasks: (1) activity cliff (AC) prediction and (2) drug-target interaction (DTI) prediction. Leveraging insights gained from the AC prediction task, we aim to improve the performance of DTI prediction through transfer learning. A universal model was developed for AC prediction, capable of identifying activity cliffs across diverse targets. Insights from this model were then incorporated into DTI prediction, enabling better handling of challenging cases involving ACs while maintaining similar overall performance. This approach establishes a strong foundation for integrating AC awareness into predictive models for drug discovery. Scientific Contribution This study presents a novel approach that applies transfer learning from AC prediction to enhance DTI prediction, addressing limitations of traditional similarity-based models. By introducing AC-awareness, we improve DTI model performance in structurally complex regions, demonstrating the benefits of integrating compound-specific and protein-contextual information. Unlike previous studies, which treat AC and DTI predictions as separate problems, this work establishes a unified framework to address both data scarcity and prediction challenges in drug discovery.
<div id='section'>Paperid: <span id='pid'>1273, <a href='https://arxiv.org/pdf/2412.16664.pdf' target='_blank'>https://arxiv.org/pdf/2412.16664.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yan Zhu, Shihao Wang, Yong Han, Yao Lu, Shulan Qiu, Ling Jin, Xiangdong Li, Weixiong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.16664">Transformer-based toxin-protein interaction analysis prioritizes airborne particulate matter components with potential adverse health effects</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Air pollution, particularly airborne particulate matter (PM), poses a significant threat to public health globally. It is crucial to comprehend the association between PM-associated toxic components and their cellular targets in humans to understand the mechanisms by which air pollution impacts health and to establish causal relationships between air pollution and public health consequences. Although many studies have explored the impact of PM on human health, the understanding of the association between toxins and the associated targets remain limited. Leveraging cutting-edge deep learning technologies, we developed tipFormer (toxin-protein interaction prediction based on transformer), a novel deep-learning tool for identifying toxic components capable of penetrating human cells and instigating pathogenic biological activities and signaling cascades. Experimental results show that tipFormer effectively captures interactions between proteins and toxic components. It incorporates dual pre-trained language models to encode protein sequences and chemicals. It employs a convolutional encoder to assimilate the sequential attributes of proteins and chemicals. It then introduces a learning module with a cross-attention mechanism to decode and elucidate the multifaceted interactions pivotal for the hotspots binding proteins and chemicals. Experimental results show that tipFormer effectively captures interactions between proteins and toxic components. This approach offers significant value to air quality and toxicology researchers by allowing high-throughput identification and prioritization of hazards. It supports more targeted laboratory studies and field measurements, ultimately enhancing our understanding of how air pollution impacts human health.
<div id='section'>Paperid: <span id='pid'>1274, <a href='https://arxiv.org/pdf/2412.13519.pdf' target='_blank'>https://arxiv.org/pdf/2412.13519.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shivasankaran Vanaja Pandi, Bharath Ramsundar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13519">Open-Source Protein Language Models for Function Prediction and Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models (PLMs) have shown promise in improving the understanding of protein sequences, contributing to advances in areas such as function prediction and protein engineering. However, training these models from scratch requires significant computational resources, limiting their accessibility. To address this, we integrate a PLM into DeepChem, an open-source framework for computational biology and chemistry, to provide a more accessible platform for protein-related tasks.
  We evaluate the performance of the integrated model on various protein prediction tasks, showing that it achieves reasonable results across benchmarks. Additionally, we present an exploration of generating plastic-degrading enzyme candidates using the model's embeddings and latent space manipulation techniques. While the results suggest that further refinement is needed, this approach provides a foundation for future work in enzyme design. This study aims to facilitate the use of PLMs in research fields like synthetic biology and environmental sustainability, even for those with limited computational resources.
<div id='section'>Paperid: <span id='pid'>1275, <a href='https://arxiv.org/pdf/2412.10411.pdf' target='_blank'>https://arxiv.org/pdf/2412.10411.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shashank Pathak, Guohui Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.10411">Pre-trained protein language model for codon optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motivation: Codon optimization of Open Reading Frame (ORF) sequences is essential for enhancing mRNA stability and expression in applications like mRNA vaccines, where codon choice can significantly impact protein yield which directly impacts immune strength. In this work, we investigate the use of a pre-trained protein language model (PPLM) for getting a rich representation of amino acids which could be utilized for codon optimization. This leaves us with a simpler fine-tuning task over PPLM in optimizing ORF sequences.
  Results: The ORFs generated by our proposed models outperformed their natural counterparts encoding the same proteins on computational metrics for stability and expression. They also demonstrated enhanced performance against the benchmark ORFs used in mRNA vaccines for the SARS-CoV-2 viral spike protein and the varicella-zoster virus (VZV). These results highlight the potential of adapting PPLM for designing ORFs tailored to encode target antigens in mRNA vaccines.
<div id='section'>Paperid: <span id='pid'>1276, <a href='https://arxiv.org/pdf/2412.09661.pdf' target='_blank'>https://arxiv.org/pdf/2412.09661.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinsong Shao, Qineng Gong, Zeyu Yin, Yu Chen, Yajie Hao, Lei Zhang, Linlin Jiang, Min Yao, Jinlong Li, Fubo Wang, Li Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09661">Language model driven: a PROTAC generation pipeline with dual constraints of structure and property</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The imperfect modeling of ternary complexes has limited the application of computer-aided drug discovery tools in PROTAC research and development. In this study, an AI-assisted approach for PROTAC molecule design pipeline named LM-PROTAC was developed, which stands for language model driven Proteolysis Targeting Chimera, by embedding a transformer-based generative model with dual constraints on structure and properties, referred to as the DCT. This study utilized the fragmentation representation of molecules and developed a language model driven pipeline. Firstly, a language model driven affinity model for protein compounds to screen molecular fragments with high affinity for the target protein. Secondly, structural and physicochemical properties of these fragments were constrained during the generation process to meet specific scenario requirements. Finally, a two-round screening of the preliminary generated molecules using a multidimensional property prediction model to generate a batch of PROTAC molecules capable of degrading disease-relevant target proteins for validation in vitro experiments, thus achieving a complete solution for AI-assisted PROTAC drug generation. Taking the tumor key target Wnt3a as an example, the LM-PROTAC pipeline successfully generated PROTAC molecules capable of inhibiting Wnt3a. The results show that DCT can efficiently generate PROTAC that targets and hydrolyses Wnt3a.
<div id='section'>Paperid: <span id='pid'>1277, <a href='https://arxiv.org/pdf/2412.06237.pdf' target='_blank'>https://arxiv.org/pdf/2412.06237.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marsha Mariya Kappan, Joby George
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.06237">In Silico Pharmacokinetic and Molecular Docking Studies of Natural Plants against Essential Protein KRAS for Treatment of Pancreatic Cancer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A kind of pancreatic cancer called Pancreatic Ductal Adenocarcinoma (PDAC) is anticipated to be one of the main causes of mortality during past years. Evidence from several researches supported the concept that the oncogenic KRAS (Ki-ras2 Kirsten rat sarcoma viral oncogene) mutation is the major cause of pancreatic cancer. KRAS acts as an on-off switch that promotes cell growth. But when the KRAS gene is mutated, it will be in one position, allowing the cell growth uncontrollably. This uncontrollable multiplication of cells causes cancer growth. Therefore, KRAS was selected as the target protein in the study. Fifty plant-derived compounds are selected for the study. To determine whether the examined drugs could bind to the KRAS complex's binding pocket, molecular docking was performed. Computational analyses were used to assess the possible ability of tested substances to pass the Blood Brain Barrier (BBB). To predict the bioactivity of ligands a machine learning model was created. Five machine learning models were created and have chosen the best one among them for analyzing the bioactivity of each ligand. From the fifty plant-derived compounds the compounds with the least binding energies are selected. Then bioactivity of these six compounds is analyzed using Random Forest Regression model. Adsorption, Distribution, Metabolism, Excretion (ADME) properties of compounds are analyzed. The results showed that borneol has powerful effects and acts as a promising agent for the treatment of pancreatic cancer. This suggests that borneol found in plants like mint, ginger, rosemary, etc., is a successful compound for the treatment of pancreatic cancer.
<div id='section'>Paperid: <span id='pid'>1278, <a href='https://arxiv.org/pdf/2412.04526.pdf' target='_blank'>https://arxiv.org/pdf/2412.04526.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daiheng Zhang, Yan Zeng, Xinyu Hong, Jinbo Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04526">Leveraging Multi-modal Representations to Predict Protein Melting Temperatures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting protein melting temperature changes (Delta Tm) is fundamental for assessing protein stability and guiding protein engineering. Leveraging multi-modal protein representations has shown great promise in capturing the complex relationships among protein sequences, structures, and functions. In this study, we develop models based on powerful protein language models, including ESM-2, ESM-3 and AlphaFold, using various feature extraction methods to enhance prediction accuracy. By utilizing the ESM-3 model, we achieve a new state-of-the-art performance on the s571 test dataset, obtaining a Pearson correlation coefficient (PCC) of 0.50. Furthermore, we conduct a fair evaluation to compare the performance of different protein language models in the Delta Tm prediction task. Our results demonstrate that integrating multi-modal protein representations could advance the prediction of protein melting temperatures.
<div id='section'>Paperid: <span id='pid'>1279, <a href='https://arxiv.org/pdf/2412.04075.pdf' target='_blank'>https://arxiv.org/pdf/2412.04075.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yoav Kan-Tor, Michael Morris Danziger, Eden Zohar, Matan Ninio, Yishai Shimoni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04075">Does your model understand genes? A benchmark of gene properties for biological and text models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The application of deep learning methods, particularly foundation models, in biological research has surged in recent years. These models can be text-based or trained on underlying biological data, especially omics data of various types. However, comparing the performance of these models consistently has proven to be a challenge due to differences in training data and downstream tasks. To tackle this problem, we developed an architecture-agnostic benchmarking approach that, instead of evaluating the models directly, leverages entity representation vectors from each model and trains simple predictive models for each benchmarking task. This ensures that all types of models are evaluated using the same input and output types. Here we focus on gene properties collected from professionally curated bioinformatics databases. These gene properties are categorized into five major groups: genomic properties, regulatory functions, localization, biological processes, and protein properties. Overall, we define hundreds of tasks based on these databases, which include binary, multi-label, and multi-class classification tasks. We apply these benchmark tasks to evaluate expression-based models, large language models, protein language models, DNA-based models, and traditional baselines. Our findings suggest that text-based models and protein language models generally outperform expression-based models in genomic properties and regulatory functions tasks, whereas expression-based models demonstrate superior performance in localization tasks. These results should aid in the development of more informed artificial intelligence strategies for biological understanding and therapeutic discovery. To ensure the reproducibility and transparency of our findings, we have made the source code and benchmark data publicly accessible for further investigation and expansion at github.com/BiomedSciAI/gene-benchmark.
<div id='section'>Paperid: <span id='pid'>1280, <a href='https://arxiv.org/pdf/2412.04069.pdf' target='_blank'>https://arxiv.org/pdf/2412.04069.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao-Yu Guo, Yi-Fan Li, Yuan Liu, Xiaoyong Pan, Hong-Bin Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04069">ProtDAT: A Unified Framework for Protein Sequence Design from Any Protein Text Description</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein design has become a critical method in advancing significant potential for various applications such as drug development and enzyme engineering. However, protein design methods utilizing large language models with solely pretraining and fine-tuning struggle to capture relationships in multi-modal protein data. To address this, we propose ProtDAT, a de novo fine-grained framework capable of designing proteins from any descriptive protein text input. ProtDAT builds upon the inherent characteristics of protein data to unify sequences and text as a cohesive whole rather than separate entities. It leverages an innovative multi-modal cross-attention, integrating protein sequences and textual information for a foundational level and seamless integration. Experimental results demonstrate that ProtDAT achieves the state-of-the-art performance in protein sequence generation, excelling in rationality, functionality, structural similarity, and validity. On 20,000 text-sequence pairs from Swiss-Prot, it improves pLDDT by 6%, TM-score by 0.26, and reduces RMSD by 1.2 Ã, highlighting its potential to advance protein design.
<div id='section'>Paperid: <span id='pid'>1281, <a href='https://arxiv.org/pdf/2412.02889.pdf' target='_blank'>https://arxiv.org/pdf/2412.02889.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ajay N. Jain, Ann E. Cleves, W. Patrick Walters
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02889">Deep-Learning Based Docking Methods: Fair Comparisons to Conventional Docking Workflows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The diffusion learning method, DiffDock, for docking small-molecule ligands into protein binding sites was recently introduced. Results included comparisons to more conventional docking approaches, with DiffDock showing superior performance. Here, we employ a fully automatic workflow using the Surflex-Dock methods to generate a fair baseline for conventional docking approaches. Results were generated for the common and expected situation where a binding site location is known and also for the condition of an unknown binding site. For the known binding site condition, Surflex-Dock success rates at 2.0 Angstroms RMSD far exceeded those for DiffDock (Top-1/Top-5 success rates, respectively, were 68/81% compared with 45/51%). Glide performed with similar success rates (67/73%) to Surflex-Dock for the known binding site condition, and results for AutoDock Vina and Gnina followed this pattern. For the unknown binding site condition, using an automated method to identify multiple binding pockets, Surflex-Dock success rates again exceeded those of DiffDock, but by a somewhat lesser margin. DiffDock made use of roughly 17,000 co-crystal structures for learning (98% of PDBBind version 2020, pre-2019 structures) for a training set in order to predict on 363 test cases (2% of PDBBind 2020) from 2019 forward. DiffDock's performance was inextricably linked with the presence of near-neighbor cases of close to identical protein-ligand complexes in the training set for over half of the test set cases. DiffDock exhibited a 40 percentage point difference on near-neighbor cases (two-thirds of all test cases) compared with cases with no near-neighbor training case. DiffDock has apparently encoded a type of table-lookup during its learning process, rendering meaningful applications beyond its reach. Further, it does not perform even close to competitively with a competently run modern docking workflow.
<div id='section'>Paperid: <span id='pid'>1282, <a href='https://arxiv.org/pdf/2412.01388.pdf' target='_blank'>https://arxiv.org/pdf/2412.01388.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Katarzyna Janocha, Annabel Ling, Alice Godson, Yulia Lampi, Simon Bornschein, Nils Y. Hammerla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01388">Harnessing Preference Optimisation in Protein LMs for Hit Maturation in Cell Therapy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cell and immunotherapy offer transformative potential for treating diseases like cancer and autoimmune disorders by modulating the immune system. The development of these therapies is resource-intensive, with the majority of drug candidates failing to progress beyond laboratory testing. While recent advances in machine learning have revolutionised areas such as protein engineering, applications in immunotherapy remain limited due to the scarcity of large-scale, standardised datasets and the complexity of cellular systems. In this work, we address these challenges by leveraging a high-throughput experimental platform to generate data suitable for fine-tuning protein language models. We demonstrate how models fine-tuned using a preference task show surprising correlations to biological assays, and how they can be leveraged for few-shot hit maturation in CARs. This proof-of-concept presents a novel pathway for applying ML to immunotherapy and could generalise to other therapeutic modalities.
<div id='section'>Paperid: <span id='pid'>1283, <a href='https://arxiv.org/pdf/2412.01174.pdf' target='_blank'>https://arxiv.org/pdf/2412.01174.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daiheng Zhang, Chengyue Gong, Qiang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01174">Rectified Flow For Structure Based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep generative models have achieved tremendous success in structure-based drug design in recent years, especially for generating 3D ligand molecules that bind to specific protein pocket. Notably, diffusion models have transformed ligand generation by providing exceptional quality and creativity. However, traditional diffusion models are restricted by their conventional learning objectives, which limit their broader applicability. In this work, we propose a new framework FlowSBDD, which is based on rectified flow model, allows us to flexibly incorporate additional loss to optimize specific target and introduce additional condition either as an extra input condition or replacing the initial Gaussian distribution. Extensive experiments on CrossDocked2020 show that our approach could achieve state-of-the-art performance on generating high-affinity molecules while maintaining proper molecular properties without specifically designing binding site, with up to -8.50 Avg. Vina Dock score and 75.0% Diversity.
<div id='section'>Paperid: <span id='pid'>1284, <a href='https://arxiv.org/pdf/2412.00109.pdf' target='_blank'>https://arxiv.org/pdf/2412.00109.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyu Shi, Yixin Tao, Shih-Chi Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00109">Deep Neural Network-Based Prediction of B-Cell Epitopes for SARS-CoV and SARS-CoV-2: Enhancing Vaccine Design through Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The accurate prediction of B-cell epitopes is critical for guiding vaccine development against infectious diseases, including SARS and COVID-19. This study explores the use of a deep neural network (DNN) model to predict B-cell epitopes for SARS-CoVandSARS-CoV-2,leveraging a dataset that incorporates essential protein and peptide features. Traditional sequence-based methods often struggle with large, complex datasets, but deep learning offers promising improvements in predictive accuracy. Our model employs regularization techniques, such as dropout and early stopping, to enhance generalization, while also analyzing key features, including isoelectric point and aromaticity, that influence epitope recognition. Results indicate an overall accuracy of 82% in predicting COVID-19 negative and positive cases, with room for improvement in detecting positive samples. This research demonstrates the applicability of deep learning in epitope mapping, suggesting that such approaches can enhance the speed and precision of vaccine design for emerging pathogens. Future work could incorporate structural data and diverse viral strains to further refine prediction capabilities.
<div id='section'>Paperid: <span id='pid'>1285, <a href='https://arxiv.org/pdf/2411.12853.pdf' target='_blank'>https://arxiv.org/pdf/2411.12853.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Poorya Khajouie, Titli Sarkar, Krishna Rauniyar, Li Chen, Wu Xu, Vijay Raghavan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.12853">Integrating Secondary Structures Information into Triangular Spatial Relationships (TSR) for Advanced Protein Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein structures represent the key to deciphering biological functions. The more detailed form of similarity among these proteins is sometimes overlooked by the conventional structural comparison methods. In contrast, further advanced methods, such as Triangular Spatial Relationship (TSR), have been demonstrated to make finer differentiations. Still, the classical implementation of TSR does not provide for the integration of secondary structure information, which is important for a more detailed understanding of the folding pattern of a protein. To overcome these limitations, we developed the SSE-TSR approach. The proposed method integrates secondary structure elements (SSEs) into TSR-based protein representations. This allows an enriched representation of protein structures by considering 18 different combinations of helix, strand, and coil arrangements. Our results show that using SSEs improves the accuracy and reliability of protein classification to varying degrees. We worked with two large protein datasets of 9.2K and 7.8K samples, respectively. We applied the SSE-TSR approach and used a neural network model for classification. Interestingly, introducing SSEs improved performance statistics for Dataset 1, with accuracy moving from 96.0% to 98.3%. For Dataset 2, where the performance statistics were already good, further small improvements were found with the introduction of SSE, giving an accuracy of 99.5% compared to 99.4%. These results show that SSE integration can dramatically improve TSR key discrimination, with significant benefits in datasets with low initial accuracies and only incremental gains in those with high baseline performance. Thus, SSE-TSR is a powerful bioinformatics tool that improves protein classification and understanding of protein function and interaction.
<div id='section'>Paperid: <span id='pid'>1286, <a href='https://arxiv.org/pdf/2411.12597.pdf' target='_blank'>https://arxiv.org/pdf/2411.12597.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiliang Yuan, Mustafa Misir
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.12597">GNNAS-Dock: Budget Aware Algorithm Selection with Graph Neural Networks for Molecular Docking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular docking is a major element in drug discovery and design. It enables the prediction of ligand-protein interactions by simulating the binding of small molecules to proteins. Despite the availability of numerous docking algorithms, there is no single algorithm consistently outperforms the others across a diverse set of docking scenarios. This paper introduces GNNAS-Dock, a novel Graph Neural Network (GNN)-based automated algorithm selection system for molecular docking in blind docking situations. GNNs are accommodated to process the complex structural data of both ligands and proteins. They benefit from the inherent graph-like properties to predict the performance of various docking algorithms under different conditions. The present study pursues two main objectives: 1) predict the performance of each candidate docking algorithm, in terms of Root Mean Square Deviation (RMSD), thereby identifying the most accurate method for specific scenarios; and 2) choose the best computationally efficient docking algorithm for each docking case, aiming to reduce the time required for docking while maintaining high accuracy. We validate our approach on PDBBind 2020 refined set, which contains about 5,300 pairs of protein-ligand complexes.
<div id='section'>Paperid: <span id='pid'>1287, <a href='https://arxiv.org/pdf/2411.11530.pdf' target='_blank'>https://arxiv.org/pdf/2411.11530.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuo Zhang, Jian K. Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11530">SeqProFT: Applying LoRA Finetuning for Sequence-only Protein Property Predictions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein language models (PLMs) are capable of learning the relationships between protein sequences and functions by treating amino acid sequences as textual data in a self-supervised manner. However, fine-tuning these models typically demands substantial computational resources and time, with results that may not always be optimized for specific tasks. To overcome these challenges, this study employs the LoRA method to perform end-to-end fine-tuning of the ESM-2 model specifically for protein property prediction tasks, utilizing only sequence information. Additionally, a multi-head attention mechanism is integrated into the downstream network to combine sequence features with contact map information, thereby enhancing the model's comprehension of protein sequences. Experimental results of extensive classification and regression tasks demonstrate that the fine-tuned model achieves strong performance and faster convergence across multiple regression and classification tasks.
<div id='section'>Paperid: <span id='pid'>1288, <a href='https://arxiv.org/pdf/2411.08992.pdf' target='_blank'>https://arxiv.org/pdf/2411.08992.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdurahman Ali Mohammed, Catherine Fonder, Donald S. Sakaguchi, Wallapak Tavanapong, Surya K. Mallapragada, Azeez Idris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08992">IDCIA: Immunocytochemistry Dataset for Cellular Image Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a new annotated microscopic cellular image dataset to improve the effectiveness of machine learning methods for cellular image analysis. Cell counting is an important step in cell analysis. Typically, domain experts manually count cells in a microscopic image. Automated cell counting can potentially eliminate this tedious, time-consuming process. However, a good, labeled dataset is required for training an accurate machine learning model. Our dataset includes microscopic images of cells, and for each image, the cell count and the location of individual cells. The data were collected as part of an ongoing study investigating the potential of electrical stimulation to modulate stem cell differentiation and possible applications for neural repair. Compared to existing publicly available datasets, our dataset has more images of cells stained with more variety of antibodies (protein components of immune responses against invaders) typically used for cell analysis. The experimental results on this dataset indicate that none of the five existing models under this study are able to achieve sufficiently accurate count to replace the manual methods. The dataset is available at https://figshare.com/articles/dataset/Dataset/21970604.
<div id='section'>Paperid: <span id='pid'>1289, <a href='https://arxiv.org/pdf/2411.08766.pdf' target='_blank'>https://arxiv.org/pdf/2411.08766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanqing Bi, Suresh Neethirajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08766">Mapping Methane -- The Impact of Dairy Farm Practices on Emissions Through Satellite Data and Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the correlation between dairy farm characteristics and methane concentrations as derived from satellite observations in Eastern Canada. Utilizing data from 11 dairy farms collected between January 2020 and December 2022, we integrated Sentinel-5P satellite methane data with critical farm-level attributes, including herd genetics, feeding practices, and management strategies. Initial analyses revealed significant correlations with methane concentrations, leading to the application of Variance Inflation Factor (VIF) and Principal Component Analysis (PCA) to address multicollinearity and enhance model stability. Subsequently, machine learning models - specifically Random Forest and Neural Networks - were employed to evaluate feature importance and predict methane emissions. Our findings indicate a strong negative correlation between the Estimated Breeding Value (EBV) for protein percentage and methane concentrations, suggesting that genetic selection for higher milk protein content could be an effective strategy for emissions reduction. The integration of atmospheric transport models with satellite data further refined our emission estimates, significantly enhancing accuracy and spatial resolution. This research underscores the potential of advanced satellite monitoring, machine learning techniques, and atmospheric modeling in improving methane emission assessments within the dairy sector. It emphasizes the critical role of farm-specific characteristics in developing effective mitigation strategies. Future investigations should focus on expanding the dataset and incorporating inversion modeling for more precise emission quantification. Balancing ecological impacts with economic viability will be essential for fostering sustainable dairy farming practices.
<div id='section'>Paperid: <span id='pid'>1290, <a href='https://arxiv.org/pdf/2411.07406.pdf' target='_blank'>https://arxiv.org/pdf/2411.07406.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jessica Irons, Patrick Cooper, Melanie McGrath, Shahroz Tariq, Andreas Duenser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.07406">Towards a criteria-based approach to selecting human-AI interaction mode</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence (AI) tools are now prevalent in many knowledge work industries. As AI becomes more capable and interactive, there is a growing need for guidance on how to employ AI most effectively. The A2C framework (Tariq, Chhetri, Nepal & Paris, 2024) distinguishes three decision-making modes for engaging AI: automation (AI completes a task, including decision/action), augmentation (AI supports human to decide) and collaboration (iterative interaction between human and AI). However, selecting the appropriate mode for a specific application is not always straightforward. The goal of the present study was to compile and trial a simple set of criteria to support recommendations about appropriate A2C mode for a given application. Drawing on human factors and computer science literature, we identified key criteria related to elements of the task, impacts on worker and support needs. From these criteria we built a scoring rubric with recommendation for A2C mode. As a preliminary test of this approach, we applied the criteria to cognitive task analysis (CTA) outputs from three tasks in the science domain - genome annotation, biological collections curation and protein crystallization - which provided insights into worker decision points, challenges and expert strategies. This paper describes the method for connecting CTA to A2C, reflecting on the challenges and future directions.
<div id='section'>Paperid: <span id='pid'>1291, <a href='https://arxiv.org/pdf/2411.05966.pdf' target='_blank'>https://arxiv.org/pdf/2411.05966.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aayush Shah, Shankar Jayaratnam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05966">Energy Efficient Protein Language Models: Leveraging Small Language Models with LoRA for Controllable Protein Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have demonstrated significant success in natural language processing (NLP) tasks and have shown promising results in other domains such as protein sequence generation. However, there remain salient differences between LLMs used for NLP, which effectively handle multiple tasks and are available in small sizes, and protein language models that are often specialized for specific tasks and only exist in larger sizes. In this work, we introduce two small protein language models, based on Llama-3-8B and Phi-3-mini, that are capable of both uncontrollable and controllable protein generation. For the uncontrollable generation task, our best model achieves an average pLDDT score of 69.75, demonstrating robust performance in generating viable protein structures. For the controllable generation task, in which the model generates proteins according to properties specified in the prompt, we achieve a remarkable average TM-Score of 0.84, indicating high structural similarity to target proteins. We chose 10 properties, including six classes of enzymes, to extend the capabilities of prior protein language models. Our approach utilizes the Low-Rank Adaptor (LoRA) technique, reducing trainable parameters to just 4% of the original model size, lowering computational requirements. By using a subset of the UniRef50 dataset and small models, we reduced the overall training time by 70% without compromising performance. Notably, Phi-3-mini reduced trainable parameters by 60%, decreasing training cost by 30% compared to Llama 3. Consequently, Phi-3 achieved a comparable TM-Score of 0.81, demonstrating that smaller models can match the performance of larger ones, like Llama 3. We also demonstrate the deployment of our models on the energy efficient ET-SoC-1 chip, significantly improving the TPS/W by a factor of 3.
<div id='section'>Paperid: <span id='pid'>1292, <a href='https://arxiv.org/pdf/2411.05421.pdf' target='_blank'>https://arxiv.org/pdf/2411.05421.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenze Yang, Sarah K. Yorke, Tuomas P. J. Knowles, Markus J. Buehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05421">Learning the rules of peptide self-assembly through data mining with large language models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Peptides are ubiquitous and important biologically derived molecules, that have been found to self-assemble to form a wide array of structures. Extensive research has explored the impacts of both internal chemical composition and external environmental stimuli on the self-assembly behaviour of these systems. However, there is yet to be a systematic study that gathers this rich literature data and collectively examines these experimental factors to provide a global picture of the fundamental rules that govern protein self-assembly behavior. In this work, we curate a peptide assembly database through a combination of manual processing by human experts and literature mining facilitated by a large language model. As a result, we collect more than 1,000 experimental data entries with information about peptide sequence, experimental conditions and corresponding self-assembly phases. Utilizing the collected data, ML models are trained and evaluated, demonstrating excellent accuracy (>80\%) and efficiency in peptide assembly phase classification. Moreover, we fine-tune our GPT model for peptide literature mining with the developed dataset, which exhibits markedly superior performance in extracting information from academic publications relative to the pre-trained model. We find that this workflow can substantially improve efficiency when exploring potential self-assembling peptide candidates, through guiding experimental work, while also deepening our understanding of the mechanisms governing peptide self-assembly. In doing so, novel structures can be accessed for a range of applications including sensing, catalysis and biomaterials.
<div id='section'>Paperid: <span id='pid'>1293, <a href='https://arxiv.org/pdf/2411.01422.pdf' target='_blank'>https://arxiv.org/pdf/2411.01422.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kusal Debnath, Pratip Rana, Preetam Ghosh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.01422">GramSeq-DTA: A grammar-based drug-target affinity prediction approach fusing gene expression information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drug-target affinity (DTA) prediction is a critical aspect of drug discovery. The meaningful representation of drugs and targets is crucial for accurate prediction. Using 1D string-based representations for drugs and targets is a common approach that has demonstrated good results in drug-target affinity prediction. However, these approach lacks information on the relative position of the atoms and bonds. To address this limitation, graph-based representations have been used to some extent. However, solely considering the structural aspect of drugs and targets may be insufficient for accurate DTA prediction. Integrating the functional aspect of these drugs at the genetic level can enhance the prediction capability of the models. To fill this gap, we propose GramSeq-DTA, which integrates chemical perturbation information with the structural information of drugs and targets. We applied a Grammar Variational Autoencoder (GVAE) for drug feature extraction and utilized two different approaches for protein feature extraction: Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN). The chemical perturbation data is obtained from the L1000 project, which provides information on the upregulation and downregulation of genes caused by selected drugs. This chemical perturbation information is processed, and a compact dataset is prepared, serving as the functional feature set of the drugs. By integrating the drug, gene, and target features in the model, our approach outperforms the current state-of-the-art DTA prediction models when validated on widely used DTA datasets (BindingDB, Davis, and KIBA). This work provides a novel and practical approach to DTA prediction by merging the structural and functional aspects of biological entities, and it encourages further research in multi-modal DTA prediction.
<div id='section'>Paperid: <span id='pid'>1294, <a href='https://arxiv.org/pdf/2411.00913.pdf' target='_blank'>https://arxiv.org/pdf/2411.00913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Boming Kang, Qinghua Cui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00913">Ratio law: mathematical descriptions for a universal relationship between AI performance and input samples</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence based on machine learning and deep learning has made significant advances in various fields such as protein structure prediction and climate modeling. However, a central challenge remains: the "black box" nature of AI, where precise quantitative relationships between inputs and outputs are often lacking. Here, by analyzing 323 AI models trained to predict human essential proteins, we uncovered a ratio law showing that model performance and the ratio of minority to majority samples can be closely linked by two concise equations. Moreover, we mathematically proved that an AI model achieves its optimal performance on a balanced dataset. More importantly, we next explore whether this finding can further guide us to enhance AI models' performance. Therefore, we divided the imbalanced dataset into several balanced subsets to train base classifiers, and then applied a bagging-based ensemble learning strategy to combine these base models. As a result, the equation-guided strategy substantially improved model performance, with increases of 4.06% and 5.28%, respectively, outperforming traditional dataset balancing techniques. Finally, we confirmed the broad applicability and generalization of these equations using different types of classifiers and 10 additional, diverse binary classification tasks. In summary, this study reveals two equations precisely linking AI's input and output, which could be helpful for unboxing the mysterious "black box" of AI.
<div id='section'>Paperid: <span id='pid'>1295, <a href='https://arxiv.org/pdf/2410.23321.pdf' target='_blank'>https://arxiv.org/pdf/2410.23321.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xin, Ma, Dong Si
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.23321">Beyond Current Boundaries: Integrating Deep Learning and AlphaFold for Enhanced Protein Structure Prediction from Low-Resolution Cryo-EM Maps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constructing atomic models from cryo-electron microscopy (cryo-EM) maps is a crucial yet intricate task in structural biology. While advancements in deep learning, such as convolutional neural networks (CNNs) and graph neural networks (GNNs), have spurred the development of sophisticated map-to-model tools like DeepTracer and ModelAngelo, their efficacy notably diminishes with low-resolution maps beyond 4 Ã. To address this shortfall, our research introduces DeepTracer-LowResEnhance, an innovative framework that synergizes a deep learning-enhanced map refinement technique with the power of AlphaFold. This methodology is designed to markedly improve the construction of models from low-resolution cryo-EM maps. DeepTracer-LowResEnhance was rigorously tested on a set of 37 protein cryo-EM maps, with resolutions ranging between 2.5 to 8.4 Ã, including 22 maps with resolutions lower than 4 Ã. The outcomes were compelling, demonstrating that 95.5\% of the low-resolution maps exhibited a significant uptick in the count of total predicted residues. This denotes a pronounced improvement in atomic model building for low-resolution maps. Additionally, a comparative analysis alongside Phenix's auto-sharpening functionality delineates DeepTracer-LowResEnhance's superior capability in rendering more detailed and precise atomic models, thereby pushing the boundaries of current computational structural biology methodologies.
<div id='section'>Paperid: <span id='pid'>1296, <a href='https://arxiv.org/pdf/2410.20318.pdf' target='_blank'>https://arxiv.org/pdf/2410.20318.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tiangang Cui, Alex Gorodetsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20318">Low-rank Bayesian matrix completion via geodesic Hamiltonian Monte Carlo on Stiefel manifolds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a new sampling-based approach for enabling efficient computation of low-rank Bayesian matrix completion and quantifying the associated uncertainty. Firstly, we design a new prior model based on the singular-value-decomposition (SVD) parametrization of low-rank matrices. Our prior is analogous to the seminal nuclear-norm regularization used in non-Bayesian setting and enforces orthogonality in the factor matrices by constraining them to Stiefel manifolds. Then, we design a geodesic Hamiltonian Monte Carlo (-within-Gibbs) algorithm for generating posterior samples of the SVD factor matrices. We demonstrate that our approach resolves the sampling difficulties encountered by standard Gibbs samplers for the common two-matrix factorization used in matrix completion. More importantly, the geodesic Hamiltonian sampler allows for sampling in cases with more general likelihoods than the typical Gaussian likelihood and Gaussian prior assumptions adopted in most of the existing Bayesian matrix completion literature. We demonstrate an applications of our approach to fit the categorical data of a mice protein dataset and the MovieLens recommendation problem. Numerical examples demonstrate superior sampling performance, including better mixing and faster convergence to a stationary distribution. Moreover, they demonstrate improved accuracy on the two real-world benchmark problems we considered.
<div id='section'>Paperid: <span id='pid'>1297, <a href='https://arxiv.org/pdf/2410.17293.pdf' target='_blank'>https://arxiv.org/pdf/2410.17293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bahar Ali, Anwar Shah, Malik Niaz, Musadaq Mansoord, Sami Ullah, Muhammad Adnan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.17293">A Fusion-Driven Approach of Attention-Based CNN-BiLSTM for Protein Family Classification -- ProFamNet</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advanced automated AI techniques allow us to classify protein sequences and discern their biological families and functions. Conventional approaches for classifying these protein families often focus on extracting N-Gram features from the sequences while overlooking crucial motif information and the interplay between motifs and neighboring amino acids. Recently, convolutional neural networks have been applied to amino acid and motif data, even with a limited dataset of well-characterized proteins, resulting in improved performance. This study presents a model for classifying protein families using the fusion of 1D-CNN, BiLSTM, and an attention mechanism, which combines spatial feature extraction, long-term dependencies, and context-aware representations. The proposed model (ProFamNet) achieved superior model efficiency with 450,953 parameters and a compact size of 1.72 MB, outperforming the state-of-the-art model with 4,578,911 parameters and a size of 17.47 MB. Further, we achieved a higher F1 score (98.30% vs. 97.67%) with more instances (271,160 vs. 55,077) in fewer training epochs (25 vs. 30).
<div id='section'>Paperid: <span id='pid'>1298, <a href='https://arxiv.org/pdf/2410.17173.pdf' target='_blank'>https://arxiv.org/pdf/2410.17173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yasha Ektefaie, Olivia Viessmann, Siddharth Narayanan, Drew Dresser, J. Mark Kim, Armen Mkrtchyan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.17173">Reinforcement learning on structure-conditioned categorical diffusion for protein inverse folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein inverse folding-that is, predicting an amino acid sequence that will fold into the desired 3D structure-is an important problem for structure-based protein design. Machine learning based methods for inverse folding typically use recovery of the original sequence as the optimization objective. However, inverse folding is a one-to-many problem where several sequences can fold to the same structure. Moreover, for many practical applications, it is often desirable to have multiple, diverse sequences that fold into the target structure since it allows for more candidate sequences for downstream optimizations. Here, we demonstrate that although recent inverse folding methods show increased sequence recovery, their "foldable diversity"-i.e. their ability to generate multiple non-similar sequences that fold into the structures consistent with the target-does not increase. To address this, we present RL-DIF, a categorical diffusion model for inverse folding that is pre-trained on sequence recovery and tuned via reinforcement learning on structural consistency. We find that RL-DIF achieves comparable sequence recovery and structural consistency to benchmark models but shows greater foldable diversity: experiments show RL-DIF can achieve an foldable diversity of 29% on CATH 4.2, compared to 23% from models trained on the same dataset. The PyTorch model weights and sampling code are available on GitHub.
<div id='section'>Paperid: <span id='pid'>1299, <a href='https://arxiv.org/pdf/2410.16302.pdf' target='_blank'>https://arxiv.org/pdf/2410.16302.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haowen Zhao, Francesco A. Aprile, Barbara Bravi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.16302">Computational design of target-specific linear peptide binders with TransformerBeta</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The computational prediction and design of peptide binders targeting specific linear epitopes is crucial in biological and biomedical research, yet it remains challenging due to their highly dynamic nature and the scarcity of experimentally solved binding data. To address this problem, we built an unprecedentedly large-scale library of peptide pairs within stable secondary structures (beta sheets), leveraging newly available AlphaFold predicted structures. We then developed a machine learning method based on the Transformer architecture for the design of specific linear binders, in analogy to a language translation task. Our method, TransformerBeta, accurately predicts specific beta strand interactions and samples sequences with beta sheet-like molecular properties, while capturing interpretable physico-chemical interaction patterns. As such, it can propose specific candidate binders targeting linear epitope for experimental validation to inform protein design.
<div id='section'>Paperid: <span id='pid'>1300, <a href='https://arxiv.org/pdf/2410.15849.pdf' target='_blank'>https://arxiv.org/pdf/2410.15849.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shikhar Vashistha, Neetesh Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15849">Focus Where It Matters: Graph Selective State Focused Attention Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional graph neural networks (GNNs) lack scalability and lose individual node characteristics due to over-smoothing, especially in the case of deeper networks. This results in sub-optimal feature representation, affecting the model's performance on tasks involving dynamically changing graphs. To address this issue, we present Graph Selective States Focused Attention Networks (GSANs) based neural network architecture for graph-structured data. The GSAN is enabled by multi-head masked self-attention (MHMSA) and selective state space modeling (S3M) layers to overcome the limitations of GNNs. In GSAN, the MHMSA allows GSAN to dynamically emphasize crucial node connections, particularly in evolving graph environments. The S3M layer enables the network to adjust dynamically in changing node states and improving predictions of node behavior in varying contexts without needing primary knowledge of the graph structure. Furthermore, the S3M layer enhances the generalization of unseen structures and interprets how node states influence link importance. With this, GSAN effectively outperforms inductive and transductive tasks and overcomes the issues that traditional GNNs experience. To analyze the performance behavior of GSAN, a set of state-of-the-art comparative experiments are conducted on graphs benchmark datasets, including $Cora$, $Citeseer$, $Pubmed$ network citation, and $protein-protein-interaction$ datasets, as an outcome, GSAN improved the classification accuracy by $1.56\%$, $8.94\%$, $0.37\%$, and $1.54\%$ on $F1-score$ respectively.
<div id='section'>Paperid: <span id='pid'>1301, <a href='https://arxiv.org/pdf/2410.15290.pdf' target='_blank'>https://arxiv.org/pdf/2410.15290.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aryan Abbasian, Mahtab Mirmohseni, Masoumeh Nasiri Kenari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15290">On the size of error ball in DNA storage channels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent experiments have demonstrated the feasibility of storing digital information in macromolecules such as DNA and protein. However, the DNA storage channel is prone to errors such as deletions, insertions, and substitutions. During the synthesis and reading phases of DNA strings, many noisy copies of the original string are generated. The problem of recovering the original string from these noisy copies is known as sequence reconstruction. A key concept in this problem is the error ball, which is the set of all possible sequences that can result from a limited number of errors applied to the original sequence. Levenshtein showed that the minimum number of noisy copies required for a given channel to recover the original sequence is equal to one plus the maximum size of the intersection of two error balls. Therefore, deriving the size of the error ball for any channel and any sequence is essential for solving the sequence reconstruction problem. In DNA storage systems, multiple types of errors such as deletion, insertion and substitution in a string could occur simultaneously. In this work, we aim to derive the size of the error ball for channels with multiple types of errors and at most three edits. Specifically, we consider the channels with single-deletion double-substitution, single-deletion double-insertion and single-insertion single-substitution errors.
<div id='section'>Paperid: <span id='pid'>1302, <a href='https://arxiv.org/pdf/2410.08938.pdf' target='_blank'>https://arxiv.org/pdf/2410.08938.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Benson Chen, Tomasz Danel, Gabriel H. S. Dreiman, Patrick J. McEnaney, Nikhil Jain, Kirill Novikov, Spurti Umesh Akki, Joshua L. Turnbull, Virja Atul Pandya, Boris P. Belotserkovskii, Jared Bryce Weaver, Ankita Biswas, Dat Nguyen, Kent Gorday, Mohammad Sultan, Nathaniel Stanley, Daniel M Whalen, Divya Kanichar, Christoph Klein, Emily Fox, R. Edward Watts
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08938">KinDEL: DNA-Encoded Library Dataset for Kinase Inhibitors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>DNA-Encoded Libraries (DELs) represent a transformative technology in drug discovery, facilitating the high-throughput exploration of vast chemical spaces. Despite their potential, the scarcity of publicly available DEL datasets presents a bottleneck for the advancement of machine learning methodologies in this domain. To address this gap, we introduce KinDEL, one of the largest publicly accessible DEL datasets and the first one that includes binding poses from molecular docking experiments. Focused on two kinases, Mitogen-Activated Protein Kinase 14 (MAPK14) and Discoidin Domain Receptor Tyrosine Kinase 1 (DDR1), KinDEL includes 81 million compounds, offering a rich resource for computational exploration. Additionally, we provide comprehensive biophysical assay validation data, encompassing both on-DNA and off-DNA measurements, which we use to evaluate a suite of machine learning techniques, including novel structure-based probabilistic models. We hope that our benchmark, encompassing both 2D and 3D structures, will help advance the development of machine learning models for data-driven hit identification using DELs.
<div id='section'>Paperid: <span id='pid'>1303, <a href='https://arxiv.org/pdf/2410.07890.pdf' target='_blank'>https://arxiv.org/pdf/2410.07890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabio S. Ferreira, John Ashburner, Arabella Bouzigues, Chatrin Suksasilp, Lucy L. Russell, Phoebe H. Foster, Eve Ferry-Bolder, John C. van Swieten, Lize C. Jiskoot, Harro Seelaar, Raquel Sanchez-Valle, Robert Laforce, Caroline Graff, Daniela Galimberti, Rik Vandenberghe, Alexandre de Mendonca, Pietro Tiraboschi, Isabel Santana, Alexander Gerhard, Johannes Levin, Sandro Sorbi, Markus Otto, Florence Pasquier, Simon Ducharme, Chris R. Butler, Isabelle Le Ber, Elizabeth Finger, Maria C. Tartaglia, Mario Masellis, James B. Rowe, Matthis Synofzik, Fermin Moreno, Barbara Borroni, Samuel Kaski, Jonathan D. Rohrer, Janaina Mourao-Miranda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07890">Identifying latent disease factors differently expressed in patient subgroups using group factor analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we propose a novel approach to uncover subgroup-specific and subgroup-common latent factors addressing the challenges posed by the heterogeneity of neurological and mental disorders, which hinder disease understanding, treatment development, and outcome prediction. The proposed approach, sparse Group Factor Analysis (GFA) with regularised horseshoe priors, was implemented with probabilistic programming and can uncover associations (or latent factors) among multiple data modalities differentially expressed in sample subgroups. Synthetic data experiments showed the robustness of our sparse GFA by correctly inferring latent factors and model parameters. When applied to the Genetic Frontotemporal Dementia Initiative (GENFI) dataset, which comprises patients with frontotemporal dementia (FTD) with genetically defined subgroups, the sparse GFA identified latent disease factors differentially expressed across the subgroups, distinguishing between "subgroup-specific" latent factors within homogeneous groups and "subgroup common" latent factors shared across subgroups. The latent disease factors captured associations between brain structure and non-imaging variables (i.e., questionnaires assessing behaviour and disease severity) across the different genetic subgroups, offering insights into disease profiles. Importantly, two latent factors were more pronounced in the two more homogeneous FTD patient subgroups (progranulin (GRN) and microtubule-associated protein tau (MAPT) mutation), showcasing the method's ability to reveal subgroup-specific characteristics. These findings underscore the potential of sparse GFA for integrating multiple data modalities and identifying interpretable latent disease factors that can improve the characterization and stratification of patients with neurological and mental health disorders.
<div id='section'>Paperid: <span id='pid'>1304, <a href='https://arxiv.org/pdf/2409.19115.pdf' target='_blank'>https://arxiv.org/pdf/2409.19115.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rodrigo Henrique Ramos, Yago Augusto Bardelotte, Cynthia de Oliveira Lage Ferreira, Adenilso Simao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19115">Identifying Key Genes in Cancer Networks Using Persistent Homology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying driver genes is crucial for understanding oncogenesis and developing targeted cancer therapies. Driver discovery methods using protein or pathway networks rely on traditional network science measures, focusing on nodes, edges, or community metrics. These methods can overlook the high-dimensional interactions that cancer genes have within cancer networks. This study presents a novel method using Persistent Homology to analyze the role of driver genes in higher-order structures within Cancer Consensus Networks derived from main cellular pathways. We integrate mutation data from six cancer types and three biological functions: DNA Repair, Chromatin Organization, and Programmed Cell Death. We systematically evaluated the impact of gene removal on topological voids ($Î²_2$ structures) within the Cancer Consensus Networks. Our results reveal that only known driver genes and cancer-associated genes influence these structures, while passenger genes do not. Although centrality measures alone proved insufficient to fully characterize impact genes, combining higher-order topological analysis with traditional network metrics can improve the precision of distinguishing between drivers and passengers. This work shows that cancer genes play an important role in higher-order structures, going beyond pairwise measures, and provides an approach to distinguish drivers and cancer-associated genes from passenger genes.
<div id='section'>Paperid: <span id='pid'>1305, <a href='https://arxiv.org/pdf/2409.16552.pdf' target='_blank'>https://arxiv.org/pdf/2409.16552.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saeed Omidi, Gianluca Fabi, Xiaopeng Wang, James C. M. Hwang, Yevgeny Berdichevsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.16552">Device for detection of activity-dependent changes in neural spheroids at MHz and GHz frequencies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Intracellular processes triggered by neural activity include changes in ionic concentrations, protein release, and synaptic vesicle cycling. These processes play significant roles in neurological disorders. The beneficial effects of brain stimulation may also be mediated through intracellular changes. There is a lack of label-free techniques for monitoring activity-dependent intracellular changes. Electromagnetic (EM) waves at frequencies larger than 1x10^6 Hz (1 MHz) were previously used to probe intracellular contents of cells, as cell membrane becomes transparent at this frequency range. EM waves interact with membranes of intracellular organelles, proteins, and water in the MHz-GHz range. In this work, we developed a device for probing the interaction between intracellular contents of active neurons and EM waves. The device used an array of grounded coplanar waveguides (GCPWs) to deliver EM waves to a three-dimensional (3D) spheroid of rat cortical neurons. Neural activity was evoked using optogenetics, with synchronous detection of propagation of EM waves. Broadband measurements were conducted in the MHz-GHz range to track changes in transmission coefficients. Neuronal activity was found to reversibly alter EM wave transmission. Pharmacological suppression of neuronal activity abolished changes in transmission. Time constants of changes in transmission were in the range of seconds to tens of seconds, suggesting the presence of relatively slow, activity-dependent intracellular processes. This study provides the first evidence that EM transmission through neuronal tissue is activity-dependent in MHz-GHz range. Device developed in this work may find future applications in studies of the mechanisms of neurological disorders and the development of new therapies.
<div id='section'>Paperid: <span id='pid'>1306, <a href='https://arxiv.org/pdf/2409.13467.pdf' target='_blank'>https://arxiv.org/pdf/2409.13467.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Roman Joeres, Daniel Bojar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13467">Higher-Order Message Passing for Glycan Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Glycans are the most complex biological sequence, with monosaccharides forming extended, non-linear sequences. As post-translational modifications, they modulate protein structure, function, and interactions. Due to their diversity and complexity, predictive models of glycan properties and functions are still insufficient.
  Graph Neural Networks (GNNs) are deep learning models designed to process and analyze graph-structured data. These architectures leverage the connectivity and relational information in graphs to learn effective representations of nodes, edges, and entire graphs. Iteratively aggregating information from neighboring nodes, GNNs capture complex patterns within graph data, making them particularly well-suited for tasks such as link prediction or graph classification across domains.
  This work presents a new model architecture based on combinatorial complexes and higher-order message passing to extract features from glycan structures into a latent space representation. The architecture is evaluated on an improved GlycanML benchmark suite, establishing a new state-of-the-art performance. We envision that these improvements will spur further advances in computational glycosciences and reveal the roles of glycans in biology.
<div id='section'>Paperid: <span id='pid'>1307, <a href='https://arxiv.org/pdf/2409.12995.pdf' target='_blank'>https://arxiv.org/pdf/2409.12995.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julia Buhmann, Ward Haddadin, LukÃ¡Å¡ Pravda, Alan Bilsland, Hagen Triendl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.12995">Improving generalisability of 3D binding affinity models in low data regimes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting protein-ligand binding affinity is an essential part of computer-aided drug design. However, generalisable and performant global binding affinity models remain elusive, particularly in low data regimes. Despite the evolution of model architectures, current benchmarks are not well-suited to probe the generalisability of 3D binding affinity models. Furthermore, 3D global architectures such as GNNs have not lived up to performance expectations. To investigate these issues, we introduce a novel split of the PDBBind dataset, minimizing similarity leakage between train and test sets and allowing for a fair and direct comparison between various model architectures. On this low similarity split, we demonstrate that, in general, 3D global models are superior to protein-specific local models in low data regimes. We also demonstrate that the performance of GNNs benefits from three novel contributions: supervised pre-training via quantum mechanical data, unsupervised pre-training via small molecule diffusion, and explicitly modeling hydrogen atoms in the input graph. We believe that this work introduces promising new approaches to unlock the potential of GNN architectures for binding affinity modelling.
<div id='section'>Paperid: <span id='pid'>1308, <a href='https://arxiv.org/pdf/2409.08729.pdf' target='_blank'>https://arxiv.org/pdf/2409.08729.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andreas Plesner, Hans Henrik Brandenborg SÃ¸rensen, SÃ¸ren Hauberg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08729">Accurate Computation of the Logarithm of Modified Bessel Functions on GPUs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bessel functions are critical in scientific computing for applications such as machine learning, protein structure modeling, and robotics. However, currently, available routines lack precision or fail for certain input ranges, such as when the order $v$ is large, and GPU-specific implementations are limited. We address the precision limitations of current numerical implementations while dramatically improving the runtime. We propose two novel algorithms for computing the logarithm of modified Bessel functions of the first and second kinds by computing intermediate values on a logarithmic scale. Our algorithms are robust and never have issues with underflows or overflows while having relative errors on the order of machine precision, even for inputs where existing libraries fail. In C++/CUDA, our algorithms have median and maximum speedups of 45x and 6150x for GPU and 17x and 3403x for CPU, respectively, over the ranges of inputs and third-party libraries tested. Compared to SciPy, the algorithms have median and maximum speedups of 77x and 300x for GPU and 35x and 98x for CPU, respectively, over the tested inputs.
  The ability to robustly compute a solution and the low relative errors allow us to fit von Mises-Fisher, vMF, distributions to high-dimensional neural network features. This is, e.g., relevant for uncertainty quantification in metric learning. We obtain image feature data by processing CIFAR10 training images with the convolutional layers of a pre-trained ResNet50. We successfully fit vMF distributions to 2048-, 8192-, and 32768-dimensional image feature data using our algorithms. Our approach provides fast and accurate results while existing implementations in SciPy and mpmath fail to fit successfully.
  Our approach is readily implementable on GPUs, and we provide a fast open-source implementation alongside this paper.
<div id='section'>Paperid: <span id='pid'>1309, <a href='https://arxiv.org/pdf/2409.04491.pdf' target='_blank'>https://arxiv.org/pdf/2409.04491.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huma Perveen, Julie Weeds
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04491">Protein sequence classification using natural language processing techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Purpose: This study aimed to enhance protein sequence classification using natural language processing (NLP) techniques while addressing the impact of sequence similarity on model performance. We compared various machine learning and deep learning models under two different data-splitting strategies: random splitting and ECOD family-based splitting, which ensures evolutionary-related sequences are grouped together. Methods: The study evaluated models such as K-Nearest Neighbors (KNN), Multinomial NaÃ¯ve Bayes, Logistic Regression, Multi-Layer Perceptron (MLP), Decision Tree, Random Forest, XGBoost, Voting and Stacking classifiers, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and transformer models (BertForSequenceClassification, DistilBERT, and ProtBert). Performance was tested using different amino acid ranges and sequence lengths with a focus on generalization across unseen evolutionary families. Results: The Voting classifier achieved the highest performance with 74% accuracy, 74% weighted F1 score, and 65% macro F1 score under random splitting, while ProtBERT obtained 77% accuracy, 76% weighted F1 score, and 61% macro F1 score among transformer models. However, performance declined across all models when tested using ECOD-based splitting, revealing the impact of sequence similarity on classification performance. Conclusion: Advanced NLP techniques, particularly ensemble methods like Voting classifiers, and transformer models show significant potential in protein classification, with sufficient training data and sequence similarity management being crucial for optimal performance. However, the use of biologically meaningful splitting methods, such as ECOD family-based splitting, is crucial for realistic performance evaluation and generalization to unseen evolutionary families.
<div id='section'>Paperid: <span id='pid'>1310, <a href='https://arxiv.org/pdf/2409.03658.pdf' target='_blank'>https://arxiv.org/pdf/2409.03658.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elyssa Sliheet, Md Abu Talha, Weihua Geng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03658">A DNN Biophysics Model with Topological and Electrostatic Features</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this project, we provide a deep-learning neural network (DNN) based biophysics model to predict protein properties. The model uses multi-scale and uniform topological and electrostatic features generated with protein structural information and force field, which governs the molecular mechanics. The topological features are generated using the element specified persistent homology (ESPH) while the electrostatic features are fast computed using a Cartesian treecode. These features are uniform in number for proteins with various sizes thus the broadly available protein structure database can be used in training the network. These features are also multi-scale thus the resolution and computational cost can be balanced by the users. The machine learning simulation on over 4000 protein structures shows the efficiency and fidelity of these features in representing the protein structure and force field for the predication of their biophysical properties such as electrostatic solvation energy. Tests on topological or electrostatic features alone and the combination of both showed the optimal performance when both features are used. This model shows its potential as a general tool in assisting biophysical properties and function prediction for the broad biomolecules using data from both theoretical computing and experiments.
<div id='section'>Paperid: <span id='pid'>1311, <a href='https://arxiv.org/pdf/2409.00610.pdf' target='_blank'>https://arxiv.org/pdf/2409.00610.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shania Mitra, Lei Huang, Manolis Kellis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.00610">ProteinRPN: Towards Accurate Protein Function Prediction with Graph-Based Region Proposals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein function prediction is a crucial task in bioinformatics, with significant implications for understanding biological processes and disease mechanisms. While the relationship between sequence and function has been extensively explored, translating protein structure to function continues to present substantial challenges. Various models, particularly, CNN and graph-based deep learning approaches that integrate structural and functional data, have been proposed to address these challenges. However, these methods often fall short in elucidating the functional significance of key residues essential for protein functionality, as they predominantly adopt a retrospective perspective, leading to suboptimal performance.
  Inspired by region proposal networks in computer vision, we introduce the Protein Region Proposal Network (ProteinRPN) for accurate protein function prediction. Specifically, the region proposal module component of ProteinRPN identifies potential functional regions (anchors) which are refined through the hierarchy-aware node drop pooling layer favoring nodes with defined secondary structures and spatial proximity. The representations of the predicted functional nodes are enriched using attention mechanisms and subsequently fed into a Graph Multiset Transformer, which is trained with supervised contrastive (SupCon) and InfoNCE losses on perturbed protein structures. Our model demonstrates significant improvements in predicting Gene Ontology (GO) terms, effectively localizing functional residues within protein structures. The proposed framework provides a robust, scalable solution for protein function annotation, advancing the understanding of protein structure-function relationships in computational biology.
<div id='section'>Paperid: <span id='pid'>1312, <a href='https://arxiv.org/pdf/2408.16245.pdf' target='_blank'>https://arxiv.org/pdf/2408.16245.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sully F. Chen, Robert J. Steele, Glen M. Hocky, Beakal Lemeneh, Shivanand P. Lad, Eric K. Oermann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16245">Large-Scale Multi-omic Biosequence Transformers for Modeling Protein-Nucleic Acid Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The transformer architecture has revolutionized bioinformatics and driven progress in the understanding and prediction of the properties of biomolecules. To date, most biosequence transformers have been trained on single-omic data-either proteins or nucleic acids and have seen incredible success in downstream tasks in each domain, with particularly noteworthy breakthroughs in protein structural modeling. However, single-omic pre-training limits the ability of these models to capture cross-modal interactions. Here we present OmniBioTE, the largest open-source multi-omic model trained on over 250 billion tokens of mixed protein and nucleic acid data. We show that despite only being trained on unlabeled sequence data, OmniBioTE learns joint representations mapping genes to their corresponding protein sequences. We further demonstrate that OmbiBioTE achieves state-of-the-art results predicting the change in Gibbs free energy (ÎG) of the binding interaction between a given nucleic acid and protein. Remarkably, we show that multi-omic biosequence transformers emergently learn useful structural information without any a priori structural training, allowing us to predict which protein residues are most involved in the protein-nucleic acid binding interaction. Lastly, compared to single-omic controls trained with identical compute, OmniBioTE demonstrates superior performance-per-FLOP across both multi-omic and single-omic benchmarks, highlighting the power of a unified modeling approach for biological sequences.
<div id='section'>Paperid: <span id='pid'>1313, <a href='https://arxiv.org/pdf/2408.12519.pdf' target='_blank'>https://arxiv.org/pdf/2408.12519.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sina Sarparast, Aldo Zaimi, Maximilian Ebert, Michael-Rock Goldsmith
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12519">Advanced atom-level representations for protein flexibility prediction utilizing graph neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein dynamics play a crucial role in many biological processes and drug interactions. However, measuring, and simulating protein dynamics is challenging and time-consuming. While machine learning holds promise in deciphering the determinants of protein dynamics from structural information, most existing methods for protein representation learning operate at the residue level, ignoring the finer details of atomic interactions. In this work, we propose for the first time to use graph neural networks (GNNs) to learn protein representations at the atomic level and predict B-factors from protein 3D structures. The B-factor reflects the atomic displacement of atoms in proteins, and can serve as a surrogate for protein flexibility. We compared different GNN architectures to assess their performance. The Meta-GNN model achieves a correlation coefficient of 0.71 on a large and diverse test set of over 4k proteins (17M atoms) from the Protein Data Bank (PDB), outperforming previous methods by a large margin. Our work demonstrates the potential of representations learned by GNNs for protein flexibility prediction and other related tasks.
<div id='section'>Paperid: <span id='pid'>1314, <a href='https://arxiv.org/pdf/2408.11356.pdf' target='_blank'>https://arxiv.org/pdf/2408.11356.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kelei He, Tiejun Dong, Jinhui Wu, Junfeng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11356">One-step Structure Prediction and Screening for Protein-Ligand Complexes using Multi-Task Geometric Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the structure of the protein-ligand complex is crucial to drug development. Existing virtual structure measurement and screening methods are dominated by docking and its derived methods combined with deep learning. However, the sampling and scoring methodology have largely restricted the accuracy and efficiency. Here, we show that these two fundamental tasks can be accurately tackled with a single model, namely LigPose, based on multi-task geometric deep learning. By representing the ligand and the protein pair as a graph, LigPose directly optimizes the three-dimensional structure of the complex, with the learning of binding strength and atomic interactions as auxiliary tasks, enabling its one-step prediction ability without docking tools. Extensive experiments show LigPose achieved state-of-the-art performance on major tasks in drug research. Its considerable improvements indicate a promising paradigm of AI-based pipeline for drug development.
<div id='section'>Paperid: <span id='pid'>1315, <a href='https://arxiv.org/pdf/2408.04847.pdf' target='_blank'>https://arxiv.org/pdf/2408.04847.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amish Mishra, Francis Motta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.04847">A Pipeline for Data-Driven Learning of Topological Features with Applications to Protein Stability Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a data-driven method to learn interpretable topological features of biomolecular data and demonstrate the efficacy of parsimonious models trained on topological features in predicting the stability of synthetic mini proteins. We compare models that leverage automatically-learned structural features against models trained on a large set of biophysical features determined by subject-matter experts (SME). Our models, based only on topological features of the protein structures, achieved 92%-99% of the performance of SME-based models in terms of the average precision score. By interrogating model performance and feature importance metrics, we extract numerous insights that uncover high correlations between topological features and SME features. We further showcase how combining topological features and SME features can lead to improved model performance over either feature set used in isolation, suggesting that, in some settings, topological features may provide new discriminating information not captured in existing SME features that are useful for protein stability prediction.
<div id='section'>Paperid: <span id='pid'>1316, <a href='https://arxiv.org/pdf/2407.21298.pdf' target='_blank'>https://arxiv.org/pdf/2407.21298.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>An Wu, Yu Pan, Fuqi Zhou, Jinghui Yan, Chuanlu Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21298">A Vectorization Method Induced By Maximal Margin Classification For Persistent Diagrams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Persistent homology is an effective method for extracting topological information, represented as persistent diagrams, of spatial structure data. Hence it is well-suited for the study of protein structures. Attempts to incorporate Persistent homology in machine learning methods of protein function prediction have resulted in several techniques for vectorizing persistent diagrams. However, current vectorization methods are excessively artificial and cannot ensure the effective utilization of information or the rationality of the methods. To address this problem, we propose a more geometrical vectorization method of persistent diagrams based on maximal margin classification for Banach space, and additionaly propose a framework that utilizes topological data analysis to identify proteins with specific functions. We evaluated our vectorization method using a binary classification task on proteins and compared it with the statistical methods that exhibit the best performance among thirteen commonly used vectorization methods. The experimental results indicate that our approach surpasses the statistical methods in both robustness and precision.
<div id='section'>Paperid: <span id='pid'>1317, <a href='https://arxiv.org/pdf/2407.18336.pdf' target='_blank'>https://arxiv.org/pdf/2407.18336.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Musa Azeem, Homayoun Valafar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.18336">Dihedral Angle Adherence: Evaluating Protein Structure Predictions in the Absence of Experimental Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Determining the 3D structures of proteins is essential in understanding their behavior in the cellular environment. Computational methods of predicting protein structures have advanced, but assessing prediction accuracy remains a challenge. The traditional method, RMSD, relies on experimentally determined structures and lacks insight into improvement areas of predictions. We propose an alternative: analyzing dihedral angles, bypassing the need for the reference structure of an evaluated protein. Our method segments proteins into amino acid subsequences and searches for matches, comparing dihedral angles across numerous proteins to compute a metric using Mahalanobis distance. Evaluated on many predictions, our approach correlates with RMSD and identifies areas for prediction enhancement. This method offers a promising route for accurate protein structure prediction assessment and improvement.
<div id='section'>Paperid: <span id='pid'>1318, <a href='https://arxiv.org/pdf/2407.18317.pdf' target='_blank'>https://arxiv.org/pdf/2407.18317.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Swati Adhikari, Parthajit Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.18317">CavDetect: A DBSCAN Algorithm based Novel Cavity Detection Model on Protein Structure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cavities on the structures of proteins are formed due to interaction between proteins and some small molecules, known as ligands. These are basically the locations where ligands bind with proteins. Actual detection of such locations is all-important to succeed in the entire drug design process. This study proposes a Voronoi Tessellation based novel cavity detection model that is used to detect cavities on the structure of proteins. As the atom space of protein structure is dense and of large volumes and the DBSCAN (Density Based Spatial Clustering of Applications with Noise) algorithm can handle such type of data very well as well as it is not mandatory to have knowledge about the numbers of clusters (cavities) in data as priori in this algorithm, this study proposes to implement the proposed algorithm with the DBSCAN algorithm.
<div id='section'>Paperid: <span id='pid'>1319, <a href='https://arxiv.org/pdf/2407.11439.pdf' target='_blank'>https://arxiv.org/pdf/2407.11439.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Changhun Lee, Gyumin Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11439">Repurformer: Transformers for Repurposing-Aware Molecule Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generating as diverse molecules as possible with desired properties is crucial for drug discovery research, which invokes many approaches based on deep generative models today. Despite recent advancements in these models, particularly in variational autoencoders (VAEs), generative adversarial networks (GANs), Transformers, and diffusion models, a significant challenge known as \textit{the sample bias problem} remains. This problem occurs when generated molecules targeting the same protein tend to be structurally similar, reducing the diversity of generation. To address this, we propose leveraging multi-hop relationships among proteins and compounds. Our model, Repurformer, integrates bi-directional pretraining with Fast Fourier Transform (FFT) and low-pass filtering (LPF) to capture complex interactions and generate diverse molecules. A series of experiments on BindingDB dataset confirm that Repurformer successfully creates substitutes for anchor compounds that resemble positive compounds, increasing diversity between the anchor and generated compounds.
<div id='section'>Paperid: <span id='pid'>1320, <a href='https://arxiv.org/pdf/2407.10666.pdf' target='_blank'>https://arxiv.org/pdf/2407.10666.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xin Peng, Ang Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.10666">Flow Perturbation to Accelerate Unbiased Sampling of Boltzmann distribution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Flow-based generative models have been employed for sampling the Boltzmann distribution, but their application to high-dimensional systems is hindered by the significant computational cost of obtaining the Jacobian of the flow. To overcome this challenge, we introduce the flow perturbation method, which incorporates optimized stochastic perturbations into the flow. By reweighting trajectories generated by the perturbed flow, our method achieves unbiased sampling of the Boltzmann distribution with orders of magnitude speedup compared to both brute force Jacobian calculations and the Hutchinson estimator. Notably, it accurately sampled the Chignolin protein with all atomic Cartesian coordinates explicitly represented, which, to our best knowledge, is the largest molecule ever Boltzmann sampled in such detail using generative models.
<div id='section'>Paperid: <span id='pid'>1321, <a href='https://arxiv.org/pdf/2407.07817.pdf' target='_blank'>https://arxiv.org/pdf/2407.07817.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manuel Bezerra-Brandao, Ronaldo Romario Tunque Cahui, Layla Hirsh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.07817">Daisy: An integrated repeat protein curation service</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tandem repeats in proteins identification, classification and curation is a complex process that requires manual processing from experts, processing power and time. There are recent and relevant advances applying machine learning for protein structure prediction and repeat classification that are useful for this process. However, no service contemplates required databases and software to supplement researching on repeat proteins. In this publication we present Daisy, an integrated repeat protein curation web service. This service can process Protein Data Bank (PDB) and the AlphaFold Database entries for tandem repeats identification. In addition, it uses an algorithm to search a sequence against a library of Pfam hidden Markov model (HMM). Repeat classifications are associated with the identified families through RepeatsDB. This prediction is considered for enhancing the ReUPred algorithm execution and hastening the repeat units identification process. The service can also operate every associated PDB and AlphaFold structure with a UniProt proteome registry. Availability: The Daisy web service is freely accessible at daisy.bioinformatica.org.
<div id='section'>Paperid: <span id='pid'>1322, <a href='https://arxiv.org/pdf/2407.07718.pdf' target='_blank'>https://arxiv.org/pdf/2407.07718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Li, Giulia Guidi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.07718">High-Performance Sorting-Based k-mer Counting in Distributed Memory with Flexible Hybrid Parallelism</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In generating large quantities of DNA data, high-throughput sequencing technologies require advanced bioinformatics infrastructures for efficient data analysis. k-mer counting, the process of quantifying the frequency of fixed-length k DNA subsequences, is a fundamental step in various bioinformatics pipelines, including genome assembly and protein prediction. Due to the growing volume of data, the scaling of the counting process is critical. In the literature, distributed memory software uses hash tables, which exhibit poor cache friendliness and consume excessive memory. They often also lack support for flexible parallelism, which makes integration into existing bioinformatics pipelines difficult. In this work, we propose HySortK, a highly efficient sorting-based distributed memory k-mer counter. HySortK reduces the communication volume through a carefully designed communication scheme and domain-specific optimization strategies. Furthermore, we introduce an abstract task layer for flexible hybrid parallelism to address load imbalances in different scenarios. HySortK achieves a 2-10x speedup compared to the GPU baseline on 4 and 8 nodes. Compared to state-of-the-art CPU software, HySortK achieves up to 2x speedup while reducing peak memory usage by 30% on 16 nodes. Finally, we integrated HySortK into an existing genome assembly pipeline and achieved up to 1.8x speedup, proving its flexibility and practicality in real-world scenarios.
<div id='section'>Paperid: <span id='pid'>1323, <a href='https://arxiv.org/pdf/2407.01574.pdf' target='_blank'>https://arxiv.org/pdf/2407.01574.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Ducrocq, Lukas Grunewald, Sebastian Westenhoff, Fredrik Lindsten
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01574">cryoSPHERE: Single-particle heterogeneous reconstruction from cryo EM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The three-dimensional structure of proteins plays a crucial role in determining their function. Protein structure prediction methods, like AlphaFold, offer rapid access to a protein structure. However, large protein complexes cannot be reliably predicted, and proteins are dynamic, making it important to resolve their full conformational distribution. Single-particle cryo-electron microscopy (cryo-EM) is a powerful tool for determining the structures of large protein complexes. Importantly, the numerous images of a given protein contain underutilized information about conformational heterogeneity. These images are very noisy projections of the protein, and traditional methods for cryo-EM reconstruction are limited to recovering only one or a few consensus conformations. In this paper, we introduce cryoSPHERE, which is a deep learning method that uses a nominal protein structure (e.g., from AlphaFold) as input, learns how to divide it into segments, and moves these segments as approximately rigid bodies to fit the different conformations present in the cryo-EM dataset. This approach provides enough constraints to enable meaningful reconstructions of single protein structural ensembles. We demonstrate this with two synthetic datasets featuring varying levels of noise, as well as two real dataset. We show that cryoSPHERE is very resilient to the high levels of noise typically encountered in experiments, where we see consistent improvements over the current state-of-the-art for heterogeneous reconstruction.
<div id='section'>Paperid: <span id='pid'>1324, <a href='https://arxiv.org/pdf/2406.19521.pdf' target='_blank'>https://arxiv.org/pdf/2406.19521.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hadeel Elayan, Samar Elmaadawy, Andrew W. Eckford, Raviraj Adve, Josep Jornet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.19521">A Thermal Study of Terahertz Induced Protein Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins can be regarded as thermal nanosensors in an intra-body network. Upon being stimulated by Terahertz (THz) frequencies that match their vibrational modes, protein molecules experience resonant absorption and dissipate their energy as heat, undergoing a thermal process. This paper aims to analyze the effect of THz signaling on the protein heat dissipation mechanism. We therefore deploy a mathematical framework based on the heat diffusion model to characterize how proteins absorb THz-electromagnetic (EM) energy from the stimulating EM fields and subsequently release this energy as heat to their immediate surroundings. We also conduct a parametric study to explain the impact of the signal power, pulse duration, and interparticle distance on the protein thermal analysis. In addition, we demonstrate the relationship between the change in temperature and the opening probability of thermally-gated ion channels. Our results indicate that a controlled temperature change can be achieved in an intra-body environment by exciting protein particles at their resonant frequencies. We further verify our results numerically using COMSOL Multiphysics and introduce an experimental framework that assesses the effects of THz radiation on protein particles. We conclude that under controlled heating, protein molecules can serve as hotspots that impact thermally-gated ion channels. Through the presented work, we infer that the heating process can be engineered on different time and length scales by controlling the THz-EM signal input.
<div id='section'>Paperid: <span id='pid'>1325, <a href='https://arxiv.org/pdf/2406.18314.pdf' target='_blank'>https://arxiv.org/pdf/2406.18314.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matan Halfon, Tomer Cohen, Raanan Fattal, Dina Schneidman-Duhovny
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.18314">ContactNet: Geometric-Based Deep Learning Model for Predicting Protein-Protein Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning approaches achieved significant progress in predicting protein structures. These methods are often applied to protein-protein interactions (PPIs) yet require Multiple Sequence Alignment (MSA) which is unavailable for various interactions, such as antibody-antigen. Computational docking methods are capable of sampling accurate complex models, but also produce thousands of invalid configurations. The design of scoring functions for identifying accurate models is a long-standing challenge. We develop a novel attention-based Graph Neural Network (GNN), ContactNet, for classifying PPI models obtained from docking algorithms into accurate and incorrect ones. When trained on docked antigen and modeled antibody structures, ContactNet doubles the accuracy of current state-of-the-art scoring functions, achieving accurate models among its Top-10 at 43% of the test cases. When applied to unbound antibodies, its Top-10 accuracy increases to 65%. This performance is achieved without MSA and the approach is applicable to other types of interactions, such as host-pathogens or general PPIs.
<div id='section'>Paperid: <span id='pid'>1326, <a href='https://arxiv.org/pdf/2406.16681.pdf' target='_blank'>https://arxiv.org/pdf/2406.16681.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yossra Gharbi, RocÃ­o Mercado
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16681">A Comprehensive Review of Emerging Approaches in Machine Learning for De Novo PROTAC Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Targeted protein degradation (TPD) is a rapidly growing field in modern drug discovery that aims to regulate the intracellular levels of proteins by harnessing the cell's innate degradation pathways to selectively target and degrade disease-related proteins. This strategy creates new opportunities for therapeutic intervention in cases where occupancy-based inhibitors have not been successful. Proteolysis-targeting chimeras (PROTACs) are at the heart of TPD strategies, which leverage the ubiquitin-proteasome system for the selective targeting and proteasomal degradation of pathogenic proteins. As the field evolves, it becomes increasingly apparent that the traditional methodologies for designing such complex molecules have limitations. This has led to the use of machine learning (ML) and generative modeling to improve and accelerate the development process. In this review, we explore the impact of ML on de novo PROTAC design $-$ an aspect of molecular design that has not been comprehensively reviewed despite its significance. We delve into the distinct characteristics of PROTAC linker design, underscoring the complexities required to create effective bifunctional molecules capable of TPD. We then examine how ML in the context of fragment-based drug design (FBDD), honed in the realm of small-molecule drug discovery, is paving the way for PROTAC linker design. Our review provides a critical evaluation of the limitations inherent in applying this method to the complex field of PROTAC development. Moreover, we review existing ML works applied to PROTAC design, highlighting pioneering efforts and, importantly, the limitations these studies face. By offering insights into the current state of PROTAC development and the integral role of ML in PROTAC design, we aim to provide valuable perspectives for researchers in their pursuit of better design strategies for this new modality.
<div id='section'>Paperid: <span id='pid'>1327, <a href='https://arxiv.org/pdf/2406.13106.pdf' target='_blank'>https://arxiv.org/pdf/2406.13106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmed Abdeen Hamed, Tamer E. Fandy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.13106">Accelerating Complex Disease Treatment through Network Medicine and GenAI: A Case Study on Drug Repurposing for Breast Cancer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The objective of this research is to introduce a network specialized in predicting drugs that can be repurposed by investigating real-world evidence sources, such as clinical trials and biomedical literature. Specifically, it aims to generate drug combination therapies for complex diseases (e.g., cancer, Alzheimer's). We present a multilayered network medicine approach, empowered by a highly configured ChatGPT prompt engineering system, which is constructed on the fly to extract drug mentions in clinical trials. Additionally, we introduce a novel algorithm that connects real-world evidence with disease-specific signaling pathways (e.g., KEGG database). This sheds light on the repurposability of drugs if they are found to bind with one or more protein constituents of a signaling pathway. To demonstrate, we instantiated the framework for breast cancer and found that, out of 46 breast cancer signaling pathways, the framework identified 38 pathways that were covered by at least two drugs. This evidence signals the potential for combining those drugs. Specifically, the most covered signaling pathway, ID hsa:2064, was covered by 108 drugs, some of which can be combined. Conversely, the signaling pathway ID hsa:1499 was covered by only two drugs, indicating a significant gap for further research. Our network medicine framework, empowered by GenAI, shows promise in identifying drug combinations with a high degree of specificity, knowing the exact signaling pathways and proteins that serve as targets. It is noteworthy that ChatGPT successfully accelerated the process of identifying drug mentions in clinical trials, though further investigations are required to determine the relationships among the drug mentions.
<div id='section'>Paperid: <span id='pid'>1328, <a href='https://arxiv.org/pdf/2406.09159.pdf' target='_blank'>https://arxiv.org/pdf/2406.09159.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Boshen Wang, Bowei Ye, Lin Xu, Jie Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09159">ALPHAGMUT: A Rationale-Guided Alpha Shape Graph Neural Network to Evaluate Mutation Effects</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In silico methods evaluating the mutation effects of missense mutations are providing an important approach for understanding mutations in personal genomes and identifying disease-relevant biomarkers. However, existing methods, including deep learning methods, heavily rely on sequence-aware information, and do not fully leverage the potential of available 3D structural information. In addition, these methods may exhibit an inability to predict mutations in domains difficult to formulate sequence-based embeddings. In this study, we introduce a novel rationale-guided graph neural network AlphaGMut to evaluate mutation effects and to distinguish pathogenic mutations from neutral mutations. We compute the alpha shapes of protein structures to obtain atomic-resolution edge connectivities and map them to an accurate residue-level graph representation. We then compute structural-, topological-, biophysical-, and sequence properties of the mutation sites, which are assigned as node attributes in the graph. These node attributes could effectively guide the graph neural network to learn the difference between pathogenic and neutral mutations using k-hop message passing with a short training period. We demonstrate that AlphaGMut outperforms state-of-the-art methods, including DeepMind's AlphaMissense, in many performance metrics. In addition, AlphaGMut has the advantage of performing well in alignment-free settings, which provides broader prediction coverage and better generalization compared to current methods requiring deep sequence-aware information.
<div id='section'>Paperid: <span id='pid'>1329, <a href='https://arxiv.org/pdf/2406.04519.pdf' target='_blank'>https://arxiv.org/pdf/2406.04519.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eirini Katsidoniotaki, Biao Su, Eleni Kelasidi, Themistoklis P. Sapsis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04519">Multifidelity digital twin for real-time monitoring of structural dynamics in aquaculture net cages</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As the global population grows and climate change intensifies, sustainable food production is critical. Marine aquaculture offers a viable solution, providing a sustainable protein source. However, the industry's expansion requires novel technologies for remote management and autonomous operations. Digital twin technology can advance the aquaculture industry, but its adoption has been limited. Fish net cages, which are flexible floating structures, are critical yet vulnerable components of aquaculture farms. Exposed to harsh and dynamic marine environments, the cages experience significant loads and risk damage, leading to fish escapes, environmental impacts, and financial losses. We propose a multifidelity surrogate modeling framework for integration into a digital twin for real-time monitoring of aquaculture net cage structural dynamics under stochastic marine conditions. Central to this framework is the nonlinear autoregressive Gaussian process method, which learns complex, nonlinear cross-correlations between models of varying fidelity. It combines low-fidelity simulation data with a small set of high-fidelity field sensor measurements, which offer the real dynamics but are costly and spatially sparse. Validated at the SINTEF ACE fish farm in Norway, our digital twin receives online metocean data and accurately predicts net cage displacements and mooring line loads, aligning closely with field measurements. The proposed framework is beneficial where application-specific data are scarce, offering rapid predictions and real-time system representation. The developed digital twin prevents potential damages by assessing structural integrity and facilitates remote operations with unmanned underwater vehicles. Our work also compares GP and GCNs for predicting net cage deformation, highlighting the latter's effectiveness in complex structural applications.
<div id='section'>Paperid: <span id='pid'>1330, <a href='https://arxiv.org/pdf/2406.03103.pdf' target='_blank'>https://arxiv.org/pdf/2406.03103.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dawid Zamojski, Agnieszka Gogler, Dorota Scieglinska, Michal Marczyk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03103">EpidermaQuant: Unsupervised detection and quantification of epidermal differentiation markers on H-DAB-stained images of reconstructed human epidermis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The integrity of the reconstructed human epidermis generated in vitro could be assessed using histological analyses combined with immunohistochemical staining of keratinocyte differentiation markers. Computer-based analysis of scanned tissue saves the expert time and may improve the accuracy of quantification by eliminating interrater reliability issues. However, technical differences during the preparation and capture of stained images and the presence of multiple artifacts may influence the outcome of computational methods. Using a dataset with 598 unannotated images showing cross-sections of in vitro reconstructed human epidermis stained with DAB-based immunohistochemistry reaction to visualize 4 different keratinocyte differentiation marker proteins (filaggrin, keratin 10, Ki67, HSPA2) and counterstained with hematoxylin, we developed an unsupervised method for the detection and quantification of immunohistochemical staining. The proposed pipeline includes the following steps: (i) color normalization to reduce the variability of pixel intensity values in different samples; (ii) color deconvolution to acquire color channels of the stains used; (iii) morphological operations to find the background area of the image; (iv) automatic image rotation; and (v) finding markers of human epidermal differentiation with clustering. Also, we created a method to exclude images without DAB-stained areas. The most effective combination of methods includes: (i) Reinhard's normalization; (ii) Ruifrok and Johnston color deconvolution method; (iii) proposed image rotation method based on boundary distribution of image intensity; (iv) k-means clustering using DAB stain intensity. These results should enhance the performance of quantitative analysis of protein markers in reconstructed human epidermis samples and enable comparison of their spatial distribution between different experimental conditions.
<div id='section'>Paperid: <span id='pid'>1331, <a href='https://arxiv.org/pdf/2406.01651.pdf' target='_blank'>https://arxiv.org/pdf/2406.01651.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhaohan Meng, Zaiqiao Meng, Ke Yuan, Iadh Ounis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01651">FusionDTI: Fine-grained Binding Discovery with Token-level Fusion for Drug-Target Interaction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting drug-target interaction (DTI) is critical in the drug discovery process. Despite remarkable advances in recent DTI models through the integration of representations from diverse drug and target encoders, such models often struggle to capture the fine-grained interactions between drugs and protein, i.e. the binding of specific drug atoms (or substructures) and key amino acids of proteins, which is crucial for understanding the binding mechanisms and optimising drug design. To address this issue, this paper introduces a novel model, called FusionDTI, which uses a token-level Fusion module to effectively learn fine-grained information for Drug-Target Interaction. In particular, our FusionDTI model uses the SELFIES representation of drugs to mitigate sequence fragment invalidation and incorporates the structure-aware (SA) vocabulary of target proteins to address the limitation of amino acid sequences in structural information, additionally leveraging pre-trained language models extensively trained on large-scale biomedical datasets as encoders to capture the complex information of drugs and targets. Experiments on three well-known benchmark datasets show that our proposed FusionDTI model achieves the best performance in DTI prediction compared with seven existing state-of-the-art baselines. Furthermore, our case study indicates that FusionDTI could highlight the potential binding sites, enhancing the explainability of the DTI prediction.
<div id='section'>Paperid: <span id='pid'>1332, <a href='https://arxiv.org/pdf/2405.16179.pdf' target='_blank'>https://arxiv.org/pdf/2405.16179.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elisenda Feliu, Nidhi Kaihnsa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16179">Network reduction and absence of Hopf Bifurcations in dual phosphorylation networks with three Intermediates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Phosphorylation networks, representing the mechanisms by which proteins are phosphorylated at one or multiple sites, are ubiquitous in cell signalling and display rich dynamics such as unlimited multistability. Dual-site phosphorylation networks are known to exhibit oscillations in the form of periodic trajectories, when phosphorylation and dephosphorylation occurs as a mixed mechanism: phosphorylation of the two sites requires one encounter of the kinase, while dephosphorylation of the two sites requires two encounters with the phosphatase. A still open question is whether a mechanism requiring two encounters for both phosphorylation and dephosphorylation also admits oscillations. In this work we provide evidence in favor of the absence of oscillations of this network by precluding Hopf bifurcations in any reduced network comprising three out of its four intermediate protein complexes. Our argument relies on a novel network reduction step that preserves the absence of Hopf bifurcations, and on a detailed analysis of the semi-algebraic conditions precluding Hopf bifurcations obtained from Hurwitz determinants of the characteristic polynomial of the Jacobian of the system. We conjecture that the removal of certain reverse reactions appearing in Michaelis-Menten-type mechanisms does not have an impact on the presence or absence of Hopf bifurcations. We prove an implication of the conjecture under certain favorable scenarios and support the conjecture with additional example-based evidence.
<div id='section'>Paperid: <span id='pid'>1333, <a href='https://arxiv.org/pdf/2405.09788.pdf' target='_blank'>https://arxiv.org/pdf/2405.09788.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabian Offert, Paul Kim, Qiaoyu Cai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.09788">Synthesizing Proteins on the Graphics Card. Protein Folding and the Limits of Critical AI Studies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates the application of the transformer architecture in protein folding, as exemplified by DeepMind's AlphaFold project, and its implications for the understanding of so-called large language models. The prevailing discourse often assumes a ready-made analogy between proteins, encoded as sequences of amino acids, and natural language, which we term the language paradigm of computational (structural) biology. Instead of assuming this analogy as given, we critically evaluate it to assess the kind of knowledge-making afforded by the transformer architecture. We first trace the analogy's emergence and historical development, carving out the influence of structural linguistics on structural biology beginning in the mid-20th century. We then examine three often overlooked preprocessing steps essential to the transformer architecture, including subword tokenization, word embedding, and positional encoding, to demonstrate its regime of representation based on continuous, high-dimensional vector spaces, which departs from the discrete nature of language. The successful deployment of transformers in protein folding, we argue, discloses what we consider a non-linguistic approach to token processing intrinsic to the architecture. We contend that through this non-linguistic processing, the transformer architecture carves out unique epistemological territory and produces a new class of knowledge, distinct from established domains. We contend that our search for intelligent machines has to begin with the shape, rather than the place, of intelligence. Consequently, the emerging field of critical AI studies should take methodological inspiration from the history of science in its quest to conceptualize the contributions of artificial intelligence to knowledge-making, within and beyond the domain-specific sciences.
<div id='section'>Paperid: <span id='pid'>1334, <a href='https://arxiv.org/pdf/2405.06836.pdf' target='_blank'>https://arxiv.org/pdf/2405.06836.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Salma J. Ahmed, Emad A. Mohammed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06836">Improving Targeted Molecule Generation through Language Model Fine-Tuning Via Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing new drugs is laborious and costly, demanding extensive time investment. In this paper, we introduce a de-novo drug design strategy, which harnesses the capabilities of language models to devise targeted drugs for specific proteins. Employing a Reinforcement Learning (RL) framework utilizing Proximal Policy Optimization (PPO), we refine the model to acquire a policy for generating drugs tailored to protein targets. The proposed method integrates a composite reward function, combining considerations of drug-target interaction and molecular validity. Following RL fine-tuning, the proposed method demonstrates promising outcomes, yielding notable improvements in molecular validity, interaction efficacy, and critical chemical properties, achieving 65.37 for Quantitative Estimation of Drug-likeness (QED), 321.55 for Molecular Weight (MW), and 4.47 for Octanol-Water Partition Coefficient (logP), respectively. Furthermore, out of the generated drugs, only 0.041% do not exhibit novelty.
<div id='section'>Paperid: <span id='pid'>1335, <a href='https://arxiv.org/pdf/2405.06663.pdf' target='_blank'>https://arxiv.org/pdf/2405.06663.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eunji Ko, Seul Lee, Minseon Kim, Dongki Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06663">Protein Representation Learning by Capturing Protein Sequence-Structure-Function Relationship</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of protein representation learning is to extract knowledge from protein databases that can be applied to various protein-related downstream tasks. Although protein sequence, structure, and function are the three key modalities for a comprehensive understanding of proteins, existing methods for protein representation learning have utilized only one or two of these modalities due to the difficulty of capturing the asymmetric interrelationships between them. To account for this asymmetry, we introduce our novel asymmetric multi-modal masked autoencoder (AMMA). AMMA adopts (1) a unified multi-modal encoder to integrate all three modalities into a unified representation space and (2) asymmetric decoders to ensure that sequence latent features reflect structural and functional information. The experiments demonstrate that the proposed AMMA is highly effective in learning protein representations that exhibit well-aligned inter-modal relationships, which in turn makes it effective for various downstream protein-related tasks.
<div id='section'>Paperid: <span id='pid'>1336, <a href='https://arxiv.org/pdf/2405.06511.pdf' target='_blank'>https://arxiv.org/pdf/2405.06511.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yonghan Yu, Ming Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06511">Towards Less Biased Data-driven Scoring with Deep Learning-Based End-to-end Database Search in Tandem Mass Spectrometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Peptide identification in mass spectrometry-based proteomics is crucial for understanding protein function and dynamics. Traditional database search methods, though widely used, rely on heuristic scoring functions and statistical estimations have to be introduced for a higher identification rate. Here, we introduce DeepSearch, the first deep learning-based end-to-end database search method for tandem mass spectrometry. DeepSearch leverages a modified transformer-based encoder-decoder architecture under the contrastive learning framework. Unlike conventional methods that rely on ion-to-ion matching, DeepSearch adopts a data-driven approach to score peptide spectrum matches. DeepSearch is also the first deep learning-based method that can profile variable post-translational modifications in a zero-shot manner. We showed that DeepSearch's scoring scheme expressed less bias and did not require any statistical estimation. We validated DeepSearch's accuracy and robustness across various datasets, including those from species with diverse protein compositions and a modification-enriched dataset. DeepSearch sheds new light on database search methods in tandem mass spectrometry.
<div id='section'>Paperid: <span id='pid'>1337, <a href='https://arxiv.org/pdf/2405.05167.pdf' target='_blank'>https://arxiv.org/pdf/2405.05167.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vanni Doffini, O. Anatole von Lilienfeld, Michael A. Nash
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.05167">Data-Error Scaling in Machine Learning on Natural Discrete Combinatorial Mutation-prone Sets: Case Studies on Peptides and Small Molecules</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate trends in the data-error scaling behavior of machine learning (ML) models trained on discrete combinatorial spaces that are prone-to-mutation, such as proteins or organic small molecules. We trained and evaluated kernel ridge regression machines using variable amounts of computationally generated training data. Our synthetic datasets comprise i) two naÃ¯ve functions based on many-body theory; ii) binding energy estimates between a protein and a mutagenised peptide; and iii) solvation energies of two 6-heavy atom structural graphs. In contrast to typical data-error scaling, our results showed discontinuous monotonic phase transitions during learning, observed as rapid drops in the test error at particular thresholds of training data. We observed two learning regimes, which we call saturated and asymptotic decay, and found that they are conditioned by the level of complexity (i.e. number of mutations) enclosed in the training set. We show that during training on this class of problems, the predictions were clustered by the ML models employed in the calibration plots. Furthermore, we present an alternative strategy to normalize learning curves (LCs) and the concept of mutant based shuffling. This work has implications for machine learning on mutagenisable discrete spaces such as chemical properties or protein phenotype prediction, and improves basic understanding of concepts in statistical learning theory.
<div id='section'>Paperid: <span id='pid'>1338, <a href='https://arxiv.org/pdf/2405.01983.pdf' target='_blank'>https://arxiv.org/pdf/2405.01983.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Frederic Renard, Cyprien Courtot, Alfredo Reichlin, Oliver Bent
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01983">Model-based reinforcement learning for protein backbone design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing protein nanomaterials of predefined shape and characteristics has the potential to dramatically impact the medical industry. Machine learning (ML) has proven successful in protein design, reducing the need for expensive wet lab experiment rounds. However, challenges persist in efficiently exploring the protein fitness landscapes to identify optimal protein designs. In response, we propose the use of AlphaZero to generate protein backbones, meeting shape and structural scoring requirements. We extend an existing Monte Carlo tree search (MCTS) framework by incorporating a novel threshold-based reward and secondary objectives to improve design precision. This innovation considerably outperforms existing approaches, leading to protein backbones that better respect structural scores. The application of AlphaZero is novel in the context of protein backbone design and demonstrates promising performance. AlphaZero consistently surpasses baseline MCTS by more than 100% in top-down protein design tasks. Additionally, our application of AlphaZero with secondary objectives uncovers further promising outcomes, indicating the potential of model-based reinforcement learning (RL) in navigating the intricate and nuanced aspects of protein design
<div id='section'>Paperid: <span id='pid'>1339, <a href='https://arxiv.org/pdf/2405.00283.pdf' target='_blank'>https://arxiv.org/pdf/2405.00283.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel A. Isaacson, Ying Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.00283">An Unstructured Mesh Reaction-Drift-Diffusion Master Equation with Reversible Reactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a convergent reaction-drift-diffusion master equation (CRDDME) to facilitate the study of reaction processes in which spatial transport is influenced by drift due to one-body potential fields within general domain geometries. The generalized CRDDME is obtained through two steps. We first derive an unstructured grid jump process approximation for reversible diffusions, enabling the simulation of drift-diffusion processes where the drift arises due to a conservative field that biases particle motion. Leveraging the Edge-Averaged Finite Element method, our approach preserves detailed balance of drift-diffusion fluxes at equilibrium, and preserves an equilibrium Gibbs-Boltzmann distribution for particles undergoing drift-diffusion on the unstructured mesh. We next formulate a spatially-continuous volume reactivity particle-based reaction-drift-diffusion model for reversible reactions of the form $\textrm{A} + \textrm{B} \leftrightarrow \textrm{C}$. A finite volume discretization is used to generate jump process approximations to reaction terms in this model. The discretization is developed to ensure the combined reaction-drift-diffusion jump process approximation is consistent with detailed balance of reaction fluxes holding at equilibrium, along with supporting a discrete version of the continuous equilibrium state. The new CRDDME model represents a continuous-time discrete-space jump process approximation to the underlying volume reactivity model. We demonstrate the convergence and accuracy of the new CRDDME through a number of numerical examples, and illustrate its use on an idealized model for membrane protein receptor dynamics in T cell signaling.
<div id='section'>Paperid: <span id='pid'>1340, <a href='https://arxiv.org/pdf/2404.17954.pdf' target='_blank'>https://arxiv.org/pdf/2404.17954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giorgos Kritikakis, Ioannis G Tollis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17954">Parameterized Linear Time Transitive Closure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inquiries such as whether a task A depends on a task B, whether an author A has been influenced by a paper B, whether a certain protein is associated with a specific biological process or molecular function, or whether class A inherits from class B, are just a few examples of inquiries that can be modeled as reachability queries on a network (Directed Graph). Digital systems answer myriad such inquiries every day.
  In this paper, we discuss the transitive closure problem. We focus on applicable solutions that enable us to answer queries fast, in constant time, and can serve in real-world applications. In contrast to the majority of research on this topic that revolves around the construction of a two-dimensional adjacency matrix, we present an approach that builds a reachability indexing scheme. This scheme enables us to answer queries in constant time and can be built in parameterized linear time. In addition, it captures a compressed data structure. Our approach and algorithms are validated by extensive experiments that shed light on the factors that play a key role in this problem. To stress the efficiency of this solution and demonstrate the potential to apply our approach to important problems, we use it to speed up Fulkerson's method for finding the width of a DAG. Our results challenge the prevailing belief, reiterated over the last thirty years, regarding the efficiency of this method.
  Our approach is based on the concept of chain decomposition. Before we delve into its description, we introduce, analyze, and utilize a chain decomposition algorithm. Furthermore, we explore how chain decomposition can facilitate transitive closure solutions introducing a general purpose linear time reduction technique that removes a large subset of transitive edges given any chain decomposition.
<div id='section'>Paperid: <span id='pid'>1341, <a href='https://arxiv.org/pdf/2404.16911.pdf' target='_blank'>https://arxiv.org/pdf/2404.16911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniele Angioletti, Stefano Raniolo, Vittorio Limongelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.16911">HEroBM: a deep equivariant graph neural network for universal backmapping from coarse-grained to all-atom representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular simulations have assumed a paramount role in the fields of chemistry, biology, and material sciences, being able to capture the intricate dynamic properties of systems. Within this realm, coarse-grained (CG) techniques have emerged as invaluable tools to sample large-scale systems and reach extended timescales by simplifying system representation. However, CG approaches come with a trade-off: they sacrifice atomistic details that might hold significant relevance in deciphering the investigated process. Therefore, a recommended approach is to identify key CG conformations and process them using backmapping methods, which retrieve atomistic coordinates. Currently, rule-based methods yield subpar geometries and rely on energy relaxation, resulting in less-than-optimal outcomes. Conversely, machine learning techniques offer higher accuracy but are either limited in transferability between systems or tied to specific CG mappings. In this work, we introduce HEroBM, a dynamic and scalable method that employs deep equivariant graph neural networks and a hierarchical approach to achieve high-resolution backmapping. HEroBM handles any type of CG mapping, offering a versatile and efficient protocol for reconstructing atomistic structures with high accuracy. Focused on local principles, HEroBM spans the entire chemical space and is transferable to systems of varying sizes. We illustrate the versatility of our framework through diverse biological systems, including a complex real-case scenario. Here, our end-to-end backmapping approach accurately generates the atomistic coordinates of a G protein-coupled receptor bound to an organic small molecule within a cholesterol/phospholipid bilayer.
<div id='section'>Paperid: <span id='pid'>1342, <a href='https://arxiv.org/pdf/2404.11068.pdf' target='_blank'>https://arxiv.org/pdf/2404.11068.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Feiwen Zhu, Arkadiusz Nowaczynski, Rundong Li, Jie Xin, Yifei Song, Michal Marcinkiewicz, Sukru Burc Eryilmaz, Jun Yang, Michael Andersch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.11068">ScaleFold: Reducing AlphaFold Initial Training Time to 10 Hours</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AlphaFold2 has been hailed as a breakthrough in protein folding. It can rapidly predict protein structures with lab-grade accuracy. However, its implementation does not include the necessary training code. OpenFold is the first trainable public reimplementation of AlphaFold. AlphaFold training procedure is prohibitively time-consuming, and gets diminishing benefits from scaling to more compute resources. In this work, we conducted a comprehensive analysis on the AlphaFold training procedure based on Openfold, identified that inefficient communications and overhead-dominated computations were the key factors that prevented the AlphaFold training from effective scaling. We introduced ScaleFold, a systematic training method that incorporated optimizations specifically for these factors. ScaleFold successfully scaled the AlphaFold training to 2080 NVIDIA H100 GPUs with high resource utilization. In the MLPerf HPC v3.0 benchmark, ScaleFold finished the OpenFold benchmark in 7.51 minutes, shown over $6\times$ speedup than the baseline. For training the AlphaFold model from scratch, ScaleFold completed the pretraining in 10 hours, a significant improvement over the seven days required by the original AlphaFold pretraining baseline.
<div id='section'>Paperid: <span id='pid'>1343, <a href='https://arxiv.org/pdf/2404.08108.pdf' target='_blank'>https://arxiv.org/pdf/2404.08108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Krzysztof Kotowski, Irena Roterman, Katarzyna Stapor
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08108">DisorderUnetLM: Validating ProteinUnet for efficient protein intrinsic disorder prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The prediction of intrinsic disorder regions has significant implications for understanding protein functions and dynamics. It can help to discover novel protein-protein interactions essential for designing new drugs and enzymes. Recently, a new generation of predictors based on protein language models (pLMs) is emerging. These algorithms reach state-of-the-art accuracy with-out calculating time-consuming multiple sequence alignments (MSAs). The article introduces the new DisorderUnetLM disorder predictor, which builds upon the idea of ProteinUnet. It uses the Attention U-Net convolutional neural network and incorporates features from the ProtTrans pLM. DisorderUnetLM achieves top results in the direct comparison with recent predictors exploiting MSAs and pLMs. Moreover, among 43 predictors from the latest CAID-2 benchmark, it ranks 1st for the Disorder-NOX subset (ROC-AUC of 0.844) and 10th for the Disorder-PDB subset (ROC-AUC of 0.924). The code and model are publicly available and fully reproducible at doi.org/10.24433/CO.7350682.v1.
<div id='section'>Paperid: <span id='pid'>1344, <a href='https://arxiv.org/pdf/2403.14983.pdf' target='_blank'>https://arxiv.org/pdf/2403.14983.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junya Wang, Yi-Jiao Zhang, Cong Xu, Jiaze Li, Jiachen Sun, Jiarong Xie, Ling Feng, Tianshou Zhou, Yanqing Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14983">Reconstructing the evolution history of networked complex systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The evolution processes of complex systems carry key information in the systems' functional properties. Applying machine learning algorithms, we demonstrate that the historical formation process of various networked complex systems can be extracted, including protein-protein interaction, ecology, and social network systems. The recovered evolution process has demonstrations of immense scientific values, such as interpreting the evolution of protein-protein interaction network, facilitating structure prediction, and particularly revealing the key co-evolution features of network structures such as preferential attachment, community structure, local clustering, degree-degree correlation that could not be explained collectively by previous theories. Intriguingly, we discover that for large networks, if the performance of the machine learning model is slightly better than a random guess on the pairwise order of links, reliable restoration of the overall network formation process can be achieved. This suggests that evolution history restoration is generally highly feasible on empirical networks.
<div id='section'>Paperid: <span id='pid'>1345, <a href='https://arxiv.org/pdf/2403.08797.pdf' target='_blank'>https://arxiv.org/pdf/2403.08797.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>James S. L. Browning, Daniel R. Tauritz, John Beckmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.08797">Evolutionary Algorithms Simulating Molecular Evolution: A New Field Proposal</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The genetic blueprint for the essential functions of life is encoded in DNA, which is translated into proteins -- the engines driving most of our metabolic processes. Recent advancements in genome sequencing have unveiled a vast diversity of protein families, but compared to the massive search space of all possible amino acid sequences, the set of known functional families is minimal. One could say nature has a limited protein "vocabulary." The major question for computational biologists, therefore, is whether this vocabulary can be expanded to include useful proteins that went extinct long ago, or maybe never evolved in the first place. We outline a computational approach to solving this problem. By merging evolutionary algorithms, machine learning (ML), and bioinformatics, we can facilitate the development of completely novel proteins which have never existed before. We envision this work forming a new sub-field of computational evolution we dub evolutionary algorithms simulating molecular evolution (EASME).
<div id='section'>Paperid: <span id='pid'>1346, <a href='https://arxiv.org/pdf/2403.07925.pdf' target='_blank'>https://arxiv.org/pdf/2403.07925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David C. Williams, Neil Inala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.07925">Physics-informed generative model for drug-like molecule conformers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a diffusion-based, generative model for conformer generation. Our model is focused on the reproduction of bonded structure and is constructed from the associated terms traditionally found in classical force fields to ensure a physically relevant representation. Techniques in deep learning are used to infer atom typing and geometric parameters from a training set. Conformer sampling is achieved by taking advantage of recent advancements in diffusion-based generation. By training on large, synthetic data sets of diverse, drug-like molecules optimized with the semiempirical GFN2-xTB method, high accuracy is achieved for bonded parameters, exceeding that of conventional, knowledge-based methods. Results are also compared to experimental structures from the Protein Databank (PDB) and Cambridge Structural Database (CSD).
<div id='section'>Paperid: <span id='pid'>1347, <a href='https://arxiv.org/pdf/2403.04395.pdf' target='_blank'>https://arxiv.org/pdf/2403.04395.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhaoqun Li, Jingcheng Yu, Qiwei Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.04395">SGNet: Folding Symmetrical Protein Complex with Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has made significant progress in protein structure prediction, advancing the development of computational biology. However, despite the high accuracy achieved in predicting single-chain structures, a significant number of large homo-oligomeric assemblies exhibit internal symmetry, posing a major challenge in structure determination. The performances of existing deep learning methods are limited since the symmetrical protein assembly usually has a long sequence, making structural computation infeasible. In addition, multiple identical subunits in symmetrical protein complex cause the issue of supervision ambiguity in label assignment, requiring a consistent structure modeling for the training. To tackle these problems, we propose a protein folding framework called SGNet to model protein-protein interactions in symmetrical assemblies. SGNet conducts feature extraction on a single subunit and generates the whole assembly using our proposed symmetry module, which largely mitigates computational problems caused by sequence length. Thanks to the elaborate design of modeling symmetry consistently, we can model all global symmetry types in quaternary protein structure prediction. Extensive experimental results on a benchmark of symmetrical protein complexes further demonstrate the effectiveness of our method.
<div id='section'>Paperid: <span id='pid'>1348, <a href='https://arxiv.org/pdf/2403.04187.pdf' target='_blank'>https://arxiv.org/pdf/2403.04187.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pouria Mistani, Venkatesh Mysore
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.04187">Preference optimization of protein language models as a multi-objective binder design paradigm</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a multi-objective binder design paradigm based on instruction fine-tuning and direct preference optimization (DPO) of autoregressive protein language models (pLMs). Multiple design objectives are encoded in the language model through direct optimization on expert curated preference sequence datasets comprising preferred and dispreferred distributions. We show the proposed alignment strategy enables ProtGPT2 to effectively design binders conditioned on specified receptors and a drug developability criterion. Generated binder samples demonstrate median isoelectric point (pI) improvements by $17\%-60\%$.
<div id='section'>Paperid: <span id='pid'>1349, <a href='https://arxiv.org/pdf/2403.00306.pdf' target='_blank'>https://arxiv.org/pdf/2403.00306.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saurav Dhar, Amlan Saha, Dhiman Goswami, Md. Abul Kashem Mia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.00306">qPMS Sigma -- An Efficient and Exact Parallel Algorithm for the Planted $(l, d)$ Motif Search Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motif finding is an important step for the detection of rare events occurring in a set of DNA or protein sequences. Extraction of information about these rare events can lead to new biological discoveries. Motifs are some important patterns that have numerous applications including the identification of transcription factors and their binding sites, composite regulatory patterns, similarity between families of proteins, etc. Although several flavors of motif searching algorithms have been studied in the literature, we study the version known as $ (l, d) $-motif search or Planted Motif Search (PMS). In PMS, given two integers $ l $, $ d $ and $ n $ input sequences we try to find all the patterns of length $ l $ that appear in each of the $ n $ input sequences with at most $ d $ mismatches. We also discuss the quorum version of PMS in our work that finds motifs that are not planted in all the input sequences but at least in $ q $ of the sequences. Our algorithm is mainly based on the algorithms qPMSPrune, qPMS7, TraverStringRef and PMS8. We introduce some techniques to compress the input strings and make faster comparison between strings with bitwise operations. Our algorithm performs a little better than the existing exact algorithms to solve the qPMS problem in DNA sequence. We have also proposed an idea for parallel implementation of our algorithm.
<div id='section'>Paperid: <span id='pid'>1350, <a href='https://arxiv.org/pdf/2403.00043.pdf' target='_blank'>https://arxiv.org/pdf/2403.00043.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rafael Josip PeniÄ, Tin VlaÅ¡iÄ, Roland G. Huber, Yue Wan, Mile Å ikiÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.00043">RiNALMo: General-Purpose RNA Language Models Can Generalize Well on Structure Prediction Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While RNA has recently been recognized as an interesting small-molecule drug target, many challenges remain to be addressed before we take full advantage of it. This emphasizes the necessity to improve our understanding of its structures and functions. Over the years, sequencing technologies have produced an enormous amount of unlabeled RNA data, which hides a huge potential. Motivated by the successes of protein language models, we introduce RiboNucleic Acid Language Model (RiNALMo) to unveil the hidden code of RNA. RiNALMo is the largest RNA language model to date, with 650M parameters pre-trained on 36M non-coding RNA sequences from several databases. It can extract hidden knowledge and capture the underlying structure information implicitly embedded within the RNA sequences. RiNALMo achieves state-of-the-art results on several downstream tasks. Notably, we show that its generalization capabilities overcome the inability of other deep learning methods for secondary structure prediction to generalize on unseen RNA families.
<div id='section'>Paperid: <span id='pid'>1351, <a href='https://arxiv.org/pdf/2402.13653.pdf' target='_blank'>https://arxiv.org/pdf/2402.13653.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eli M Carrami, Sahand Sharifzadeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.13653">PQA: Zero-shot Protein Question Answering for Free-form Scientific Enquiry with Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding protein structure and function is crucial in biology. However, current computational methods are often task-specific and resource-intensive. To address this, we propose zero-shot Protein Question Answering (PQA), a task designed to answer a wide range of protein-related queries without task-specific training. The success of PQA hinges on high-quality datasets and robust evaluation strategies, both of which are lacking in current research. Existing datasets suffer from biases, noise, and lack of evolutionary context, while current evaluation methods fail to accurately assess model performance. We introduce the Pika framework to overcome these limitations. Pika comprises a curated, debiased dataset tailored for PQA and a biochemically relevant benchmarking strategy. We also propose multimodal large language models as a strong baseline for PQA, leveraging their natural language processing and knowledge. This approach promises a more flexible and efficient way to explore protein properties, advancing protein research. Our comprehensive PQA framework, Pika, including dataset, code, and model checkpoints, is openly accessible on github.com/EMCarrami/Pika, promoting wider research in the field.
<div id='section'>Paperid: <span id='pid'>1352, <a href='https://arxiv.org/pdf/2402.07148.pdf' target='_blank'>https://arxiv.org/pdf/2402.07148.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eric L. Buehler, Markus J. Buehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07148">X-LoRA: Mixture of Low-Rank Adapter Experts, a Flexible Framework for Large Language Models with Applications in Protein Mechanics and Molecular Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We report a mixture of expert strategy to create fine-tuned large language models using a deep layer-wise token-level approach based on low-rank adaptation (LoRA). Starting with a set of pre-trained LoRA adapters, our gating strategy uses the hidden states to dynamically mix adapted layers, allowing the resulting X-LoRA model to draw upon different capabilities and create never-before-used deep layer-wise combinations to solve tasks. The design is inspired by the biological principles of universality and diversity, where neural network building blocks are reused in different hierarchical manifestations. Hence, the X-LoRA model can be easily implemented for any existing large language model (LLM) without a need for modifications of the underlying structure. We develop a tailored X-LoRA model that offers scientific capabilities including forward/inverse analysis tasks and enhanced reasoning capability, focused on biomaterial analysis, protein mechanics and design. The impact of this work include access to readily expandable and adaptable models with strong domain knowledge and the capability to integrate across areas of knowledge. Featuring experts in biology, mathematics, reasoning, bio-inspired materials, mechanics and materials, chemistry, protein biophysics, mechanics and quantum-mechanics based molecular properties, we conduct a series of physics-focused case studies. We examine knowledge recall, protein mechanics forward/inverse tasks, protein design, adversarial agentic modeling including ontological knowledge graph construction, as well as molecular design. The model is capable not only of making quantitative predictions of nanomechanical properties of proteins or quantum mechanical molecular properties, but also reasons over the results and correctly predicts likely mechanisms that explain distinct molecular behaviors.
<div id='section'>Paperid: <span id='pid'>1353, <a href='https://arxiv.org/pdf/2402.05953.pdf' target='_blank'>https://arxiv.org/pdf/2402.05953.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ji Hwan Park, Vikash Prasad, Sydney Newsom, Fares Najar, Rakhi Rajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.05953">idMotif: An Interactive Motif Identification in Protein Sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This article introduces idMotif, a visual analytics framework designed to aid domain experts in the identification of motifs within protein sequences. Motifs, short sequences of amino acids, are critical for understanding the distinct functions of proteins. Identifying these motifs is pivotal for predicting diseases or infections. idMotif employs a deep learning-based method for the categorization of protein sequences, enabling the discovery of potential motif candidates within protein groups through local explanations of deep learning model decisions. It offers multiple interactive views for the analysis of protein clusters or groups and their sequences. A case study, complemented by expert feedback, illustrates idMotif's utility in facilitating the analysis and identification of protein sequences and motifs.
<div id='section'>Paperid: <span id='pid'>1354, <a href='https://arxiv.org/pdf/2402.04268.pdf' target='_blank'>https://arxiv.org/pdf/2402.04268.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Ghafarollahi, M. J. Buehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.04268">ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing de novo proteins beyond those found in nature holds significant promise for advancements in both scientific and engineering applications. Current methodologies for protein design often rely on AI-based models, such as surrogate models that address end-to-end problems by linking protein structure to material properties or vice versa. However, these models frequently focus on specific material objectives or structural properties, limiting their flexibility when incorporating out-of-domain knowledge into the design process or comprehensive data analysis is required. In this study, we introduce ProtAgents, a platform for de novo protein design based on Large Language Models (LLMs), where multiple AI agents with distinct capabilities collaboratively address complex tasks within a dynamic environment. The versatility in agent development allows for expertise in diverse domains, including knowledge retrieval, protein structure analysis, physics-based simulations, and results analysis. The dynamic collaboration between agents, empowered by LLMs, provides a versatile approach to tackling protein design and analysis problems, as demonstrated through diverse examples in this study. The problems of interest encompass designing new proteins, analyzing protein structures and obtaining new first-principles data -- natural vibrational frequencies -- via physics simulations. The concerted effort of the system allows for powerful automated and synergistic design of de novo proteins with targeted mechanical properties. The flexibility in designing the agents, on one hand, and their capacity in autonomous collaboration through the dynamic LLM-based multi-agent environment on the other hand, unleashes great potentials of LLMs in addressing multi-objective materials problems and opens up new avenues for autonomous materials discovery and design.
<div id='section'>Paperid: <span id='pid'>1355, <a href='https://arxiv.org/pdf/2402.03946.pdf' target='_blank'>https://arxiv.org/pdf/2402.03946.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Busra Senderin, Nurcan Tuncbag, Elif Surer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03946">BioNet-XR: Biological Network Visualization Framework for Virtual Reality and Mixed Reality Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interaction networks (PPIN) enable the study of cellular processes in organisms. Visualizing PPINs in extended reality (XR), including virtual reality (VR) and mixed reality (MR), is crucial for exploring subnetworks, evaluating protein positions, and collaboratively analyzing and discussing on networks with the help of recent technological advancements. Here, we present BioNet-XR, a 3D visualization framework, to visualize PPINs in VR and MR environments. BioNet-XR was developed with the Unity3D game engine. Our framework provides state-of-the-art methods and visualization features including teleportation between nodes, general and first-person view to explore the network, subnetwork construction via PageRank, Steiner tree, and all-pair shortest path algorithms for a given set of initial nodes. We used usability tests to gather feedback from both specialists (bioinformaticians) and generalists (multidisciplinary groups), addressing the need for usability evaluations of visualization tools. In the MR version of BioNet-XR, users can seamlessly transition to real-world environments and interact with protein interaction networks. BioNet-XR is highly modular and adaptable for visualization of other biological networks, such as metabolic and regulatory networks, and extension with additional network methods.
<div id='section'>Paperid: <span id='pid'>1356, <a href='https://arxiv.org/pdf/2402.01829.pdf' target='_blank'>https://arxiv.org/pdf/2402.01829.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shreyas V, Swati Agarwal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01829">Predicting ATP binding sites in protein sequences using Deep Learning and Natural Language Processing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting ATP-Protein Binding sites in genes is of great significance in the field of Biology and Medicine. The majority of research in this field has been conducted through time- and resource-intensive 'wet experiments' in laboratories. Over the years, researchers have been investigating computational methods computational methods to accomplish the same goals, utilising the strength of advanced Deep Learning and NLP algorithms. In this paper, we propose to develop methods to classify ATP-Protein binding sites. We conducted various experiments mainly using PSSMs and several word embeddings as features. We used 2D CNNs and LightGBM classifiers as our chief Deep Learning Algorithms. The MP3Vec and BERT models have also been subjected to testing in our study. The outcomes of our experiments demonstrated improvement over the state-of-the-art benchmarks.
<div id='section'>Paperid: <span id='pid'>1357, <a href='https://arxiv.org/pdf/2401.10211.pdf' target='_blank'>https://arxiv.org/pdf/2401.10211.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhengyi Li, Menglu Li, Lida Zhu, Wen Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.10211">Improving PTM Site Prediction by Coupling of Multi-Granularity Structure and Multi-Scale Sequence Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein post-translational modification (PTM) site prediction is a fundamental task in bioinformatics. Several computational methods have been developed to predict PTM sites. However, existing methods ignore the structure information and merely utilize protein sequences. Furthermore, designing a more fine-grained structure representation learning method is urgently needed as PTM is a biological event that occurs at the atom granularity. In this paper, we propose a PTM site prediction method by Coupling of Multi-Granularity structure and Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically, multigranularity structure-aware representation learning is designed to learn neighborhood structure representations at the amino acid, atom, and whole protein granularity from AlphaFold predicted structures, followed by utilizing contrastive learning to optimize the structure representations.Additionally, multi-scale sequence representation learning is used to extract context sequence information, and motif generated by aligning all context sequences of PTM sites assists the prediction. Extensive experiments on three datasets show that PTM-CMGMS outperforms the state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1358, <a href='https://arxiv.org/pdf/2401.05370.pdf' target='_blank'>https://arxiv.org/pdf/2401.05370.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahdi Ghorbani, Leo Gendelev, Paul Beroza, Michael J. Keiser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05370">Autoregressive fragment-based diffusion for pocket-aware ligand design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we introduce AutoFragDiff, a fragment-based autoregressive diffusion model for generating 3D molecular structures conditioned on target protein structures. We employ geometric vector perceptrons to predict atom types and spatial coordinates of new molecular fragments conditioned on molecular scaffolds and protein pockets. Our approach improves the local geometry of the resulting 3D molecules while maintaining high predicted binding affinity to protein targets. The model can also perform scaffold extension from user-provided starting molecular scaffold.
<div id='section'>Paperid: <span id='pid'>1359, <a href='https://arxiv.org/pdf/2401.04246.pdf' target='_blank'>https://arxiv.org/pdf/2401.04246.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joseph C. Kim, David Bloore, Karan Kapoor, Jun Feng, Ming-Hong Hao, Mengdi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04246">Scalable Normalizing Flows Enable Boltzmann Generators for Macromolecules</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Boltzmann distribution of a protein provides a roadmap to all of its functional states. Normalizing flows are a promising tool for modeling this distribution, but current methods are intractable for typical pharmacological targets; they become computationally intractable due to the size of the system, heterogeneity of intra-molecular potential energy, and long-range interactions. To remedy these issues, we present a novel flow architecture that utilizes split channels and gated attention to efficiently learn the conformational distribution of proteins defined by internal coordinates. We show that by utilizing a 2-Wasserstein loss, one can smooth the transition from maximum likelihood training to energy-based training, enabling the training of Boltzmann Generators for macromolecules. We evaluate our model and training strategy on villin headpiece HP35(nle-nle), a 35-residue subdomain, and protein G, a 56-residue protein. We demonstrate that standard architectures and training strategies, such as maximum likelihood alone, fail while our novel architecture and multi-stage training strategy are able to model the conformational distributions of protein G and HP35.
<div id='section'>Paperid: <span id='pid'>1360, <a href='https://arxiv.org/pdf/2401.02789.pdf' target='_blank'>https://arxiv.org/pdf/2401.02789.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hilbert Yuen In Lam, Xing Er Ong, Marek Mutwil
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02789">Large Language Models in Plant Biology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs), such as ChatGPT, have taken the world by storm and have passed certain forms of the Turing test. However, LLMs are not limited to human language and analyze sequential data, such as DNA, protein, and gene expression. The resulting foundation models can be repurposed to identify the complex patterns within the data, resulting in powerful, multi-purpose prediction tools able to explain cellular systems. This review outlines the different types of LLMs and showcases their recent uses in biology. Since LLMs have not yet been embraced by the plant community, we also cover how these models can be deployed for the plant kingdom.
<div id='section'>Paperid: <span id='pid'>1361, <a href='https://arxiv.org/pdf/2401.00014.pdf' target='_blank'>https://arxiv.org/pdf/2401.00014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>J. Gliozzo, G. MarinÃ², A. Bonometti, M. Frasca, D. Malchiodi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00014">Resource-Limited Automated Ki67 Index Estimation in Breast Cancer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The prediction of tumor progression and chemotherapy response has been recently tackled exploiting Tumor Infiltrating Lymphocytes (TILs) and the nuclear protein Ki67 as prognostic factors. Recently, deep neural networks (DNNs) have been shown to achieve top results in estimating Ki67 expression and simultaneous determination of intratumoral TILs score in breast cancer cells. However, in the last ten years the extraordinary progress induced by deep models proliferated at least as much as their resource demand. The exorbitant computational costs required to query (and in some cases also to store) a deep model represent a strong limitation in resource-limited contexts, like that of IoT-based applications to support healthcare personnel. To this end, we propose a resource consumption-aware DNN for the effective estimate of the percentage of Ki67-positive cells in breast cancer screenings. Our approach reduced up to 75% and 89% the usage of memory and disk space respectively, up to 1.5x the energy consumption, and preserved or improved the overall accuracy of a benchmark state-of-the-art solution. Encouraged by such positive results, we developed and structured the adopted framework so as to allow its general purpose usage, along with a public software repository to support its usage.
<div id='section'>Paperid: <span id='pid'>1362, <a href='https://arxiv.org/pdf/2312.17495.pdf' target='_blank'>https://arxiv.org/pdf/2312.17495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaohua Lu, Liangxu Xie, Lei Xu, Rongzhi Mao, Shan Chang, Xiaojun Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.17495">Integrating Chemical Language and Molecular Graph in Multimodal Fused Deep Learning for Drug Property Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting molecular properties is a challenging but essential task in drug discovery. Recently, many mono-modal deep learning methods have been successfully applied to molecular property prediction. However, the inherent limitation of mono-modal learning arises from relying solely on one modality of molecular representation, which restricts a comprehensive understanding of drug molecules and hampers their resilience against data noise. To overcome the limitations, we construct multimodal deep learning models to cover different molecular representations. We convert drug molecules into three molecular representations, SMILES-encoded vectors, ECFP fingerprints, and molecular graphs. To process the modal information, Transformer-Encoder, bi-directional gated recurrent units (BiGRU), and graph convolutional network (GCN) are utilized for feature learning respectively, which can enhance the model capability to acquire complementary and naturally occurring bioinformatics information. We evaluated our triple-modal model on six molecule datasets. Different from bi-modal learning models, we adopt five fusion methods to capture the specific features and leverage the contribution of each modal information better. Compared with mono-modal models, our multimodal fused deep learning (MMFDL) models outperform single models in accuracy, reliability, and resistance capability against noise. Moreover, we demonstrate its generalization ability in the prediction of binding constants for protein-ligand complex molecules in the refined set of PDBbind. The advantage of the multimodal model lies in its ability to process diverse sources of data using proper models and suitable fusion methods, which would enhance the noise resistance of the model while obtaining data diversity.
<div id='section'>Paperid: <span id='pid'>1363, <a href='https://arxiv.org/pdf/2312.10770.pdf' target='_blank'>https://arxiv.org/pdf/2312.10770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Divya Nori, Shivali Singireddy, Marina Ten Have
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10770">Identification of Knowledge Neurons in Protein Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural language models have become powerful tools for learning complex representations of entities in natural language processing tasks. However, their interpretability remains a significant challenge, particularly in domains like computational biology where trust in model predictions is crucial. In this work, we aim to enhance the interpretability of protein language models, specifically the state-of-the-art ESM model, by identifying and characterizing knowledge neurons - components that express understanding of key information. After fine-tuning the ESM model for the task of enzyme sequence classification, we compare two knowledge neuron selection methods that preserve a subset of neurons from the original model. The two methods, activation-based and integrated gradient-based selection, consistently outperform a random baseline. In particular, these methods show that there is a high density of knowledge neurons in the key vector prediction networks of self-attention modules. Given that key vectors specialize in understanding different features of input sequences, these knowledge neurons could capture knowledge of different enzyme sequence motifs. In the future, the types of knowledge captured by each neuron could be characterized.
<div id='section'>Paperid: <span id='pid'>1364, <a href='https://arxiv.org/pdf/2312.05791.pdf' target='_blank'>https://arxiv.org/pdf/2312.05791.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan RanÄeloviÄ, Kinga NyÃ­ri, Gergely KoppÃ¡ny, Marcel Baranyi, JÃ³zsef TÃ³vÃ¡ri, Attila KigyÃ³s, JÃ³zsef TimÃ¡r, BeÃ¡ta G. VÃ©rtessy, Vince Grolmusz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.05791">Gluing GAP to RAS Mutants: A New Approach to an Old Problem in Cancer Drug Development</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mutated genes may lead to cancer development in numerous tissues. While more than 600 cancer-causing genes are known today, some of the most widespread mutations are connected to the RAS gene: RAS mutations are found in approximately 25% of all human tumors. Specifically, KRAS mutations are involved in the three most lethal cancers in U.S.: pancreatic ductal adenocarcinoma, colorectal adenocarcinoma, and lung adenocarcinoma. These cancers are among the most difficult to treat, and they are frequently excluded from chemotherapeutic attacks as hopeless cases. The mutated KRAS proteins have specific 3-dimensional conformations, which perturb functional interaction with the GAP protein on the GAP:RAS complex surface leading to a signaling cascade and uncontrolled cell growth. Here we describe a gluing docking method for finding small molecules that bind to both the GAP and the mutated KRAS molecules. These small molecules glue together the GAP and the mutated KRAS molecules and may serve as new cancer drugs for the most lethal, most difficult-to-treat carcinomas. As a proof of concept, we identify two new, drug-like small molecules with the new method: these compounds specifically inhibit the growth of PANC-1 cell line with KRAS mutation G12D in vitro and in vivo. Importantly, the two new compounds show significantly lower IC50 and higher specificity against the G12D KRAS mutant as compared to the recently described MRTX-1133 inhibitor against the G12D KRAS mutant.
<div id='section'>Paperid: <span id='pid'>1365, <a href='https://arxiv.org/pdf/2312.04911.pdf' target='_blank'>https://arxiv.org/pdf/2312.04911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sergey Kucheryavskiy, Sergei Zhilin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.04911">Collinear datasets augmentation using Procrustes validation sets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a new method for the augmentation of numeric and mixed datasets. The method generates additional data points by utilizing cross-validation resampling and latent variable modeling. It is particularly efficient for datasets with moderate to high degrees of collinearity, as it directly utilizes this property for generation. The method is simple, fast, and has very few parameters, which, as shown in the paper, do not require specific tuning. It has been tested on several real datasets; here, we report detailed results for two cases, prediction of protein in minced meat based on near infrared spectra (fully numeric data with high degree of collinearity) and discrimination of patients referred for coronary angiography (mixed data, with both numeric and categorical variables, and moderate collinearity). In both cases, artificial neural networks were employed for developing the regression and the discrimination models. The results show a clear improvement in the performance of the models; thus for the prediction of meat protein, fitting the model to the augmented data resulted in a reduction in the root mean squared error computed for the independent test set by 1.5 to 3 times.
<div id='section'>Paperid: <span id='pid'>1366, <a href='https://arxiv.org/pdf/2312.01272.pdf' target='_blank'>https://arxiv.org/pdf/2312.01272.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongyan Du, Guo-Wei Wei, Tingjun Hou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.01272">Multiscale Topology in Interactomic Network: From Transcriptome to Antiaddiction Drug Repurposing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The escalating drug addiction crisis in the United States underscores the urgent need for innovative therapeutic strategies. This study embarked on an innovative and rigorous strategy to unearth potential drug repurposing candidates for opioid and cocaine addiction treatment, bridging the gap between transcriptomic data analysis and drug discovery. We initiated our approach by conducting differential gene expression analysis on addiction-related transcriptomic data to identify key genes. We propose a novel topological differentiation to identify key genes from a protein-protein interaction (PPI) network derived from DEGs. This method utilizes persistent Laplacians to accurately single out pivotal nodes within the network, conducting this analysis in a multiscale manner to ensure high reliability. Through rigorous literature validation, pathway analysis, and data-availability scrutiny, we identified three pivotal molecular targets, mTOR, mGluR5, and NMDAR, for drug repurposing from DrugBank. We crafted machine learning models employing two natural language processing (NLP)-based embeddings and a traditional 2D fingerprint, which demonstrated robust predictive ability in gauging binding affinities of DrugBank compounds to selected targets. Furthermore, we elucidated the interactions of promising drugs with the targets and evaluated their drug-likeness. This study delineates a multi-faceted and comprehensive analytical framework, amalgamating bioinformatics, topological data analysis and machine learning, for drug repurposing in addiction treatment, setting the stage for subsequent experimental validation. The versatility of the methods we developed allows for applications across a range of diseases and transcriptomic datasets.
<div id='section'>Paperid: <span id='pid'>1367, <a href='https://arxiv.org/pdf/2312.00796.pdf' target='_blank'>https://arxiv.org/pdf/2312.00796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gustavo Sganzerla Martinez, Mansi Dutt, Anuj Kumar, David J Kelvin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00796">Multiple Protein Profiler 1.0 (MPP): A webserver for predicting and visualizing physiochemical properties of proteins at the proteome level</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Determining the physicochemical properties of a protein can reveal important insights in their structure, biological functions, stability, and interactions with other molecules. Although tools for computing properties of proteins already existed, we could not find a comprehensive tool that enables the calculations of multiple properties for multiple input proteins on the proteome level at once. Facing this limitation, we have developed Multiple Protein Profiler (MPP) 1.0 as an integrated tool that allows the profiling of 12 individual properties of multiple proteins in a significant manner. MPP provides a tabular and graphic visualization of properties of multiple proteins. The tool is freely accessible at https://mproteinprofiler.microbiologyandimmunology.dal.ca/
<div id='section'>Paperid: <span id='pid'>1368, <a href='https://arxiv.org/pdf/2312.00509.pdf' target='_blank'>https://arxiv.org/pdf/2312.00509.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alessandro Mascaro, Federico Castelletti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00509">Bayesian causal discovery from unknown general interventions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the problem of learning causal Directed Acyclic Graphs (DAGs) using combinations of observational and interventional experimental data. Current methods tailored to this setting assume that interventions either destroy parent-child relations of the intervened (target) nodes or only alter such relations without modifying the parent sets, even when the intervention targets are unknown. We relax this assumption by proposing a Bayesian method for causal discovery from general interventions, which allow for modifications of the parent sets of the unknown targets. Even in this framework, DAGs and general interventions may be identifiable only up to some equivalence classes. We provide graphical characterizations of such interventional Markov equivalence and devise compatible priors for Bayesian inference that guarantee score equivalence of indistinguishable structures. We then develop a Markov Chain Monte Carlo (MCMC) scheme to approximate the posterior distribution over DAGs, intervention targets and induced parent sets. Finally, we evaluate the proposed methodology on both simulated and real protein expression data.
<div id='section'>Paperid: <span id='pid'>1369, <a href='https://arxiv.org/pdf/2311.15936.pdf' target='_blank'>https://arxiv.org/pdf/2311.15936.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Richard Moulange, Max Langenkamp, Tessa Alexanian, Samuel Curtis, Morgan Livingston
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.15936">Towards Responsible Governance of Biological Design Tools</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in generative machine learning have enabled rapid progress in biological design tools (BDTs) such as protein structure and sequence prediction models. The unprecedented predictive accuracy and novel design capabilities of BDTs present new and significant dual-use risks. For example, their predictive accuracy allows biological agents, whether vaccines or pathogens, to be developed more quickly, while the design capabilities could be used to discover drugs or evade DNA screening techniques. Similar to other dual-use AI systems, BDTs present a wicked problem: how can regulators uphold public safety without stifling innovation? We highlight how current regulatory proposals that are primarily tailored toward large language models may be less effective for BDTs, which require fewer computational resources to train and are often developed in an open-source manner. We propose a range of measures to mitigate the risk that BDTs are misused, across the areas of responsible development, risk assessment, transparency, access management, cybersecurity, and investing in resilience. Implementing such measures will require close coordination between developers and governments.
<div id='section'>Paperid: <span id='pid'>1370, <a href='https://arxiv.org/pdf/2311.12814.pdf' target='_blank'>https://arxiv.org/pdf/2311.12814.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alvaro Prat, Hisham Abdel Aty, Gintautas KamuntaviÄius, Tanya Paquet, Povilas NorvaiÅ¡as, Piero Gasparotto, Roy Tal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12814">HydraScreen: A Generalizable Structure-Based Deep Learning Approach to Drug Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose HydraScreen, a deep-learning approach that aims to provide a framework for more robust machine-learning-accelerated drug discovery. HydraScreen utilizes a state-of-the-art 3D convolutional neural network, designed for the effective representation of molecular structures and interactions in protein-ligand binding. We design an end-to-end pipeline for high-throughput screening and lead optimization, targeting applications in structure-based drug design. We assess our approach using established public benchmarks based on the CASF 2016 core set, achieving top-tier results in affinity and pose prediction (Pearson's r = 0.86, RMSE = 1.15, Top-1 = 0.95). Furthermore, we utilize a novel interaction profiling approach to identify potential biases in the model and dataset to boost interpretability and support the unbiased nature of our method. Finally, we showcase HydraScreen's capacity to generalize across unseen proteins and ligands, offering directions for future development of robust machine learning scoring functions. HydraScreen (accessible at https://hydrascreen.ro5.ai) provides a user-friendly GUI and a public API, facilitating easy assessment of individual protein-ligand complexes.
<div id='section'>Paperid: <span id='pid'>1371, <a href='https://arxiv.org/pdf/2311.02127.pdf' target='_blank'>https://arxiv.org/pdf/2311.02127.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adil Mudasir Malla, Asif Ali Banka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.02127">A Systematic Review of Deep Graph Neural Networks: Challenges, Classification, Architectures, Applications & Potential Utility in Bioinformatics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, tasks of machine learning ranging from image processing & audio/video analysis to natural language understanding have been transformed by deep learning. The data content in all these scenarios are expressed via Euclidean space. However, a considerable amount of application data is structured in non-Euclidean space and is expressed as graphs, e.g. dealing with complicated interactions & object interdependencies. Modelling physical systems, learning molecular signatures, identifying protein interactions and predicting diseases involve utilising a model that can adapt from graph data. Graph neural networks (GNNs), specified as artificial-neural models, employ message transmission between graph nodes to represent graph dependencies and are primarily used in the non-Euclidean domain. Variants of GNN like Graph Recurrent Networks (GRN), Graph Auto Encoder (GAE), Graph Convolution Networks (GCN), Graph Adversarial Methods & Graph Reinforcement learning have exhibited breakthrough productivity on a wide range of tasks, especially in the field of bioinformatics, in recent years as a result of the rapid collection of biological network data. Apart from presenting all existing GNN models, mathematical analysis and comparison of the variants of all types of GNN have been highlighted in this survey. Graph neural networks are investigated for their potential real-world applications in various fields, focusing on Bioinformatics. Furthermore, resources for evaluating graph neural network models and accessing open-source code & benchmark data sets are included. Ultimately, we provide some (seven) proposals for future research in this rapidly evolving domain. GNNs have the potential to be an excellent tool for solving a wide range of biological challenges in bioinformatics research, as they are best represented as connected complex graphs.
<div id='section'>Paperid: <span id='pid'>1372, <a href='https://arxiv.org/pdf/2310.20609.pdf' target='_blank'>https://arxiv.org/pdf/2310.20609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ernesto Araya Valdivia, Hemant Tyagi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.20609">Graph Matching via convex relaxation to the simplex</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the Graph Matching problem, which consists of finding the best possible alignment between two input graphs, and has many applications in computer vision, network deanonymization and protein alignment. A common approach to tackle this problem is through convex relaxations of the NP-hard \emph{Quadratic Assignment Problem} (QAP).
  Here, we introduce a new convex relaxation onto the unit simplex and develop an efficient mirror descent scheme with closed-form iterations for solving this problem. Under the correlated Gaussian Wigner model, we show that the simplex relaxation admits a unique solution with high probability. In the noiseless case, this is shown to imply exact recovery of the ground truth permutation. Additionally, we establish a novel sufficiency condition for the input matrix in standard greedy rounding methods, which is less restrictive than the commonly used `diagonal dominance' condition. We use this condition to show exact one-step recovery of the ground truth (holding almost surely) via the mirror descent scheme, in the noiseless setting. We also use this condition to obtain significantly improved conditions for the GRAMPA algorithm [Fan et al. 2019] in the noiseless setting.
<div id='section'>Paperid: <span id='pid'>1373, <a href='https://arxiv.org/pdf/2310.17164.pdf' target='_blank'>https://arxiv.org/pdf/2310.17164.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Long-Huei Chen, Mohana Prasad Sathya Moorthy, Pratyaksh Sharma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.17164">Bridging Phylogeny and Taxonomy with Protein-protein Interaction Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The protein-protein interaction (PPI) network provides an overview of the complex biological reactions vital to an organism's metabolism and survival. Even though in the past PPI network were compared across organisms in detail, there has not been large-scale research on how individual PPI networks reflect on the species relationships. In this study we aim to increase our understanding of the tree of life and taxonomy by gleaming information from the PPI networks. We successful created (1) a predictor of network statistics based on known traits of existing species in the phylogeny, and (2) a taxonomic classifier of organism using the known protein network statistics, whether experimentally determined or predicted de novo. With the knowledge of protein interactions at its core, our two models effectively connects two field with widely diverging methodologies - the phylogeny and taxonomy of species.
<div id='section'>Paperid: <span id='pid'>1374, <a href='https://arxiv.org/pdf/2310.14764.pdf' target='_blank'>https://arxiv.org/pdf/2310.14764.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruth Veevers, Dan MacLean
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.14764">Improved K-mer Based Prediction of Protein-Protein Interactions With Chaos Game Representation, Deep Learning and Reduced Representation Bias</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interactions drive many biological processes, including the detection of phytopathogens by plants' R-Proteins and cell surface receptors. Many machine learning studies have attempted to predict protein-protein interactions but performance is highly dependent on training data; models have been shown to accurately predict interactions when the proteins involved are included in the training data, but achieve consistently poorer results when applied to previously unseen proteins. In addition, models that are trained using proteins that take part in multiple interactions can suffer from representation bias, where predictions are driven not by learned biological features but by learning of the structure of the interaction dataset.
  We present a method for extracting unique pairs from an interaction dataset, generating non-redundant paired data for unbiased machine learning. After applying the method to datasets containing _Arabidopsis thaliana_ and pathogen effector interations, we developed a convolutional neural network model capable of learning and predicting interactions from Chaos Game Representations of proteins' coding genes.
<div id='section'>Paperid: <span id='pid'>1375, <a href='https://arxiv.org/pdf/2310.09685.pdf' target='_blank'>https://arxiv.org/pdf/2310.09685.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam Winnifrith, Carlos Outeiral, Brian Hie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.09685">Generative artificial intelligence for de novo protein design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Engineering new molecules with desirable functions and properties has the potential to extend our ability to engineer proteins beyond what nature has so far evolved. Advances in the so-called "de novo" design problem have recently been brought forward by developments in artificial intelligence. Generative architectures, such as language models and diffusion processes, seem adept at generating novel, yet realistic proteins that display desirable properties and perform specified functions. State-of-the-art design protocols now achieve experimental success rates nearing 20%, thus widening the access to de novo designed proteins. Despite extensive progress, there are clear field-wide challenges, for example in determining the best in silico metrics to prioritise designs for experimental testing, and in designing proteins that can undergo large conformational changes or be regulated by post-translational modifications and other cellular processes. With an increase in the number of models being developed, this review provides a framework to understand how these tools fit into the overall process of de novo protein design. Throughout, we highlight the power of incorporating biochemical knowledge to improve performance and interpretability.
<div id='section'>Paperid: <span id='pid'>1376, <a href='https://arxiv.org/pdf/2310.06725.pdf' target='_blank'>https://arxiv.org/pdf/2310.06725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julia R. Rogers, GergÅ NikolÃ©nyi, Mohammed AlQuraishi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06725">Growing ecosystem of deep learning methods for modeling protein$\unicode{x2013}$protein interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Numerous cellular functions rely on protein$\unicode{x2013}$protein interactions. Efforts to comprehensively characterize them remain challenged however by the diversity of molecular recognition mechanisms employed within the proteome. Deep learning has emerged as a promising approach for tackling this problem by exploiting both experimental data and basic biophysical knowledge about protein interactions. Here, we review the growing ecosystem of deep learning methods for modeling protein interactions, highlighting the diversity of these biophysically-informed models and their respective trade-offs. We discuss recent successes in using representation learning to capture complex features pertinent to predicting protein interactions and interaction sites, geometric deep learning to reason over protein structures and predict complex structures, and generative modeling to design de novo protein assemblies. We also outline some of the outstanding challenges and promising new directions. Opportunities abound to discover novel interactions, elucidate their physical mechanisms, and engineer binders to modulate their functions using deep learning and, ultimately, unravel how protein interactions orchestrate complex cellular behaviors.
<div id='section'>Paperid: <span id='pid'>1377, <a href='https://arxiv.org/pdf/2310.04028.pdf' target='_blank'>https://arxiv.org/pdf/2310.04028.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucie Bourguignon, Caroline Weis, Catherine R. Jutzeler, Michael Adamer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.04028">Genetic prediction of quantitative traits: a machine learner's guide focused on height</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning and deep learning have been celebrating many successes in the application to biological problems, especially in the domain of protein folding. Another equally complex and important question has received relatively little attention by the machine learning community, namely the one of prediction of complex traits from genetics. Tackling this problem requires in-depth knowledge of the related genetics literature and awareness of various subtleties associated with genetic data. In this guide, we provide an overview for the machine learning community on current state of the art models and associated subtleties which need to be taken into consideration when developing new models for phenotype prediction. We use height as an example of a continuous-valued phenotype and provide an introduction to benchmark datasets, confounders, feature selection, and common metrics.
<div id='section'>Paperid: <span id='pid'>1378, <a href='https://arxiv.org/pdf/2310.03086.pdf' target='_blank'>https://arxiv.org/pdf/2310.03086.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Suresh Kumar, Dhanyashri Guruparan, Pavithren Aaron, Philemon Telajan, Kavinesh Mahadevan, Dinesh Davagandhi, Ong Xin Yue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03086">Deep Learning in Computational Biology: Advancements, Challenges, and Future Outlook</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has become a powerful tool in computational biology, revolutionising the analysis and interpretation of biological data over time. In our article review, we delve into various aspects of deep learning in computational biology. Specifically, we examine its history, advantages, and challenges. Our focus is on two primary applications: DNA sequence classification and prediction, as well as protein structure prediction from sequence data. Additionally, we provide insights into the outlook for this field. To fully harness the potential of deep learning in computational biology, it is crucial to address the challenges that come with it. These challenges include the requirement for large, labelled datasets and the interpretability of deep learning models. The use of deep learning in the analysis of DNA sequences has brought about a significant transformation in the detection of genomic variants and the analysis of gene expression. This has greatly contributed to the advancement of personalised medicine and drug discovery. Convolutional neural networks (CNNs) have been shown to be highly accurate in predicting genetic variations and gene expression levels. Deep learning techniques are used for analysing epigenetic data, including DNA methylation and histone modifications. This provides valuable insights into metabolic conditions and gene regulation. The field of protein structure prediction has been significantly impacted by deep learning, which has enabled accurate determination of the three-dimensional shape of proteins and prediction of their interactions. The future of deep learning in computational biology looks promising. With the development of advanced deep learning models and interpretation techniques, there is potential to overcome current challenges and further our understanding of biological systems.
<div id='section'>Paperid: <span id='pid'>1379, <a href='https://arxiv.org/pdf/2309.14404.pdf' target='_blank'>https://arxiv.org/pdf/2309.14404.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zebin Ma, Yonglin Zou, Xiaobin Huang, Wenjin Yan, Hao Xu, Jiexin Yang, Ying Zhang, Jinqi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.14404">pLMFPPred: a novel approach for accurate prediction of functional peptides integrating embedding from pre-trained protein language model and imbalanced learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Functional peptides have the potential to treat a variety of diseases. Their good therapeutic efficacy and low toxicity make them ideal therapeutic agents. Artificial intelligence-based computational strategies can help quickly identify new functional peptides from collections of protein sequences and discover their different functions.Using protein language model-based embeddings (ESM-2), we developed a tool called pLMFPPred (Protein Language Model-based Functional Peptide Predictor) for predicting functional peptides and identifying toxic peptides. We also introduced SMOTE-TOMEK data synthesis sampling and Shapley value-based feature selection techniques to relieve data imbalance issues and reduce computational costs. On a validated independent test set, pLMFPPred achieved accuracy, Area under the curve - Receiver Operating Characteristics, and F1-Score values of 0.974, 0.99, and 0.974, respectively. Comparative experiments show that pLMFPPred outperforms current methods for predicting functional peptides.The experimental results suggest that the proposed method (pLMFPPred) can provide better performance in terms of Accuracy, Area under the curve - Receiver Operating Characteristics, and F1-Score than existing methods. pLMFPPred has achieved good performance in predicting functional peptides and represents a new computational method for predicting functional peptides.
<div id='section'>Paperid: <span id='pid'>1380, <a href='https://arxiv.org/pdf/2309.10008.pdf' target='_blank'>https://arxiv.org/pdf/2309.10008.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanlin Zhang, Wenzheng Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.10008">DeepHEN: quantitative prediction essential lncRNA genes and rethinking essentialities of lncRNA genes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gene essentiality refers to the degree to which a gene is necessary for the survival and reproductive efficacy of a living organism. Although the essentiality of non-coding genes has been documented, there are still aspects of non-coding genes' essentiality that are unknown to us. For example, We do not know the contribution of sequence features and network spatial features to essentiality. As a consequence, in this work, we propose DeepHEN that could answer the above question. By buidling a new lncRNA-proteion-protein network and utilizing both representation learning and graph neural network, we successfully build our DeepHEN models that could predict the essentiality of lncRNA genes. Compared to other methods for predicting the essentiality of lncRNA genes, our DeepHEN model not only tells whether sequence features or network spatial features have a greater influence on essentiality but also addresses the overfitting issue of those methods caused by the low number of essential lncRNA genes, as evidenced by the results of enrichment analysis.
<div id='section'>Paperid: <span id='pid'>1381, <a href='https://arxiv.org/pdf/2309.05413.pdf' target='_blank'>https://arxiv.org/pdf/2309.05413.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zequn Lin, Zhaofan Lu, Zengru Di, Ying Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.05413">Learning noise-induced transitions by multi-scaling reservoir computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Noise is usually regarded as adversarial to extract the effective dynamics from time series, such that the conventional data-driven approaches usually aim at learning the dynamics by mitigating the noisy effect. However, noise can have a functional role of driving transitions between stable states underlying many natural and engineered stochastic dynamics. To capture such stochastic transitions from data, we find that leveraging a machine learning model, reservoir computing as a type of recurrent neural network, can learn noise-induced transitions. We develop a concise training protocol for tuning hyperparameters, with a focus on a pivotal hyperparameter controlling the time scale of the reservoir dynamics. The trained model generates accurate statistics of transition time and the number of transitions. The approach is applicable to a wide class of systems, including a bistable system under a double-well potential, with either white noise or colored noise. It is also aware of the asymmetry of the double-well potential, the rotational dynamics caused by non-detailed balance, and transitions in multi-stable systems. For the experimental data of protein folding, it learns the transition time between folded states, providing a possibility of predicting transition statistics from a small dataset. The results demonstrate the capability of machine-learning methods in capturing noise-induced phenomena.
<div id='section'>Paperid: <span id='pid'>1382, <a href='https://arxiv.org/pdf/2308.16309.pdf' target='_blank'>https://arxiv.org/pdf/2308.16309.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>George A. Elder, Conrad Bessant
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16309">Inferring Compensatory Kinase Networks in Yeast using Prolog</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Signalling pathways are conserved across different species, therefore making yeast a model organism to study these via disruption of kinase activity. Yeast has 159 genes that encode protein kinases and phosphatases, and 136 of these have counterparts in humans. Therefore any insight in this model organism could potentially offer indications of mechanisms of action in the human kinome. The study utilises a Prolog-based approach, data from a yeast kinase deletions strains study and publicly available kinase-protein associations. Prolog, a programming language that is well-suited for symbolic reasoning is used to reason over the data and infer compensatory kinase networks. This approach is based on the idea that when a kinase is knocked out, other kinases may compensate for this loss of activity. Background knowledge on kinases targeting proteins is used to guide the analysis. This knowledge is used to infer the potential compensatory interactions between kinases based on the changes in phosphorylation observed in the phosphoproteomics data from the yeast study. The results demonstrate the effectiveness of the Prolog-based approach in analysing complex cell signalling mechanisms in yeast. The inferred compensatory kinase networks provide new insights into the regulation of cell signalling in yeast and may aid in the identification of potential therapeutic targets for modulating signalling pathways in yeast and other organisms.
<div id='section'>Paperid: <span id='pid'>1383, <a href='https://arxiv.org/pdf/2308.13891.pdf' target='_blank'>https://arxiv.org/pdf/2308.13891.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Natalie Wang, Casey Overby Taylor
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.13891">Drug Interaction Vectors Neural Network: DrIVeNN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Polypharmacy, the concurrent use of multiple drugs to treat a single condition, is common in patients managing multiple or complex conditions. However, as more drugs are added to the treatment plan, the risk of adverse drug events (ADEs) rises rapidly. Many serious ADEs associated with polypharmacy only become known after the drugs are in use. It is impractical to test every possible drug combination during clinical trials. This issue is particularly prevalent among older adults with cardiovascular disease (CVD) where polypharmacy and ADEs are commonly observed. In this research, our primary objective was to identify key drug features to build and evaluate a model for modeling polypharmacy ADEs. Our secondary objective was to assess our model on a domain-specific case study. We developed a two-layer neural network that incorporated drug features such as molecular structure, drug-protein interactions, and mono drug side effects (DrIVeNN). We assessed DrIVeNN using publicly available side effect databases and determined Principal Component Analysis (PCA) with a variance threshold of 0.95 as the most effective feature selection method. DrIVeNN performed moderately better than state-of-the-art models like RESCAL, DEDICOM, DeepWalk, Decagon, DeepDDI, KGDDI, and KGNN in terms of AUROC for the drug-drug interaction prediction task. We also conducted a domain-specific case study centered on the treatment of cardiovascular disease (CVD). When the best performing model architecture was applied to the CVD treatment cohort, there was a significant increase in performance from the general model. We observed an average AUROC for CVD drug pair prediction increasing from 0.826 (general model) to 0.975 (CVD specific model). Our findings indicate the strong potential of domain-specific models for improving the accuracy of drug-drug interaction predictions.
<div id='section'>Paperid: <span id='pid'>1384, <a href='https://arxiv.org/pdf/2308.12104.pdf' target='_blank'>https://arxiv.org/pdf/2308.12104.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Basant Lal Sharma, Luigi E. Perotti, Sanjay Dharmavaram
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12104">Computational Modeling of Coupled Interactions of Fluid Membranes with Embedded Filaments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present a computational formulation based on continuum mechanics to study the interaction of fluid membranes embedded with semiflexible filaments. This is motivated by systems in membrane biology, such as cytoskeletal networks and protein filaments aiding the cell fission process. We model the membrane as a fluid shell via the Helfrich-Canham energy and the filament as a one-dimensional Cosserat continuum. We assume the filament to be tethered to the surface of the membrane in a way that it is allowed to float on the surface freely. The novel filament-membrane coupling, which is anticipated to yield interesting physics, also gives rise to unique computational challenges, which we address in this work. We present validation results and apply the formulation to certain problems inspired by cellular biology.
<div id='section'>Paperid: <span id='pid'>1385, <a href='https://arxiv.org/pdf/2308.09086.pdf' target='_blank'>https://arxiv.org/pdf/2308.09086.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucian Chan, Marcel Verdonk, Carl Poelking
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09086">Embracing assay heterogeneity with neural processes for markedly improved bioactivity predictions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the bioactivity of a ligand is one of the hardest and most important challenges in computer-aided drug discovery. Despite years of data collection and curation efforts by research organizations worldwide, bioactivity data remains sparse and heterogeneous, thus hampering efforts to build predictive models that are accurate, transferable and robust. The intrinsic variability of the experimental data is further compounded by data aggregation practices that neglect heterogeneity to overcome sparsity. Here we discuss the limitations of these practices and present a hierarchical meta-learning framework that exploits the information synergy across disparate assays by successfully accounting for assay heterogeneity. We show that the model achieves a drastic improvement in affinity prediction across diverse protein targets and assay types compared to conventional baselines. It can quickly adapt to new target contexts using very few observations, thus enabling large-scale virtual screening in early-phase drug discovery.
<div id='section'>Paperid: <span id='pid'>1386, <a href='https://arxiv.org/pdf/2308.07453.pdf' target='_blank'>https://arxiv.org/pdf/2308.07453.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Mohammadi, Mohammad Al Janaideh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07453">Sign Gradient Descent Algorithms for Kinetostatic Protein Folding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a sign gradient descent (SGD) algorithm for predicting the three-dimensional folded protein molecule structures under the kinetostatic compliance method (KCM). In the KCM framework, which can be used to simulate the range of motion of peptide-based nanorobots/nanomachines, protein molecules are modeled as a large number of rigid nano-linkages that form a kinematic mechanism under motion constraints imposed by chemical bonds while folding under the kinetostatic effect of nonlinear interatomic force fields. In a departure from the conventional successive kinetostatic fold compliance framework, the proposed SGD-based iterative algorithm in this paper results in convergence to the local minima of the free energy of protein molecules corresponding to their final folded conformations in a faster and more robust manner. KCMbased folding dynamics simulations of the backbone chains of protein molecules demonstrate the effectiveness of the proposed algorithm.
<div id='section'>Paperid: <span id='pid'>1387, <a href='https://arxiv.org/pdf/2307.13004.pdf' target='_blank'>https://arxiv.org/pdf/2307.13004.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihao Li, Changkun Jiang, Jianqiang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.13004">DeepGATGO: A Hierarchical Pretraining-Based Graph-Attention Model for Automatic Protein Function Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic protein function prediction (AFP) is classified as a large-scale multi-label classification problem aimed at automating protein enrichment analysis to eliminate the current reliance on labor-intensive wet-lab methods. Currently, popular methods primarily combine protein-related information and Gene Ontology (GO) terms to generate final functional predictions. For example, protein sequences, structural information, and protein-protein interaction networks are integrated as prior knowledge to fuse with GO term embeddings and generate the ultimate prediction results. However, these methods are limited by the difficulty in obtaining structural information or network topology information, as well as the accuracy of such data. Therefore, more and more methods that only use protein sequences for protein function prediction have been proposed, which is a more reliable and computationally cheaper approach. However, the existing methods fail to fully extract feature information from protein sequences or label data because they do not adequately consider the intrinsic characteristics of the data itself. Therefore, we propose a sequence-based hierarchical prediction method, DeepGATGO, which processes protein sequences and GO term labels hierarchically, and utilizes graph attention networks (GATs) and contrastive learning for protein function prediction. Specifically, we compute embeddings of the sequence and label data using pre-trained models to reduce computational costs and improve the embedding accuracy. Then, we use GATs to dynamically extract the structural information of non-Euclidean data, and learn general features of the label dataset with contrastive learning by constructing positive and negative example samples. Experimental results demonstrate that our proposed model exhibits better scalability in GO term enrichment analysis on large-scale datasets.
<div id='section'>Paperid: <span id='pid'>1388, <a href='https://arxiv.org/pdf/2307.12451.pdf' target='_blank'>https://arxiv.org/pdf/2307.12451.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael S. Jones, Kirill Shmilovich, Andrew L. Ferguson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.12451">DiAMoNDBack: Diffusion-denoising Autoregressive Model for Non-Deterministic Backmapping of CÎ± Protein Traces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Coarse-grained molecular models of proteins permit access to length and time scales unattainable by all-atom models and the simulation of processes that occur on long-time scales such as aggregation and folding. The reduced resolution realizes computational accelerations but an atomistic representation can be vital for a complete understanding of mechanistic details. Backmapping is the process of restoring all-atom resolution to coarse-grained molecular models. In this work, we report DiAMoNDBack (Diffusion-denoising Autoregressive Model for Non-Deterministic Backmapping) as an autoregressive denoising diffusion probability model to restore all-atom details to coarse-grained protein representations retaining only CÎ± coordinates. The autoregressive generation process proceeds from the protein N-terminus to C-terminus in a residue-by-residue fashion conditioned on the CÎ± trace and previously backmapped backbone and side chain atoms within the local neighborhood. The local and autoregressive nature of our model makes it transferable between proteins. The stochastic nature of the denoising diffusion process means that the model generates a realistic ensemble of backbone and side chain all-atom configurations consistent with the coarse-grained CÎ± trace. We train DiAMoNDBack over 65k+ structures from Protein Data Bank (PDB) and validate it in applications to a hold-out PDB test set, intrinsically-disordered protein structures from the Protein Ensemble Database (PED), molecular dynamics simulations of fast-folding mini-proteins from DE Shaw Research, and coarse-grained simulation data. We achieve state-of-the-art reconstruction performance in terms of correct bond formation, avoidance of side chain clashes, and diversity of the generated side chain configurational states. We make DiAMoNDBack model publicly available as a free and open source Python package.
<div id='section'>Paperid: <span id='pid'>1389, <a href='https://arxiv.org/pdf/2307.10991.pdf' target='_blank'>https://arxiv.org/pdf/2307.10991.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stephen JosÃ¨ Hanson, Vivek Yadav, Catherine Hanson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.10991">Dense Sample Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Learning (DL) , a variant of the neural network algorithms originally proposed in the 1980s, has made surprising progress in Artificial Intelligence (AI), ranging from language translation, protein folding, autonomous cars, and more recently human-like language models (CHATbots), all that seemed intractable until very recently. Despite the growing use of Deep Learning (DL) networks, little is actually understood about the learning mechanisms and representations that makes these networks effective across such a diverse range of applications. Part of the answer must be the huge scale of the architecture and of course the large scale of the data, since not much has changed since 1987. But the nature of deep learned representations remain largely unknown. Unfortunately training sets with millions or billions of tokens have unknown combinatorics and Networks with millions or billions of hidden units cannot easily be visualized and their mechanisms cannot be easily revealed. In this paper, we explore these questions with a large (1.24M weights; VGG) DL in a novel high density sample task (5 unique tokens with at minimum 500 exemplars per token) which allows us to more carefully follow the emergence of category structure and feature construction. We use various visualization methods for following the emergence of the classification and the development of the coupling of feature detectors and structures that provide a type of graphical bootstrapping, From these results we harvest some basic observations of the learning dynamics of DL and propose a new theory of complex feature construction based on our results.
<div id='section'>Paperid: <span id='pid'>1390, <a href='https://arxiv.org/pdf/2306.11375.pdf' target='_blank'>https://arxiv.org/pdf/2306.11375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carles Navarro, Maciej Majewski, Gianni de Fabritiis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.11375">Top-down machine learning of coarse-grained protein force-fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing accurate and efficient coarse-grained representations of proteins is crucial for understanding their folding, function, and interactions over extended timescales. Our methodology involves simulating proteins with molecular dynamics and utilizing the resulting trajectories to train a neural network potential through differentiable trajectory reweighting. Remarkably, this method requires only the native conformation of proteins, eliminating the need for labeled data derived from extensive simulations or memory-intensive end-to-end differentiable simulations. Once trained, the model can be employed to run parallel molecular dynamics simulations and sample folding events for proteins both within and beyond the training distribution, showcasing its extrapolation capabilities. By applying Markov State Models, native-like conformations of the simulated proteins can be predicted from the coarse-grained simulations. Owing to its theoretical transferability and ability to use solely experimental static structures as training data, we anticipate that this approach will prove advantageous for developing new protein force fields and further advancing the study of protein dynamics, folding, and interactions.
<div id='section'>Paperid: <span id='pid'>1391, <a href='https://arxiv.org/pdf/2306.08469.pdf' target='_blank'>https://arxiv.org/pdf/2306.08469.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yilin Ding, Zhen Liu, Hao Hao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.08469">Self-supervised Learning and Graph Classification under Heterophily</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised learning has shown its promising capability in graph representation learning in recent work. Most existing pre-training strategies usually choose the popular Graph neural networks (GNNs), which can be seen as a special form of low-pass filter, fail to effectively capture heterophily. In this paper, we first present an experimental investigation exploring the performance of low-pass and high-pass filters in heterophily graph classification, where the results clearly show that high-frequency signal is important for learning heterophily graph representation. On the other hand, it is still unclear how to effectively capture the structural pattern of graphs and how to measure the capability of the self-supervised pre-training strategy in capturing graph structure. To address the problem, we first design a quantitative metric to Measure Graph Structure (MGS), which analyzes correlation between structural similarity and embedding similarity of graph pairs. Then, to enhance the graph structural information captured by self-supervised learning, we propose a novel self-supervised strategy for Pre-training GNNs based on the Metric (PGM). Extensive experiments validate our pre-training strategy achieves state-of-the-art performance for molecular property prediction and protein function prediction. In addition, we find choosing the suitable filter sometimes may be better than designing good pre-training strategies for heterophily graph classification.
<div id='section'>Paperid: <span id='pid'>1392, <a href='https://arxiv.org/pdf/2306.06156.pdf' target='_blank'>https://arxiv.org/pdf/2306.06156.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Timothy F. Truong, Tristan Bepler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06156">PoET: A generative model of protein families as sequences-of-sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative protein language models are a natural way to design new proteins with desired functions. However, current models are either difficult to direct to produce a protein from a specific family of interest, or must be trained on a large multiple sequence alignment (MSA) from the specific family of interest, making them unable to benefit from transfer learning across families. To address this, we propose $\textbf{P}$r$\textbf{o}$tein $\textbf{E}$volutionary $\textbf{T}$ransformer (PoET), an autoregressive generative model of whole protein families that learns to generate sets of related proteins as sequences-of-sequences across tens of millions of natural protein sequence clusters. PoET can be used as a retrieval-augmented language model to generate and score arbitrary modifications conditioned on any protein family of interest, and can extrapolate from short context lengths to generalize well even for small families. This is enabled by a unique Transformer layer; we model tokens sequentially within sequences while attending between sequences order invariantly, allowing PoET to scale to context lengths beyond those used during training. In extensive experiments on deep mutational scanning datasets, we show that PoET outperforms existing protein language models and evolutionary sequence models for variant function prediction across proteins of all MSA depths. We also demonstrate PoET's ability to controllably generate new protein sequences.
<div id='section'>Paperid: <span id='pid'>1393, <a href='https://arxiv.org/pdf/2306.04658.pdf' target='_blank'>https://arxiv.org/pdf/2306.04658.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuchi Qiu, Guo-Wei Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.04658">Mathematics-assisted directed evolution and protein engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Directed evolution is a molecular biology technique that is transforming protein engineering by creating proteins with desirable properties and functions. However, it is experimentally impossible to perform the deep mutational scanning of the entire protein library due to the enormous mutational space, which scales as $20^N$ , where N is the number of amino acids. This has led to the rapid growth of AI-assisted directed evolution (AIDE) or AI-assisted protein engineering (AIPE) as an emerging research field. Aided with advanced natural language processing (NLP) techniques, including long short-term memory, autoencoder, and transformer, sequence-based embeddings have been dominant approaches in AIDE and AIPE. Persistent Laplacians, an emerging technique in topological data analysis (TDA), have made structure-based embeddings a superb option in AIDE and AIPE. We argue that a class of persistent topological Laplacians (PTLs), including persistent Laplacians, persistent path Laplacians, persistent sheaf Laplacians, persistent hypergraph Laplacians, persistent hyperdigraph Laplacians, and evolutionary de Rham-Hodge theory, can effectively overcome the limitations of the current TDA and offer a new generation of more powerful TDA approaches. In the general framework of topological deep learning, mathematics-assisted directed evolution (MADE) has a great potential for future protein engineering.
<div id='section'>Paperid: <span id='pid'>1394, <a href='https://arxiv.org/pdf/2306.03521.pdf' target='_blank'>https://arxiv.org/pdf/2306.03521.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shishir Adhikari, Alkan KabakÃ§Ä±oÄlu, Alexander Strang, Deniz Yuret, Michael Hinczewski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03521">Machine learning in and out of equilibrium</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The algorithms used to train neural networks, like stochastic gradient descent (SGD), have close parallels to natural processes that navigate a high-dimensional parameter space -- for example protein folding or evolution. Our study uses a Fokker-Planck approach, adapted from statistical physics, to explore these parallels in a single, unified framework. We focus in particular on the stationary state of the system in the long-time limit, which in conventional SGD is out of equilibrium, exhibiting persistent currents in the space of network parameters. As in its physical analogues, the current is associated with an entropy production rate for any given training trajectory. The stationary distribution of these rates obeys the integral and detailed fluctuation theorems -- nonequilibrium generalizations of the second law of thermodynamics. We validate these relations in two numerical examples, a nonlinear regression network and MNIST digit classification. While the fluctuation theorems are universal, there are other aspects of the stationary state that are highly sensitive to the training details. Surprisingly, the effective loss landscape and diffusion matrix that determine the shape of the stationary distribution vary depending on the simple choice of minibatching done with or without replacement. We can take advantage of this nonequilibrium sensitivity to engineer an equilibrium stationary state for a particular application: sampling from a posterior distribution of network weights in Bayesian machine learning. We propose a new variation of stochastic gradient Langevin dynamics (SGLD) that harnesses without replacement minibatching. In an example system where the posterior is exactly known, this SGWORLD algorithm outperforms SGLD, converging to the posterior orders of magnitude faster as a function of the learning rate.
<div id='section'>Paperid: <span id='pid'>1395, <a href='https://arxiv.org/pdf/2306.01818.pdf' target='_blank'>https://arxiv.org/pdf/2306.01818.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Shoaib Farooq, Hafiz Ali Younas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.01818">Beta Thalassemia Carriers detection empowered federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Thalassemia is a group of inherited blood disorders that happen when hemoglobin, the protein in red blood cells that carries oxygen, is not made enough. It is found all over the body and is needed for survival. If both parents have thalassemia, a child's chance of getting it increases. Genetic counselling and early diagnosis are essential for treating thalassemia and stopping it from being passed on to future generations. It may be hard for healthcare professionals to differentiate between people with thalassemia carriers and those without. The current blood tests for beta thalassemia carriers are too expensive, take too long, and require too much screening equipment. The World Health Organization says there is a high death rate for people with thalassemia. Therefore, it is essential to find thalassemia carriers to act quickly. High-performance liquid chromatography (HPLC), the standard test method, has problems such as cost, time, and equipment needs. So, there must be a quick and cheap way to find people carrying the thalassemia gene. Using federated learning (FL) techniques, this study shows a new way to find people with the beta-thalassemia gene. FL allows data to be collected and processed on-site while following privacy rules, making it an excellent choice for sensitive health data. Researchers used FL to train a model for beta-thalassemia carriers by looking at the complete blood count results and red blood cell indices. The model was 92.38 % accurate at telling the difference between beta-thalassemia carriers and people who did not have the disease. The proposed FL model is better than other published methods in terms of how well it works, how reliable it is, and how private it is. This research shows a promising, quick, accurate, and low-cost way to find thalassemia carriers and opens the door for screening them on a large scale.
<div id='section'>Paperid: <span id='pid'>1396, <a href='https://arxiv.org/pdf/2305.19215.pdf' target='_blank'>https://arxiv.org/pdf/2305.19215.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Albert Xue, Jingyou Rao, Sriram Sankararaman, Harold Pimentel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.19215">dotears: Scalable, consistent DAG estimation using observational and interventional data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>New biological assays like Perturb-seq link highly parallel CRISPR interventions to a high-dimensional transcriptomic readout, providing insight into gene regulatory networks. Causal gene regulatory networks can be represented by directed acyclic graph (DAGs), but learning DAGs from observational data is complicated by lack of identifiability and a combinatorial solution space. Score-based structure learning improves practical scalability of inferring DAGs. Previous score-based methods are sensitive to error variance structure; on the other hand, estimation of error variance is difficult without prior knowledge of structure. Accordingly, we present $\texttt{dotears}$ [doo-tairs], a continuous optimization framework which leverages observational and interventional data to infer a single causal structure, assuming a linear Structural Equation Model (SEM). $\texttt{dotears}$ exploits structural consequences of hard interventions to give a marginal estimate of exogenous error structure, bypassing the circular estimation problem. We show that $\texttt{dotears}$ is a provably consistent estimator of the true DAG under mild assumptions. $\texttt{dotears}$ outperforms other methods in varied simulations, and in real data infers edges that validate with higher precision and recall than state-of-the-art methods through differential expression tests and high-confidence protein-protein interactions.
<div id='section'>Paperid: <span id='pid'>1397, <a href='https://arxiv.org/pdf/2305.17183.pdf' target='_blank'>https://arxiv.org/pdf/2305.17183.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai San Chan, Huimiao Chen, Chenyu Jin, Yuxuan Tian, Dingchang Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.17183">ProGroTrack: Deep Learning-Assisted Tracking of Intracellular Protein Growth Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate tracking of cellular and subcellular structures, along with their dynamics, plays a pivotal role in understanding the underlying mechanisms of biological systems. This paper presents a novel approach, ProGroTrack, that combines the You Only Look Once (YOLO) and ByteTrack algorithms within the detection-based tracking (DBT) framework to track intracellular protein nanostructures. Focusing on iPAK4 protein fibers as a representative case study, we conducted a comprehensive evaluation of YOLOv5 and YOLOv8 models, revealing the superior performance of YOLOv5 on our dataset. Notably, YOLOv5x achieved an impressive mAP50 of 0.839 and F-score of 0.819. To further optimize detection capabilities, we incorporated semi-supervised learning for model improvement, resulting in enhanced performances in all metrics. Subsequently, we successfully applied our approach to track the growth behavior of iPAK4 protein fibers, revealing their two distinct growth phases consistent with a previously reported kinetic model. This research showcases the promising potential of our approach, extending beyond iPAK4 fibers. It also offers a significant advancement in precise tracking of dynamic processes in live cells, and fostering new avenues for biomedical research.
<div id='section'>Paperid: <span id='pid'>1398, <a href='https://arxiv.org/pdf/2305.15441.pdf' target='_blank'>https://arxiv.org/pdf/2305.15441.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>M. Zaki Jawaid, Robin W. Yeo, Aayushma Gautam, T. Blair Gainous, Daniel O. Hart, Timothy P. Daley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.15441">Improving few-shot learning-based protein engineering with evolutionary sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing novel functional proteins remains a slow and expensive process due to a variety of protein engineering challenges; in particular, the number of protein variants that can be experimentally tested in a given assay pales in comparison to the vastness of the overall sequence space, resulting in low hit rates and expensive wet lab testing cycles. In this paper, we propose a few-shot learning approach to novel protein design that aims to accelerate the expensive wet lab testing cycle and is capable of leveraging a training dataset that is both small and skewed ($\approx 10^5$ datapoints, $< 1\%$ positive hits). Our approach is composed of two parts: a semi-supervised transfer learning approach to generate a discrete fitness landscape for a desired protein function and a novel evolutionary Monte Carlo Markov Chain sampling algorithm to more efficiently explore the fitness landscape. We demonstrate the performance of our approach by experimentally screening predicted high fitness gene activators, resulting in a dramatically improved hit rate compared to existing methods. Our method can be easily adapted to other protein engineering and design problems, particularly where the cost associated with obtaining labeled data is significantly high. We have provided open source code for our method at https:// github.com/SuperSecretBioTech/evolutionary_monte_carlo_search.
<div id='section'>Paperid: <span id='pid'>1399, <a href='https://arxiv.org/pdf/2305.12297.pdf' target='_blank'>https://arxiv.org/pdf/2305.12297.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ginestra Bianconi, Sergey N. Dorogovtsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.12297">The theory of percolation on hypergraphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hypergraphs capture the higher-order interactions in complex systems and always admit a factor graph representation, consisting of a bipartite network of nodes and hyperedges. As hypegraphs are ubiquitous, investigating hypergraph robustness is a problem of major research interest. In the literature the robustness of hypergraphs as been so far only treated adopting factor-graph percolation which describe well higher-order interactions which remain functional even after the removal of one of more of their nodes. This approach, however, fall short to describe situations in which higher-order interactions fail when anyone of their nodes is removed, this latter scenario applying for instance to supply chains, catalytic networks, protein-interaction networks, networks of chemical reactions, etc. Here we show that in these cases the correct process to investigate is hypergraph percolation with is distinct from factor graph percolation. We build a message-passing theory of hypergraph percolation and we investigate its critical behavior using generating function formalism supported by Monte Carlo simulations on random graph and real data. Notably, we show that the node percolation threshold on hypergraphs exceeds node percolation threshold on factor graphs. Furthermore we show that differently from what happens in ordinary graphs, on hypergraphs the node percolation threshold and hyperedge percolation threshold do not coincide, with the node percolation threshold exceeding the hyperedge percolation threshold. These results demonstrate that any fat-tailed cardinality distribution of hyperedges cannot lead to the hyper-resilience phenomenon in hypergraphs in contrast to their factor graphs, where the divergent second moment of a cardinality distribution guarantees zero percolation threshold.
<div id='section'>Paperid: <span id='pid'>1400, <a href='https://arxiv.org/pdf/2305.11398.pdf' target='_blank'>https://arxiv.org/pdf/2305.11398.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yelena Mejova, Lydia Manikonda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.11398">Comfort Foods and Community Connectedness: Investigating Diet Change during COVID-19 Using YouTube Videos on Twitter</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unprecedented lockdowns at the start of the COVID-19 pandemic have drastically changed the routines of millions of people, potentially impacting important health-related behaviors. In this study, we use YouTube videos embedded in tweets about diet, exercise and fitness posted before and during COVID-19 to investigate the influence of the pandemic lockdowns on diet and nutrition. In particular, we examine the nutritional profile of the foods mentioned in the transcript, description and title of each video in terms of six macronutrients (protein, energy, fat, sodium, sugar, and saturated fat). These macronutrient values were further linked to demographics to assess if there are specific effects on those potentially having insufficient access to healthy sources of food. Interrupted time series analysis revealed a considerable shift in the aggregated macronutrient scores before and during COVID-19. In particular, whereas areas with lower incomes showed decrease in energy, fat, and saturated fat, those with higher percentage of African Americans showed an elevation in sodium. Word2Vec word similarities and odds ratio analysis suggested a shift from popular diets and lifestyle bloggers before the lockdowns to the interest in a variety of healthy foods, communal sharing of quick and easy recipes, as well as a new emphasis on comfort foods. To the best of our knowledge, this work is novel in terms of linking attention signals in tweets, content of videos, their nutrients profile, and aggregate demographics of the users. The insights made possible by this combination of resources are important for monitoring the secondary health effects of social distancing, and informing social programs designed to alleviate these effects.
<div id='section'>Paperid: <span id='pid'>1401, <a href='https://arxiv.org/pdf/2305.03136.pdf' target='_blank'>https://arxiv.org/pdf/2305.03136.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David H. Brookes, Jakub Otwinowski, Sam Sinai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.03136">Contrastive losses as generalized models of global epistasis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fitness functions map large combinatorial spaces of biological sequences to properties of interest. Inferring these multimodal functions from experimental data is a central task in modern protein engineering. Global epistasis models are an effective and physically-grounded class of models for estimating fitness functions from observed data. These models assume that a sparse latent function is transformed by a monotonic nonlinearity to emit measurable fitness. Here we demonstrate that minimizing supervised contrastive loss functions, such as the Bradley-Terry loss, is a simple and flexible technique for extracting the sparse latent function implied by global epistasis. We argue by way of a fitness-epistasis uncertainty principle that the nonlinearities in global epistasis models can produce observed fitness functions that do not admit sparse representations, and thus may be inefficient to learn from observations when using a Mean Squared Error (MSE) loss (a common practice). We show that contrastive losses are able to accurately estimate a ranking function from limited data even in regimes where MSE is ineffective and validate the practical utility of this insight by demonstrating that contrastive loss functions result in consistently improved performance on benchmark tasks.
<div id='section'>Paperid: <span id='pid'>1402, <a href='https://arxiv.org/pdf/2305.01941.pdf' target='_blank'>https://arxiv.org/pdf/2305.01941.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sergio Romero-Romero, Sebastian Lindner, Noelia Ferruz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.01941">Exploring the Protein Sequence Space with Global Generative Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in specialized large-scale architectures for training image and language have profoundly impacted the field of computer vision and natural language processing (NLP). Language models, such as the recent ChatGPT and GPT4 have demonstrated exceptional capabilities in processing, translating, and generating human languages. These breakthroughs have also been reflected in protein research, leading to the rapid development of numerous new methods in a short time, with unprecedented performance. Language models, in particular, have seen widespread use in protein research, as they have been utilized to embed proteins, generate novel ones, and predict tertiary structures. In this book chapter, we provide an overview of the use of protein generative models, reviewing 1) language models for the design of novel artificial proteins, 2) works that use non-Transformer architectures, and 3) applications in directed evolution approaches.
<div id='section'>Paperid: <span id='pid'>1403, <a href='https://arxiv.org/pdf/2304.03775.pdf' target='_blank'>https://arxiv.org/pdf/2304.03775.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alan Nawzad Amin, Eli Nathan Weinstein, Debora Susan Marks
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.03775">Biological Sequence Kernels with Guaranteed Flexibility</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Applying machine learning to biological sequences - DNA, RNA and protein - has enormous potential to advance human health, environmental sustainability, and fundamental biological understanding. However, many existing machine learning methods are ineffective or unreliable in this problem domain. We study these challenges theoretically, through the lens of kernels. Methods based on kernels are ubiquitous: they are used to predict molecular phenotypes, design novel proteins, compare sequence distributions, and more. Many methods that do not use kernels explicitly still rely on them implicitly, including a wide variety of both deep learning and physics-based techniques. While kernels for other types of data are well-studied theoretically, the structure of biological sequence space (discrete, variable length sequences), as well as biological notions of sequence similarity, present unique mathematical challenges. We formally analyze how well kernels for biological sequences can approximate arbitrary functions on sequence space and how well they can distinguish different sequence distributions. In particular, we establish conditions under which biological sequence kernels are universal, characteristic and metrize the space of distributions. We show that a large number of existing kernel-based machine learning methods for biological sequences fail to meet our conditions and can as a consequence fail severely. We develop straightforward and computationally tractable ways of modifying existing kernels to satisfy our conditions, imbuing them with strong guarantees on accuracy and reliability. Our proof techniques build on and extend the theory of kernels with discrete masses. We illustrate our theoretical results in simulation and on real biological data sets.
<div id='section'>Paperid: <span id='pid'>1404, <a href='https://arxiv.org/pdf/2304.02682.pdf' target='_blank'>https://arxiv.org/pdf/2304.02682.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arjang Fahim, Stephanie Irausquin, Homayoun Valafar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.02682">nD-PDPA: nDimensional Probability Density Profile Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the recent advances in various Structural Genomics Projects, a large gap remains between the number of sequenced and structurally characterized proteins. Some reasons for this discrepancy include technical difficulties, labor, and the cost related to determining a structure by experimental methods such as NMR spectroscopy. Several computational methods have been developed to expand the applicability of NMR spectroscopy by addressing temporal and economical problems more efficiently. While these methods demonstrate successful outcomes to solve more challenging and structurally novel proteins, the cost has not been reduced significantly. Probability Density Profile Analysis (PDPA) has been previously introduced by our lab to directly address the economics of structure determination of routine proteins and the identification of novel structures from a minimal set of unassigned NMR data. 2D-PDPA (in which 2D denotes incorporation of data from two alignment media) has been successful in identifying the structural homolog of an unknown protein within a library of ~1000 decoy structures. In order to further expand the selectivity and sensitivity of PDPA, the incorporation of additional data was necessary. However, the expansion of the original PDPA approach was limited by its computational requirements where the inclusion of additional data would render it computationally intractable. Here we present the most recent developments of PDPA method (nD-PDPA: n Dimensional Probability Density Profile Analysis) that eliminate 2D-PDPA's computational limitations, and allows inclusion of RDC data from multiple vector types in multiple alignment media.
<div id='section'>Paperid: <span id='pid'>1405, <a href='https://arxiv.org/pdf/2303.16209.pdf' target='_blank'>https://arxiv.org/pdf/2303.16209.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Myeonghun Lee, Kyoungmin Min
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.16209">AmorProt: Amino Acid Molecular Fingerprints Repurposing based Protein Fingerprint</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As protein therapeutics play an important role in almost all medical fields, numerous studies have been conducted on proteins using artificial intelligence. Artificial intelligence has enabled data driven predictions without the need for expensive experiments. Nevertheless, unlike the various molecular fingerprint algorithms that have been developed, protein fingerprint algorithms have rarely been studied. In this study, we proposed the amino acid molecular fingerprints repurposing based protein (AmorProt) fingerprint, a protein sequence representation method that effectively uses the molecular fingerprints corresponding to 20 amino acids. Subsequently, the performances of the tree based machine learning and artificial neural network models were compared using (1) amyloid classification and (2) isoelectric point regression. Finally, the applicability and advantages of the developed platform were demonstrated through a case study and the following experiments: (3) comparison of dataset dependence with feature based methods; (4) feature importance analysis; and (5) protein space analysis. Consequently, the significantly improved model performance and data set independent versatility of the AmorProt fingerprint were verified. The results revealed that the current protein representation method can be applied to various fields related to proteins, such as predicting their fundamental properties or interaction with ligands.
<div id='section'>Paperid: <span id='pid'>1406, <a href='https://arxiv.org/pdf/2303.11833.pdf' target='_blank'>https://arxiv.org/pdf/2303.11833.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunseung Kim, Haeyeon Choi, Dongju Kang, Won Bo Lee, Jonggeol Na
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.11833">Materials Discovery with Extreme Properties via Reinforcement Learning-Guided Combinatorial Chemistry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of most materials discovery is to discover materials that are superior to those currently known. Fundamentally, this is close to extrapolation, which is a weak point for most machine learning models that learn the probability distribution of data. Herein, we develop reinforcement learning-guided combinatorial chemistry, which is a rule-based molecular designer driven by trained policy for selecting subsequent molecular fragments to get a target molecule. Since our model has the potential to generate all possible molecular structures that can be obtained from combinations of molecular fragments, unknown molecules with superior properties can be discovered. We theoretically and empirically demonstrate that our model is more suitable for discovering better compounds than probability distribution-learning models. In an experiment aimed at discovering molecules that hit seven extreme target properties, our model discovered 1,315 of all target-hitting molecules and 7,629 of five target-hitting molecules out of 100,000 trials, whereas the probability distribution-learning models failed. Moreover, it has been confirmed that every molecule generated under the binding rules of molecular fragments is 100% chemically valid. To illustrate the performance in actual problems, we also demonstrate that our models work well on two practical applications: discovering protein docking molecules and HIV inhibitors.
<div id='section'>Paperid: <span id='pid'>1407, <a href='https://arxiv.org/pdf/2303.11434.pdf' target='_blank'>https://arxiv.org/pdf/2303.11434.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Partho Ghosh, Md. Aynal Haque
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.11434">ResDTA: Predicting Drug-Target Binding Affinity Using Residual Skip Connections</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The discovery of novel drug target (DT) interactions is an important step in the drug development process. The majority of computer techniques for predicting DT interactions have focused on binary classification, with the goal of determining whether or not a DT pair interacts. Protein ligand interactions, on the other hand, assume a continuous range of binding strength values, also known as binding affinity, and forecasting this value remains a difficulty. As the amount of affinity data in DT knowledge-bases grows, advanced learning techniques such as deep learning architectures can be used to predict binding affinities. In this paper, we present a deep-learning-based methodology for predicting DT binding affinities using just sequencing information from both targets and drugs. The results show that the proposed deep learning-based model that uses the 1D representations of targets and drugs is an effective approach for drug target binding affinity prediction and it does not require additional chemical domain knowledge to work with. The model in which high-level representations of a drug and a target are constructed via CNNs that uses residual skip connections and also with an additional stream to create a high-level combined representation of the drug-target pair achieved the best Concordance Index (CI) performance in one of the largest benchmark datasets, outperforming the recent state-of-the-art method AttentionDTA and many other machine-learning and deep-learning based baseline methods for DT binding affinity prediction that uses the 1D representations of targets and drugs.
<div id='section'>Paperid: <span id='pid'>1408, <a href='https://arxiv.org/pdf/2303.08818.pdf' target='_blank'>https://arxiv.org/pdf/2303.08818.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daeseok Lee, Jeunghyun Byun, Bonggun Shin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08818">Boosting Convolutional Neural Networks' Protein Binding Site Prediction Capacity Using SE(3)-invariant transformers, Transfer Learning and Homology-based Augmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Figuring out small molecule binding sites in target proteins, in the resolution of either pocket or residue, is critical in many virtual and real drug-discovery scenarios. Since it is not always easy to find such binding sites based on domain knowledge or traditional methods, different deep learning methods that predict binding sites out of protein structures have been developed in recent years. Here we present a new such deep learning algorithm, that significantly outperformed all state-of-the-art baselines in terms of the both resolutions$\unicode{x2013}$pocket and residue. This good performance was also demonstrated in a case study involving the protein human serum albumin and its binding sites. Our algorithm included new ideas both in the model architecture and in the training method. For the model architecture, it incorporated SE(3)-invariant geometric self-attention layers that operate on top of residue-level CNN outputs. This residue-level processing of the model allowed a transfer learning between the two resolutions, which turned out to significantly improve the binding pocket prediction. Moreover, we developed novel augmentation method based on protein homology, which prevented our model from over-fitting. Overall, we believe that our contribution to the literature is twofold. First, we provided a new computational method for binding site prediction that is relevant to real-world applications, as shown by the good performance on different benchmarks and case study. Second, the novel ideas in our method$\unicode{x2013}$the model architecture, transfer learning and the homology augmentation$\unicode{x2013}$would serve as useful components in future works.
<div id='section'>Paperid: <span id='pid'>1409, <a href='https://arxiv.org/pdf/2303.06945.pdf' target='_blank'>https://arxiv.org/pdf/2303.06945.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxing Guo, Xuening Zhu, Zixin Hu, Xiaoxi Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.06945">CoGANPPIS: A Coevolution-enhanced Global Attention Neural Network for Protein-Protein Interaction Site Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein-protein interactions are of great importance in biochemical processes. Accurate prediction of protein-protein interaction sites (PPIs) is crucial for our understanding of biological mechanism. Although numerous approaches have been developed recently and achieved gratifying results, there are still two limitations: (1) Most existing models have excavated a number of useful input features, but failed to take coevolutionary features into account, which could provide clues for inter-residue relationships; (2) The attention-based models only allocate attention weights for neighboring residues, instead of doing it globally, which may limit the model's prediction performance since some residues being far away from the target residues might also matter.
  We propose a coevolution-enhanced global attention neural network, a sequence-based deep learning model for PPIs prediction, called CoGANPPIS. Specifically, CoGANPPIS utilizes three layers in parallel for feature extraction: (1) Local-level representation aggregation layer, which aggregates the neighboring residues' features as the local feature representation; (2) Global-level representation learning layer, which employs a novel coevolution-enhanced global attention mechanism to allocate attention weights to all residues on the same protein sequences; (3) Coevolutionary information learning layer, which applies CNN & pooling to coevolutionary information to obtain the coevolutionary profile representation. Then, the three outputs are concatenated and passed into several fully connected layers for the final prediction. Extensive experiments on two benchmark datasets have been conducted, demonstrating that our proposed model achieves the state-of-the-art performance.
<div id='section'>Paperid: <span id='pid'>1410, <a href='https://arxiv.org/pdf/2302.09563.pdf' target='_blank'>https://arxiv.org/pdf/2302.09563.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huijuan Wang, Maurice HT Ling, Tze Kwang Chua, Chueh Loo Poh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.09563">Two Cellular Resource Based Models Linking Growth and Parts Characteristics Aids the Study and Optimization of Synthetic Gene Circuits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A major challenge in synthetic genetic circuit development is the inter-dependency between heterologous gene expressions by circuits and host's growth rate. Increasing heterologous gene expression increases burden to the host, resulting in host growth reduction; which reduces overall heterologous protein abundance. Hence, it is difficult to design predictable genetic circuits. Here, we develop two biophysical models; one for promoter, another for RBS; to correlate heterologous gene expression and growth reduction. We model cellular resource allocation in E. coli to describe the burden, as growth reduction, caused by genetic circuits. To facilitate their uses in genetic circuit design, inputs to the model are common characteristics of biological parts [e.g. relative promoter strength (RPU) and relative ribosome binding sites strength (RRU)]. The models suggest that E. coli's growth rate reduces linearly with increasing RPU / RRU of the genetic circuits; thus, providing 2 handy models taking parts characteristics as input to estimate growth rate reduction for fine tuning genetic circuit design in silico prior to construction. Our promoter model correlates well with experiments using various genetic circuits, both single and double expression cassettes, up to a relative promoter unit of 3.7 with a 60% growth rate reduction (average R2 ~ 0.9).
<div id='section'>Paperid: <span id='pid'>1411, <a href='https://arxiv.org/pdf/2302.03294.pdf' target='_blank'>https://arxiv.org/pdf/2302.03294.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan Parkinson, Wei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.03294">Linear-scaling kernels for protein sequences and small molecules outperform deep learning while providing uncertainty quantitation and improved interpretability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gaussian process (GP) is a Bayesian model which provides several advantages for regression tasks in machine learning such as reliable quantitation of uncertainty and improved interpretability. Their adoption has been precluded by their excessive computational cost and by the difficulty in adapting them for analyzing sequences (e.g. amino acid and nucleotide sequences) and graphs (e.g. ones representing small molecules). In this study, we develop efficient and scalable approaches for fitting GP models as well as fast convolution kernels which scale linearly with graph or sequence size. We implement these improvements by building an open-source Python library called xGPR. We compare the performance of xGPR with the reported performance of various deep learning models on 20 benchmarks, including small molecule, protein sequence and tabular data. We show that xGRP achieves highly competitive performance with much shorter training time. Furthermore, we also develop new kernels for sequence and graph data and show that xGPR generally outperforms convolutional neural networks on predicting key properties of proteins and small molecules. Importantly, xGPR provides uncertainty information not available from typical deep learning models. Additionally, xGPR provides a representation of the input data that can be used for clustering and data visualization. These results demonstrate that xGPR provides a powerful and generic tool that can be broadly useful in protein engineering and drug discovery.
<div id='section'>Paperid: <span id='pid'>1412, <a href='https://arxiv.org/pdf/2302.02811.pdf' target='_blank'>https://arxiv.org/pdf/2302.02811.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohit Goswami, Ruhila S., Amrita Goswami, Sonaly Goswami, Debabrata Goswami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.02811">Unified Software Design Patterns for Simulated Annealing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Any optimization algorithm programming interface can be seen as a black-box function with additional free parameters. In this spirit, simulated annealing (SA) can be implemented in pseudo-code within the dimensions of a single slide with free parameters relating to the annealing schedule. Such an implementation, however, necessarily neglects much of the structure necessary to take advantage of advances in computing resources and algorithmic breakthroughs. Simulated annealing is often introduced in myriad disciplines, from discrete examples like the Traveling Salesman Problem (TSP) to molecular cluster potential energy exploration or even explorations of a protein's configurational space. Theoretical guarantees also demand a stricter structure in terms of statistical quantities, which cannot simply be left to the user. We will introduce several standard paradigms and demonstrate how these can be "lifted" into a unified framework using object-oriented programming in Python. We demonstrate how clean, interoperable, reproducible programming libraries can be used to access and rapidly iterate on variants of Simulated Annealing in a manner which can be extended to serve as a best practices blueprint or design pattern for a data-driven optimization library.
<div id='section'>Paperid: <span id='pid'>1413, <a href='https://arxiv.org/pdf/2302.02427.pdf' target='_blank'>https://arxiv.org/pdf/2302.02427.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sneha K H, Adhithya Sudeesh, Pramod P Nair, Prashanth Suravajhala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.02427">Biologically inspired ChaosNet architecture for Hypothetical Protein Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>ChaosNet is a type of artificial neural network framework developed for classification problems and is influenced by the chaotic property of the human brain. Each neuron of the ChaosNet architecture is the one-dimensional chaotic map called the Generalized Luroth Series (GLS). The addition of GLS as neurons in ChaosNet makes the computations straightforward while utilizing the advantageous elements of chaos. With substantially less data, ChaosNet has been demonstrated to do difficult classification problems on par with or better than traditional ANNs. In this paper, we use Chaosnet to perform a functional classification of Hypothetical proteins [HP], which is indeed a topic of great interest in bioinformatics. The results obtained with significantly lesser training data are compared with the standard machine learning techniques used in the literature.
<div id='section'>Paperid: <span id='pid'>1414, <a href='https://arxiv.org/pdf/2302.01435.pdf' target='_blank'>https://arxiv.org/pdf/2302.01435.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tong Lin, Sijie Chen, Ruchira Basu, Dehu Pei, Xiaolin Cheng, Levent Burak Kara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.01435">Target specific peptide design using latent space approximate trajectory collector</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the prevalence and many successes of deep learning applications in de novo molecular design, the problem of peptide generation targeting specific proteins remains unsolved. A main barrier for this is the scarcity of the high-quality training data. To tackle the issue, we propose a novel machine learning based peptide design architecture, called Latent Space Approximate Trajectory Collector (LSATC). It consists of a series of samplers on an optimization trajectory on a highly non-convex energy landscape that approximates the distributions of peptides with desired properties in a latent space. The process involves little human intervention and can be implemented in an end-to-end manner. We demonstrate the model by the design of peptide extensions targeting Beta-catenin, a key nuclear effector protein involved in canonical Wnt signalling. When compared with a random sampler, LSATC can sample peptides with $36\%$ lower binding scores in a $16$ times smaller interquartile range (IQR) and $284\%$ less hydrophobicity with a $1.4$ times smaller IQR. LSATC also largely outperforms other common generative models. Finally, we utilized a clustering algorithm to select 4 peptides from the 100 LSATC designed peptides for experimental validation. The result confirms that all the four peptides extended by LSATC show improved Beta-catenin binding by at least $20.0\%$, and two of the peptides show a $3$ fold increase in binding affinity as compared to the base peptide.
<div id='section'>Paperid: <span id='pid'>1415, <a href='https://arxiv.org/pdf/2301.11288.pdf' target='_blank'>https://arxiv.org/pdf/2301.11288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>HacÄ± Ä°smail Aslan, Chang Choi, Hoon Ko
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.11288">Classification of vertices on social networks by multiple approaches</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the advent of the expressions of data other than tabular formats, the topological compositions which make samples interrelated came into prominence. Analogically, those networks can be interpreted as social connections, dataflow maps, citation influence graphs, protein bindings, etc. However, in the case of social networks, it is highly crucial to evaluate the labels of discrete communities. The reason underneath for such a study is the non-negligible importance of analyzing graph networks to partition the vertices by using the topological features of network graphs, solely. For each of these interaction-based entities, a social graph, a mailing dataset, and two citation sets are selected as the testbench repositories. This paper, it was not only assessed the most valuable method but also determined how graph neural networks work and the need to improve against non-neural network approaches which are faster and computationally cost-effective. Also, this paper showed a limit to be excesses by prospective graph neural network variations by using the topological features of networks trialed.
<div id='section'>Paperid: <span id='pid'>1416, <a href='https://arxiv.org/pdf/2301.10612.pdf' target='_blank'>https://arxiv.org/pdf/2301.10612.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>AyÅenaz Ezgi Ergin, Deniz Turgay AltÄ±lar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.10612">Consensus Algorithm For Calculation Of Protein Binding Affinity Using Multiple Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The major histocompatibility complex (MHC) molecules, which bind peptides for presentation on the cell surface, play an important role in cell-mediated immunity. In light of developing databases and technologies over the years, significant progress has been made in research on peptide binding affinity calculation. Several in techniques have been developed to predict peptide binding to MHC class I. Most of the research on MHC Class I due to its nature brings better performance and more. Considering the use of different methods and different technologies, and the approach of similar methods on different proteins, a classification was created according to the binding affinity of protein peptides.
<div id='section'>Paperid: <span id='pid'>1417, <a href='https://arxiv.org/pdf/2301.04492.pdf' target='_blank'>https://arxiv.org/pdf/2301.04492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Hunkler, Kay Diederichs, Oleksandra Kukharenko, Christine Peter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.04492">Fast conformational clustering of extensive molecular dynamics simulation data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present an unsupervised data processing workflow that is specifically designed to obtain a fast conformational clustering of long molecular dynamics simulation trajectories. In this approach we combine two dimensionality reduction algorithms (cc\_analysis and encodermap) with a density-based spatial clustering algorithm (HDBSCAN). The proposed scheme benefits from the strengths of the three algorithms while avoiding most of the drawbacks of the individual methods. Here the cc\_analysis algorithm is for the first time applied to molecular simulation data. Encodermap complements cc\_analysis by providing an efficient way to process and assign large amounts of data to clusters. The main goal of the procedure is to maximize the number of assigned frames of a given trajectory, while keeping a clear conformational identity of the clusters that are found. In practice we achieve this by using an iterative clustering approach and a tunable root-mean-square-deviation-based criterion in the final cluster assignment. This allows to find clusters of different densities as well as different degrees of structural identity. With the help of four test systems we illustrate the capability and performance of this clustering workflow: wild-type and thermostable mutant of the Trp-cage protein (TC5b and TC10b), NTL9 and Protein B. Each of these systems poses individual challenges to the scheme, which in total give a nice overview of the advantages, as well as potential difficulties that can arise when using the proposed method.
<div id='section'>Paperid: <span id='pid'>1418, <a href='https://arxiv.org/pdf/2301.02748.pdf' target='_blank'>https://arxiv.org/pdf/2301.02748.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon K. S. Chu, Kathy Y. Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.02748">Generative Antibody Design for Complementary Chain Pairing Sequences through Encoder-Decoder Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current protein language models (pLMs) predominantly focus on single-chain protein sequences and often have not accounted for constraints on generative design imposed by protein-protein interactions. To address this gap, we present paired Antibody T5 (pAbT5), an encoder-decoder model to generate complementary heavy or light chain from its pairing partner. We show that our model respects conservation in framework regions and variability in hypervariable domains, demonstrated by agreement with sequence alignment and variable-length CDR loops. We also show that our model captures chain pairing preferences through the recovery of ground-truth chain type and gene families. Our results showcase the potential of pAbT5 in generative antibody design, incorporating biological constraints from chain pairing preferences.
<div id='section'>Paperid: <span id='pid'>1419, <a href='https://arxiv.org/pdf/2301.00843.pdf' target='_blank'>https://arxiv.org/pdf/2301.00843.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Chen, Alexander G. Strang, Andrew W. Eckford, Peter J. Thomas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.00843">Explicitly Solvable Continuous-time Inference for Partially Observed Markov Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many natural and engineered systems can be modeled as discrete state Markov processes. Often, only a subset of states are directly observable. Inferring the conditional probability that a system occupies a particular hidden state, given the partial observation, is a problem with broad application. In this paper, we introduce a continuous-time formulation of the sum-product algorithm, which is a well-known discrete-time method for finding the hidden states' conditional probabilities, given a set of finite, discrete-time observations. From our new formulation, we can explicitly solve for the conditional probability of occupying any state, given the transition rates and observations within a finite time window. We apply our algorithm to a realistic model of the cystic fibrosis transmembrane conductance regulator (CFTR) protein for exact inference of the conditional occupancy probability, given a finite time series of partial observations.
<div id='section'>Paperid: <span id='pid'>1420, <a href='https://arxiv.org/pdf/2212.14206.pdf' target='_blank'>https://arxiv.org/pdf/2212.14206.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pranjali Awasthi, David Recio-Mitter, Yosuke Kyle Sugi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.14206">Maximizing Use-Case Specificity through Precision Model Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Language models have become increasingly popular in recent years for tasks like information retrieval. As use-cases become oriented toward specific domains, fine-tuning becomes default for standard performance. To fine-tune these models for specific tasks and datasets, it is necessary to carefully tune the model's hyperparameters and training techniques. In this paper, we present an in-depth analysis of the performance of four transformer-based language models on the task of biomedical information retrieval. The models we consider are DeepMind's RETRO (7B parameters), GPT-J (6B parameters), GPT-3 (175B parameters), and BLOOM (176B parameters). We compare their performance on the basis of relevance, accuracy, and interpretability, using a large corpus of 480000 research papers on protein structure/function prediction as our dataset. Our findings suggest that smaller models, with <10B parameters and fine-tuned on domain-specific datasets, tend to outperform larger language models on highly specific questions in terms of accuracy, relevancy, and interpretability by a significant margin (+50% on average). However, larger models do provide generally better results on broader prompts.
<div id='section'>Paperid: <span id='pid'>1421, <a href='https://arxiv.org/pdf/2212.01191.pdf' target='_blank'>https://arxiv.org/pdf/2212.01191.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peter C. Kroon, Fabian GrÃ¼newald, Jonathan Barnoud, Marco van Tilburg, Chris Brasnett, Paulo C. T. Souza, Tsjerk A. Wassenaar, Siewert-Jan Marrink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.01191">Martinize2 and Vermouth: Unified Framework for Topology Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ongoing advances in force field and computer hardware development enable the use of molecular dynamics (MD) to simulate increasingly complex systems with the ultimate goal of reaching cellular complexity. At the same time, rational design by high-throughput (HT) simulations is another forefront of MD. In these areas, the Martini coarse-grained force field, especially the latest version (i.e. v3), is being actively explored because it offers an enhanced spatial-temporal resolution. However, the automation tools for preparing simulations with the Martini force field, accompanying the previous version, were not designed for HT simulations or studies of complex cellular systems. Therefore, they become a major limiting factor. To address these shortcomings, we present the open-source Vermouth python library. Vermouth is designed to become the unified framework for developing programs, which prepare, run, and analyze Martini simulations of complex systems. To demonstrate the power of the Vermouth library, the Martinize2 program is showcased as a generalization of the martinize script, originally aimed to set up simulations of proteins. In contrast to the previous version, Martinize2 automatically handles protonation states in proteins and post-translation modifications, offers more options to fine-tune structural biases such as the elastic network (EN), and can convert non-protein molecules such as ligands. Finally, Martinize2 is used in two high-complexity benchmarks. The entire I-TASSER protein template database as well as a subset of 200,000 structures from the AlphaFold Protein Structure Database are converted to CG resolution and we illustrate how the checks on input structure quality can safeguard high-throughput applications.
<div id='section'>Paperid: <span id='pid'>1422, <a href='https://arxiv.org/pdf/2211.15669.pdf' target='_blank'>https://arxiv.org/pdf/2211.15669.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yeojin Kim, Hyunju Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.15669">PINNet: a deep neural network with pathway prior knowledge for Alzheimer's disease</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identification of Alzheimer's Disease (AD)-related transcriptomic signatures from blood is important for early diagnosis of the disease. Deep learning techniques are potent classifiers for AD diagnosis, but most have been unable to identify biomarkers because of their lack of interpretability. To address these challenges, we propose a pathway information-based neural network (PINNet) to predict AD patients and analyze blood and brain transcriptomic signatures using an interpretable deep learning model. PINNet is a deep neural network (DNN) model with pathway prior knowledge from either the Gene Ontology or Kyoto Encyclopedia of Genes and Genomes databases. Then, a backpropagation-based model interpretation method was applied to reveal essential pathways and genes for predicting AD. We compared the performance of PINNet with a DNN model without a pathway. Performances of PINNet outperformed or were similar to those of DNN without a pathway using blood and brain gene expressions, respectively. Moreover, PINNet considers more AD-related genes as essential features than DNN without a pathway in the learning process. Pathway analysis of protein-protein interaction modules of highly contributed genes showed that AD-related genes in blood were enriched with cell migration, PI3K-Akt, MAPK signaling, and apoptosis in blood. The pathways enriched in the brain module included cell migration, PI3K-Akt, MAPK signaling, apoptosis, protein ubiquitination, and t-cell activation. Collectively, with prior knowledge about pathways, PINNet reveals essential pathways related to AD.
<div id='section'>Paperid: <span id='pid'>1423, <a href='https://arxiv.org/pdf/2207.06399.pdf' target='_blank'>https://arxiv.org/pdf/2207.06399.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Constantine Glen Evans, Jackson O'Brien, Erik Winfree, Arvind Murugan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.06399">Pattern recognition in the nucleation kinetics of non-equilibrium self-assembly</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inspired by biology's most sophisticated computer, the brain, neural networks constitute a profound reformulation of computational principles. Remarkably, analogous high-dimensional, highly-interconnected computational architectures also arise within information-processing molecular systems inside living cells, such as signal transduction cascades and genetic regulatory networks. Might neuromorphic collective modes be found more broadly in other physical and chemical processes, even those that ostensibly play non-information-processing roles such as protein synthesis, metabolism, or structural self-assembly? Here we examine nucleation during self-assembly of multicomponent structures, showing that high-dimensional patterns of concentrations can be discriminated and classified in a manner similar to neural network computation. Specifically, we design a set of 917 DNA tiles that can self-assemble in three alternative ways such that competitive nucleation depends sensitively on the extent of co-localization of high-concentration tiles within the three structures. The system was trained in-silico to classify a set of 18 grayscale 30 x 30 pixel images into three categories. Experimentally, fluorescence and atomic force microscopy monitoring during and after a 150-hour anneal established that all trained images were correctly classified, while a test set of image variations probed the robustness of the results. While slow compared to prior biochemical neural networks, our approach is surprisingly compact, robust, and scalable. This success suggests that ubiquitous physical phenomena, such as nucleation, may hold powerful information processing capabilities when scaled up as high-dimensional multicomponent systems.
<div id='section'>Paperid: <span id='pid'>1424, <a href='https://arxiv.org/pdf/2206.15051.pdf' target='_blank'>https://arxiv.org/pdf/2206.15051.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Brent Sprangers, Nick Vannieuwenhoven
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.15051">Group-invariant tensor train networks for supervised learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Invariance has recently proven to be a powerful inductive bias in machine learning models. One such class of predictive or generative models are tensor networks. We introduce a new numerical algorithm to construct a basis of tensors that are invariant under the action of normal matrix representations of an arbitrary discrete group. This method can be up to several orders of magnitude faster than previous approaches. The group-invariant tensors are then combined into a group-invariant tensor train network, which can be used as a supervised machine learning model. We applied this model to a protein binding classification problem, taking into account problem-specific invariances, and obtained prediction accuracy in line with state-of-the-art deep learning approaches.
<div id='section'>Paperid: <span id='pid'>1425, <a href='https://arxiv.org/pdf/2206.11600.pdf' target='_blank'>https://arxiv.org/pdf/2206.11600.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jorge Fernandez-de-Cossio-Diaz, Simona Cocco, Remi Monasson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.11600">Disentangling representations in Restricted Boltzmann Machines without adversaries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A goal of unsupervised machine learning is to build representations of complex high-dimensional data, with simple relations to their properties. Such disentangled representations make easier to interpret the significant latent factors of variation in the data, as well as to generate new data with desirable features. Methods for disentangling representations often rely on an adversarial scheme, in which representations are tuned to avoid discriminators from being able to reconstruct information about the data properties (labels). Unfortunately adversarial training is generally difficult to implement in practice. Here we propose a simple, effective way of disentangling representations without any need to train adversarial discriminators, and apply our approach to Restricted Boltzmann Machines (RBM), one of the simplest representation-based generative models. Our approach relies on the introduction of adequate constraints on the weights during training, which allows us to concentrate information about labels on a small subset of latent variables. The effectiveness of the approach is illustrated with four examples: the CelebA dataset of facial images, the two-dimensional Ising model, the MNIST dataset of handwritten digits, and the taxonomy of protein families. In addition, we show how our framework allows for analytically computing the cost, in terms of log-likelihood of the data, associated to the disentanglement of their representations.
<div id='section'>Paperid: <span id='pid'>1426, <a href='https://arxiv.org/pdf/2206.02925.pdf' target='_blank'>https://arxiv.org/pdf/2206.02925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manu Aggarwal, Vipul Periwal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.02925">Tight basis cycle representatives for persistent homology of large data sets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Persistent homology (PH) is a popular tool for topological data analysis that has found applications across diverse areas of research. It provides a rigorous method to compute robust topological features in discrete experimental observations that often contain various sources of uncertainties. Although powerful in theory, PH suffers from high computation cost that precludes its application to large data sets. Additionally, most analyses using PH are limited to computing the existence of nontrivial features. Precise localization of these features is not generally attempted because, by definition, localized representations are not unique and because of even higher computation cost. For scientific applications, such a precise location is a sine qua non for determining functional significance. Here, we provide a strategy and algorithms to compute tight representative boundaries around nontrivial robust features in large data sets. To showcase the efficiency of our algorithms and the precision of computed boundaries, we analyze three data sets from different scientific fields. In the human genome, we found an unexpected effect on loops through chromosome 13 and the sex chromosomes, upon impairment of chromatin loop formation. In a distribution of galaxies in the universe, we found statistically significant voids. In protein homologs with significantly different topology, we found voids attributable to ligand-interaction, mutation, and differences between species.
<div id='section'>Paperid: <span id='pid'>1427, <a href='https://arxiv.org/pdf/2205.15364.pdf' target='_blank'>https://arxiv.org/pdf/2205.15364.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiqin Zhu, Zheng Yao, Guanqiu Qi, Neal Mazur, Baisen Cong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.15364">Associative Learning Mechanism for Drug-Target Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a necessary process in drug development, finding a drug compound that can selectively bind to a specific protein is highly challenging and costly. Drug-target affinity (DTA), which represents the strength of drug-target interaction (DTI), has played an important role in the DTI prediction task over the past decade. Although deep learning has been applied to DTA-related research, existing solutions ignore fundamental correlations between molecular substructures in molecular representation learning of drug compound molecules/protein targets. Moreover, traditional methods lack the interpretability of the DTA prediction process. This results in missing feature information of intermolecular interactions, thereby affecting prediction performance. Therefore, this paper proposes a DTA prediction method with interactive learning and an autoencoder mechanism. The proposed model enhances the corresponding ability to capture the feature information of a single molecular sequence by the drug/protein molecular representation learning module and supplements the information interaction between molecular sequence pairs by the interactive information learning module. The DTA value prediction module fuses the drug-target pair interaction information to output the predicted value of DTA. Additionally, this paper theoretically proves that the proposed method maximizes evidence lower bound (ELBO) for the joint distribution of the DTA prediction model, which enhances the consistency of the probability distribution between the actual value and the predicted value. The experimental results confirm mutual transformer-drug target affinity (MT-DTA) achieves better performance than other comparative methods.
<div id='section'>Paperid: <span id='pid'>1428, <a href='https://arxiv.org/pdf/2205.00071.pdf' target='_blank'>https://arxiv.org/pdf/2205.00071.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>FrÃ©dÃ©ric Giroire, Nicolas Nisse, Kostiantyn Ohulchanskyi, MaÅgorzata Sulkowska, Thibaud Trolliet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.00071">Preferential attachment hypergraph with vertex deactivation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of complex networks, hypergraph models have so far received significantly less attention than graphs. However, many real-life networks feature multiary relations (co-authorship, protein reactions) may therefore be modeled way better by hypergraphs. Also, a recent study by Broido and Clauset suggests that a power-law degree distribution is not as ubiquitous in the natural systems as it was thought so far. They experimentally confirm that a majority of networks (56% of around 1000 networks that undergone the test) favor a power-law with an exponential cutoff over other distributions. We address the two above observations by introducing a preferential attachment hypergraph model which allows for vertex deactivations. The phenomenon of vertex deactivations is rare in existing theoretical models and omnipresent in real-life scenarios (social network accounts which are not maintained forever, collaboration networks in which people retire, technological networks in which devices break down). We prove that the degree distribution of the proposed model follows a power-law with an exponential cutoff. We also check experimentally that a Scopus collaboration network has the same characteristic. We believe that our model will predict well the behavior of systems from a variety of domains.
<div id='section'>Paperid: <span id='pid'>1429, <a href='https://arxiv.org/pdf/2204.04117.pdf' target='_blank'>https://arxiv.org/pdf/2204.04117.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maksim Kitsak, Alexander Ganin, Ahmed Elmokashfi, Hongzhu Cui, Daniel A. Eisenberg, David L. Alderson, Dmitry Korkin, Igor Linkov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.04117">Finding shortest and nearly shortest path nodes in large substantially incomplete networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamic processes on networks, be it information transfer in the Internet, contagious spreading in a social network, or neural signaling, take place along shortest or nearly shortest paths. Unfortunately, our maps of most large networks are substantially incomplete due to either the highly dynamic nature of networks, or high cost of network measurements, or both, rendering traditional path finding methods inefficient. We find that shortest paths in large real networks, such as the network of protein-protein interactions (PPI) and the Internet at the autonomous system (AS) level, are not random but are organized according to latent-geometric rules. If nodes of these networks are mapped to points in latent hyperbolic spaces, shortest paths in them align along geodesic curves connecting endpoint nodes. We find that this alignment is sufficiently strong to allow for the identification of shortest path nodes even in the case of substantially incomplete networks. We demonstrate the utility of latent-geometric path-finding in problems of cellular pathway reconstruction and communication security.
<div id='section'>Paperid: <span id='pid'>1430, <a href='https://arxiv.org/pdf/2203.00999.pdf' target='_blank'>https://arxiv.org/pdf/2203.00999.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vikram Singh, Vikram Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.00999">DeepAutoPIN: An automorphism orbits based deep neural network for characterizing the organizational diversity of protein interactomes across the tree of life</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The enormous diversity of life forms thriving in drastically different environmental milieus involves a complex interplay among constituent proteins interacting with each other. However, the organizational principles characterizing the evolution of protein interaction networks (PINs) across the tree of life are largely unknown. Here we study 4,738 PINs belonging to 16 phyla to discover phyla-specific architectural features and examine if there are some evolutionary constraints imposed on the networks' topologies. We utilized positional information of a network's nodes by normalizing the frequencies of automorphism orbits appearing in graphlets of sizes 2-5. We report that orbit usage profiles (OUPs) of networks belonging to the three domains of life are contrastingly different not only at the domain level but also at the scale of phyla. Integrating the information related to protein families, domains, subcellular location, gene ontology, and pathways, our results indicate that wiring patterns of PINs in different phyla are not randomly generated rather they are shaped by evolutionary constraints imposed on them. There exist subtle but substantial variations in the wiring patterns of PINs that enable OUPs to differentiate among different superfamilies. A deep neural network was trained on differentially expressed orbits resulting in a prediction accuracy of 85%.
<div id='section'>Paperid: <span id='pid'>1431, <a href='https://arxiv.org/pdf/2202.03632.pdf' target='_blank'>https://arxiv.org/pdf/2202.03632.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenkun Shi, Qianqian Yuan, Ruoyu Wang, Hoaran Li, Xiaoping Liao, Hongwu Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.03632">ECRECer: Enzyme Commission Number Recommendation and Benchmarking based on Multiagent Dual-core Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enzyme Commission (EC) numbers, which associate a protein sequence with the biochemical reactions it catalyzes, are essential for the accurate understanding of enzyme functions and cellular metabolism. Many ab-initio computational approaches were proposed to predict EC numbers for given input sequences directly. However, the prediction performance (accuracy, recall, precision), usability, and efficiency of existing methods still have much room to be improved. Here, we report ECRECer, a cloud platform for accurately predicting EC numbers based on novel deep learning techniques. To build ECRECer, we evaluate different protein representation methods and adopt a protein language model for protein sequence embedding. After embedding, we propose a multi-agent hierarchy deep learning-based framework to learn the proposed tasks in a multi-task manner. Specifically, we used an extreme multi-label classifier to perform the EC prediction and employed a greedy strategy to integrate and fine-tune the final model. Comparative analyses against four representative methods demonstrate that ECRECer delivers the highest performance, which improves accuracy and F1 score by 70% and 20% over the state-of-the-the-art, respectively. With ECRECer, we can annotate numerous enzymes in the Swiss-Prot database with incomplete EC numbers to their full fourth level. Take UniPort protein "A0A0U5GJ41" as an example (1.14.-.-), ECRECer annotated it with "1.14.11.38", which supported by further protein structure analysis based on AlphaFold2. Finally, we established a webserver (https://ecrecer.biodesign.ac.cn) and provided an offline bundle to improve usability.
<div id='section'>Paperid: <span id='pid'>1432, <a href='https://arxiv.org/pdf/2201.12041.pdf' target='_blank'>https://arxiv.org/pdf/2201.12041.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Piotr Klukowski, Roland Riek, Peter GÃ¼ntert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.12041">Rapid protein assignments and structures from raw NMR spectra with the deep learning technique ARTINA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nuclear Magnetic Resonance (NMR) spectroscopy is one of the major techniques in structural biology with over 11,800 protein structures deposited in the Protein Data Bank. NMR can elucidate structures and dynamics of small and medium size proteins in solution, living cells, and solids, but has been limited by the tedious data analysis process. It typically requires weeks or months of manual work of a trained expert to turn NMR measurements into a protein structure. Automation of this process is an open problem, formulated in the field over 30 years ago. Here, we present a solution to this challenge that enables the completely automated analysis of protein NMR data within hours after completing the measurements. Using only NMR spectra and the protein sequence as input, our machine learning-based method, ARTINA, delivers signal positions, resonance assignments, and structures strictly without any human intervention. Tested on a 100-protein benchmark comprising 1329 multidimensional NMR spectra, ARTINA demonstrated its ability to solve structures with 1.44 Ã median RMSD to the PDB reference and to identify 91.36% correct NMR resonance assignments. ARTINA can be used by non-experts, reducing the effort for a protein assignment or structure determination by NMR essentially to the preparation of the sample and the spectra measurements.
<div id='section'>Paperid: <span id='pid'>1433, <a href='https://arxiv.org/pdf/2201.09194.pdf' target='_blank'>https://arxiv.org/pdf/2201.09194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiaoling Ye, Arash A. Amini, Qing Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.09194">Distributed Learning of Generalized Linear Causal Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the task of learning causal structures from data stored on multiple machines, and propose a novel structure learning method called distributed annealing on regularized likelihood score (DARLS) to solve this problem. We model causal structures by a directed acyclic graph that is parameterized with generalized linear models, so that our method is applicable to various types of data. To obtain a high-scoring causal graph, DARLS simulates an annealing process to search over the space of topological sorts, where the optimal graphical structure compatible with a sort is found by a distributed optimization method. This distributed optimization relies on multiple rounds of communication between local and central machines to estimate the optimal structure. We establish its convergence to a global optimizer of the overall score that is computed on all data across local machines. To the best of our knowledge, DARLS is the first distributed method for learning causal graphs with such theoretical guarantees. Through extensive simulation studies, DARLS has shown competing performance against existing methods on distributed data, and achieved comparable structure learning accuracy and test-data likelihood with competing methods applied to pooled data across all local machines. In a real-world application for modeling protein-DNA binding networks with distributed ChIP-Sequencing data, DARLS also exhibits higher predictive power than other methods, demonstrating a great advantage in estimating causal networks from distributed data.
<div id='section'>Paperid: <span id='pid'>1434, <a href='https://arxiv.org/pdf/2201.04609.pdf' target='_blank'>https://arxiv.org/pdf/2201.04609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahdi Ghorbani, Samarjeet Prasad, Jeffery B. Klauda, Bernard R. Brooks
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.04609">GraphVAMPNet, using graph neural networks and variational approach to markov processes for dynamical modeling of biomolecules</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Finding low dimensional representation of data from long-timescale trajectories of biomolecular processes such as protein-folding or ligand-receptor binding is of fundamental importance and kinetic models such as Markov modeling have proven useful in describing the kinetics of these systems. Recently, an unsupervised machine learning technique called VAMPNet was introduced to learn the low dimensional representation and linear dynamical model in an end-to-end manner. VAMPNet is based on variational approach to Markov processes (VAMP) and relies on neural networks to learn the coarse-grained dynamics. In this contribution, we combine VAMPNet and graph neural networks to generate an end-to-end framework to efficiently learn high-level dynamics and metastable states from the long-timescale molecular dynamics trajectories. This method bears the advantages of graph representation learning and uses graph message passing operations to generate an embedding for each datapoint which is used in the VAMPNet to generate a coarse-grained representation. This type of molecular representation results in a higher resolution and more interpretable Markov model than the standard VAMPNet enabling a more detailed kinetic study of the biomolecular processes. Our GraphVAMPNet approach is also enhanced with an attention mechanism to find the important residues for classification into different metastable states.
<div id='section'>Paperid: <span id='pid'>1435, <a href='https://arxiv.org/pdf/2110.12414.pdf' target='_blank'>https://arxiv.org/pdf/2110.12414.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ray Zirui Zhang, Li-Tien Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.12414">A Compact Coupling Interface Method with Accurate Gradient Approximation for Elliptic Interface Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the Compact Coupling Interface Method (CCIM), a finite difference method capable of obtaining second-order accurate approximations of not only solution values but their gradients, for elliptic complex interface problems with interfacial jump conditions. Such elliptic interface boundary value problems with interfacial jump conditions are a critical part of numerous applications in fields such as heat conduction, fluid flow, materials science, and protein docking, to name a few. A typical example involves the construction of biomolecular shapes, where such elliptic interface problems are in the form of linearized Poisson-Boltzmann equations, involving discontinuous dielectric constants across the interface, that govern electrostatic contributions. Additionally, when interface dynamics are involved, the normal velocity of the interface might be comprised of the normal derivatives of solution, which can be approximated to second-order by our method, resulting in accurate interface dynamics. Our method, which can be formulated in arbitrary spatial dimensions, combines elements of the highly-regarded Coupling Interface Method, for such elliptic interface problems, and Smereka's second-order accurate discrete delta function. The result is a variation and hybrid with a more compact stencil than that found in the Coupling Interface Method, and with advantages, borne out in numerical experiments involving both geometric model problems and complex biomolecular surfaces, in more robust error profiles.
<div id='section'>Paperid: <span id='pid'>1436, <a href='https://arxiv.org/pdf/2110.00725.pdf' target='_blank'>https://arxiv.org/pdf/2110.00725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Patrick D. Tran, Thomas A. Blanpied, Paul J. Atzberger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.00725">Drift-Diffusion Dynamics and Phase Separation in Curved Cell Membranes and Dendritic Spines: Hybrid Discrete-Continuum Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop methods for investigating protein drift-diffusion dynamics in heterogeneous cell membranes and the roles played by geometry, diffusion, chemical kinetics, and phase separation. Our hybrid stochastic numerical methods combine discrete particle descriptions with continuum-level models for tracking the individual protein drift-diffusion dynamics when coupled to continuum fields. We show how our approaches can be used to investigate phenomena motivated by protein kinetics within dendritic spines. The spine geometry is hypothesized to play an important biological role regulating synaptic strength, protein kinetics, and self-assembly of clusters. We perform simulation studies for model spine geometries varying the neck size to investigate how phase-separation and protein organization is influenced by different shapes. We also show how our methods can be used to study the roles of geometry in reaction-diffusion systems including Turing instabilities. Our methods provide general approaches for investigating protein kinetics and drift-diffusion dynamics within curved membrane structures.
<div id='section'>Paperid: <span id='pid'>1437, <a href='https://arxiv.org/pdf/2107.05556.pdf' target='_blank'>https://arxiv.org/pdf/2107.05556.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>RÄ±za ÃzÃ§elik, Alperen BaÄ, Berk AtÄ±l, Melih Barsbey, Arzucan ÃzgÃ¼r, Elif ÃzkÄ±rÄ±mlÄ±
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2107.05556">DebiasedDTA: A Framework for Improving the Generalizability of Drug-Target Affinity Prediction Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational models that accurately predict the binding affinity of an input protein-chemical pair can accelerate drug discovery studies. These models are trained on available protein-chemical interaction datasets, which may contain dataset biases that may lead the model to learn dataset-specific patterns, instead of generalizable relationships. As a result, the prediction performance of models drops for previously unseen biomolecules, $\textit{i.e.}$ the prediction models cannot generalize to biomolecules outside of the dataset. The latest approaches that aim to improve model generalizability either have limited applicability or introduce the risk of degrading prediction performance. Here, we present DebiasedDTA, a novel drug-target affinity (DTA) prediction model training framework that addresses dataset biases to improve the generalizability of affinity prediction models. DebiasedDTA reweights the training samples to mitigate the effect of dataset biases and is applicable to most DTA prediction models. The results suggest that models trained in the DebiasedDTA framework can achieve improved generalizability in predicting the interactions of the previously unseen biomolecules, as well as performance improvements on those previously seen. Extensive experiments with different biomolecule representations, model architectures, and datasets demonstrate that DebiasedDTA can upgrade DTA prediction models irrespective of the biomolecule representation, model architecture, and training dataset. Last but not least, we release DebiasedDTA as an open-source python library to enable other researchers to debias their own predictors and/or develop their own debiasing methods. We believe that this python library will corroborate and foster research to develop more generalizable DTA prediction models.
<div id='section'>Paperid: <span id='pid'>1438, <a href='https://arxiv.org/pdf/2102.06984.pdf' target='_blank'>https://arxiv.org/pdf/2102.06984.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanbaek Lyu, Yacoub H. Kureh, Joshua Vendrow, Mason A. Porter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2102.06984">Learning low-rank latent mesoscale structures in networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It is common to use networks to encode the architecture of interactions between entities in complex systems in the physical, biological, social, and information sciences. To study the large-scale behavior of complex systems, it is useful to examine mesoscale structures in networks as building blocks that influence such behavior. We present a new approach for describing low-rank mesoscale structures in networks, and we illustrate our approach using several synthetic network models and empirical friendship, collaboration, and protein--protein interaction (PPI) networks. We find that these networks possess a relatively small number of `latent motifs' that together can successfully approximate most subgraphs of a network at a fixed mesoscale. We use an algorithm for `network dictionary learning' (NDL), which combines a network-sampling method and nonnegative matrix factorization, to learn the latent motifs of a given network. The ability to encode a network using a set of latent motifs has a wide variety of applications to network-analysis tasks, such as comparison, denoising, and edge inference. Additionally, using a new network denoising and reconstruction (NDR) algorithm, we demonstrate how to denoise a corrupted network by using only the latent motifs that one learns directly from the corrupted network.
<div id='section'>Paperid: <span id='pid'>1439, <a href='https://arxiv.org/pdf/2101.11885.pdf' target='_blank'>https://arxiv.org/pdf/2101.11885.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tineke Blom, Joris M. Mooij
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2101.11885">Causality and independence in perfectly adapted dynamical systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Perfect adaptation in a dynamical system is the phenomenon that one or more variables have an initial transient response to a persistent change in an external stimulus but revert to their original value as the system converges to equilibrium. With the help of the causal ordering algorithm, one can construct graphical representations of dynamical systems that represent the causal relations between the variables and the conditional independences in the equilibrium distribution. We apply these tools to formulate sufficient graphical conditions for identifying perfect adaptation from a set of first-order differential equations. Furthermore, we give sufficient conditions to test for the presence of perfect adaptation in experimental equilibrium data. We apply this method to a simple model for a protein signalling pathway and test its predictions both in simulations and using real-world protein expression data. We demonstrate that perfect adaptation can lead to misleading orientation of edges in the output of causal discovery algorithms.
<div id='section'>Paperid: <span id='pid'>1440, <a href='https://arxiv.org/pdf/2101.03735.pdf' target='_blank'>https://arxiv.org/pdf/2101.03735.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Wang, Wei Xie, Tugce Martagan, Alp Akcay, Bram van Ravenstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2101.03735">Biomanufacturing Harvest Optimization with Small Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In biopharmaceutical manufacturing, fermentation processes play a critical role in productivity and profit. A fermentation process uses living cells with complex biological mechanisms, leading to high variability in the process outputs, namely, the protein and impurity levels. By building on the biological mechanisms of protein and impurity growth, we introduce a stochastic model to characterize the accumulation of the protein and impurity levels in the fermentation process. However, a common challenge in the industry is the availability of only a very limited amount of data, especially in the development and early stages of production. This adds an additional layer of uncertainty, referred to as model risk, due to the difficulty of estimating the model parameters with limited data. In this paper, we study the harvesting decision for a fermentation process (i.e., when to stop the fermentation and collect the production reward) under model risk. We adopt a Bayesian approach to update the unknown parameters of the growth-rate distributions, and use the resulting posterior distributions to characterize the impact of model risk on fermentation output variability. The harvesting problem is formulated as a Markov decision process model with knowledge states that summarize the posterior distributions and hence incorporate the model risk in decision-making. Our case studies at MSD Animal Health demonstrate that the proposed model and solution approach improve the harvesting decisions in real life by achieving substantially higher average output from a fermentation batch along with lower batch-to-batch variability.
<div id='section'>Paperid: <span id='pid'>1441, <a href='https://arxiv.org/pdf/1908.07471.pdf' target='_blank'>https://arxiv.org/pdf/1908.07471.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aditya Bharadwaj, David Gwizdala, Yoonjin Kim, Kurt Luther, T. M. Murali
</span></div><div id="title">Title: <a href="https://arxiv.org/html/1908.07471">Flud: a hybrid crowd-algorithm approach for visualizing biological networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern experiments in many disciplines generate large quantities of network (graph) data. Researchers require aesthetic layouts of these networks that clearly convey the domain knowledge and meaning. However, the problem remains challenging due to multiple conflicting aesthetic criteria and complex domain-specific constraints. In this paper, we present a strategy for generating visualizations that can help network biologists understand the protein interactions that underlie processes that take place in the cell. Specifically, we have developed Flud, an online game with a purpose (GWAP) that allows humans with no expertise to design biologically meaningful graph layouts with the help of algorithmically generated suggestions. Further, we propose a novel hybrid approach for graph layout wherein crowdworkers and a simulated annealing algorithm build on each other's progress. To showcase the effectiveness of Flud, we recruited crowd workers on Amazon Mechanical Turk to lay out complex networks that represent signaling pathways. Our results show that the proposed hybrid approach outperforms state-of-the-art techniques for graphs with a large number of feedback loops. We also found that the algorithmically generated suggestions guided the players when they are stuck and helped them improve their score. Finally, we discuss broader implications for mixed-initiative interactions in human computation games.
<div id='section'>Paperid: <span id='pid'>1442, <a href='https://arxiv.org/pdf/1401.1137.pdf' target='_blank'>https://arxiv.org/pdf/1401.1137.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>FranÃ§ois Caron, Emily B. Fox
</span></div><div id="title">Title: <a href="https://arxiv.org/html/1401.1137">Sparse graphs using exchangeable random measures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Statistical network modeling has focused on representing the graph as a discrete structure, namely the adjacency matrix, and considering the exchangeability of this array. In such cases, the Aldous-Hoover representation theorem (Aldous, 1981;Hoover, 1979} applies and informs us that the graph is necessarily either dense or empty. In this paper, we instead consider representing the graph as a measure on $\mathbb{R}_+^2$. For the associated definition of exchangeability in this continuous space, we rely on the Kallenberg representation theorem (Kallenberg, 2005). We show that for certain choices of such exchangeable random measures underlying our graph construction, our network process is sparse with power-law degree distribution. In particular, we build on the framework of completely random measures (CRMs) and use the theory associated with such processes to derive important network properties, such as an urn representation for our analysis and network simulation. Our theoretical results are explored empirically and compared to common network models. We then present a Hamiltonian Monte Carlo algorithm for efficient exploration of the posterior distribution and demonstrate that we are able to recover graphs ranging from dense to sparse--and perform associated tests--based on our flexible CRM-based formulation. We explore network properties in a range of real datasets, including Facebook social circles, a political blogosphere, protein networks, citation networks, and world wide web networks, including networks with hundreds of thousands of nodes and millions of edges.
<div id='section'>Paperid: <span id='pid'>1443, <a href='https://arxiv.org/pdf/2507.14908.pdf' target='_blank'>https://arxiv.org/pdf/2507.14908.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Ayomide Olanrewaju
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14908">Partial Symmetry Enforced Attention Decomposition (PSEAD): A Group-Theoretic Framework for Equivariant Transformers in Biological Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This research introduces the Theory of Partial Symmetry Enforced Attention Decomposition (PSEAD), a new and rigorous group-theoretic framework designed to seamlessly integrate local symmetry awareness into the core architecture of self-attention mechanisms within Transformer models. We formalize the concept of local permutation subgroup actions on windows of biological data, proving that under such actions, the attention mechanism naturally decomposes into a direct sum of orthogonal irreducible components. Critically, these components are intrinsically aligned with the irreducible representations of the acting permutation subgroup, thereby providing a powerful mathematical basis for disentangling symmetric and asymmetric features. We show that PSEAD offers substantial advantages. These include enhanced generalization capabilities to novel biological motifs exhibiting similar partial symmetries, unprecedented interpretability by allowing direct visualization and analysis of attention contributions from different symmetry channels, and significant computational efficiency gains by focusing representational capacity on relevant symmetric subspaces. Beyond static data analysis, we extend PSEAD's applicability to dynamic biological processes within reinforcement learning paradigms, showcasing its potential to accelerate the discovery and optimization of biologically meaningful policies in complex environments like protein folding and drug discovery. This work lays the groundwork for a new generation of biologically informed, symmetry-aware artificial intelligence models.
<div id='section'>Paperid: <span id='pid'>1444, <a href='https://arxiv.org/pdf/2506.16309.pdf' target='_blank'>https://arxiv.org/pdf/2506.16309.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gergely Flamich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.16309">Data Compression with Relative Entropy Coding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over the last few years, machine learning unlocked previously infeasible features for compression, such as providing guarantees for users' privacy or tailoring compression to specific data statistics (e.g., satellite images or audio recordings of animals) or users' audiovisual perception. This, in turn, has led to an explosion of theoretical investigations and insights that aim to develop new fundamental theories, methods and algorithms better suited for machine learning-based compressors. In this thesis, I contribute to this trend by investigating relative entropy coding, a mathematical framework that generalises classical source coding theory. Concretely, relative entropy coding deals with the efficient communication of uncertain or randomised information. One of its key advantages is that it extends compression methods to continuous spaces and can thus be integrated more seamlessly into modern machine learning pipelines than classical quantisation-based approaches. Furthermore, it is a natural foundation for developing advanced compression methods that are privacy-preserving or account for the perceptual quality of the reconstructed data. The thesis considers relative entropy coding at three conceptual levels: After introducing the basics of the framework, (1) I prove results that provide new, maximally tight fundamental limits to the communication and computational efficiency of relative entropy coding; (2) I use the theory of Poisson point processes to develop and analyse new relative entropy coding algorithms, whose performance attains the theoretic optima and (3) I showcase the strong practical performance of relative entropy coding by applying it to image, audio, video and protein data compression using small, energy-efficient, probabilistic neural networks called Bayesian implicit neural representations.
<div id='section'>Paperid: <span id='pid'>1445, <a href='https://arxiv.org/pdf/2505.24426.pdf' target='_blank'>https://arxiv.org/pdf/2505.24426.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Gamez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.24426">P: A Universal Measure of Predictive Intelligence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over the last thirty years, considerable progress has been made with the development of systems that can drive cars, play games, predict protein folding and generate natural language. These systems are described as intelligent and there has been a great deal of talk about the rapid increase in artificial intelligence and its potential dangers. However, our theoretical understanding of intelligence and ability to measure it lag far behind our capacity for building systems that mimic intelligent human behaviour. There is no commonly agreed definition of the intelligence that AI systems are said to possess. No-one has developed a practical measure that would enable us to compare the intelligence of humans, animals and AIs on a single ratio scale.
  This paper sets out a new universal measure of intelligence that is based on the hypothesis that prediction is the most important component of intelligence. As an agent interacts with its normal environment, the accuracy of its predictions is summed up and the complexity of its predictions and perceived environment is accounted for using Kolmogorov complexity. Two experiments were carried out to evaluate the practical feasibility of the algorithm. These demonstrated that it could measure the intelligence of an agent embodied in a virtual maze and an agent that makes predictions about time-series data. This universal measure could be the starting point for a new comparative science of intelligence that ranks humans, animals and AIs on a single ratio scale.
<div id='section'>Paperid: <span id='pid'>1446, <a href='https://arxiv.org/pdf/2505.03105.pdf' target='_blank'>https://arxiv.org/pdf/2505.03105.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xule Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03105">Cognitio Emergens: Agency, Dimensions, and Dynamics in Human-AI Knowledge Co-Creation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific knowledge creation is fundamentally transforming as humans and AI systems evolve beyond tool-user relationships into co-evolutionary epistemic partnerships. When AlphaFold revolutionized protein structure prediction, researchers described engaging with an epistemic partner that reshaped how they conceptualized fundamental relationships. This article introduces Cognitio Emergens (CE), a framework addressing critical limitations in existing models that focus on static roles or narrow metrics while failing to capture how scientific understanding emerges through recursive human-AI interaction over time. CE integrates three components addressing these limitations: Agency Configurations describing how authority distributes between humans and AI (Directed, Contributory, Partnership), with partnerships dynamically oscillating between configurations rather than following linear progression; Epistemic Dimensions capturing six specific capabilities emerging through collaboration across Discovery, Integration, and Projection axes, creating distinctive "capability signatures" that guide development; and Partnership Dynamics identifying forces shaping how these relationships evolve, particularly the risk of epistemic alienation where researchers lose interpretive control over knowledge they formally endorse. Drawing from autopoiesis theory, social systems theory, and organizational modularity, CE reveals how knowledge co-creation emerges through continuous negotiation of roles, values, and organizational structures. By reconceptualizing human-AI scientific collaboration as fundamentally co-evolutionary, CE offers a balanced perspective that neither uncritically celebrates nor unnecessarily fears AI's evolving role, instead providing conceptual tools for cultivating partnerships that maintain meaningful human participation while enabling transformative scientific breakthroughs.
<div id='section'>Paperid: <span id='pid'>1447, <a href='https://arxiv.org/pdf/2504.08526.pdf' target='_blank'>https://arxiv.org/pdf/2504.08526.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Charles Rathkopf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08526">Hallucination, reliability, and the role of generative AI in science</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative AI is increasingly used in scientific domains, from protein folding to climate modeling. But these models produce distinctive errors known as hallucinations - outputs that are incorrect yet superficially plausible. Worse, some arguments suggest that hallucinations are an inevitable consequence of the mechanisms underlying generative inference. Fortunately, such arguments rely on a conception of hallucination defined solely with respect to internal properties of the model, rather than in reference to the empirical target system. This conception fails to distinguish epistemically benign errors from those that threaten scientific inference. I introduce the concept of corrosive hallucination to capture the epistemically troubling subclass: misrepresentations that are substantively misleading and resistant to systematic anticipation. I argue that although corrosive hallucinations do pose a threat to scientific reliability, they are not inevitable. Scientific workflows such as those surrounding AlphaFold and GenCast, both of which serve as case studies, can neutralize their effects by imposing theoretical constraints during training, and by strategically screening for errors at inference time. When embedded in such workflows, generative AI can reliably contribute to scientific knowledge.
<div id='section'>Paperid: <span id='pid'>1448, <a href='https://arxiv.org/pdf/2504.04654.pdf' target='_blank'>https://arxiv.org/pdf/2504.04654.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ngoc-Quang Nguyen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04654">EquiCPI: SE(3)-Equivariant Geometric Deep Learning for Structure-Aware Prediction of Compound-Protein Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of compound-protein interactions (CPI) remains a cornerstone challenge in computational drug discovery. While existing sequence-based approaches leverage molecular fingerprints or graph representations, they critically overlook three-dimensional (3D) structural determinants of binding affinity. To bridge this gap, we present EquiCPI, an end-to-end geometric deep learning framework that synergizes first-principles structural modeling with SE(3)-equivariant neural networks. Our pipeline transforms raw sequences into 3D atomic coordinates via ESMFold for proteins and DiffDock-L for ligands, followed by physics-guided conformer re-ranking and equivariant feature learning. At its core, EquiCPI employs SE(3)-equivariant message passing over atomic point clouds, preserving symmetry under rotations, translations, and reflections, while hierarchically encoding local interaction patterns through tensor products of spherical harmonics. The proposed model is evaluated on BindingDB (affinity prediction) and DUD-E (virtual screening), EquiCPI achieves performance on par with or exceeding the state-of-the-art deep learning competitors.
<div id='section'>Paperid: <span id='pid'>1449, <a href='https://arxiv.org/pdf/2504.01389.pdf' target='_blank'>https://arxiv.org/pdf/2504.01389.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junyu Hou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01389">De Novo Molecular Design Enabled by Direct Preference Optimization and Curriculum Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>De novo molecular design has extensive applications in drug discovery and materials science. The vast chemical space renders direct molecular searches computationally prohibitive, while traditional experimental screening is both time- and labor-intensive. Efficient molecular generation and screening methods are therefore essential for accelerating drug discovery and reducing costs. Although reinforcement learning (RL) has been applied to optimize molecular properties via reward mechanisms, its practical utility is limited by issues in training efficiency, convergence, and stability. To address these challenges, we adopt Direct Preference Optimization (DPO) from NLP, which uses molecular score-based sample pairs to maximize the likelihood difference between high- and low-quality molecules, effectively guiding the model toward better compounds. Moreover, integrating curriculum learning further boosts training efficiency and accelerates convergence. A systematic evaluation of the proposed method on the GuacaMol Benchmark yielded excellent scores. For instance, the method achieved a score of 0.883 on the Perindopril MPO task, representing a 6\% improvement over competing models. And subsequent target protein binding experiments confirmed its practical efficacy. These results demonstrate the strong potential of DPO for molecular design tasks and highlight its effectiveness as a robust and efficient solution for data-driven drug discovery.
<div id='section'>Paperid: <span id='pid'>1450, <a href='https://arxiv.org/pdf/2503.17368.pdf' target='_blank'>https://arxiv.org/pdf/2503.17368.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Romain Lacombe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17368">Non-Canonical Crosslinks Confound Evolutionary Protein Structure Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evolution-based protein structure prediction models have achieved breakthrough success in recent years. However, they struggle to generalize beyond evolutionary priors and on sequences lacking rich homologous data. Here we present a novel, out-of-domain benchmark based on sactipeptides, a rare class of ribosomally synthesized and post-translationally modified peptides (RiPPs) characterized by sulfur-to-$Î±$-carbon thioether bridges creating cross-links between cysteine residues and backbone. We evaluate recent models on predicting conformations compatible with these cross-links bridges for the 10 known sactipeptides with elucidated post-translational modifications. Crucially, the structures of 5 of them have not yet been experimentally resolved. This makes the task a challenging problem for evolution-based models, which we find exhibit limited performance (0.0% to 19.2% GDT-TS on sulfur-to-$Î±$-carbon distance). Our results point at the need for physics-informed models to sustain progress in biomolecular structure prediction.
<div id='section'>Paperid: <span id='pid'>1451, <a href='https://arxiv.org/pdf/2503.14806.pdf' target='_blank'>https://arxiv.org/pdf/2503.14806.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pawel Rubach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14806">Applying Large-Scale Distributed Computing to Structural Bioinformatics -- Bridging Legacy HPC Clusters With Big Data Technologies Using kafka-slurm-agent</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents the Kafka Slurm Agent (KSA), an open source (Apache 2.0 license) distributed computing and stream processing engine designed to help researchers distribute Python-based computational tasks across multiple Slurm-managed HPC clusters and workstations. Written entirely in Python, this extensible framework utilizes an Apache Kafka broker for asynchronous communication between its components. It is intended for non-expert users and does not require administrative privileges or additional libraries to run on Slurm. The framework's development was driven by the introduction of the AlphaFold protein structure prediction model, specifically, it was first created to facilitate the detection of knots in protein chains within structures predicted by AlphaFold. KSA has since been applied to several structural bioinformatics research projects, among others, leading to the discovery of new knotted proteins with previously unknown knot types. These knotted structures are now part of the AlphaKnot 2.0 web server and database, where KSA is applied to manage the knot detection process for user-uploaded structures.
<div id='section'>Paperid: <span id='pid'>1452, <a href='https://arxiv.org/pdf/2501.01477.pdf' target='_blank'>https://arxiv.org/pdf/2501.01477.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weihang Dai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01477">A Survey of Deep Learning Methods in Protein Bioinformatics and its Impact on Protein Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proteins are sequences of amino acids that serve as the basic building blocks of living organisms. Despite rapidly growing databases documenting structural and functional information for various protein sequences, our understanding of proteins remains limited because of the large possible sequence space and the complex inter- and intra-molecular forces. Deep learning, which is characterized by its ability to learn relevant features directly from large datasets, has demonstrated remarkable performance in fields such as computer vision and natural language processing. It has also been increasingly applied in recent years to the data-rich domain of protein sequences with great success, most notably with Alphafold2's breakout performance in the protein structure prediction. The performance improvements achieved by deep learning unlocks new possibilities in the field of protein bioinformatics, including protein design, one of the most difficult but useful tasks. In this paper, we broadly categorize problems in protein bioinformatics into three main categories: 1) structural prediction, 2) functional prediction, and 3) protein design, and review the progress achieved from using deep learning methodologies in each of them. We expand on the main challenges of the protein design problem and highlight how advances in structural and functional prediction have directly contributed to design tasks. Finally, we conclude by identifying important topics and future research directions.
<div id='section'>Paperid: <span id='pid'>1453, <a href='https://arxiv.org/pdf/2412.21103.pdf' target='_blank'>https://arxiv.org/pdf/2412.21103.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linus Zwaka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.21103">Parallel DNA Sequence Alignment on High-Performance Systems with CUDA and MPI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sequence alignment is a cornerstone of bioinformatics, widely used to identify similarities between DNA, RNA, and protein sequences and studying evolutionary relationships and functional properties. The Needleman-Wunsch algorithm remains a robust and accurate method for global sequence alignment. However, its computational complexity, O(mn), poses significant challenges when processing large-scale datasets or performing multiple sequence alignments. To address these limitations, a hybrid implementation of the Needleman-Wunsch algorithm that leverages CUDA for parallel execution on GPUs and MPI for distributed computation across multiple nodes on a supercomputer is proposed. CUDA efficiently offloads computationally intensive tasks to GPU cores, while MPI enables communication and workload distribution across nodes to handle large-scale alignments.
  This work details the implementation and performance evaluation of the Needleman-Wunsch algorithm in a massively parallel computing environment. Experimental results demonstrate significant acceleration of the alignment process compared to traditional CPU-based implementations, particularly for large input sizes and multiple sequence alignments. In summary, the combination of CUDA and MPI effectively overcomes the computational bottlenecks inherent to the Needleman-Wunsch algorithm without requiring substantial modifications to the underlying algorithm, highlighting the potential of high-performance computing in advancing sequence alignment workflows.
<div id='section'>Paperid: <span id='pid'>1454, <a href='https://arxiv.org/pdf/2412.12214.pdf' target='_blank'>https://arxiv.org/pdf/2412.12214.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabio Zamio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12214">DLSOM: A Deep learning-based strategy for liver cancer subtyping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Liver cancer is a leading cause of cancer-related mortality worldwide, with its high genetic heterogeneity complicating diagnosis and treatment. This study introduces DLSOM, a deep learning framework utilizing stacked autoencoders to analyze the complete somatic mutation landscape of 1,139 liver cancer samples, covering 20,356 protein-coding genes. By transforming high-dimensional mutation data into three low-dimensional features, DLSOM enables robust clustering and identifies five distinct liver cancer subtypes with unique mutational, functional, and biological profiles. Subtypes SC1 and SC2 exhibit higher mutational loads, while SC3 has the lowest, reflecting mutational heterogeneity. Novel and COSMIC-associated mutational signatures reveal subtype-specific molecular mechanisms, including links to hypermutation and chemotherapy resistance. Functional analyses further highlight the biological relevance of each subtype. This comprehensive framework advances precision medicine in liver cancer by enabling the development of subtype-specific diagnostics, biomarkers, and therapies, showcasing the potential of deep learning in addressing cancer complexity.
<div id='section'>Paperid: <span id='pid'>1455, <a href='https://arxiv.org/pdf/2412.07678.pdf' target='_blank'>https://arxiv.org/pdf/2412.07678.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wang Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07678">Can linguists better understand DNA?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multilingual transfer ability, which reflects how well models fine-tuned on one source language can be applied to other languages, has been well studied in multilingual pre-trained models. However, the existence of such capability transfer between natural language and gene sequences/languages remains under explored.This study addresses this gap by drawing inspiration from the sentence-pair classification task used for evaluating sentence similarity in natural language. We constructed two analogous tasks: DNA-pair classification(DNA sequence similarity) and DNA-protein-pair classification(gene coding determination). These tasks were designed to validate the transferability of capabilities from natural language to gene sequences. Even a small-scale pre-trained model like GPT-2-small, which was pre-trained on English, achieved an accuracy of 78% on the DNA-pair classification task after being fine-tuned on English sentence-pair classification data(XTREME PAWS-X). While training a BERT model on multilingual text, the precision reached 89%. On the more complex DNA-protein-pair classification task, however, the model's output was barely distinguishable from random output.Experimental validation has confirmed that the transfer of capabilities from natural language to biological language is unequivocally present. Building on this foundation, we have also investigated the impact of model parameter scale and pre-training on this capability transfer. We provide recommendations for facilitating the transfer of capabilities from natural language to genetic language,as well as new approaches for conducting biological research based on this capability.This study offers an intriguing new perspective on exploring the relationship between natural language and genetic language.
<div id='section'>Paperid: <span id='pid'>1456, <a href='https://arxiv.org/pdf/2410.22652.pdf' target='_blank'>https://arxiv.org/pdf/2410.22652.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Caleb Musfeldt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.22652">Development of a Python-Based Software for Calculating the Jones Polynomial: Insights into the Behavior of Polymers and Biopolymers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This thesis details a Python-based software designed to calculate the Jones polynomial, a vital mathematical tool from Knot Theory used for characterizing the topological and geometrical complexity of curves in \( \mathbb{R}^3 \), which is essential in understanding physical systems of filaments, including the behavior of polymers and biopolymers. The Jones polynomial serves as a topological invariant capable of distinguishing between different knot structures. This capability is fundamental to characterizing the architecture of molecular chains, such as proteins and DNA. Traditional computational methods for deriving the Jones polynomial have been limited by closure-schemes and high execution costs, which can be impractical for complex structures like those that appear in real life. This software implements methods that significantly reduce calculation times, allowing for more efficient and practical applications in the study of biological polymers. It utilizes a divide-and-conquer approach combined with parallel computing and applies recursive Reidemeister moves to optimize the computation, transitioning from an exponential to a near-linear runtime for specific configurations. This thesis provides an overview of the software's functions, detailed performance evaluations using protein structures as test cases, and a discussion of the implications for future research and potential algorithmic improvements.
<div id='section'>Paperid: <span id='pid'>1457, <a href='https://arxiv.org/pdf/2410.01755.pdf' target='_blank'>https://arxiv.org/pdf/2410.01755.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Sholehrasa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.01755">Integrating Protein Sequence and Expression Level to Analysis Molecular Characterization of Breast Cancer Subtypes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Breast cancer's complexity and variability pose significant challenges in understanding its progression and guiding effective treatment. This study aims to integrate protein sequence data with expression levels to improve the molecular characterization of breast cancer subtypes and predict clinical outcomes. Using ProtGPT2, a language model designed for protein sequences, we generated embeddings that capture the functional and structural properties of proteins sequence. These embeddings were integrated with protein expression level to form enriched biological representations, which were analyzed using machine learning methods like ensemble K-means for clustering and XGBoost for classification. Our approach enabled successful clustering of patients into biologically distinct groups and accurately predicted clinical outcomes such as survival and biomarkers status, achieving high performance metrics, notably an F1 score of 0.88 for survival and 0.87 for biomarkers status prediction. Feature importance analysis identified KMT2C, CLASP2, and MYO1B as key proteins involved in hormone signaling, cytoskeletal remodeling, and therapy resistance in hormone receptor-positive and triple-negative breast cancer, with potential influence on breast cancer subtype behavior and progression. Furthermore, protein-protein interaction networks and correlation analyses revealed functional interdependencies among proteins that may influence breast cancer subtype behavior and progression. These findings suggest that integrating protein sequence and expression data provides valuable insights into tumor biology and has significant potential to enhance personalized treatment strategies in breast cancer care.
<div id='section'>Paperid: <span id='pid'>1458, <a href='https://arxiv.org/pdf/2409.16333.pdf' target='_blank'>https://arxiv.org/pdf/2409.16333.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxing Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.16333">Predicting Distance matrix with large language models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structural prediction has long been considered critical in RNA research, especially following the success of AlphaFold2 in protein studies, which has drawn significant attention to the field. While recent advances in machine learning and data accumulation have effectively addressed many biological tasks, particularly in protein related research. RNA structure prediction remains a significant challenge due to data limitations. Obtaining RNA structural data is difficult because traditional methods such as nuclear magnetic resonance spectroscopy, Xray crystallography, and electron microscopy are expensive and time consuming. Although several RNA 3D structure prediction methods have been proposed, their accuracy is still limited. Predicting RNA structural information at another level, such as distance maps, remains highly valuable. Distance maps provide a simplified representation of spatial constraints between nucleotides, capturing essential relationships without requiring a full 3D model. This intermediate level of structural information can guide more accurate 3D modeling and is computationally less intensive, making it a useful tool for improving structural predictions. In this work, we demonstrate that using only primary sequence information, we can accurately infer the distances between RNA bases by utilizing a large pretrained RNA language model coupled with a well trained downstream transformer.
<div id='section'>Paperid: <span id='pid'>1459, <a href='https://arxiv.org/pdf/2409.06428.pdf' target='_blank'>https://arxiv.org/pdf/2409.06428.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jakub Rydzewski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06428">Spectral Map for Slow Collective Variables, Markovian Dynamics, and Transition State Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the behavior of complex molecular systems is a fundamental problem in physical chemistry. To describe the long-time dynamics of such systems, which is responsible for their most informative characteristics, we can identify a few slow collective variables (CVs) while treating the remaining fast variables as thermal noise. This enables us to simplify the dynamics and treat it as diffusion in a free-energy landscape spanned by slow CVs, effectively rendering the dynamics Markovian. Our recent statistical learning technique, spectral map [Rydzewski, J. Phys. Chem. Lett. 2023, 14, 22, 5216-5220], explores this strategy to learn slow CVs by maximizing a spectral gap of a transition matrix. In this work, we introduce several advancements into our framework, using a high-dimensional reversible folding process of a protein as an example. We implement an algorithm for coarse-graining Markov transition matrices to partition the reduced space of slow CVs kinetically and use it to define a transition state ensemble. We show that slow CVs learned by spectral map closely approach the Markovian limit for an overdamped diffusion. We demonstrate that coordinate-dependent diffusion coefficients only slightly affect the constructed free-energy landscapes. Finally, we present how spectral map can be used to quantify the importance of features and compare slow CVs with structural descriptors commonly used in protein folding. Overall, we demonstrate that a single slow CV learned by spectral map can be used as a physical reaction coordinate to capture essential characteristics of protein folding.
<div id='section'>Paperid: <span id='pid'>1460, <a href='https://arxiv.org/pdf/2408.07154.pdf' target='_blank'>https://arxiv.org/pdf/2408.07154.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ralph P. Lano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.07154">Self-folding Self-replication</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inspired by protein folding, we explored the construction of three-dimensional structures and machines from one-dimensional chains of simple building blocks. This approach not only allows us to recreate the self-replication mechanism introduced earlier, but also significantly simplifies the process. We introduced a new set of folding blocks that facilitate the formation of secondary structures such as Î±-helices and \b{eta}-sheets, as well as more advanced tertiary and quaternary structures, including self-replicating machines. The introduction of rotational degrees of freedom leads to a reduced variety of blocks and, most importantly, reduces the overall size of the machines by a factor of five. In addition, we present a universal copier-constructor, a highly efficient self-replicating mechanism composed of approximately 40 blocks, including the restictions posed on it. The paper also addresses evolutionary considerations, outlining several steps on the evolutionary ladder towards more sophisticated self-replicating systems. Finally, this study offers a clear rationale for nature's preference for one-dimensional chains in constructing three-dimensional structures.
<div id='section'>Paperid: <span id='pid'>1461, <a href='https://arxiv.org/pdf/2407.10452.pdf' target='_blank'>https://arxiv.org/pdf/2407.10452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amritpal Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.10452">GraphPrint: Extracting Features from 3D Protein Structure for Drug Target Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate drug target affinity prediction can improve drug candidate selection, accelerate the drug discovery process, and reduce drug production costs. Previous work focused on traditional fingerprints or used features extracted based on the amino acid sequence in the protein, ignoring its 3D structure which affects its binding affinity. In this work, we propose GraphPrint: a framework for incorporating 3D protein structure features for drug target affinity prediction. We generate graph representations for protein 3D structures using amino acid residue location coordinates and combine them with drug graph representation and traditional features to jointly learn drug target affinity. Our model achieves a mean square error of 0.1378 and a concordance index of 0.8929 on the KIBA dataset and improves over using traditional protein features alone. Our ablation study shows that the 3D protein structure-based features provide information complementary to traditional features.
<div id='section'>Paperid: <span id='pid'>1462, <a href='https://arxiv.org/pdf/2407.00111.pdf' target='_blank'>https://arxiv.org/pdf/2407.00111.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ben Fauber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.00111">Accurate Prediction of Ligand-Protein Interaction Affinities with Fine-Tuned Small Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We describe the accurate prediction of ligand-protein interaction (LPI) affinities, also known as drug-target interactions (DTI), with instruction fine-tuned pretrained generative small language models (SLMs). We achieved accurate predictions for a range of affinity values associated with ligand-protein interactions on out-of-sample data in a zero-shot setting. Only the SMILES string of the ligand and the amino acid sequence of the protein were used as the model inputs. Our results demonstrate a clear improvement over machine learning (ML) and free-energy perturbation (FEP+) based methods in accurately predicting a range of ligand-protein interaction affinities, which can be leveraged to further accelerate drug discovery campaigns against challenging therapeutic targets.
<div id='section'>Paperid: <span id='pid'>1463, <a href='https://arxiv.org/pdf/2405.19076.pdf' target='_blank'>https://arxiv.org/pdf/2405.19076.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Markus J. Buehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.19076">Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials Analysis and Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present Cephalo, a series of multimodal vision large language models (V-LLMs) designed for materials science applications, integrating visual and linguistic data for enhanced understanding. A key innovation of Cephalo is its advanced dataset generation method. Cephalo is trained on integrated image and text data from thousands of scientific papers and science-focused Wikipedia data demonstrates can interpret complex visual scenes, generate precise language descriptions, and answer queries about images effectively. The combination of a vision encoder with an autoregressive transformer supports multimodal natural language understanding, which can be coupled with other generative methods to create an image-to-text-to-3D pipeline. To develop more capable models from smaller ones, we report both mixture-of-expert methods and model merging. We examine the models in diverse use cases that incorporate biological materials, fracture and engineering analysis, protein biophysics, and bio-inspired design based on insect behavior. Generative applications include bio-inspired designs, including pollen-inspired architected materials, as well as the synthesis of bio-inspired material microstructures from a photograph of a solar eclipse. Additional model fine-tuning with a series of molecular dynamics results demonstrate Cephalo's enhanced capabilities to accurately predict statistical features of stress and atomic energy distributions, as well as crack dynamics and damage in materials.
<div id='section'>Paperid: <span id='pid'>1464, <a href='https://arxiv.org/pdf/2405.12986.pdf' target='_blank'>https://arxiv.org/pdf/2405.12986.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saddam Hussain Khan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12986">A Novel Feature Map Enhancement Technique Integrating Residual CNN and Transformer for Alzheimer Diseases Diagnosis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Alzheimer diseases (ADs) involves cognitive decline and abnormal brain protein accumulation, necessitating timely diagnosis for effective treatment. Therefore, CAD systems leveraging deep learning advancements have demonstrated success in AD detection but pose computational intricacies and the dataset minor contrast, structural, and texture variations. In this regard, a novel hybrid FME-Residual-HSCMT technique is introduced, comprised of residual CNN and Transformer concepts to capture global and local fine-grained AD analysis in MRI. This approach integrates three distinct elements: a novel CNN Meet Transformer (HSCMT), customized residual learning CNN, and a new Feature Map Enhancement (FME) strategy to learn diverse morphological, contrast, and texture variations of ADs. The proposed HSCMT at the initial stage utilizes stem convolution blocks that are integrated with CMT blocks followed by systematic homogenous and structural (HS) operations. The customized CMT block encapsulates each element with global contextual interactions through multi-head attention and facilitates computational efficiency through lightweight. Moreover, inverse residual and stem CNN in customized CMT enables effective extraction of local texture information and handling vanishing gradients. Furthermore, in the FME strategy, residual CNN blocks utilize TL-based generated auxiliary and are combined with the proposed HSCMT channels at the target level to achieve diverse enriched feature space. Finally, diverse enhanced channels are fed into a novel spatial attention mechanism for optimal pixel selection to reduce redundancy and discriminate minor contrast and texture inter-class variation. The proposed achieves an F1-score (98.55%), an accuracy of 98.42% and a sensitivity of 98.50%, a precision of 98.60% on the standard Kaggle dataset, and demonstrates outperformance existing ViTs and CNNs methods.
<div id='section'>Paperid: <span id='pid'>1465, <a href='https://arxiv.org/pdf/2405.10824.pdf' target='_blank'>https://arxiv.org/pdf/2405.10824.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Davide Rucci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.10824">Real-World Graph Analysis: Techniques for Static, Dynamic, and Temporal Communities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graphs are widely used in various fields of computer science. They have also found application in unrelated areas, leading to a diverse range of problems. These problems can be modeled as relationships between entities in various contexts, such as social networks, protein interactions in cells, and route maps. Therefore it is logical to analyze these data structures with diverse approaches, whether they are numerical or structural, global or local, approximate or exact. In particular, the concept of community plays an important role in local structural analysis, as it is able to highlight the composition of the underlying graph while providing insights into what the organization and importance of the nodes in a network look like. This thesis pursues the goal of extracting knowledge from different kinds of graphs, including static, dynamic, and temporal graphs, with a particular focus on their community substructures. To tackle this task we use combinatorial algorithms that can list all the communities in a graph according to different formalizations, such as cliques, $k$-graphlets, and $k$-cores. We first develop new algorithms to enumerate subgraphs, using traditional and novel techniques such as push-out amortization, and CPU cache analysis to boost their efficiency. We then extend these concepts to the analysis of real-world graphs across diverse domains, ranging from social networks to autonomous systems modeled as temporal graphs. In this field, there is currently no widely accepted adaptation, even for straightforward subgraphs like $k$-cores, and the available data is expanding both in terms of quantity and scale. As a result, our findings advance the state of the art both from a theoretical and a practical perspective and can be used in a static or dynamic setting to further speed up and refine graph analysis techniques.
<div id='section'>Paperid: <span id='pid'>1466, <a href='https://arxiv.org/pdf/2405.06651.pdf' target='_blank'>https://arxiv.org/pdf/2405.06651.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arnav Swaroop
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06651">Using GANs for De Novo Protein Design Targeting Microglial IL-3R$Î±$ to Inhibit Alzheimer's Progression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>IL-3 is a hemopoietic growth factor that usually targets blood cell precursors; IL-3R is a cytokine receptor that binds to IL-3. However, IL-3 takes on a different role in the context of glial cells in the nervous system, where studies show that the protein IL-3 protects against Alzheimer's disease by activating microglia at their IL-3R receptors, causing the microglia to clear out the tangles caused by the build-up of misfolded Tau proteins. In this study, we seek to ascertain what role the secondary structure of IL-3 plays in its binding with the receptor. The motivation behind this study is to learn more about the mechanism and identify possible drugs that might be able to activate it, in hopes of inhibiting the spread of Alzheimer's Disease. From a preliminary analysis of complexes containing IL-3 and IL-3R, we hypothesized that the binding is largely due to the interactions of three alpha helix structures stretching towards the active site on the receptor. The original Il-3 protein serves as the control in this experiment; the other proteins being tested are generated through several types of computational de novo protein design, where machine learning allows for the production of entirely novel structures. The efficacy of the generated proteins is assessed through docking simulations with the IL-3R receptor, and the binding poses are also qualitatively examined to gain insight into the function of the binding. From the docking data and poses, the most successful proteins were those with similar secondary structure to IL-3.
<div id='section'>Paperid: <span id='pid'>1467, <a href='https://arxiv.org/pdf/2405.01619.pdf' target='_blank'>https://arxiv.org/pdf/2405.01619.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dexuan Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01619">An Efficient Finite Element Solver for a Nonuniform size-modified Poisson-Nernst-Planck Ion Channel Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents an efficient finite element iterative method for solving a nonuniform size-modified Poisson-Nernst-Planck ion channel (SMPNPIC) model, along with a SMPNPIC program package that works for an ion channel protein with a three-dimensional crystallographic structure and an ionic solvent with multiple ionic species. In particular, the SMPNPIC model is constructed and then reformulated by novel mathematical techniques so that each iteration of the method only involves linear boundary value problems and nonlinear algebraic systems, circumventing the numerical difficulties caused by the strong nonlinearities, strong asymmetries, and strong differential equation coupling of the SMPNPIC model. To further improve the method's efficiency, an efficient modified Newton iterative method is adapted to the numerical solution of each related nonlinear algebraic system. Numerical results for a voltage-dependent anion channel (VDAC) and a mixture solution of four ionic species demonstrate the method's convergence, the package's high performance, and the importance of considering nonuniform ion size effects. They also partially validate the SMPNPIC model by the anion selectivity property of VDAC.
<div id='section'>Paperid: <span id='pid'>1468, <a href='https://arxiv.org/pdf/2404.14169.pdf' target='_blank'>https://arxiv.org/pdf/2404.14169.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mattia Corti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14169">Exploring tau protein and amyloid-beta propagation: a sensitivity analysis of mathematical models based on biological data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Alzheimer's disease is the most common dementia worldwide. Its pathological development is well known to be connected with the accumulation of two toxic proteins: tau protein and amyloid-$Î²$. Mathematical models and numerical simulations can predict the spreading patterns of misfolded proteins in this context. However, the calibration of the model parameters plays a crucial role in the final solution. In this work, we perform a sensitivity analysis of heterodimer and Fisher-Kolmogorov models to evaluate the impact of the equilibrium values of protein concentration on the solution patterns. We adopt advanced numerical methods such as the IMEX-DG method to accurately describe the propagating fronts in the propagation phenomena in a polygonal mesh of sagittal patient-specific brain geometry derived from magnetic resonance images. We calibrate the model parameters using biological measurements in the brain cortex for the tau protein and the amyloid-$Î²$ in Alzheimer's patients and controls. Finally, using the sensitivity analysis results, we discuss the applicability of both models in the correct simulation of the spreading of the two proteins.
<div id='section'>Paperid: <span id='pid'>1469, <a href='https://arxiv.org/pdf/2403.17293.pdf' target='_blank'>https://arxiv.org/pdf/2403.17293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Salim Sazzed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17293">Tracing and segmentation of molecular patterns in 3-dimensional cryo-et/em density maps through algorithmic image processing and deep learning-based techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the structures of biological macromolecules is highly important as they are closely associated with cellular functionalities. Comprehending the precise organization actin filaments is crucial because they form the dynamic cytoskeleton, which offers structural support to cells and connects the cell's interior with its surroundings. However, determining the precise organization of actin filaments is challenging due to the poor quality of cryo-electron tomography (cryo-ET) images, which suffer from low signal-to-noise (SNR) ratios and the presence of missing wedge, as well as diverse shape characteristics of actin filaments. To address these formidable challenges, the primary component of this dissertation focuses on developing sophisticated computational techniques for tracing actin filaments. In particular, three novel methodologies have been developed: i) BundleTrac, for tracing bundle-like actin filaments found in Stereocilium, ii) Spaghetti Tracer, for tracing filaments that move individually with loosely cohesive movements, and iii) Struwwel Tracer, for tracing randomly orientated actin filaments in the actin network. The second component of the dissertation introduces a convolutional neural network (CNN) based segmentation model to determine the location of protein secondary structures, such as helices and beta-sheets, in medium-resolution (5-10 Angstrom) 3-dimensional cryo-electron microscopy (cryo-EM) images. This methodology later evolved into a tool named DeepSSETracer. The final component of the dissertation presents a novel algorithm, cylindrical fit measure, to estimate image structure match at helix regions in medium-resolution cryo-EM images. Overall, my dissertation has made significant contributions to addressing critical research challenges in structural biology by introducing various computational methods and tools.
<div id='section'>Paperid: <span id='pid'>1470, <a href='https://arxiv.org/pdf/2403.15419.pdf' target='_blank'>https://arxiv.org/pdf/2403.15419.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinwei Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15419">Attention is all you need for boosting graph convolutional neural network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Convolutional Neural Networks (GCNs) possess strong capabilities for processing graph data in non-grid domains. They can capture the topological logical structure and node features in graphs and integrate them into nodes' final representations. GCNs have been extensively studied in various fields, such as recommendation systems, social networks, and protein molecular structures. With the increasing application of graph neural networks, research has focused on improving their performance while compressing their size. In this work, a plug-in module named Graph Knowledge Enhancement and Distillation Module (GKEDM) is proposed. GKEDM can enhance node representations and improve the performance of GCNs by extracting and aggregating graph information via multi-head attention mechanism. Furthermore, GKEDM can serve as an auxiliary transferor for knowledge distillation. With a specially designed attention distillation method, GKEDM can distill the knowledge of large teacher models into high-performance and compact student models. Experiments on multiple datasets demonstrate that GKEDM can significantly improve the performance of various GCNs with minimal overhead. Furthermore, it can efficiently transfer distilled knowledge from large teacher networks to small student networks via attention distillation.
<div id='section'>Paperid: <span id='pid'>1471, <a href='https://arxiv.org/pdf/2402.04944.pdf' target='_blank'>https://arxiv.org/pdf/2402.04944.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Esfandiar Nava-Yazdani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.04944">Elastic Analysis of Augmented Curves and Constrained Surfaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The square root velocity transformation provides a convenient and numerically efficient approach to functional and shape data analysis of curves. We study fundamental geometric properties of curves under this transformation. Moreover, utilizing natural geometric constructions, we employ the approach for intrinsic comparison within several classes of surfaces and augmented curves, which arise in the real world applications such as tubes, ruled surfaces, spherical strips, protein molecules and hurricane tracks.
<div id='section'>Paperid: <span id='pid'>1472, <a href='https://arxiv.org/pdf/2401.11562.pdf' target='_blank'>https://arxiv.org/pdf/2401.11562.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pratik Worah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.11562">Enhancing selectivity using Wasserstein distance based reweighing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given two labeled data-sets $\mathcal{S}$ and $\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\mathcal{T}$.
  On the theoretical side, we prove that when the metric entropy of the input datasets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.
  As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1 (a highly similar protein). In our example dataset, of the 43 distinct small molecules predicted to be most selective from the enamine catalog, 2 small molecules were experimentally verified to be selective, i.e., they reduced the enzyme activity of MNK2 below 50\% but not MNK1, at 10$Î¼$M -- a 5\% success rate.
<div id='section'>Paperid: <span id='pid'>1473, <a href='https://arxiv.org/pdf/2401.08668.pdf' target='_blank'>https://arxiv.org/pdf/2401.08668.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Florian Neukart
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08668">Thermodynamic Perspectives on Computational Complexity: Exploring the P vs. NP Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The resolution of the P vs. NP problem, a cornerstone in computational theory, remains elusive despite extensive exploration through mathematical logic and algorithmic theory. This paper takes a novel approach by integrating information theory, thermodynamics, and computational complexity, offering a comprehensive landscape of interdisciplinary study. We focus on entropy, a concept traditionally linked with uncertainty and disorder, and reinterpret it to assess the complexity of computational problems. Our research presents a structured framework for establishing entropy profiles within computational tasks, enabling a clear distinction between P and NP-classified problems. This framework quantifies the 'information cost' associated with these problem categories, highlighting their intrinsic computational complexity. We introduce Entropy-Driven Annealing (EDA) as a new method to decipher the energy landscapes of computational problems, focusing on the unique characteristics of NP problems. This method proposes a differential thermodynamic profile for NP problems in contrast to P problems and explores potential thermodynamic routes for finding polynomial-time solutions to NP challenges. Our introduction of EDA and its application to complex computational problems like the Boolean satisfiability problem (SAT) and protein-DNA complexes suggests a potential pathway toward unraveling the intricacies of the P vs. NP problem.
<div id='section'>Paperid: <span id='pid'>1474, <a href='https://arxiv.org/pdf/2311.07632.pdf' target='_blank'>https://arxiv.org/pdf/2311.07632.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zecheng Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.07632">ResMGCN: Residual Message Graph Convolution Network for Fast Biomedical Interactions Discovering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biomedical information graphs are crucial for interaction discovering of biomedical information in modern age, such as identification of multifarious molecular interactions and drug discovery, which attracts increasing interests in biomedicine, bioinformatics, and human healthcare communities. Nowadays, more and more graph neural networks have been proposed to learn the entities of biomedical information and precisely reveal biomedical molecule interactions with state-of-the-art results. These methods remedy the fading of features from a far distance but suffer from remedying such problem at the expensive cost of redundant memory and time. In our paper, we propose a novel Residual Message Graph Convolution Network (ResMGCN) for fast and precise biomedical interaction prediction in a different idea. Specifically, instead of enhancing the message from far nodes, ResMGCN aggregates lower-order information with the next round higher information to guide the node update to obtain a more meaningful node representation. ResMGCN is able to perceive and preserve various messages from the previous layer and high-order information in the current layer with least memory and time cost to obtain informative representations of biomedical entities. We conduct experiments on four biomedical interaction network datasets, including protein-protein, drug-drug, drug-target, and gene-disease interactions, which demonstrates that ResMGCN outperforms previous state-of-the-art models while achieving superb effectiveness on both storage and time.
<div id='section'>Paperid: <span id='pid'>1475, <a href='https://arxiv.org/pdf/2311.04128.pdf' target='_blank'>https://arxiv.org/pdf/2311.04128.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>William Gilpin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.04128">Generative learning for nonlinear dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern generative machine learning models demonstrate surprising ability to create realistic outputs far beyond their training data, such as photorealistic artwork, accurate protein structures, or conversational text. These successes suggest that generative models learn to effectively parametrize and sample arbitrarily complex distributions. Beginning half a century ago, foundational works in nonlinear dynamics used tools from information theory to infer properties of chaotic attractors from time series, motivating the development of algorithms for parametrizing chaos in real datasets. In this perspective, we aim to connect these classical works to emerging themes in large-scale generative statistical learning. We first consider classical attractor reconstruction, which mirrors constraints on latent representations learned by state space models of time series. We next revisit early efforts to use symbolic approximations to compare minimal discrete generators underlying complex processes, a problem relevant to modern efforts to distill and interpret black-box statistical models. Emerging interdisciplinary works bridge nonlinear dynamics and learning theory, such as operator-theoretic methods for complex fluid flows, or detection of broken detailed balance in biological datasets. We anticipate that future machine learning techniques may revisit other classical concepts from nonlinear dynamics, such as transinformation decay and complexity-entropy tradeoffs.
<div id='section'>Paperid: <span id='pid'>1476, <a href='https://arxiv.org/pdf/2311.01431.pdf' target='_blank'>https://arxiv.org/pdf/2311.01431.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei M Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.01431">Empirical Lossless Compression Bound of a Data Sequence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the lossless compression bound of any individual data sequence. If we fit the data by a parametric model, the entropy quantity $nH({\hat Î¸}_n)$ obtained by plugging in the maximum likelihood estimate is an underestimate of the bound, where $n$ is the number of words. Shtarkov showed that the normalized maximum likelihood (NML) distribution or code length is optimal in a minimax sense for any parametric family. We show by the local asymptotic normality that the NML code length for the exponential families is $nH(\hat Î¸_n) +\frac{d}{2}\log \, \frac{n}{2Ï} +\log \int_Î |I(Î¸)|^{1/2}\, dÎ¸+o(1)$, where $d$ is the model dimension or dictionary size, and $|I(Î¸)|$ is the determinant of the Fisher information matrix. We also demonstrate that sequentially predicting the optimal code length for the next word via a Bayesian mechanism leads to the mixture code, whose pathwise length is given by $nH({\hat Î¸}_n) +\frac{d}{2}\log \, \frac{n}{2Ï} +\log \frac{|\, I({\hat Î¸}_n)|^{1/2}}{w({\hat Î¸}_n)}+o(1) $, where $w(Î¸)$ is a prior. The asymptotics apply to not only discrete symbols but also continuous data if the code length for the former is replaced by the description length for the latter. The analytical result is exemplified by calculating compression bounds of protein-encoding DNA sequences under different parsing models. Typically, the highest compression is achieved when the parsing is in phase of the amino acid codons. On the other hand, the compression rates of pseudo-random sequences are larger than 1 regardless parsing models. These model-based results are in consistency with that random sequences are incompressible as asserted by the Kolmogorov complexity theory. The empirical lossless compression bound is particularly more accurate when dictionary size is relatively large.
<div id='section'>Paperid: <span id='pid'>1477, <a href='https://arxiv.org/pdf/2310.20539.pdf' target='_blank'>https://arxiv.org/pdf/2310.20539.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chi-Ning Chou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.20539">The Computational Lens: from Quantum Physics to Neuroscience</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Two transformative waves of computing have redefined the way we approach science. The first wave came with the birth of the digital computer, which enabled scientists to numerically simulate their models and analyze massive datasets. This technological breakthrough led to the emergence of many sub-disciplines bearing the prefix "computational" in their names. Currently, we are in the midst of the second wave, marked by the remarkable advancements in artificial intelligence. From predicting protein structures to classifying galaxies, the scope of its applications is vast, and there can only be more awaiting us on the horizon.
  While these two waves influence scientific methodology at the instrumental level, in this dissertation, I will present the computational lens in science, aiming at the conceptual level. Specifically, the central thesis posits that computation serves as a convenient and mechanistic language for understanding and analyzing information processing systems, offering the advantages of composability and modularity.
  This dissertation begins with an illustration of the blueprint of the computational lens, supported by a review of relevant previous work. Subsequently, I will present my own works in quantum physics and neuroscience as concrete examples. In the concluding chapter, I will contemplate the potential of applying the computational lens across various scientific fields, in a way that can provide significant domain insights, and discuss potential future directions.
<div id='section'>Paperid: <span id='pid'>1478, <a href='https://arxiv.org/pdf/2310.10395.pdf' target='_blank'>https://arxiv.org/pdf/2310.10395.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elizabeth Munch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.10395">An Invitation to the Euler Characteristic Transform</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Euler characteristic transform (ECT) is a simple to define yet powerful representation of shape. The idea is to encode an embedded shape using sub-level sets of a a function defined based on a given direction, and then returning the Euler characteristics of these sublevel sets. Because the ECT has been shown to be injective on the space of embedded simplicial complexes, it has been used for applications spanning a range of disciplines, including plant morphology and protein structural analysis. In this survey article, we present a comprehensive overview of the Euler characteristic transform, highlighting the main idea on a simple leaf example, and surveying its its key concepts, theoretical foundations, and available applications.
<div id='section'>Paperid: <span id='pid'>1479, <a href='https://arxiv.org/pdf/2306.17525.pdf' target='_blank'>https://arxiv.org/pdf/2306.17525.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Markus J. Buehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.17525">MeLM, a generative pretrained language modeling framework that solves forward and inverse mechanics problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We report a flexible multi-modal mechanics language model, MeLM, applied to solve various nonlinear forward and inverse problems, that can deal with a set of instructions, numbers and microstructure data. The framework is applied to various examples including bio-inspired hierarchical honeycomb design, carbon nanotube mechanics, and protein unfolding. In spite of the flexible nature of the model-which allows us to easily incorporate diverse materials, scales, and mechanical features-it performs well across disparate forward and inverse tasks. Based on an autoregressive attention-model, MeLM effectively represents a large multi-particle system consisting of hundreds of millions of neurons, where the interaction potentials are discovered through graph-forming self-attention mechanisms that are then used to identify relationships from emergent structures, while taking advantage of synergies discovered in the training data. We show that the model can solve complex degenerate mechanics design problems and determine novel material architectures across a range of hierarchical levels, providing an avenue for materials discovery and analysis. Looking beyond the demonstrations reported in this paper, we discuss other opportunities in applied mechanics and general considerations about the use of large language models in modeling, design, and analysis that can span a broad spectrum of material properties from mechanical, thermal, optical, to electronic.
<div id='section'>Paperid: <span id='pid'>1480, <a href='https://arxiv.org/pdf/2305.04934.pdf' target='_blank'>https://arxiv.org/pdf/2305.04934.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Markus J. Buehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.04934">Generative Pretrained Autoregressive Transformer Graph Neural Network applied to the Analysis and Discovery of Novel Proteins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We report a flexible language-model based deep learning strategy, applied here to solve complex forward and inverse problems in protein modeling, based on an attention neural network that integrates transformer and graph convolutional architectures in a causal multi-headed graph mechanism, to realize a generative pretrained model. The model is applied to predict secondary structure content (per-residue level and overall content), protein solubility, and sequencing tasks. Further trained on inverse tasks, the model is rendered capable of designing proteins with these properties as target features. The model is formulated as a general framework, completely prompt-based, and can be adapted for a variety of downstream tasks. We find that adding additional tasks yields emergent synergies that the model exploits in improving overall performance, beyond what would be possible by training a model on each dataset alone. Case studies are presented to validate the method, yielding protein designs specifically focused on structural proteins, but also exploring the applicability in the design of soluble, antimicrobial biomaterials. While our model is trained to ultimately perform 8 distinct tasks, with available datasets it can be extended to solve additional problems. In a broader sense, this work illustrates a form of multiscale modeling that relates a set of ultimate building blocks (here, byte-level utf8 characters that define the nature of the physical system at hand) to complex output. This materiomic scheme captures complex emergent relationships between universal building block and resulting properties via a synergizing learning capacity to express a set of potentialities embedded in the knowledge used in training, via the interplay of universality and diversity.
<div id='section'>Paperid: <span id='pid'>1481, <a href='https://arxiv.org/pdf/2304.11116.pdf' target='_blank'>https://arxiv.org/pdf/2304.11116.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.11116">Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we aim to develop a large language model (LLM) with the reasoning ability on complex graph data. Currently, LLMs have achieved very impressive performance on various natural language learning tasks, extensions of which have also been applied to study the vision tasks with multi-modal data. However, when it comes to the graph learning tasks, existing LLMs present very serious flaws due to their several inherited weaknesses in performing {multi-step logic reasoning}, {precise mathematical calculation} and {perception about the spatial and temporal factors}.
  To address such challenges, in this paper, we will investigate the principles, methodologies and algorithms to empower existing LLMs with graph reasoning ability, which will have tremendous impacts on the current research of both LLMs and graph learning. Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with prompts augmented by ChatGPT to use external graph reasoning API tools. Specifically, we will investigate to teach Graph-ToolFormer to handle various graph data reasoning tasks in this paper, including both (1) very basic graph data loading and graph property reasoning tasks, ranging from simple graph order and size to the graph diameter and periphery, and (2) more advanced reasoning tasks on real-world graph data, such as bibliographic networks, protein molecules, sequential recommender systems, social networks and knowledge graphs.
<div id='section'>Paperid: <span id='pid'>1482, <a href='https://arxiv.org/pdf/2304.10212.pdf' target='_blank'>https://arxiv.org/pdf/2304.10212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Kopp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10212">The impact of the AI revolution on asset management</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent progress in deep learning, a special form of machine learning, has led to remarkable capabilities machines can now be endowed with: they can read and understand free flowing text, reason and bargain with human counterparts, translate texts between languages, learn how to take decisions to maximize certain outcomes, etc. Today, machines have revolutionized the detection of cancer, the prediction of protein structures, the design of drugs, the control of nuclear fusion reactors etc. Although these capabilities are still in their infancy, it seems clear that their continued refinement and application will result in a technological impact on nearly all social and economic areas of human activity, the likes of which we have not seen before. In this article, I will share my view as to how AI will likely impact asset management in general and I will provide a mental framework that will equip readers with a simple criterion to assess whether and to what degree a given fund really exploits deep learning and whether a large disruption risk from deep learning exist.
<div id='section'>Paperid: <span id='pid'>1483, <a href='https://arxiv.org/pdf/2304.07558.pdf' target='_blank'>https://arxiv.org/pdf/2304.07558.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ella Gale
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.07558">Icospherical Chemical Objects (ICOs) allow for chemical data augmentation and maintain rotational, translation and permutation invariance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dataset augmentation is a common way to deal with small datasets; Chemistry datasets are often small. Spherical convolutional neural networks (SphNNs) and Icosahedral neural networks (IcoNNs) are a type of geometric machine learning algorithm that maintains rotational symmetry. Molecular structure has rotational invariance and is inherently 3-D, and thus we need 3-D encoding methods to input molecular structure into machine learning. In this paper I present Icospherical Chemical Objects (ICOs) that enable the encoding of 3-D data in a rotationally invariant way which works with spherical or icosahedral neural networks and allows for dataset augmentation. I demonstrate the ICO featurisation method on the following tasks: predicting general molecular properties, predicting solubility of drug like molecules and the protein binding problem and find that ICO and SphNNs perform well on all problems.
<div id='section'>Paperid: <span id='pid'>1484, <a href='https://arxiv.org/pdf/2303.10429.pdf' target='_blank'>https://arxiv.org/pdf/2303.10429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuanjiao Zong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.10429">Protein Sequence Design with Batch Bayesian Optimisation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein sequence design is a challenging problem in protein engineering, which aims to discover novel proteins with useful biological functions. Directed evolution is a widely-used approach for protein sequence design, which mimics the evolution cycle in a laboratory environment and conducts an iterative protocol. However, the burden of laboratory experiments can be reduced by using machine learning approaches to build a surrogate model of the protein landscape and conducting in-silico population selection through model-based fitness prediction. In this paper, we propose a new method based on Batch Bayesian Optimization (Batch BO), a well-established optimization method, for protein sequence design. By incorporating Batch BO into the directed evolution process, our method is able to make more informed decisions about which sequences to select for artificial evolution, leading to improved performance and faster convergence. We evaluate our method on a suite of in-silico protein sequence design tasks and demonstrate substantial improvement over baseline algorithms.
<div id='section'>Paperid: <span id='pid'>1485, <a href='https://arxiv.org/pdf/2303.09683.pdf' target='_blank'>https://arxiv.org/pdf/2303.09683.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Annie Thomas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.09683">Three dimensional chaos game representation of protein sequences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A new three dimensional approach to the chaos game representation of protein sequences is explored in this thesis. The basics of DNA, the synthesis of proteins from DNA, protein structure and functionality and sequence alignment techniques are presented. The mathematical background needed for understanding the chaos game representation and fractal analysis are briefly discussed.
  An account of the existing literature on the chaos game representation of DNA sequences and a detailed account of the chaos game representation of protein sequences in two dimensions with its advantages and limitations are presented. We explore a new three dimensional approach to the chaos game representation of protein sequences (3D-CGR) and study its ability a) to determine protein sequence similarity and differences, b) to study the effect of dinucleotide biases at amino acid level on the 3D-CGR derived protein homology, and c) to identify sequence similarity based on shuffled motifs that could be used for studying protein evolution due to exon shuffling.
<div id='section'>Paperid: <span id='pid'>1486, <a href='https://arxiv.org/pdf/2303.06301.pdf' target='_blank'>https://arxiv.org/pdf/2303.06301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hodaka Yamaji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.06301">On the Number of Maximal Cliques in Two-Dimensional Random Geometric Graphs: Euclidean and Hyperbolic</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Maximal clique enumeration appears in various real-world networks, such as social networks and protein-protein interaction networks for different applications. For general graph inputs, the number of maximal cliques can be up to $3^{|V|/3}$. However, many previous works suggest that the number is much smaller than that on real-world networks, and polynomial-delay algorithms enable us to enumerate them in a realistic-time span. To bridge the gap between the worst case and practice, we consider the number of maximal cliques in two popular models of real-world networks: Euclidean random geometric graphs and hyperbolic random graphs. We show that the number of maximal cliques on Euclidean random geometric graphs is lower and upper bounded by $\exp(Î©(|V|^{1/3}))$ and $\exp(O(|V|^{1/3+Îµ}))$ with high probability for any $Îµ> 0$. For a hyperbolic random graph, we give the bounds of $\exp(Î©(|V|^{(3-Î³)/6}))$ and $\exp(O(|V|^{(3-Î³+Îµ)/6)}))$ where $Î³$ is the power-law degree exponent between 2 and 3.
<div id='section'>Paperid: <span id='pid'>1487, <a href='https://arxiv.org/pdf/2302.10692.pdf' target='_blank'>https://arxiv.org/pdf/2302.10692.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>GrÃ©goire Mialon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10692">On Inductive Biases for Machine Learning in Data Constrained Settings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning with limited data is one of the biggest problems of machine learning. Current approaches to this issue consist in learning general representations from huge amounts of data before fine-tuning the model on a small dataset of interest. While such technique, coined transfer learning, is very effective in domains such as computer vision or natural langage processing, it does not yet solve common problems of deep learning such as model interpretability or the overall need for data. This thesis explores a different answer to the problem of learning expressive models in data constrained settings: instead of relying on big datasets to learn neural networks, we will replace some modules by known functions reflecting the structure of the data. Very often, these functions will be drawn from the rich literature of kernel methods. Indeed, many kernels can reflect the underlying structure of the data, thus sparing learning parameters to some extent. Our approach falls under the hood of "inductive biases", which can be defined as hypothesis on the data at hand restricting the space of models to explore during learning. We demonstrate the effectiveness of this approach in the context of sequences, such as sentences in natural language or protein sequences, and graphs, such as molecules. We also highlight the relationship between our work and recent advances in deep learning. Additionally, we study convex machine learning models. Here, rather than proposing new models, we wonder which proportion of the samples in a dataset is really needed to learn a "good" model. More precisely, we study the problem of safe sample screening, i.e, executing simple tests to discard uninformative samples from a dataset even before fitting a machine learning model, without affecting the optimal model. Such techniques can be used to prune datasets or mine for rare samples.
<div id='section'>Paperid: <span id='pid'>1488, <a href='https://arxiv.org/pdf/2301.01110.pdf' target='_blank'>https://arxiv.org/pdf/2301.01110.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jacob Rast
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.01110">Causal Discovery for Gene Regulatory Network Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biological systems and processes are networks of complex nonlinear regulatory interactions between nucleic acids, proteins, and metabolites. A natural way in which to represent these interaction networks is through the use of a graph. In this formulation, each node represents a nucleic acid, protein, or metabolite and edges represent intermolecular interactions (inhibition, regulation, promotion, coexpression, etc.). In this work, a novel algorithm for the discovery of latent graph structures given experimental data is presented.
<div id='section'>Paperid: <span id='pid'>1489, <a href='https://arxiv.org/pdf/2209.06865.pdf' target='_blank'>https://arxiv.org/pdf/2209.06865.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriele Scheler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.06865">Sketch of a novel approach to a neural model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we lay out a novel model of neuroplasticity in the form of a horizontal-vertical integration model of neural processing. The horizontal plane consists of a network of neurons connected by adaptive transmission links. This fits with standard computational neuroscience approaches. Each individual neuron also has a vertical dimension with internal parameters steering the external membrane-expressed parameters. These determine neural transmission. The vertical system consists of (a) external parameters at the membrane layer, divided into compartments (spines, boutons) (b) internal parameters in the sub-membrane zone and the cytoplasm with its protein signaling network and (c) core parameters in the nucleus for genetic and epigenetic information. In such models, each node (=neuron) in the horizontal network has its own internal memory. Neural transmission and information storage are systematically separated. This is an important conceptual advance over synaptic weight models. We discuss the membrane-based (external) filtering and selection of outside signals for processing. Not every transmission event leaves a trace. We also illustrate the neuron-internal computing strategies from intracellular protein signaling to the nucleus as the core system. We want to show that the individual neuron has an important role in the computation of signals. Many assumptions derived from the synaptic weight adjustment hypothesis of memory may not hold in a real brain. We present the neuron as a self-programming device, rather than passively determined by ongoing input. We believe a new approach to neural modeling will benefit the third wave of AI. Ultimately we strive to build a flexible memory system that processes facts and events automatically.
<div id='section'>Paperid: <span id='pid'>1490, <a href='https://arxiv.org/pdf/2101.00863.pdf' target='_blank'>https://arxiv.org/pdf/2101.00863.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michele Coscia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2101.00863">The Atlas for the Aspiring Network Scientist</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Network science is the field dedicated to the investigation and analysis of complex systems via their representations as networks. We normally model such networks as graphs: sets of nodes connected by sets of edges and a number of node and edge attributes. This deceptively simple object is the starting point of never-ending complexity, due to its ability to represent almost every facet of reality: chemical interactions, protein pathways inside cells, neural connections inside the brain, scientific collaborations, financial relations, citations in art history, just to name a few examples. If we hope to make sense of complex networks, we need to master a large analytic toolbox: graph and probability theory, linear algebra, statistical physics, machine learning, combinatorics, and more.
  This book aims at providing the first access to all these tools. It is intended as an "Atlas", because its interest is not in making you a specialist in using any of these techniques. Rather, after reading this book, you will have a general understanding about the existence and the mechanics of all these approaches. You can use such an understanding as the starting point of your own career in the field of network science. This has been, so far, an interdisciplinary endeavor. The founding fathers of this field come from many different backgrounds: mathematics, sociology, computer science, physics, history, digital humanities, and more. This Atlas is charting your path to be something different from all of that: a pure network scientist.
<div id='section'>Paperid: <span id='pid'>1491, <a href='https://arxiv.org/pdf/1909.05006.pdf' target='_blank'>https://arxiv.org/pdf/1909.05006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sanzo Miyazawa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/1909.05006">Boltzmann machine learning and regularization methods for inferring evolutionary fields and couplings from a multiple sequence alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The inverse Potts problem to infer a Boltzmann distribution for homologous protein sequences from their single-site and pairwise amino acid frequencies recently attracts a great deal of attention in the studies of protein structure and evolution. We study regularization and learning methods and how to tune regularization parameters to correctly infer interactions in Boltzmann machine learning. Using $L_2$ regularization for fields, group $L_1$ for couplings is shown to be very effective for sparse couplings in comparison with $L_2$ and $L_1$. Two regularization parameters are tuned to yield equal values for both the sample and ensemble averages of evolutionary energy. Both averages smoothly change and converge, but their learning profiles are very different between learning methods. The Adam method is modified to make stepsize proportional to the gradient for sparse couplings. It is shown by first inferring interactions from protein sequences and then from Monte Carlo samples that the fields and couplings can be well recovered, but that recovering the pairwise correlations in the resolution of a total energy is harder for the natural proteins than for the protein-like sequences. Selective temperature for folding/structural constrains in protein evolution is also estimated.
